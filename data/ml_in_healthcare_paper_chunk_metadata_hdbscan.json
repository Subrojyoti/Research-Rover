[
    {
        "text": "University of DundeeUnlocking medical leadership’s potentialKeijser, Wouter A. ; Martin, GraemePublished in:BMJ LeaderDOI:10.1136/leader-2019-000136Publication date:2020Document VersionPeer reviewed versionLink to publication in Discovery Research PortalCitation for published version (APA):Keijser, W. A., & Martin, G. (2020). Unlocking medical leadership’s potential: a multilevel virtuous circle? BMJLeader, 4(1), 6-11. https://doi.org/10.1136/leader-2019-000136General rightsCopyright and moral rights for the publications made accessible in Discovery Research Portal are retained by the authors and/or othercopyright owners and it is a condition of accessing publications that users recognise and abide by the legal requirements associated withthese rights. • Users may download and print one copy of any publication from Discovery Research Portal for the purpose of private study or research. • You may not further distribute the material or use it for any profit-making activity or commercial gain. • You may freely distribute the URL identifying the publication in the public portal.Take down policyIf you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediatelyand investigate your claim.Download date: 28. 2020Confidential: For Review OnlyUnlocking Medical Leadership's Potential: A Multi-Level Virtuous Circle?Journal: BMJ LeaderManuscript ID leader-2019-000136.R2Article Type: Original researchDate Submitted by the Author: n/aComplete List of Authors: Keijser, Wouter; Universiteit Twente, Faculty of Behavioral, Management and Social Sciences (BMS) Change Management and Organizational Behaviour (CMOB); DIRMI Institution Foundation, Martin, Graeme; University of Dundee, School of Business Keywords: medical leadership, professionalism, learning organisation, effectiveness, health systemhttps://mc.manuscriptcentral.com/bmjleaderThis article has been accepted for publication following peer review, and the Version of Record can be accessed online at https://doi.org/10.1136/ leader-2019-000136 Keijser, WA & Martin, G 2020, 'Unlocking medical leadership’s potential: a multilevel virtuous circle? ', BMJ Leader, vol. 4, no. 6-11. Confidential: For Review Only1Unlocking Medical Leadership’s Potential: A Multi-Level Virtuous Circle?Wouter A. Keijser MD (corresponding author)Faculty of Behavioral, Management and Social Sciences (BMS) ChangeManagement and Organizational Behavior (CMOB)University Twente, Enschede, The NetherlandsDIRMI Foundation, Utrecht, The NetherlandsPostal Address: Pal Maleterstraat 15, 3573PE Utrecht, the NetherlandsTelephone: +31628541565wouter@keijser.comProf. Graeme Martin, PhDChair of Management and Director of ResearchSchool of BusinessUniversity of DundeeDundee, ScotlandAbstract Medical leadership (ML) has been introduced in many countries, promising to support healthcare services improvement and help further system reform through effective leadership behaviours. This paper provides a conceptual framework to analyse ML’s potential in the context of healthcare’s complex, multi-faceted setting. We identify four interrelated levels of analysis, or domains, that influence ML’s potential to transform healthcare delivery. These are: the healthcare ecosystem domain; the professional domain; the organizational domain; and individual doctor domain. We discuss the tensions between the various actors working in and across these domains and argue that greater multi-level and multi-stakeholder collaborative working in healthcare is necessary to reprofessionalize and transform healthcare ecosystems.Page 1 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only2INTRODUCTIONThe main focus of this paper is to provide a context-specific ‘thinking frame’ that helps doctors and the wider healthcare community to understand medical leadership’s (ML) potential to impact on the scope and pace of change and innovation in different kinds of healthcare systems. ML has emerged over the last decade as a thoughtful attempt to rethink medical professionalism by doctors and their associations and as a major initiative in reforming and improving healthcare service delivery, quality and safety[1]. However, much of ML’s current discourse and practice has focused on individual doctors’ competences, guided by the introduction of various national and regional ML competency frameworks and associated ML training programmes[2, 3, 4]. Although ML can and does contribute to healthcare transformation and system reform[5, 6, 7], we argue its current focus on individual level competences is both limited and limiting because, like traditional leadership theory in general, it risks emphasizing medicine’s ‘muscular individualism’ of competences, traits and behaviours and ‘one-size-fits-all prescriptions for development[8]. We further contend that understanding and realising ML’s potential warrant a more multi-level and context-specific approach that places ML theory and practice in healthcare’s multi-faceted, multi-stakeholder and multi-levelled perspectives.So, building on a short critique of the extant literature and contemporary changes in healthcare, we have developed a framework that can help practitioners understand and assess ML’s potential impact on transforming different kinds of healthcare systems. Here, we distinguish four levels of analyses, which we call ‘domains’ (Figure 1). These domains represent most, if not all, relevant stakeholders, the multitude of formal regulations, processes, social interactions, and the habitual ways-of-working that govern how daily life in healthcare is constituted. We argue ML has to be understood as one key element of a healthcare ecosystem, which we define as a combination of political, economic and cultural institutions in a region that support transformative healthcare outcomes, where interdependent actors and factors are coordinated in such a way as to enable productive healthcare innovation.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 0
    },
    {
        "text": "Moreover, since ML mirrors one of society’s most esteemed profession’s attempts at ‘reprofessionalization’, its future success will depend on other healthcare ecosystem actors’ capacity to reflect on the(ir) current status quo and seek novel and significant ways forward. Our focus is on the region because within nation states, there are considerable differences on how healthcare and its professions are organized, such as the United Kingdom and United States[56]. Therefore, by developing this framework, we hope to contribute to the theory and practice of healthcare Page 2 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only3reform. We proceed by locating our framework in recent changes in healthcare, outline its theoretical foundations, and then discuss its nature and potential for analysing and advancing ML’s promise.BACKGROUND TO THE PROBLEMMedicine’s doctor-centred, hierarchically ordered, professional jurisdictions and primarily monodisciplinary education and enculturation have remained relatively unchanged since the times of Hippocrates of Kos[9, 10]. Accordingly, prototypical identity, status and power arrangements between healthcare professions still characterize much of healthcare’s daily practices[11]. Recently, however, different types of Western healthcare systems are progressively struggling with economic constraints; complex demands of ageing populations; integration of health and social care; implementing information technologies; and more recent innovations such as artificial intelligence[12]. As a consequence, more hybridized forms of healthcare systems have developed, reflecting shifts in patterns of ‘institutional logics’. These logics comprise templates of assumptions, beliefs, rules and practices that guide the interpretations, meanings and actions of various actors in the healthcare field[13, 14, 15]. In healthcare, changes have been triggered by shifting combinations of market, bureaucratic and statist (or political-democratic) logics, which have caused doctors to revisit the traditional medical professional logics that have historically governed national and regional systems of healthcare delivery[15, 16, 17, 18, 56]. Such hybridization, which has led to a questioning of what it means to be a medical professional in increasingly complex healthcare systems, has been an important driving force behind the emergence of doctors’ latest professional guise – that of ‘medical leader’[19]. The ‘promise’ of ML, cloaked in doctors’ emerging role as a ‘leader’, rests in the new non-clinical competencies with which they attempt to answer to growing needs of interdisciplinary (net)working, co-creative innovation and continuous quality improvement[5]. However, doctors are also well-known for their allegiance to professional autonomy, sovereign medical expertise, ‘occupational closure’, and the ‘hidden curriculum’ in educating the profession’s new members[9, 10, 20, 21]. This status quo bias, often found among senior medical professionals, can and does provide significant opposition to hybridization[10].Nevertheless, in theory at least, the emergence of ML has the potential to reform or transform national and regional healthcare ecosystems. But this potential will only be realised if there is a contemporaneous and substantial shifting of the status quo of rules and belief systems of other professions (e.g., allied professionals; healthcare management) and those who regulate and govern healthcare systems and organizations (e.g., policy makers; regulatory Page 3 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only4bodies; boards; professional associations). This seemingly paradoxical and reciprocal ‘stand-off’ is characteristic of the, often puzzling and wicked, challenges that accompany transformational healthcare change. Questions arise, such as: (How) will ML change the nature of our healthcare ecosystems? And, alternatively: (How) can adequate healthcare ecosystem reform instil adequate ML? Our answers to these questions are rooted in the non-linear and unpredictable character of transformational change, which often lies juxtaposed to the more linear and predictable ways of solution-finding that exemplify our bio-medical traditions.Present-day healthcare ecosystems are the product of different combinations of local actors and local political, economic and cultural factors established over many decades, and in some cases, centuries. Thus, the promise of ML in contributing to healthcare ecosystem reform necessitates a multifaceted, historically and contextually-sensitive approach at various levels to enable sustainable change and shifts in professionals’ position and identities[22]. Such reform is also contingent on inter- and intra-system differences, which suggest that one-size-fits-all practices are unlikely to be universally effective. Thus, customizable strategies are probably required to address various local ecosystem contexts. These comprise differences in how healthcare is funded, in the emphasis placed on healthcare domains - e.g., acute care; primary care; mental healthcare; e-health services; public health; and social care - as well as in the differences found among medical specialties. Differences can also be found at the individual level, with doctors exhibiting very different identity motives and personal traits that shape their willingness and ability to accept ecosystem changes[10]. When considering the potential of ML and its development, these distinctions, including those induced by local organizational culture and professional siloes, suggest contextually-specific sets of needs, demands and (re)solutions. Thus, comprehending the concept of ML as a response to contemporary changes in healthcare ecosystems requires more than just scrutinizing one single profession or viewpoint.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 1
    },
    {
        "text": "Steering transformative processes into advantageous directions (including answering the question of ‘How to unlock the potential of ML?’) warrants a deep understanding of local healthcare ecosystem elements and their dynamics, which we now present in our conceptual framework. A CONCEPTUAL FRAMEWORKIn developing a conceptual framework, we attempt to simplify healthcare’s complexity by drawing on Scott’s categorization of organizational life and its links with (re)professionalization[23, 24]. We do so by adopting a representation of four dimensions Page 4 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only5pointing to different levels of analysis. These four domains reflect the fundamental aspects of a healthcare ecosystem, and jointly represent dynamics of the endless sequence of change in the institutional field of healthcare and its professions such as medicine. These domains are: (1) the healthcare ecosystem domain; (2) the professional domain; (3) the organizational domain; and (4) the individual doctor domain (Figure 1). Figure 1 Framework for analysing the potential of medical leadership at various institutional levels***about here***These domains constitute the classifications of various institutional, organizational and professional forces responsible for the (re)creation and sustainment of frames of meaning and professional identities that jointly dictate what happens in daily-life[25]. Furthermore, the conceptual framework encompasses the various (and varying) interdependent actors and factors in a healthcare ecosystem. As we will show, the idea of ML interacts with all four dimensions. In the following paragraphs, we elaborate on our framework by describing the four domains, their interrelatedness and relationship with ML. We conclude with an overview of selected practical tactics and approaches that can further ML, and describe their potential impact, and relevance to the discourse of ML (Table 1).The Healthcare Ecosystem DomainWe propose the Healthcare Ecosystem Domain as our framework’s first and most ‘macro’ level of analysis. In this domain, we argue, more collaborative oriented governance regulations and arrangements are imperative to effective healthcare reform, as well as to unlocking ML’s potential. Experiences from regions that have successfully legislated for large scale reform show this to be a complex and long-term proposition requiring investments and unconventional approaches in (re)engineering at the more ‘macro’ healthcare system-level[50, 51]. To expedite a successful transition from fragmented, siloed and mono-specialist processes towards systems of more flexible and fluid networks, various system-level aspects must be coordinated, such as: legislation; funding structures; accountability regulations; quality schemes; and educational programs. In contrast with changes that follow a one-element-at-a-time implementation approach, such multifaceted realignment of various system-level themes fosters a more Page 5 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only6collective, multi-stakeholder, thus ecosystem-type of reform. Ultimately, an ecosystem-level restructuring also provides a more safe ‘landing strip’ for various healthcare professions, including medicine, in finding a new and more adequate balance between “soft (trust, collaboration) and hard (financial incentives) levers”[52 p:54]. Without such synchronous adaptation of the various elements at the macro-level, existing organizational and professional arrangements will risk a continuation of a status-quo bias and traditional fragmented ways of working[9]. For example, legislating for adequately incentivizing collaborative avenues of change can empower (or, if necessary, oblige) medical, nursing, allied health professions and managers (and their linked regulatory and policy bodies) to co-create related intra- and interprofessional standards, mechanisms, policies and educational schemes in order to sustainably produce innovative ways of working. These effects signify the interrelatedness between the current ecosystem-level domain and the other three domains, which we describe in the next sections.Some regions are investing in forms of intentional collective professional identity ‘re-creation’, for example by implementing planned national clinical leadership programs[5]. Other efforts induce interprofessional collaboration by offering comprehensive and locally tailorable interprofessional teamwork curricula (e.g. Using regional-level endorsed initiatives, governmental agencies encourage local change and institutional entrepreneurship in a non-formative and co-creative way. This also generates and elevates visible ‘hot spots’ experimenting and role-modelling promising new approaches. Moreover, these tactics support (e.g., regional) directorates in gradually introducing well-evidenced interventions that assist local, field-level change ‘champions’, in particular doctors enacting effective ML. Such top-down endorsement of bottom-level ‘proven’ and peer-supported initiatives can be inspirational, in particular to doctors.Lastly, we believe that doctors are better placed than many other actors to play an important role in leading at the healthcare ecosystem level because of their education and training. Their analytic capabilities, combined with knowledge of health, disease, treatment and care-processes, as well as their subjective position in allegiance creation, provide indispensable capabilities for reconstructing ways of working[24 p:28]. However, while having the skill, they may lack the will because their powerful positions and professional socialization can also result in significant status-quo bias decision-making regarding significant reform efforts[10][20].",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 2
    },
    {
        "text": "This discrepancy embodies one of the most wicked of challenges in system transformation[53] and represents a further point of tension between the system and professional domains, to which we now turn.Page 6 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only7The Professional DomainHealthcare’s daily routines are influenced through a continuous establishing and redesigning of professional norms, values, identities and behaviours. These dictate what should happen at healthcare’s frontlines[23]. The ideas and identities held by professionals, which serve as their prescriptive, evaluative and obligatory requirements for professional social interactions and behaviours, are also influenced significantly by their professional structures and associations. Therefore, we use the Professional Domain as our second level of analysis, since it entails professional moral, rights, privileges and responsibilities that form doctors’ daily reality, and comprises how they are educated, enculturated and trained throughout their careers and amidst their peers.Increasingly, interprofessional practice and education are acknowledged as promising new routes towards a new collaborative professionalism[33, 34]. As a consequence, demands for interprofessional practices prompt redesign of formal as well as informal ‘rules of the game’ within and between healthcare professions. This includes anticipatory processes to effectively navigate the shifting of roles and responsibilities between professions[35]. Interdisciplinary healthcare teams, for example, incorporate non-hierarchical and non-linear working in their complex and multi-partner settings, through approaches like inclusive interprofessional sense-making and co-creation[15]. Various elements influencing the wished-for re-embedding of modern interprofessional arrangements that accompany these processes reside in this domain[36].Followership theory, which stresses the relationships between leaders and followers[37], has given rise to more distributed or shared leadership models, resulting in a more inclusive leadership concept affecting all professions[28, 38, 39]. With evidence for interprofessional teamwork as a key-determinant for high quality care on the rise, elements that enhance or impede (shared) leadership’s effectiveness in and across interdisciplinary teams is increasingly regarded as critical[30, 40]. Thus, it is no surprise that recent ML competency frameworks firmly emphasize doctors’ ‘soft’ competencies aimed at collaborating with others, for example in multidisciplinary teams[41]. Inevitably, there is a growing need for new interprofessional principles and arrangements that exceed ancient mono-disciplinary paradigms in healthcare’s education and practice, which have characterized healthcare’s archetypical doctor-nurse dyadic nature for centuries[42]. These changes, we argue, require medical professional bodies in particular, but also policymakers and regulators, educational institutions, healthcare organizations and many other bodies to rethink various aspects of 21st Century’s Page 7 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only8healthcare professionalism for the benefit of their pluriform constituencies and the public at large. These proposed changes demonstrate the relatedness between the Healthcare Ecosystem and Professional Domain as well as our next domain reflecting perspectives of healthcare services delivery: the 24/7 challenge of adequately synthesizing various professional activity that constitutes healthcare, scaffolded by appropriate resourcing and management.The Organizational DomainIn the global pursuit for value-based and integrated care, day-to-day healthcare operations increasingly rely on smooth interdepartmental and organization networking[43]. Also, the quality, timeliness, inclusiveness and safety of contemporary healthcare services are gradually built on more intense interprofessional ‘relational coordination’ (i.e., sharing values; being respectful and trusting; communicating more accurately, frequently and timeously)[44], while the once widely-separated siloes of social care systems, healthcare organizations, and various community-based services are rushing to deliver on their collective responsibility for citizens’ seamless care[43]. This new organizational perspective, focusing on the region where newly-constituted ‘service users’ (rather than patients) live, work and meet with professionals, digitally or physically, requires a divesting of the old ways of working. Here, ML’s explicit focus on more collaborative forms of practice and innovation holds a promise of facilitating such wide-ranging integration. Moreover, doctors are well-positioned as change agents for having “first-hand experience of the work under consideration”, being “trusted by fellow-workers (and patients)” and providing “to the organization of work a flexible, immediate, policy-oriented dynamism and pragmatic adaptability”[45 p:87].However, realizing effective integrated care at an ecosystem level involves dealing with complex transformational change issue and the corresponding “diffuse unreliability, aversion to responsibility, rigid authoritarianism, rule-resistant incompetence and paternalism” associated with it[45 p:87]. A variety of researchers and practitioners have reported on the significance of creating a local receptive context for change as a prerequisite for such reforms[46, 50, 51]. This action decrees wise investments as well as role-modelling effective leadership at all organizational levels, including board, executive, clinical and managerial. Scholars also suggest that organizations and their executives have to devote considerable time and resources for adequate change management and infrastructures to implement new practices[47, 48, 49]. Eventually, organizations, regulators, managers and doctors who consider promoting ML as a cornerstone of forming modern regional care networks, are advised to create learning organizations that “adapt better to rapid environmental change and implement quality Page 8 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only9improvement practices more quickly”[49 p:287].",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 3
    },
    {
        "text": "Incidentally, such transformative settings also provide excellent practice-based learning opportunities, essential to medical and other leadership development: a two-sided sword of organizations’ investments in their ‘social capital’[4, 9, 45]. The overarching aim and corresponding expectation is that contemporary top-down endorsed, middle-management enhanced and bottom-up co-created healthcare transformation will encompass improvement of organizational performances in various hard and soft dimensions[26, 27], which also requires individual doctors to have a strong voice in how they are led and how change is navigated. This focus on voice presages our fourth and last domain.The Individual Doctor DomainThe Individual Doctor Domain echoes Scott’s institutional ‘cultural-cognitive’ dimension of individuals and groups that, often unconsciously, agree upon various social as well as ‘unwritten’ aspects of their institutional life[23]. It is in this domain, that daily reality is reflected; in other words: what actually happens in work life. It is also at this level that doctors are being increasingly challenged to justify their position, status and knowledge sovereignty in healthcare and society. Patients and other stakeholders demand more time and attention, while bureaucratic accountability processes, intensified communication and information exchange within ever expanding interprofessional networks contribute to doctors’ fatigue and burn-out[26, 27]. As a result, doctors have responded variously to these pressures, for example, through opposition, reluctance or willing acceptance to change or by taking up hybrid managerial-clinical functions and, ultimately, by incorporating ML in their professional repertoire of competencies and identities[10, 20]. Thus, growing numbers of doctors participate in ML competency trainings, offered at various stages during their careers [17, 28, 29]. Furthermore, new competency frameworks provide them generic taxonomies and a first generation of ML competency assessment tools supports benchmarking and monitoring of their ML proficiency and development efforts[20, 30].Despite ML’s appealing intentions, however, its emergence is accompanied by various forms of resistance and ambiguity at the individual doctor level. First, ML can generate negative emotions among some doctors, because they doubt the motivations of those peers who occupy or aspire to formal leadership positions[20]. Doctors enacting managerial leadership are sometimes seen as ‘heretics’, ‘crossing lines in the sand’ or going to the ‘dark side’[1, 10]. Additionally, doctors often perceive competency frameworks as utopian, rendering them as super-professionals or as ‘Jacks-of-all-trades’ and deflecting them from their primary role of Page 9 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only10providing patient care[31, p1]. Thirdly, many clinicians see ML education as an unwelcome extra burden onto their already overloaded clinical work as well as obligations in continuous education and revalidation. Finally, ML encourages doctors at times to take a ‘back seat’ or share leadership with other clinical professions[15]. To some doctors these are awkward and unwelcome new propositions, especially among those at later stages in their career[28].Arguably, the design, planning and delivery of ML training, often hosted by professional associations or ‘in house’ by healthcare organizations[3, 4, 6, 32], need to reflect on such contestations. These also need to take into account that generic or one-size-fits-all approaches can be inappropriate at the level of individual doctors. To be effective, ML development activities should be adequately tailored to the perspectives of doctors’ specialties, varying from clinical setting (e.g., geography; payment structure; clinic size; population), medical specialty, career stage, experiential repertoire, to their individual traits and personal needs and interests. Ultimately, the often relatively time-consuming, hence highly-resourced and expensive ML development activities will gain greater legitimacy when well-aligned with the individual, but also when rooted in high levels of regional healthcare ecosystem appropriateness[6, 32]. Therefore, we reason, ML development at the individual doctor level is importantly informed by professional, organizational and ecosystem-level perspectives, illuminated in the preceding sections. *** Table 1 about here ***Page 10 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only11Table 1.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 4
    },
    {
        "text": "Selected practical tactics and approaches in unlocking ML’s potential, their anticipated effects and relevance to MLDomain Tactics and Approaches Effects Relevance to MLIncentivize more interprofessional performance and value-creationCo-creative rethinking and execution of interprofessional arrangementsML enables doctors to effectively co-design and -lead interprofessional practiseLegislate for inter-sectoral and -organizational collaboration in healthcare delivery and professional educationIntentional agency to span old ‘boundaries’ and redesign processes fostering patient-centred careCreation of practice-based ‘spaces’ for ML learningHealthcare EcosystemInduce principles of collaborate governance at all levelsMulti-level and homogeneous regulatory and managerial activities that instigate and sustain change and reformDirect ML’s discourse into profitable directions, in contrast to, for example, re-emergence of ‘medical dominance’Encourage non-medical professions to rethink their professional leadershipMulti-disciplinary contribution to collective ‘clinical leadership’ paradigmMedical profession role-models re-professionalization towards shared leadership-based workingMedical associations focus on renewing medicine’s social ‘contract’ with societyPositioning and empowering medical professionals as ambassadors of transformation Doctors well-positioned to facilitate and uphold (or resist …) changeProfessionalCoincide leadership development of healthcare professions and healthcare managersBridging the clinician-management ‘gap’ and strengthening of wicked problem-solving proficiencyInfusion of non-clinical management perspectives in ML development and vice versaIntegrate ML development in organizational development and quality improvement initiativesMedical engagement enhances success and reduces risk of tribal issuesInterdisciplinary projects provide learning platform for MLInvest in inter-professional education and inter-organizational learning Optimal transition of modern workforce between pre-clinical education and clinical practiceEngraining both doctors’ leadership potential and clinical patient-centred focus in patient-pathwaysOrganizationalInvest in research and development of quality directives relating ML training and certification of coachesContribution to (current thin) body of evidence for effective ML training and absent quality regulations(More) evidence-based ML best practices and educationTailor individual ML development activities to, for example, medical specialty or local organizationAugmenting effectiveness and return-on-investment of (often resource-intensive) ML trainingAvoid unnecessary or inadequate use of clinical time (demotivating physicians)Use ML development portfolioAdequate focus and monitoring of ML development activitiesML integrated in (continuing) medical education Individual doctorStimulate doctors to identify with new medical professionalism and cultivate their most suitable ML stylesDoctors contribute to their best individual abilities as members of organization and team(s)ML is not a ‘Jack-of-all-trades’ concept and is amplified by intrinsic motivation and identity changePage 11 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only12DISCUSSIONWe have argued that doctors can help establish a new discourse of professionalism by role-modelling continuous patient-centeredness, interprofessional value-congruence and allegiance creation[42] and by leading in a co-constructing, inclusive way[28]. More reciprocal interprofessional collaboration can help professions to convene in discussing the abundance of paradoxical issues that characterize current modes of care that see service users as whole people rather than patients to be treated. Despite their historical origins as an elite, sovereign profession with a strong status quo bias, doctors’ extended training and distinct patient-centred views render them capable of understanding and addressing contradictory arguments of clinical and managerial colleagues in shared decision-making and as potential innovators in healthcare ecosystems[10, 54]. This potential for ML to innovate helps counter an over-reliance on bio-medically oriented clinical protocols, policies, managerial enforcements and bureaucracies. Rightly positioned, organised and having identity motives consistent with ecosystem change, doctors who are trained in effective ML could trail-blaze more favourable professional ways of healthcare reform[10,18]. Such ML can produce high degrees of medical engagement, which helps avert the often-disruptive, hence intimidating, changes and tribal reactions that accompany the re-design of interprofessional arrangements and related their logics and jurisdictions. However, doctors also need to be sufficiently supported in rebalancing their extensive patient-focused clinical expertise with such new skills in organizing leadership and improvement in healthcare ecosystems. Therefore, as we have tried to show in our paper, much remains in the hands of others at diverse levels, to facilitate this already overburdened group of medical experts. Ultimately, we contend, unconventional collaboration between the various stakeholders represented in the four domains, can prevent doctors’ new cloak of ML from evolving into an undesirable ‘Trojan horse’ of a professional reclaiming of traditional institutional position, sovereignty and status quo bias.In this paper we extend the scope of ML beyond individual doctors’ training and performance in their relatively new role of ‘leader’[2]. Explaining ML from four different, yet interrelated, viewpoints, we provide a framework that helps explain impediments in healthcare ecosystem reform that often sprout from deeply rooted medical professional embeddedness. Moreover, as we exemplified in Table 1, the framework helps identifying (often less-conventional) ways to mitigate those barriers, for example through collaborative, multi-level and multi-stakeholder approaches that overarch existing principles[52, 55].Page 12 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only13Our framework is not a universalistic recipe: it is intended as a ‘thinking model’ for all healthcare’s stakeholders to distinguish and rethink their individual, vastly changing, positions and enactments amidst their colleagues in local settings and in regard to other related groups or bodies.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 5
    },
    {
        "text": "Central to this framework, we position the recently-emerged concept of leadership of the medical profession, which we find currently trail-blazing by redefining its professional identity[10]. In doing so, we propose medicine could be seen as role-modelling for other professions’ agentic work and stimulating their non-medical colleagues to also courageously start or proceed in exploring their leadership potential. As we have tried to lay out above, those at the highest managerial, political and administrative positions could follow these trails by finding unconventional collaborative ways of governance and management. In return, this could facilitate other actors in the pluralistic field of healthcare, such as educationalists, administrators, legislators, management, directorates, coaches as well as doctors in taking up leadership to co-create well-aligned new ways of providing healthcare to our patients. CONCLUSIONSThe logics that regulate tomorrows’ healthcare are created while we work, re-think and re-create todays’ routines. Attempts to steer this eternal process more deliberately are a difficult as well as a responsible task for all involved in healthcare service delivery, governance and management. We acknowledge that health systems and settings vary greatly, which is why we have used the regionally-focused healthcare ecosystems perspective. In so doing, we hope this paper contributes to reform efforts, for example by using our framework to differentiate between the various elements and stakeholders that reflect healthcare’s complex, systemic nature. Unlocking the potential of ML, alike many other new concepts that arise during times of transformation, requires bold thinking and acting, daring entering new territories and creating new structures. Moving away from “relatively narrow, single-levelled programmatic change strategies”[49 p:282] towards multi-level and multi-stakeholder ecosystem reform, could offer us leverage for wise creations from which our service users will benefit.Acknowledgements: We thank Celeste Wilderom for her comments on earlier drafts of this manuscript. We are also grateful to the Academy of Management for hosting the event that gave birth to this paper. We are also grateful to the events’ co-contributors, Trish Reay, Peter Lees and Jamie Stoller, and the conference’s attendees. Additionally, we thank the Page 13 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only14anonymous BMJ Leader reviewers and our Editor, Amit Nigam, for their valuable suggestions and help during the process of developing this paper.Contributors: WK and GM both conceptualized the framework and drafted the manuscript. Both authors have approved the final version to be published and are accountable for all aspects of the work.Funding: This work was not externally funded.Competing interests: None declared.Patient consent: Not required.Ethics approval: Not required. Provenance and peer review: Not commissioned; externally peer reviewed. Open access: TBD.Page 14 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only15REFERENCES1. Spurgeon P, Clark J, & Ham C. Medical leadership: from the dark side to centre stage. 2017; CRC Press, New York, NY, USA.2. Dath D, Chan M-K, Abbott C. CanMEDS 2015: From Manager to Leader. 2015; Ottawa: The Royal College of Physicians and Surgeons of Canada, Canada.3. Barry E, Grunberg N, Kleber H. Approaches for Curriculum and Assessment in Leader and Leadership Education and Development Programs in American Medical Schools. MedEdPublish 2018;7:23.4. Stoller J. 2019. Developing Physician Leaders: Does it Work? BMJ Leader 2019 (This Issue).5. Sebastian A, Fulop L, Dadich A, Fitzgerald A, Kippist L, & Smyth A. Health LEADS Australia and implications for medical leadership. Leadersh Health Serv 2014;27:355-370. 6. Grady CM, & Hinings CR. Turning the Titanic: physicians as both leaders and managers in healthcare reform. Leadersh Health Serv. 2018. DOI: doi.org/10.1108/LHS-09-2017-0058. 7. Keijser WA, Huq JL, & Reay T. Enacting Medical Leadership to Address Wicked Problems . BMJ Leader 2019 (This Issue).8. Suddaby R, Seidl D, & Le JK. Strategy-as-practice meets neo-institutional theory. Strat Org. 2013;11:329-344.9. Noordegraaf M, Schneider MME, Van Rensen EL, Boselie PPEF. Cultural complementarity: reshaping professional and organizational logics in developing frontline medical leadership. Public Manag Rev 2015;18:1111-1137.10. Martin G, Siebert S, Howieson, WB, et al. How do elite doctors respond to tensions in hybrid healthcare organizations. Ac Man Proceed 2017;1:11574.11. Spyridonidis D, Hendy J, & Barlow J. Understanding hybrid roles: The role of identity processes amongst physicians. Public Adm 2015;93:395-411.12. Coiera E. The fate of medicine in the time of AI. Lancet 2018;392:2331-2332.13. Meyer JW, & Rowan B. Institutionalized organizations: Formal structure as myth and ceremony. AJS 1977;83:340–363.Page 15 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only1614. Thornton PH, & Ocasio W. Institutional logics. In: R. Greenwood R, Oliver C, Sahlin K, & Suddaby R eds. Handbook of organizational institutionalism. 2008; Sage, London, UK, p99-129.15. Reay T, Goodrick E, Casebeer A. Getting leopards to change their spots: Co-creating a new professional role identity. Ac Manag J. 2017;60:1043-1070.16. Kirkpatrick I, Jespersen PK, Dent M, et al. Medicine and Management in a Comparative Perspective: The Cases of England and Denmark. Sociol Health Illn 2009;31:642–58.17. McGivern G, Currie G, Ferlie E, et al. Hybrid Manager-Professionals’ Identity Work: The maintenance and hybridization of medical professionalism in managerial contexts.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 6
    },
    {
        "text": "Publ Admin 2015;93:412-432.18. Kyratsis Y, Atun R, Phillips N, et al. Health Systems In Transition: Professional Identity Work In The Context Of Shifting Institutional Logics. Acad Man J 2017;60:610-641.19. Hartley, K. (2016). Untangling approaches to management and leadership across systems of medical education. BMC health services research, 16(2), 180.20. Martin G, Beech N, MacIntosh, et al. Potential challenges facing distributed leadership in health care: evidence from the UK National Health Service. Sociol Health Illn 2015a;37: 14-29.21. Philibert I, Elsey E, Fleming S, & Razack S. Learning and professional acculturation through work: Examining the clinical learning environment through the sociocultural lens. Med Teach 2019:1-5.22. Keijser WA, Poorthuis M, Tweedie J, et al. Review of determinants of national medical leadership development. BML Leader 2017;1:36-43.23. Scott WR, Institutions and Organizations: Ideas and Interests. 2008; Sage Publications, Los Angeles, CA, USA.24. Reay T, Goodrick E, & Hinings CR. Institutionalization and Professionalization. In Ferlie E, Montgomery K, & Pedersen AR eds. The Oxford Handbook of Health Care Management. 2016; Oxford University Press, Oxford, UK.25. Douglas, M., 1986. How Institutions Think. Swensen, S., Kabcenell, A., & Shanafelt, T. (2016). Physician-organization collaboration reduces physician burnout and promotes engagement: The Mayo Clinic experience. Journal of Healthcare Management, 61(2), 105-127.Page 16 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only1727. Ann Fam Med 2014;12:537-76.28. Martin G, Siebert S, Howieson B & Bushfield S. The changing experience of work of consultants in NHS Scotland. British Medical Association, London, UK. 2015b. Available online at: http://bma.org.uk/working-for-change/negotiating-for-the-profession/bma-consultants-committee/committee/scotland/reinvigorating-local-advisory-structures.29. Lees P, & Armit K. Medical leadership: an evidence-free zone? BMJ Leader 2018;2:52-53.30. Chesluk BJ, Bernabeo E, Hess B, Lynn LA, Reddy and Holmboe ES. A New Tool To Give Hospitalists Feedback To Improve Interprofessional Teamwork And Advance Patient Care. Health Aff 2012;31:2485-2492.31. Ewert B. Focusing on quality care rather than ‘checking boxes’: How to exit the labyrinth of multiple accountabilities in hybrid healthcare arrangements. Publ Admin DOI: ttps://doi.org/10.1111/padm.12556. 32. Turner S, Chan M-K, McKimm J, et al. Discipline-specific competency-based curricula for leadership learning in medical specialty training: A critical review of the literature. Leadersh Health Serv. 2018;31:152-166.33. WHO. World Health Organization. Framework on integrated, people-centred health services. April 2016. Available online at: http://apps.who.int/gb/ebwha/pdf_files/WHA69/A69_39-en.pdf?ua=1&ua=1.34. Egener BE, Mason DJ, McDonald WJ, et al. The charter on professionalism for health care organizations. Acad Med 2017;92:1091.35. Karimi-Shahanjarini A, Shakibazadeh E, Rashidian, et al. Barriers and facilitators to the implementation of doctor-nurse substitution strategies in primary care: a qualitative evidence synthesis. Cochrane DBSyst Rev 2019;(4).36. MacIntosh R, Beech N, & Martin G. Dialogues and dialetics: Limits to clinician–manager interaction in healthcare organizations. So Sci Med 2012;74:332-339.37. Epitropaki O, Kark R, Mainemelis C, & Lord RG. Leadership and followership identity processes: A multilevel review. Leadership Q 2017;28:104-129.Page 17 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only1838. McKimm J, Rankin D, Poole P, et al. Developing medical leadership: a comparative review of approaches in the UK and New Zealand. International J Leadersh Publ Serv 2009;5:10-24.39. Fitzgerald L, Ferlie E, McGivern G, & Buchanan D. Distributed leadership patterns and service improvement: Evidence and argument from English healthcare. Leadership Q 2013:24(1):227-239.40. Gittell JH, Beswick J, Goldmann D, & Wallack SS. Teamwork methods for accountable care: Relational coordination and TeamSTEPPS®. Health Care Manage Rev 2015; 40:116–125.41. DeRue DS, & Ashford SJ. Who will lead and who will follow? A social process of leadership identity construction in organizations. Acad Manag Rev 2010;35:627-647.42. Tweed A, Singfield A, Taylor JRA, et al. Creating allegiance: leading transformational change within the NHS. BMJ Leader 2018;2:110–114.43. Berwick DM, Nolan TW, & Whittington J. The triple aim: care, health, and cost. Health Aff 2008;3:759-769.44. Gittell JH, Godfrey M, & Thistlethwaite J. Interprofessional collaborative practice and relational coordination: Improving healthcare through relationships. J Interprof Care 2013;27:210-213.45. Iliffe S & Manthorpe J. Reshaping common sense: management, power and the allure of medical leadership in England's NHS. Soundings 2018;69(69):80-91.46. Context and action in the transformation of the firm: A Reprise. 2012;49:1304-1328.47. Siebert S, Bushfield S, Martin G. & Howieson WB. Eroding respectability: deprofessionalization through organizational spaces, Work, Employ and Soc. 2018;32330-347.48. Lee TH, Campion EW, Morrissey S, Drazen JM. Leading the transformation of healthcare delivery. N Engl J Med 2015;373:2468-2469.49. Ferlie EB, & Shortell SM. Improving the quality of health care in the United Kingdom and the United States: a framework for change. Milbank Q 2001;79(2):281-315.50. Shearer H, Bradbury E, & Wylie J. Creating the conditions for integrated systems of care: Learning from two large-scale approaches to changing thinking, practice and behaviour in Scotland and North West England. Int J Integr Care 2017;17:1-8.Page 18 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Confidential: For Review Only1951. Schubert I, Siegel A, Graf E, et al. Study protocol for a quasi-experimental claims-based study evaluating 10-year results of the population-based integrated healthcare model ‘Gesundes Kinzigtal’ (Healthy Kinzigtal): the INTEGRAL study. BMJ Open 2018;9. DOI: 10.1136/bmjopen-2018-025945.52.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 7
    },
    {
        "text": "Denis JL, & van Gestel N. Medical doctors in healthcare leadership: theoretical and practical challenges. BMC health serv res 2016;16(2):158.53. Grint K. Wicked problems and clumsy solutions: the role of leadership. In The new public leadership challenge. 2010; Palgrave Macmillan, London, UK p:169-186.54. Huq J-L., Reay T, & Chreim S. Protecting the paradox of interprofessional collaboration. Org Stud 2017;38(3-4):513-538.55. Zietsma C, Lawrence TB. Institutional work in the transformation of an organizational field: The interplay of boundary work and practice work. Adm Sci Q. 2010;55(2):189–221.56. Bevan, G., Karaikolos, M., Exley, J., Nolte, E., Connolly, S., & Mays, N. (2014). The four health systems of the United Kingdom: how do they compare? London: The Health Foundation/ Nuffield Trust. Page 19 of 44https://mc.manuscriptcentral.com/bmjleaderBMJ Leader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 8
    },
    {
        "text": "1, pp.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 9
    },
    {
        "text": "Despite some evidence of its success, such lofty promises remain unfulfilled.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 10
    },
    {
        "text": "Data sharing statement: Not applicable.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 11
    },
    {
        "text": "New York: Syracuse.26.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 12
    },
    {
        "text": "Bodenheimer T & Sinsky C. From Triple to Quadruple Aim: Care of the Patient Requires Care of the Provider.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 13
    },
    {
        "text": "Sixty 69th WH Assembly.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 14
    },
    {
        "text": "A69/39.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 15
    },
    {
        "text": "Pettigrew AM.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 16
    },
    {
        "text": "J Man Stud.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 17
    },
    {
        "text": "The launch of NEJM Catalyst.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 18
    },
    {
        "text": "Or both?",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 19
    },
    {
        "text": "Apr.",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 20
    },
    {
        "text": "TeamSTEPPS[40]).",
        "paperTitle": "Unlocking medical leadership’s potential:a multilevel virtuous circle?",
        "doi": "10.1136/leader-2019-000136",
        "chunk_index_in_doc": 21
    },
    {
        "text": "Privacy-Preserving Scoring of Tree Ensembles: A Novel Framework for AI in Healthcare Kyle Fritchman∗, Keerthanaa Saminathan∗, Rafael Dowsley†, Tyler Hughes‡, Martine De Cock∗,§, Anderson Nascimento∗ and Ankur Teredesai∗,‡ ∗Institute of Technology, University of Washington, Tacoma, Washington, USA Email: kfritchman46@gmail.com, keergs@uw.edu, mdecock@uw.edu, andclay@uw.edu, ankurt@uw.edu †Dept. of Computer Science, Aarhus University, Aarhus, Denmark Email: rafael@cs.au.dk ‡KenSci, Seattle, Washington, USA Email: tyler@kensci.com, ankur@kensci.com §Dept. of Applied Math., Comp. Science and Statistics, Ghent University, Ghent, Belgium Email: martine.decock@ugent.be Abstract—Machine Learning (ML) techniques now impact a wide variety of domains. Highly regulated industries such as healthcare and finance have stringent compliance and data governance policies around data sharing. Advances in secure multiparty computation (SMC) for privacy-preserving machine learning (PPML) can help transform these regulated industries by allowing ML computations over encrypted data with personally identifiable information (PII). Yet very little of SMC-based PPML has been put into practice so far. In this paper we present the very first framework for privacy- preserving classification of tree ensembles with application in healthcare. We first describe the underlying cryptographic protocols that enable a healthcare organization to send en- crypted data securely to a ML scoring service and obtain encrypted class labels without the scoring service actually seeing that input in the clear. We then describe the deployment challenges we solved to integrate these protocols in a cloud based scalable risk-prediction platform with multiple ML models for healthcare AI. Included are system internals, and evaluations of our deployment for supporting physicians to drive better clinical outcomes in an accurate, scalable, and provably secure manner. To the best of our knowledge, this is the first such applied framework with SMC-based privacy- preserving machine learning for healthcare. Keywords-privacy-preserving machine learning; secure mul- tiparty computation; encryption; healthcare; random forest; boosted decision trees I. INTRODUCTION Data-driven applications are economic drivers of growth and are becoming essential in many domains, including healthcare, infrastructure, and public policy. The data in- volved is often very sensitive and personal in nature. The importance of protecting the privacy of individuals in a data science ecosystem where large-scale collection and processing are commonplace is central to achieving trans- formational impact. The need to protect personal privacy in the “era of big data”, and the potential to do so successfully in the future, with techniques that allow computation over encrypted data, are widely acknowledged [1], [2]. Industries like healthcare and finance are highly regulated when it comes to data ownership, use and data sharing for analytics. These regulations are always evolving. Organiza- tions that are tasked with custody of personal information, be it patient health or other data, are skeptical of their ability to engage in machine learning (ML), partly due to lack of clarity on policies governing use of such data, and partly due to the fear of unknowingly violating the privacy of individuals that may occur in the process of mining such information [3], [4]. The kind of privacy- preserving machine learning (PPML) solution we offer in this paper can help policy makers understand and explain the potential of ML over encrypted data, and how it may inform future evolution of such regulation. The use of PPML will enable organizations to decrease liability because they will be able to provide ML services over encrypted data, without requiring individuals to expose their personal data to anyone. In many ML applications, one party – such as a health system or an insurer or a third party cloud platform – possesses a trained ML model, and the need or desire arises to make predictions with that ML model for an input that is held by a second party, which could be a customer or a patient. One such example is a physician using a prediction model to estimate the risk of 30-day hospital readmission of a patient [5], [6]. The problem that we address in this paper is how to classify the second party’s input with the first party’s classifier such that, at the end of the interaction, the second party is still the only one who knows what their input looks like, and the first party is still the only one who knows what the classifier looks like. To this end, we use techniques from secure multiparty computation (SMC), an umbrella term for cryptographic approaches that allow two or more parties to jointly com- pute a specified output from their private information in a distributed fashion, without actually revealing the private information to each other [7]. In particular, we work with secret sharing based solutions in which the parties share their information using a linear secret sharing scheme. Next, operations are performed by the parties over the shares till the desired outcome is obtained. The final result can be recovered by combining the final shares, and disclosed as intended, i.e. to one of the parties or to both.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 0
    },
    {
        "text": "While SMC has been hailed as a potential solution to enable PPML [2], [8], very little of it has been put into practice so far [9]. Part of this is due to the fact that while in theory any function can be evaluated on private information from different parties using a secure function evaluation protocol (SFE), the use of conventional SFE protocols typically results in an increase of computation time by up to several orders of magnitude. To enable PPML, domain specific customized SMC techniques need to be developed and implemented. In this paper we describe (1) how we successfully de- signed such cryptographic protocols for privacy-preserving classification with tree ensembles [10] – random forests (RFs) and boosted decision trees (boosted DTs) – and (2) how we integrated them in the KenSci ML platform for predicting clinical outcomes of patients. The large majority of the economic value created by AI today stems from supervised learning applications [11]. Within supervised learning, RFs and boosted DTs are among the most common algorithms of choice for data scientists across the world, because of their wide applicability and their state-of-the-art performance. Our focus on tree ensem- bles is therefore intentional: to create a widespread impact on applied ML use-cases that are prevalent today. Acknowl- edging that deployment of PPML solutions requires a non- trivial effort, we describe how the SMC based retooling of the KenSci ML platform required us to rework the KenSci data science workflow. The secure prediction environment has been developed in collaboration with expert physicians at KenSci who currently work with many of the large healthcare systems in the U.S., Europe, and Asia. Our system produces the same precision (hit rate) compared to non- encrypted in-the-clear models, while preserving the privacy of patient records and trained machine learning models. Widespread adoption of solutions such as one presented in this paper will have a significant impact on health outcomes and public policy, and enable global health systems to transition to cloud-based ML systems. II. RELATED WORK SMC based Machine Learning. A significant body of work in PPML with SMC has focused on the problem of privacy-preserving training of machine learning models (see, e.g., [12], [13], [14], [15], [16] and references therein). Privacy-preserving protocols for predicting with trained ML classifiers – hereafter also referred to as “scoring” – has received far less attention. Non-application specific protocols were designed just lately. Bost et al. [17] introduced privacy- preserving protocols for hyperplane-based, Naive Bayes and DT classifiers, Wu et al. [18] for DTs and RFs, David et al. [19] for hyperplane-based and Naive Bayes classifiers, and De Cock et al. [20] for DTs and hyperplane-based classifiers. De Hoogh et al. [14] had also previously presented a proto- col for privacy-preserving scoring of DTs with categorical attributes. The protocol for privacy-preserving scoring of DTs of De Cock et al. [20] cannot be directly used as a building block to obtain random forests and boosted decision trees. We present in Section III a modified protocol for scoring decision trees that does the job. Regarding tree ensembles, to the best of our knowledge, no protocols have been proposed in the literature for privacy- preserving scoring with boosted DTs. The protocol of Wu et al. [18] for privacy-preserving scoring of RFs relies on an original comparison protocol based on the Paillier encryption scheme and on an oblivious transfer scheme. Both of these building blocks involve expensive public-key cryptography operations. Our solution, on the other hand, only uses additions and multiplications over a finite ring in the online phase. Differential Privacy. Most work and results concerning privacy-preserving data mining are based on differential privacy (DP), a field in cryptography that aims to maximize the accuracy of answers to queries from databases while minimizing the chances of identifying its records. Before releasing statistics of a dataset, noise is added to prevent an adversary from learning information about any particular individual in the dataset from the aggregate statistics [21]. While DP has been proven very useful in ensuring the privacy of information in data, the need to address privacy risks at the level of computations that manipulate data, and the potential of SMC as a suitable technique for this, have recently been acknowledged [1]. The aim of DP in an ML setting is protecting the privacy of information in the dataset used during training, whereas the focus in this paper is on the use of SMC to protect the trained model and the privacy of new user data that is classified with the model. Deployed SMC systems for PPML. In contrast to DP, SMC has come to the attention of the data mining and knowledge discovery community only fairly recently, and deployed prototypes are still few and far between.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 1
    },
    {
        "text": "Notewor- thy are the endeavors of the ICT company Cybernetica who developed the SMC platform Sharemind, and deployed it in privacy-preserving applications for statistical analysis and fraud detection based on tax records in Estonia [22], [23]. As far as we are aware, there are no deployed SMC based systems yet for privacy-preserving training of ML models, nor for scoring, as we present in this paper. Model Extraction Attacks. In the system that we present in this paper, we classify one party’s input with another party’s classifier. At the end of the interaction, the party with the classifier will not have learned anything about the other party’s input, and the party with the input will not have learned anything about the other party’s classifier (other than the depth of the decision trees, see Section III). At that point, the output of the classification (class label) is typically disclosed to the party who gave the input, and this class label in itself can leak information about the model. It has been shown that popular ML model classes like logistic regression, neural networks, and DTs are vulnerable to model inversion attacks [24] and model extraction attacks [25]. In a model inversion attack, an adversary who has black-box query access to the model uses the revealed labels and the associated confidence scores of the classifier to uncover information about individuals in the training data. In a model extraction attack, an adversary uses the same kind of information to reverse engineer the model. Model ensembles, such as the tree ensembles that we use in this paper, are suspected to be more resilient to such extraction attacks, because their output is an aggregate of a number of individual models [25]. Nevertheless, some countermeasures may be needed to prevent a model inversion or model extraction attack, which is beyond the scope of the current paper. Regardless, it should be clear that (1) the SMC solution presented in this paper computes the class label in a fully secure manner; (2) only the label that is revealed to the party with the input after the secure computation might leak some information about the classifier; (3) the party with the classifier does not learn anything about the input of the other party at any point. The privacy of the patient or user who is using the ML scoring service is thus fully protected, even if the trained ML model becomes subject to a model inversion or a model extraction attack. III. CRYPTOGRAPHIC PROTOCOLS A. Problem Description In many ML applications, one party – such as a hospital or an insurance company – possesses a trained ML model, and the need or desire arises to make predictions with that model for an input that is held by a second party, which could be a customer or a patient. Using terminology common in cryptography, we will henceforth refer to the first party as Alice, and the second party as Bob. A commonly adopted approach is for Bob (the user) to give his input to Alice (the company), so that Alice can classify the input and return the predicted class label to Bob and/or follow up with actions derived from the knowledge of the class label. Typical examples are a Netflix customer who discloses his preferences in the form of ratings, in return for personal- ized movie recommendations; a user uploading a photo on Microsoft’s how-old.net to get an estimate of the age of the people in the photo; and a healthcare provider using a clinical outcome prediction tool to estimate the risk of 30- day hospital readmission of a patient. In all these cases, the information of the customer, user, or patient (Bob) is fully disclosed to the first party (Alice) holding the machine learning model. The problem that we address in this paper is how to classify the input held by Bob with the classifier held by Alice in such a way that no one, including Alice, learns Bob’s input. A straightforward solution that might come to mind is for Alice to give her classifier to Bob, so that Bob can classify his input locally on his own machine. While this approach would protect Bob’s privacy, it is in many cases not a viable solution because it violates Alice’s privacy: trained ML models are often proprietary and need to be kept secret in order for the company not loose an important competitive advantage [26]. The challenge faced is therefore how to classify Bob’s input with Alice’s classifier such that, at the end of the interaction, Bob is still the only one who knows what his input looks like, and Alice is still the only one who knows what her classifier looks like.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 2
    },
    {
        "text": "In Section III-D we present a cryptographic protocol for solving the problem above in the case when the classifier is a random forest (RF) or a boosted decision trees (boosted DTs) model. We consider honest-but-curious, static adver- saries, like other privacy-preserving classification protocols so far. A static adversary chooses the set of corrupted parties before the protocol execution. An honest-but-curious adversary follows the instructions of the protocol, but tries to gather additional information. We use as a building block an adaptation of the protocol for privacy-preserving scoring of DTs of De Cock et al. [20], which we recall in Section III-C, after presenting preliminaries about the security model in Section III-B. B. Cryptographic Preliminaries and Building Blocks Security Model: We consider the security of our pro- tocols in the Universal Composability (UC) framework [7], [27] due to the fact that this framework considers the security of the protocols under arbitrary composition (i.e., multiple copies of the protocol can be run concurrently to themselves and to other protocols), which covers environments like the Internet. It is the default model for considering the security of cryptographic protocols nowadays. The UC composition theorem ensures that a protocol that is proven UC-secure can be securely executed in such environments. Additionally, the UC framework allows the modular design of complex protocols. A version of the UC composition theorem for the setting with honest-but-curious, static adversaries, is given by Cramer et. al. [7, Theorem 4.20]. Commodity-based Model: The commodity-based model [28] is a setup assumption about the existence of a trusted initializer that pre-distributes correlated randomness during an initialization phase (which can happen far before the protocol execution, even before knowing the inputs) to the parties participating in the protocol. The trusted initializer is not involved in any other part of the execution and does not learn any input from the parties. The main advantage of this model is that it enables very efficient solutions with unconditional security. The commodity-based model allows the realization of non-trivial functionality in the UC framework and has already been used to get very efficient secure computation protocols for tasks such as computing inner-products [29], [30] and other linear algebra operations [31], string equality [30], set intersection [30], oblivious polynomial evaluation [32] and verifiable secret sharing [33]. It was used in protocols for PPML [15], [19], [20]. In practice, this correlated randomness can be distributed by: (1) a single trusted server, (2) many not completely trusted servers (only a majority of honest servers is necessary [28]), or (3) pre-computed by the parties in an offline phase using an SMC protocol to emulate the trusted initializer (in this case the advantage is in offloading the heavy computation to be run at any idle time). Secret Sharing: We perform SMC using additively secret sharings to do computations modulo q. A value x is secret shared over Zq = {0, 1, . , q − 1} between two parties Alice and Bob by picking xA, xB ∈ Zq uniformly at random subject to the constraint that x = xA+xB mod q, and then revealing xA to Alice and xB to Bob. This secret sharing will be denoted by JxK q , which can be thought of as a shorthand for (xA, xB). Notice that from the point of view of Alice (resp., of Bob), no information about x is revealed by xA (resp., by xB). A secret shared value x can be revealed to one party by sending him the share of the other party. Building Blocks: We use as a building block Beaver’s protocol [34] for multiplication of numbers, denoted by piDM . If two parties Alice and Bob each have shares xA, yA, xB , and yB of numbers x and y, then they can follow protocol piDM to compute shares zA and zB of z = x · y. We also use the protocol piDC for performing secure distributed bitwise comparison due to Garay et al. [35] with secret sharings in the field Z2. In this case, Alice and Bob have bitwise shares of two numbers x and y, which are expressed as bit strings of length l, and they follow the protocol to determine whether x ≥ y. piDC outputs a secret sharing of 1 if x ≥ y and of 0 otherwise. Finally we use the protocols for oblivious input selection piOIS and for secure argmax piargmax of De Cock et al. [20]. In the case of piOIS , Alice has as input a vector of values, x = (x1, . , xn), in which each value is expressed as a bit string of length l. Bob has as input k, the index of the desired input value xk.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 3
    },
    {
        "text": "At the end of the protocol, Alice and Bob have a secret sharing of zi over Z2, for i = 1, . , l, which are the bits that make up xk. Bob has not learned any of the values of Alice’s vector x, and Alice has not learned which index k Bob was interested in. In the case of piargmax, Alice and Bob have as input bitwise shares of m values that need to be compared. At the end of the protocol, they have a secret sharing of the index of the largest value. For the proof that these protocols are correct and UC-secure against honest-but-curious adversaries in the commodity-based model, and for the description of opti- mizations of these protocols (and also for more details), we refer to [20], [36]. We use the same fixed-point representa- tion of Catrina and Saxena [37] to deal with real numbers (i.e., fixed-point precision real numbers are mapped into integers). C. Decision Trees For privacy-preserving scoring with decision trees, we propose a novel protocol that improves the method proposed in [20]. In [20], Bob has an input feature vector x = (x1, . , xn) ∈ Rn and Alice has a single decision tree used to classify Bob’s feature vector. At the end of the privacy- preserving scoring protocol in [20], the inferred class label is opened to Bob. The case that we consider in this paper is more general: instead of a single decision tree, Alice has an ensemble of decision trees, that have each been trained to output probabilities associated with the class labels (as opposed to only the class labels themselves, as in [20]). Bob should not learn the class label inferred by each individual tree from the ensemble for his input, or their probabilities; only the aggregated result should be disclosed to Bob (see Section III-D). The privacy-preserving scoring protocol piDT for DTs from [20] cannot be directly used in that scenario. We propose a new protocol for scoring decision trees that is different from the one in [20] in two ways: (1) at the end of piDT the output is not opened towards Bob, but instead it is kept as a secret sharing to perform further computations; and (2) instead of having a category associated with each leaf node of the decision tree, we have a probability vector over the class labels, i.e. a class distribution, associated with each leaf node. By using the novel protocol as a building block, we can them obtain privacy preserving scoring of random forests and boosted decision trees. As stated above, Bob has as input his feature vector x = (x1, . , xn) ∈ Rn. Alice has an ensemble of decision trees, in which each tree is a model D = (d,G,H,w), where d is the depth of the tree, G maps the leaves to the class output ci, i = 1, · · · , k. Each class output is associated with a class distribution. H maps branch nodes (always considered in level-order) to input features and w is a vector of thresholds. An example of a DT of depth d = 3 is depicted in Figure 1. It is assumed without loss of generality that the binary tree is full, i.e. that it contains all 2d − 1 internal nodes (branch nodes) and 2d leaf nodes. A decision tree can always be filled with dummy nodes to make it full. To this end, a leaf that occurs at level s < d is expanded into a subtree of depth d−s in which all the leaves are copies of the original leaf, and the branch nodes contain a new dummy feature with a randomly chosen threshold. Note that this can be done offline by Alice, before she engages in any privacy- preserving scoring protocol. Each branch node of a decision tree tests the value of x2 ≥ w1 x1 ≥ w3 x3 ≥ w7 c1 : 0.2 c2 : 0.7 c3 : 0.1 c1 : 0.2 c2 : 0.2 c3 : 0.6 z7 = 1 z7 = 0 x4 ≥ w6 c1 : 0.1 c2 : 0.0 c3 : 0.9 c1 : 0.0 c2 : 0.6 c3 : 0.4 z6 = 1 z6 = 0 z3 = 1 z3 = 0 x3 ≥ w2 x2 ≥ w5 c1 : 0.1 c2 : 0.8 c3 : 0.1 c1 : 0.9 c2 : 0.1 c3 : 0.0 z5 = 1 z5 = 0 x1 ≥ w4 c1 : 0.1 c2 : 0.7 c3 : 0.2 c1 : 0.8 c2 : 0.2 c3 : 0.0 z4 = 1 z4 = 0 z2 = 1 z2 = 0 z1 = 1 z1 = 0 Figure 1.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 4
    },
    {
        "text": "Example of a decision tree of depth d = 3 for a classification problem with three classes c1, c2 and c3. Secure Decision Tree Protocol piDT Alice has as input a decision tree model D = (d,G,H,w) and Bob has a feature vector x. Alice and Bob proceed as follows: 1) For i = 1, . , 2d−1, Alice and Bob obtain bitwise secret sharings of xH(i) by using piOIS with inputs x1, · · · , xn from Bob and input H(i) from Alice. 2) Let [pD(c1), pD(c2), . , pD(ck)] be a class distribution vector in which pD(ci) is the probability that x belongs to class ci according to decision tree D. There will be one class distribution vector per possible output of the tree. 3) Alice multiplies the probabilities in the leaf nodes of each decision tree D by a confidence factor α offline. Alice them maps these real numbers as integers according to the procedure in [20] and bit-wise shares the resulting weighted probability vectors pi = [α · pD(c1), α · pD(c2), . , α · pD(ck)] with Bob, for i = 1, . , 2d − 1. 4) For i = 1, . , 2d − 1, Alice and Bob securely compare xH(i) and wi. For the input wi, Alice inputs its bit representation and Bob inputs zeros. Let JziK2 denote the result. 5) For j = 0, . , 2d − 1, let jd . j1 be the binary representation of j with d bits and let bk . b1 be the one-hot encoding of G(j + 1)− 1. For r = 1, . , k, initialize Jyj,rK2 with the shares (0, br). Initialize u = 1 and s = d. While s > 0 do: a) For r = 1, . , k, Jyj,rK2 ← Jyj,rK2(JzuK2 + js). b) Update u← 2u+ js and s← s− 1. 6) For all r = 1, . , k compute JσrK2 ←∑2d−1j=0 Jyj,rK2 7) Alice and Bob secure compute qi = [σ1 ·α·pD(c1), σ2 ·α·pD(c2), . , σk ·α·pD(ck)] with Bob, for i = 1, . , 2d−1 by using piDM . Alice and Bob securely add all the resulting vectors qi component-wise producing the secret sharingJpK 2 of the weighted probability vector p, the desired output. Figure 2. The protocol for secure scoring of a decision tree a particular feature xH(i) against a specified threshold wi and branches according to the results. Let zi be the Boolean variable denoting the result of the comparison, i.e. zi = 1 if xH(i) ≥ wi, and zi = 0 otherwise. Each leaf node specifies a probability distribution over the k possible classes c1, . The classification algorithm for a stand-alone decision tree proceeds as follows: • Starting from the root node, for the current branch node vi, evaluate zi. If zi = 1, take the left branch; otherwise, the right branch. • When a leaf node is reached, output G(j), where j is the index of the leaf, and G(j) the class distribution corresponding to that leaf, and terminate. Inspired by the ideas of Bost et al. [17], we per- form inference with a decision tree D by evaluating a polynomial PD: {0, 1}2d−1→{1, . , 2d}. On input z = (z1, . , z2d−1), PD gives the index of the selected leaf level. This polynomial is a sum of terms such that each term corresponds to one possible path in the tree. Given z, the term corresponding to the path taken by x in the tree evaluates to the inference result (i.e., the index of the leaf), while the remaining terms evaluate to zero. Similar as in [20], the idea of the secure protocol piDT for scoring decision trees (see Figure Figure 2) is that, for each branch node, Alice and Bob use the oblivious input selection protocol piOIS to obtain bitwise secret sharings of the value xH(i) that will be compared against the threshold wi of this node. piOIS guarantees that Bob does not learn which feature will be used in the comparison at each branch node, and also that Alice does not learn the values of the features. Then the comparisons are performed using the secure distributed comparison protocol piDC in order to obtain z, which is then used to evaluate the polynomial PD using the secure multiplication protocol piDM and local addition of secret sharings. The only information leaked about the tree structure to Bob is its depth d. The full description of protocol piDT is given in Figure 2. The proof that the decision tree protocol piDT is correct and UC-secure against honest-but-curious adversaries in the commodity- based is simmilar to the one in [20], [36]. D. Tree Ensembles We assume that Alice has an ensemble of decision trees D1, D2, .",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 5
    },
    {
        "text": ", Dm, each with an associated confidence factor or weight α1, α2, . , αm, and Bob wants to classify his input x = (x1, . , xn) with this ensemble. For each tree Dj individually, the inference algorithm produces a class distribution vector [pDj (c1), pDj (c2), . , pDj (ck)] in which pDj (ci) is the probability that x belongs to class ci according to decision tree Dj . To obtain a final classification result, these intermediate results are aggregated as follows: c = arg k max i=1 m∑ j=1 αj · pDj (ci) (1) i.e. the predicted label is that of the class with the highest weighted average of probabilities among the individual decision trees. In the case of random forests, all αj’s are usually 1, while in boosted decision tree models the αj’s can vary, reflecting the confidence in each tree as a correct classifier. Without loss of generality, we can assume that Alice multiplies the probabilities in the leaf nodes of each decision tree Dj with αj offline, before engaging in any computation with Bob. As a result, the outcome of the pro- tocol piDT will be secret sharings of the weighted probability vectors pj = [αj · pDj (c1), αj · pDj (c2), . , αj · pDj (ck)] thereby stripping away the need for computationally more expensive secure multiplications of the tree weights with the class probabilities. Our solution for obtaining this final class label in a privacy-preserving manner then works as follows. First, for each tree Dj in the ensemble we use the protocol piDT for scoring x, obtaining as a result a secret sharing of the weighted probability vector, i.e. the probability vector multiplied by the weight αj of the tree Dj . After that, a secure bitwise addition protocol [38] is used to add these weighted vectors and obtain one accumulator for each of the possible categories (note that these accumulators are still kept as secret sharings). Finally, the secure argmax protocol is executed with these accumulators as input to obtain the most likely category. The full description of protocol piTE is in Figure 3. The security of protocol piTE follows from the UC- security of the building blocks using the UC composition theorem. IV. SYSTEM DESIGN A. The KenSci Platform KenSci has developed a novel healthcare-specific AI plat- form where standardized ML models are used by customers as templates to enable end-to-end solutions for various problems across care management, cost predictions, and operational efficiency in health systems. The design of this platform required KenSci to solve non-traditional ML challenges such as feature standardization for healthcare, data integration across multiple data sources, and setting up cloud-based scalable data pipelines, subject to the constraint that all services need to be compliant with various regulatory standards. Over the years, KenSci has developed many ML models for various use cases, as well as proprietary model orchestration components to be able to score these models at scale on datasets that may contain PHI (protected health information). KenSci also developed innovative ways to ex- pose ML model end-points to backward integrate into health IT systems that are prevalent in the healthcare systems. Figure 4 and 5 present a high level system overview of a KenSci deployment service for model scoring. Both diagrams depict a server (Alice) with a model bank of classifiers, and a client (Bob/Healthcare System) that wishes to risk-stratify and score patient data. The KenSci healthcare AI platform acts as an intermediary. Figure 4 depicts the traditional process where the client’s data is encrypted at- rest, say in a database, at the client side, as well as in- transit to the server’s side. At server side, the data is then decrypted before classification, and a score or class label is generated. This class label or score is then encrypted and returned to the client side, where it is again subsequently decrypted. The next Figure 5 depicts our approach using the cryptographic protocols presented in Section III where the data is kept encrypted during computation as well, in addition to the traditional encryption at-rest (in storage) and in-transit. The fundamental difference between the two approaches in Figure 4 and 5, is that with the approach in Figure 5, the client’s data is never exposed to the ML model server. In-the-clear scoring (Figure 4) can operate without the use of sessions initiated by KenSci between the client and the server; the client can provide all of the required inputs to a traditional model, and receive a score in response. Invocation of the privacy-preserving execution environment as described in Figure 5 requires iterative back-and-forth communication between the client and the server during the scoring operation. To accomplish this, we must guarantee Secure Tree Ensemble Protocol piTE Alice has as input decision tree models D1, .",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 6
    },
    {
        "text": ", Dm, with Dj = (dj , Gj , Hj ,wj), and Bob has a feature vector x. Alice and Bob proceed as follows: 1) For each of the trees D1, . , Dm in the ensemble, use the protocol piDT to obtain a secret sharing JpjK2 of the weighted probability vector pj . 2) Compute JaK 2 ←∑jJpjK2 using a protocol for secure bitwise addition [38]. 3) The secure argmax protocol piargmax is run with the k elements of a as input and Bob obtains the most likely category as output. Figure 3. The protocol for secure scoring of a tree ensemble Figure 4. KenSci ML Platform deployment with “in-the-clear” scoring. Data is encrypted during storage and transit, but decrypted before model scoring. Data and models both reside in the customer’s cloud subscription. Figure 5. KenSci ML Platform deployment with privacy-preserving scoring. Data is encrypted at-rest (in storage), in-transit, and for scoring computations. that the intermediate state about the scoring operation is held on both sides of the connection, and the model bank is built in a way to allow this run-time communication. Our solution uses a session-style approach, pairing a client with a model service in favor of other implementations. We have also designed a solution that maintains the tally of calculations done on the model side in a database store on the model cluster, such that any model server can respond to a client’s request. B. From Standard to Encrypted Model Format As part of our deployment framework we created a capability that allows us to accept any tree-based classifier into the encrypted model bank of the privacy-preserving model execution environment at KenSci. Different adapters were used to convert from native R, Python, or the Predictive Model Markup Language PMML, to the format required by the privacy-preserving model execution environment. These adapters work by iteratively traversing the model’s branches (or multiple trees) to produce a standardized representation. Ultimately, the nature of the model’s tree (nodes and their weights) must be communicated. Once this format has been produced, it can be associated with the appropriate metadata about a model (model identifier, performance characteristics, and so on) and made consumable to clients. Decision trees, random forests and boosted decision tree models are all stored as a TreeModel data structure, repre- sented as a dictionary, and saved as a JSON string. This TreeModel contains a list of the class labels, the input features that the model requires, the weights/confidence of the trees, and a list of the trees themselves. The ‘weights’ field only exists if the model is a boosted decision tree model. The ‘classes’ field is a list of the resulting labels the model can produce. For each tree in the ensemble, TreeModel contains the following properties: • Features: A list of the feature names for each node in the tree, in level-order. For the tree in Figure 1, this list is [x2, x3, x1, x1, x2, x4, x3]. The same feature can occur more than once. The function H(i) returns the index of the input feature for node i, e.g. H(5) = 2. The ith feature corresponds to the ith threshold. There can be duplicate features, but each feature/threshold pair is a unique tuple and generally represents a unique node. Sometimes you may have nodes in different parts of the tree with identical feature/threshold values. We only need to store the tuple once. Let fi represent the feature name of the ith node. Let the function H(i) return the index of the input feature for node i. • Thresholds: A list of the thresholds for each node of the tree. For the tree in Figure 1, this list is [w1, w2, w3, w4, w5, w6, w7]. The ith threshold, denoted by wi, corresponds to the ith feature. There can be duplicate thresholds, but each feature/threshold pair is a unique tuple. Let ti represent the threshold value of the ith node. • Depth: It is an integer that represents the depth of the tree. • Classifiers: An array of arrays where each internal array maps to the leaf of the tree whose nodal path is represented by the corresponding internal array of the ‘polynomial’ field. So the ith array of the ‘classifier’ field is the votes of the leaf attained by the threshold comparison of every node listed in the ith array of the ‘polynomial’ field evaluating to 1. The length of each internal array is the same as the length of the ‘classes’ field in the TreeModel, since each element of the classifier’s internal arrays is that leaf’s vote to the corresponding class. In other words, each internal array corresponds to the probability distri- bution over the class labels in the leaf of a tree. Let classifier[i][c] be the vote for class c from leaf i.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 7
    },
    {
        "text": "For the tree in Figure 1 this array is [[0.8, 0.2, 0.0], [0.1, 0.7, 0.2], [0.9, 0.1, 0.0], [0.1, 0.8, 0.1], [0.0, 0.6, 0.4], [0.1, 0.0, 0.9], [0.2, 0.2, 0.6], [0.2, 0.7, 0.1]]. C. Implementation We now present detailed information about the implemen- tation of our protocol described in Section III-D. 1) Requested model and data are piped into the ClientSide secure multiparty computation DT/RF/ADA evaluator as a json string in the following format: {“cmd” : “score”, “modelName” : “name”, “modelID” : “id”, “data” : {“feature1” : value1, . , “featuren” : valuen}}. The model name and id are model identifiers used to identify exactly which type of model the client is requesting. 2) The ClientSide evaluator sends the ServerSide evaluator the list of variable names in their given order of evaluation: [“feature1”, . , “featuren”] v 3) Score model. If the model is an Adaboost model and has tree confidence values, we multiply these weights into the classifiers of each tree before starting the multiparty computation scoring on data. Each tree can be scored in parallel, but in our current deployments the tree scoring is serial. a) For each tree, the ServerSide evaluator sends the di- mensions of the ‘polynomial’ field to the ClientSide evaluator. This leaks the depth of the tree - the only information that the client ever learns about the model. b) For i = 1, . , 2d−1, the client and the server obtain bitwise secret sharings of xH(i) by executing the protocol piOIS with inputs x1, . ;xn from the client and input H(i) from the server. c) For i = 1, ..., 2d − 1, securely compare xH(i) and wi. For the input wi, the server inputs its bit representation and the client inputs zeros. Let [[zi]]2 denote the result. d) Create a two dimensional array y such that y[i] contains the bitwise shares of the one hot encod- ing of G(i + 1) − 1 for i = 0, . , 2d − 1. For i = 0, . , 2d−1, iteratively multiply every bit in y[i] d times where d is the depth of the tree according to Step 5 in Secure Decision Tree protocol in Figure 2. e) For j = 0, . , 2d − 1, add the bit shares of y[j] as TreeOutput[r] = ∑2d−1 j=0 y[j][r] according to Step 6 in Figure 2. Both the evaluators now hold the shares of the one hot encoding of the output leaf. f) For i = 0, . , 2d − 1, do secure bitwise multi- plication of the i′th bit in the tree output with the bit representation of the weighted probability vectors of (i + 1)′th leaf. Do a bitwise addition of the weighted probability vectors of 2d leaf nodes. The evaluators now hold the bitwise shares of the weighted probability vector corresponding to the tree output. g) When all the trees have been scored and the shares of each final classifier have been calculated, the cor- responding ‘votes’ from each tree are added together via bitwise addition. h) Perform the secure argmax function to select the index k of the highest vote. i) Open k to the client. The client can then get class[k] from the known list of classes. V. PERFORMANCE The overall runtime of the protocol is O(2d · l · log(l)), where l is the bit length used for the feature values, the thresholds in the branch nodes, and the probabilities, and d is the depth of the decision trees. The round complexity, i.e. the number of sequential steps in the protocol (discounting on operations that can be done in parallel) is O(log l). To illustrate the practical runtime performance, we apply the protocol to predict the risk that patients run to get an infection after surgery using tree ensemble models as described in [39]. Each patient is characterized by a vector with 94 features, namely their gender, age, and 92 features derived from blood tests done prior to surgery. The task is to predict whether the patient will develop an infection after surgery or not. Table I shows the time it takes to classify a patient in a privacy-preserving manner with AdaBoost models (ADA) and random forests (RF), with a varying number of trees (10, 50, 100). The predictive accuracy is the same as when classifying without any encryption (i.e. an AUC of around 85%, depending on the model), since the cryptographic protocols perform the same operations as the traditional, unencrypted classification algorithms, thereby obtaining the same class labels. The experiments were run on a 64 bit Linux virtual machine with 72 vCPUs and 144 GB RAM.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 8
    },
    {
        "text": "Table I TIME REQUIRED TO CLASSIFY A PATIENT IN A PRIVACY-PRESERVING MANNER; AVERAGE RUNTIME OVER 3 RUNS Model Number of Trees Depth of Trees Runtime (sec) ADA 10 1 3 ADA 50 1 10 ADA 100 1 19 RF 10 4 18 RF 50 4 84 RF 100 4 160 Each experiment was repeated 3 times, and the average runtime is recorded in Table I. In the ADA models, by default, each of the trees in the trained models is a decision stump, i.e. a tree of depth 1. In RF models, each tree is of depth d = 4. In all models, the number of bits used for the representation of numbers is l = 30. As the experiments show, the runtime grows with the number of trees as well as with the depth of the trees. With an AdaBoost model of 50 trees, which was the best model in [39], it takes approximately 10 sec to make a prediction for a patient in a fully privacy-preserving manner, allowing secure predictions for 360 patients per hour on a single machine. VI. CONCLUSION In this paper we have presented the first secure multiparty computation (SMC) enabled cryptographic protocols for private classification with tree ensembles – random forests and boosted decision trees – and the deployment of our protocols in the KenSci healthcare analytics platform. To the best of our knowledge this is the very first time a SMC-based privacy-preserving machine learning protocol goes live in a real world scenario. Techniques such as the ones here presented are making it increasingly clear that sacrificing privacy for the benefits of Big Data and AI shouldn’t be necessary. From a technological perspective, SMC makes privacy-preserving machine learning possible. The field is still in its infancy, and deployed solutions are few and far between. Our results help bringing this exciting field a step closer to practical use. ACKNOWLEDGMENT Kyle Fritchman was employed at KenSci, Inc. while conducting this work. Rafael Dowsley has received funding from the European Research Council (ERC) under the European Unions’s Horizon 2020 research and innovation programme under grant agreement No 669255 (MPCPRO) and from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 731583 (SODA). REFERENCES [1] C. Dwork and G. J. Pappas, “Privacy in information-rich intelligent infrastructure,” arXiv preprint arXiv:1706.01985, 2017. [2] Commission of Evidence-Based Policymaking, “The promise of evidence-based policymaking,” https: //www.cep.gov/content/dam/cep/report/cep-final-report.pdf, 2017. [3] K. Fiveash, “Google AI given access to health records of 1.6 million english patients,” ArsTechnica, https://arstechnica.com/information-technology/2016/05/ google-deepmind-ai-nhs-data-sharing-controversy/, 2016. [4] Royal Free London NHS, “Google Deepmind data agreement with NHS UK,” https://drive.google.com/file/ d/0BwQ4esYYFC04NFVTRW12TTFFRFE/view, 2016. [5] S. Basu Roy, A. Teredesai, K. Zolfaghar, R. Liu, D. Hazel, S. Newman, and A. Marinez, “Dynamic hierarchical classifi- cation for patient risk-of-readmission,” in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2015, pp. 1691–1700. [6] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, and N. Elhadad, “Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission,” in Pro- ceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2015, pp. 1721– 1730. [7] R. Cramer, I. Damga˚rd, and J. B. Nielsen, Secure Multiparty Computation and Secret Sharing. Cambridge University Press, 2015. [8] R. Wyden, “Wyden pushes for stronger security in collec- tion of personal information,” https://www.wyden.senate.gov/ download/20170515-wyden-mpc-letter-to-cep, 2017. [9] P. Bogetoft, D. L. Christensen, I. Damga˚rd, M. Geisler, T. Jakobsen, M. Krøigaard, J. D. Nielsen, J. B. Nielsen, K. Nielsen, J. Pagter et al., “Secure multiparty computation goes live,” in International Conference on Financial Cryptog- raphy and Data Security. Springer, 2009, pp. 325–343. [10] T. G. Dietterich, “Ensemble methods in machine learning,” in International Workshop on Multiple Classifier Systems, ser. LNCS, vol. 1857. Springer, 2000, pp. 1–15. [11] A. Ng, “The state of artificial intelligence,” MIT Technical Review, https://www.youtube.com/watch?v=NKpuX yzdYs, 2017. [12] C. C. Aggarwal and S. Y. Philip, “A general survey of privacy- preserving data mining models and algorithms,” in Privacy- preserving data mining. Springer, 2008, pp. 11–52. [13] V. Nikolaenko, U. Weinsberg, S. Ioannidis, M. Joye, D. Boneh, and N. Taft, “Privacy-preserving ridge regression on hundreds of millions of records,” in 2013 IEEE Symposium on Security and Privacy. IEEE Computer Society Press, May 2013, pp. 334–348. [14] S. de Hoogh, B. Schoenmakers, P. Chen, and H. op den Akker, “Practical secure decision tree learning in a teletreatment ap- plication,” in FC 2014, ser. LNCS, N. Christin and R. Safavi- Naini, Eds., vol. 8437. Springer, Heidelberg, Mar. 2014, pp. 179–194. [15] M. De Cock, R. Dowsley, A. C. A. Nascimento, and S. C. Newman, “Fast, privacy preserving linear regression over distributed datasets based on pre-distributed data,” in AISec 2015, 2015.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 9
    },
    {
        "text": "[16] C. Clifton, M. Kantarcioglu, J. Vaidya, X. Lin, and M. Y. Zhu, “Tools for privacy preserving distributed data mining,” ACM SIGKDD Explorations Newsletter, vol. 4, no. 2, pp. 28–34, 2002. [17] R. Bost, R. A. Popa, S. Tu, and S. Goldwasser, “Machine learning classification over encrypted data,” in NDSS 2015. The Internet Society, Feb. 2015. [18] D. J. Wu, T. Feng, M. Naehrig, and K. E. Lauter, “Privately evaluating decision trees and random forests,” PoPETs, vol. 2016, no. 4, pp. 335–355, 2016. [19] B. M. David, R. Dowsley, R. Katti, and A. C. A. Nascimento, “Efficient unconditionally secure comparison and privacy pre- serving machine learning classification protocols,” in ProvSec 2015, ser. LNCS, M. H. Au and A. Miyaji, Eds., vol. 9451. Springer, Heidelberg, Nov. 2015, pp. 354–367. [20] M. De Cock, R. Dowsley, C. Horst, R. Katti, A. Nascimento, W.-S. Poon, and S. Truex, “Efficient and private scoring of decision trees, support vector machines and logistic regression models based on pre-computation,” IEEE Transactions on Dependable and Secure Computing, vol. PP, no. 99, 2017. [21] C. Dwork, “Differential privacy: A survey of results,” in In- ternational Conference on Theory and Applications of Models of Computation. Springer, 2008, pp. 1–19. [22] D. Bogdanov, M. Jo˜emets, S. Siim, and M. Vaht, “Privacy-preserving tax fraud detection in the cloud with realistic data volumes,” T-4-24, Cybernetica AS, https://cyber.ee/en/research/, Tech. Rep., 2016. [23] D. Bogdanov, L. Kamm, B. Kubo, R. Rebane, V. Sokk, and R. Talviste, “Students and taxes: a privacy-preserving study using secure computation,” Proceedings on Privacy Enhancing Technologies, vol. 2016, no. 3, pp. 117–135, 2016. [24] M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacks that exploit confidence information and basic coun- termeasures,” in Proceedings of the 22nd ACM SIGSAC Con- ference on Computer and Communications Security, 2015, pp. 1322–1333. [25] F. Trame`r, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Stealing machine learning models via prediction APIs,” in USENIX Security Symposium, 2016, pp. 601–618. [26] G. Ateniese, L. V. Mancini, A. Spognardi, A. Villani, D. Vi- tali, and G. Felici, “Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers,” International Journal of Security and Networks, vol. 10, no. 3, pp. 137–150, 2015. [27] R. Canetti, “Universally composable security: A new paradigm for cryptographic protocols,” in 42nd FOCS. IEEE Computer Society Press, Oct. 2001, pp. 136–145. [28] D. Beaver, “Commodity-based cryptography (extended ab- stract),” in 29th ACM STOC. ACM Press, May 1997, pp. 446–455. [29] R. Dowsley, J. Graaf, D. Marques, and A. C. A. Nascimento, “A two-party protocol with trusted initializer for computing the inner product,” in WISA 10, ser. LNCS, Y. Chung and M. Yung, Eds., vol. 6513. Springer, Heidelberg, Aug. 2011, pp. 337–350. [30] Y. Ishai, E. Kushilevitz, S. Meldgaard, C. Orlandi, and A. Paskin-Cherniavsky, “On the power of correlated ran- domness in secure computation,” in TCC 2013, ser. LNCS, A. Sahai, Ed., vol. 7785. Springer, Heidelberg, Mar. 2013, pp. 600–620. [31] B. David, R. Dowsley, J. van de Graaf, D. Marques, A. C. A. Nascimento, and A. C. B. Pinto, “Unconditionally secure, universally composable privacy preserving linear algebra,” Information Forensics and Security, IEEE Transactions on, vol. 11, no. 1, pp. 59–73, 2016. [32] R. Tonicelli, A. C. A. Nascimento, R. Dowsley, J. Mu¨ller- Quade, H. Imai, G. Hanaoka, and A. Otsuka, “Information- theoretically secure oblivious polynomial evaluation in the commodity-based model,” International Journal of Informa- tion Security, vol. 14, no. 1, pp. 73–84, 2015. [33] R. Dowsley, J. Mu¨ller-Quade, A. Otsuka, G. Hanaoka, H. Imai, and A. C. A. Nascimento, “Universally composable and statistically secure verifiable secret sharing scheme based on pre-distributed data,” IEICE Transactions, vol. 94-A, no. 2, pp. 725–734, 2011. [34] D. Beaver, “Efficient multiparty protocols using circuit ran- domization,” in CRYPTO’91, ser. LNCS, J. Feigenbaum, Ed., vol. 576. Springer, Heidelberg, Aug. 1992, pp. 420–432. [35] J. A. Garay, B. Schoenmakers, and J. Villegas, “Practical and secure solutions for integer comparison,” in PKC 2007, ser. LNCS, T. Okamoto and X. Wang, Eds., vol. 4450. Springer, Heidelberg, Apr. 2007, pp. 330–342. [36] R. Dowsley, “Cryptography based on correlated data: Foun- dations and practice,” Ph.D. dissertation, Karlsruhe Institute of Technology, Germany, 2016. [37] O. Catrina and A. Saxena, “Secure computation with fixed- point numbers,” in FC 2010, ser. LNCS, R. Sion, Ed., vol. 6052. Springer, Heidelberg, Jan. 2010, pp. 35–50. [38] S. J. A. de Hoogh, “Design of large scale applications of secure multiparty computation: Secure linear programming,” Ph.D. dissertation, Technische Universiteit Eindhoven, 2012. [39] P. Mandagani, S. Coleman, A. Zahid, A. Pugel Ehlers, S. Basu Roy, and M. De Cock, “Machine learning models for surgical site infection prediction,” in AMIA KDDM- WG Symposium (American medical Informatics Association Knowledge Discovery and Data Mining Working Group), 2016.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 10
    },
    {
        "text": ". . . . . . . . . . . . . . . . . . . . . . . . .",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 11
    },
    {
        "text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 12
    },
    {
        "text": ", ck.",
        "paperTitle": "Privacy-preserving scoring of tree ensembles : a novel framework for AI in healthcare",
        "doi": "10.1109/bigdata.2018.8622627",
        "chunk_index_in_doc": 13
    },
    {
        "text": "Comput. Comput. Appl. Comput. Comput. SN COMPUT.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 0
    },
    {
        "text": "Machine learning in manufacturing: Advantages, challenges, and applications. Journal of Industrial and Production Engineering 39.5 (2022): 365-380. Journal of Industrial Mechanics 8.2 (2023): 44-53.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 1
    },
    {
        "text": "[17] Parvez, Md Shohel, et al. IRBM, 41(1):58–70, 2020. Medical Archives, 74(1):39, 2020.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 2
    },
    {
        "text": "The gradient boosting classifier attained the highest accuracy of 99.80%. RF and ANN were trained and tested with 10-fold cross-validation, achieving accuracies of 97.12% and 94.5%, respectively. ANN and RF was deployed on CKD datasets having data of 455 instances with 25 features in [53]. The accuracy obtained by RF and ANN was 97.12% and 94.5%, respectively. Highest Precision of 99.11% was achieved using ET and KNN.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 3
    },
    {
        "text": "Table 2 summarizes the performance of some ML models in breast cancer classification. 36, October 2023 14 Table 2: State of art approaches for applying ML in Breast Cancer Classification Ref. Classification of Breast Cancer Malignancy Using Machine Learning Mechanisms in TensorFlow and Keras. A. El-Shair, L. A. Sánchez-Pérez and S. A. Rawashdeh, \"Comparative Study of Machine Learning Algorithms using a Breast Cancer Dataset,\" 2020 IEEE International Conference on Electro Information Technology (EIT), Chicago, IL, USA, 2020, pp. Breast Cancer Prediction: A Comparative Study Using Machine Learning Techniques. Machine Learning Techniques for Breast Cancer Prediction. [66] E. A. Bayrak, P. Kırcı and T. Ensari, \"Comparison of Machine Learning Methods for Breast Cancer Diagnosis,\" 2019 Scientific Meeting on Electrical-Electronics & Biomedical Engineering and Computer Science (EBBT), Istanbul, Turkey, 2019, pp. [67] M. Amrane, S. Oukid, I. Gagaoua and T. Ensarİ, \"Breast cancer classification using machine learning,\" 2018 Electric Electronics, Computer Science, Biomedical Engineerings' Meeting (EBBT), Istanbul, Turkey, 2018, pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 4
    },
    {
        "text": "One prevalent utilization of deep learning in the healthcare field involves the identification and classification of possibly malignant lesions in radiographic images. The utilization of deep learning techniques is becoming more prevalent in the field of radiomics, which involves the identification of diagnostically significant characteristics in imaging data that beyond the capabilities of human visual perception [22]. Radiomics and deep learning are frequently utilized in the domain of oncology-focused image analysis. Machine learning, deep learning, and bio-inspired computing techniques have been applied in medical prognoses, but none has consistently provided accurate results. [22] Fakoor R, Ladhak F, Nazi A, Huber M. Using deep learning to enhance cancer diagnosis and classification. The role of deep learning and radiomic feature extraction in cancer-specific predictive modelling: a review.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 5
    },
    {
        "text": "(2021) combined Long Short-Term Memory (LSTM) with GAN, accurately detecting heart disease patients from the MIT-BIH dataset with up to 99.4% accuracy [47]. These recent developments in GAN-based approaches showcase their potential in improving the accuracy and performance of machine learning models for cardiac disease diagnosis. The integration of GANs with other machine learning techniques holds promise for addressing imbalance-related challenges and achieving high accuracy in predicting heart diseases. [60] Bhattacharya, D.; Banerjee, S.; Bhattacharya, S.; Uma Shankar, B.; Mitra, S. GAN-based novel approach for data augmentation with improved disease classification.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 6
    },
    {
        "text": "The utilization of ML techniques has demonstrated considerable promise in the categorization of dementia, a multifaceted neurological condition that impacts cognitive abilities. By utilizing sophisticated algorithms and computational methodologies, ML models possess the capacity to examine a wide range of data sources and assist in the timely identification, prediction, and tailored therapeutic strategies for individuals affected by dementia. Several researchers already deployed various ML models to classify dementia patient. Table 1 summarizes some ML models deployed in dementia diagnosis.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 7
    },
    {
        "text": "36, October 2023 10 The Significance of Machine Learning in Clinical Disease Diagnosis: A Review S.M. To tackle these challenges, researchers, physicians, and patients are turning to machine learning (ML), an artificial intelligence (AI) discipline, to develop solutions. By leveraging sophisticated ML and AI methods, healthcare stakeholders gain enhanced diagnostic and treatment capabilities. By exploring various ML algorithms used in healthcare applications, the review presents the latest trends and approaches in ML-based disease diagnosis (MLBDD). This review aims to shed light on the prospects of ML in healthcare, particularly in disease diagnosis. INTRODUCTION In the medical field, artificial intelligence (AI) plays a crucial role in developing algorithms and techniques to aid in disease diagnosis. ML has found widespread applications in various fields, from cutting-edge technology to healthcare, including disease diagnosis. In the healthcare sector, patient datasets stored in electronic healthcare records can be leveraged to extract relevant information using ML techniques [8, 9, 10]. These algorithms aid in disease diagnosis by analyzing data and predicting the underlying causes of illnesses based on disease-causing variables extracted from electronic health records [11]. Compared to traditional bio statistical approaches, machine learning has gained popularity for tasks like classification, prediction, and clustering involving complex healthcare data. Overall, the use of ML in healthcare has shown great promise in advancing disease analysis, diagnosis, and treatment, showcasing its potential to transform the field by leveraging vast amounts of data for accurate and efficient healthcare solutions [16-21]. Supervised learning is a fundamental requirement for the bulk of machine learning and precision medicine applications, wherein a training dataset is necessary to possess known outcome variables, such as the beginning of disease. The neural network, a sophisticated variant of machine learning, has been a prominent technology in healthcare research for several decades. Over the years, intelligent healthcare systems have commonly relied on centralized artificial intelligence (AI) capabilities situated in either the cloud or the data center to facilitate the learning and analysis of health data. Furthermore, it is anticipated that in forthcoming healthcare systems, a centralized AI architecture may become less appropriate due to the decentralized nature of health data, which is dispersed across a vast IoMT network. Hence, it is imperative to adopt distributed artificial intelligence (AI) methodologies in order to facilitate the development of scalable and privacy-conscious intelligent healthcare applications at the network edge. ML FOR DIFFERENT DISEASE DIAGNOSIS In recent years, the proliferation of accessible hardware and cloud computing resources has ushered in a significant increase in the application of Machine Learning (ML) across various facets of human life. Among these evolving domains, the healthcare sector stands out as an industry progressively adapting to the potential of ML. The implementation of ML algorithms within healthcare holds tremendous promise due to the substantial data volume amassed for each individual patient. This reservoir of data empowers ML algorithms to proactively chart comprehensive treatment plans for patients, contributing to cost reduction and an enhanced overall patient experience. By analyzing these data repositories, ML algorithms bolster healthcare professionals in predicting forthcoming health issues, thus effectively capitalizing on patients' historical data. The rapid progression of ML technology has catalyzed the paradigm shift towards information-centric healthcare administration and delivery. Contemporary healthcare enhancement strategies, characterized by a multidisciplinary approach, in conjunction with refined imaging and genetics-informed personalized therapeutic models, hinge on the underpinning of ML-powered information systems. As such, Machine Learning is substantiating its role as an indispensable asset poised to drive significant advancements within the healthcare domain. Various ML approaches have gained significant attention from both academics and practitioners in disease diagnosis. This section provides an overview of focusing on the application of ML models in diagnosing various types of diseases. 3.2 Heart Disease Detection Machine learning (ML) approaches have been extensively used by researchers and practitioners to identify cardiac disease [33, 34]. Furthermore, deep learning (DL) algorithms have garnered attention in cardiac disease detection. (2020) compared SVM, Random Forest (RF), Ordinal Regression, Logistic Regression (LR), and Naive Bayes (NB) for heart disease detection, with SVM yielding 95% accuracy [38]. Besides SVM and CNN, other algorithms like ensemble learning [39], k-Nearest Neighbors (kNN) [40], Decision Trees (DT) [41], Linear Discriminant Analysis (LDA) [42], and Bayesian Networks (BN) [43] were also employed in heart disease prediction. Further research in this area is expected to enhance the capabilities of ML models to detect heart disease and contribute to more effective healthcare diagnostics. Despite the wide adoption of ML applications in heart disease diagnosis, there is a lack of research addressing the challenges related to unbalanced data in multiclass classification. Further research is needed to address these issues and improve the transparency and robustness of ML-based cardiac disease detection systems. [55] utilized a dataset of 551 patients and implemented nine distinct machine learning algorithms.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 8
    },
    {
        "text": "CHALLENGES & FUTURE DIRECTIONS ML-based applications have been widely employed in illness detection; nevertheless, the implementation of these applications in healthcare as practical tools presents several problems for researchers and practitioners. The utilization of machine learning models in the development of illness diagnosis models carries the potential for significant harm in the event of misclassification pertaining to a specific disease. One of the primary issues associated with the machine learning (ML) model pertains to its tendency to frequently misidentify a region as diseased, hence leading to erroneous outcomes. CONCLUSION Machine learning has the potential to bring about numerous technological revolutions in the healthcare industry. Machine learning will become increasingly important in healthcare as data volumes increase. Machine learning in healthcare data analysis: A survey. Machine learning in the medical industry. ; Khor, W. Big data and machine learning algorithms for health-care delivery. [11] Garg, A.; Mago, V. Role of machine learning in medical research: A survey. Classification techniques for cardiovascular diseases using supervised machine learning. An exhaustive review of machine and deep learning based diagnosis of heart diseases.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 9
    },
    {
        "text": "Several ML models, including RF, extreme gradient boosting (XGB), LR, elastic net (ElasNet), lasso and ridge regression, k-NN, SVM, and artificial neural network (ANN), were compared for CKD risk prediction. In a separate investigation [49], researchers employed SVM, AdaBoost, LDA, and gradient boosting (GBoost) algorithms to formulate accurate models for CKD prediction, utilizing a dataset from the UCI machine learning repository. In [50], authors concentrated on the CKD dataset, employing LR, Decision Tree (DT), and k-NN algorithms to develop three distinct CKD prediction models. Similarly, another study [51] evaluated Naïve Bayes (NB), RF, and LR models for CKD risk prediction, achieving respective accuracies of 93.9%, 98.88%, and 94.76% on the dataset. Furthermore, in [52], a system for CKD risk prediction was proposed using data from 455 patients and real-time dataset. A machine learning-based model was created in [54] with the aim of predicting chronic kidney disease (CKD) in patients. In [61], a methodology based on supervised learning was presented, focusing on developing efficient models for predicting the risk of chronic kidney disease (CKD) occurrence. Comparison and development of machine learning tools in the prediction of chronic kidney disease progression. ; Shultana, S.; Afrin, S.; Anjum, A.A.; Khan, A.A. Optimization of prediction method of chronic kidney disease using machine learning algorithm. Comparative Analysis for Prediction of Kidney Disease Using Intelligent Machine Learning Methods. [51] CKD Prediction Dataset. ; Keya, S.A.; Tisha, S.A.; Hossain, S. Risk factor prediction of chronic kidney disease based on machine learning algorithms. ; Sakib, N.; Islam, T.; Shahbaaz, M.; Pantho, S.S. Risk prediction of chronic kidney disease using machine learning algorithms. Prediction of chronic kidney disease-a machine learning perspective. [55] J. Xiao, R. Ding, X. Xu, H. Guan, X. Feng, T. Sun, S. Zhu, and Z. Ye, ‘‘Comparison and development of machine learning tools in the prediction of chronic kidney disease progression,’’ J. Transl. B. Naib, ‘‘Chronic kidney disease prediction using machine learning: A new approach,’’ Int. A Deep Prediction of Chronic Kidney Disease by Employing Machine Learning Method. [61] Dritsas, E.; Trigka, M. Machine Learning Techniques for Chronic Kidney Disease Risk Prediction.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 10
    },
    {
        "text": "Sci. Sci. Biosci. SCI.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 11
    },
    {
        "text": "3.1 Dementia Classification Alzheimer's Disease (AD) constitutes the most prevalent form of dementia necessitating extensive medical attention. This progression results in impairments to memory and cognitive abilities, eventually leading to an inability to perform basic tasks. Dementia linked to Alzheimer's manifests in various stages: (a) Mild Cognitive Impairment: Often marked by memory lapses as individuals age, it can also evolve into dementia for some. (b) Mild Dementia: Individuals with mild dementia experience cognitive difficulties that impact their daily routines. Symptoms include memory loss, confusion, personality changes, disorientation, and struggles with routine tasks. (c) Moderate Dementia: This stage involves increased complexity in daily life, requiring additional care and support. Symptoms mirror mild dementia but are more pronounced. (d) Severe Dementia: Symptoms worsen in this phase, with communication impairments and a need for constant care.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 12
    },
    {
        "text": "Med. Med. Med. Methods Med. Med., vol.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 13
    },
    {
        "text": "International Journal of Computer Applications (0975 – 8887) Volume 185 – No. International Journal of Computer Applications (0975 – 8887) Volume 185 – No. Notably, the global relevance of COVID-19 has led to numerous studies International Journal of Computer Applications (0975 – 8887) Volume 185 – No. International Journal of Computer Applications (0975 – 8887) Volume 185 – No. International Journal of Computer Applications (0975 – 8887) Volume 185 – No. IEEE Access 2021, 9, 35501–35513. IEEE Access 2017, 5, 8869–8879. International Journal of Computer Applications (0975 – 8887) Volume 185 – No. In Proceedings of the 2011 World Congress on Information and Communication Technologies, Mumbai, India, 11–14 December 2011; pp. SN Computer Science, 1(6):1–6, 2020. KSII Transactions on Internet and Information Systems (TIIS), 15(7):2304–2320, 2021. In Proceedings of the 2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT), Kharagpur, India, 1–3 July 2020; pp. International Journal of Computer Applications (0975 – 8887) Volume 185 – No. IEEE Access 2021, 9, 17312–17334. In Proceedings of the 2022 6th International Conference on Trends in Electronics and Informatics (ICOEI), Tirunelveli, India, 28–30 April 2022; pp. Procedia Computer Science, 218, 1314-1320.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 14
    },
    {
        "text": "Liu et al. Wang et al. Rath et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 15
    },
    {
        "text": "36, October 2023 11 2. 36, October 2023 15 5. 2021, 40, 100370. 36, October 2023 16 (2023). 2018, 9, 1–11. 2019, 17, 119. 2021, 2021, 6141470. 278–287, May 2018. 2021, 18, 2599–2613.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 16
    },
    {
        "text": "(2020). (2022). (2022). (2021). (2020).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 17
    },
    {
        "text": "; Paul, S.; Chowdhury, A.; Luna, S.A.; Yazdan, M.M.S. [Google Scholar] [7] Sinha, U.; Singh, A.; Sharma, D.K. [8] Wuest, T.; Weimer, D.; Irgens, C.; Thoben, K.D. [12] Yan, Z.; Zhan, Y.; Peng, Z.; Liao, S.; Shinagawa, Y.; Zhang, S.; Metaxas, D.N. [14] Schlemper, J.; Caballero, J.; Hajnal, J.V. [15] Mehta, J.; Majumdar, A. [21] Mondal, M. Rubaiyat Hossain, et al. [23] Vial A, Stirling D, Field M, et al. [25] Nguyen, D. C., Pham, Q. V., Pathirana, P. N., Ding, M., Seneviratne, A., Lin, Z., ... & Hwang, W. J. [26] Bharati, S., Mondal, M. R. H., & Podder, P. (2023). [27] Bharati, S., Mondal, M. R. H., Podder, P., & Kose, U. [28] Bharati, S., Mondal, M., Podder, P., & Prasath, V. B. [29] Bharati, S., Mondal, M. H., Khamparia, A., Mondal, R. H., Podder, P., Bhushan, B. et al. [30] Bharati, S., Podder, P., Mondal, M. R. H., & Paul, P. K. (2021). ; Gupta, N.K. ; Mahmud, M.; Saha, P.K. ; Gupta, K.D. [38] Nan Liu, Zhiping Lin, Jiuwen Cao, Zhixiong Koh, Tongtong Zhang, Guang-Bin Huang, Wee Ser, and Marcus Eng Hock Ong. [39] Devansh Shah, Samir Patel, and Santosh Kumar Bharti. [40] Xuchu Wang, Suiqiang Zhai, and Yanmin Niu. [45] Yilin Wang, Le Sun, and Sudha Subramani. [46] Adyasha Rath, Debahuti Mishra, Ganapati Panda, and Suresh Chandra Satapathy. [48] Xiao, J.; Ding, R.; Xu, X.; Guan, H.; Feng, X.; Sun, T.; Zhu, S.; Ye, Z. [49] Ghosh, P.; Shamrat, F.J.M. ; Tazin, T.; Bourouis, S.; Khan, M.M. ; Akter, S.; Hossen, M.S. 36, October 2023 17 [54] Chittora, P.; Chaurasia, S.; Chakrabarti, P.; Kumawat, G.; Chakrabarti, T.; Leonowicz, Z.; Jasiński, M.; Jasiński, Ł.; Gono, R.; Jasińska, E.; et al. [56] S. Drall, G. S. Drall, S. Singh, and B. ; Pramanik, A.; Rahman, M.S.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 18
    },
    {
        "text": "By analyzing the current literature, the study provides insights into state-of-the-art methodologies and their performance metrics.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 19
    },
    {
        "text": "For instance, a neurofuzzy-integrated system was developed in [33] for detecting heart disease that achieved accuracy of approximately 89%.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 20
    },
    {
        "text": "Yet, the study's primary limitation is the absence of a well-defined clarification regarding the performance of their suggested technique across diverse scenarios like multiclass classification, extensive data analysis, and addressing imbalanced class distribution.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 21
    },
    {
        "text": "Furthermore, there's a notable omission of dialogue regarding the model's trustworthiness and interpretability, a factor progressively vital in medical domains to enhance comprehensibility for non-medical individuals.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 22
    },
    {
        "text": "In [35], researchers introduced a deep CNN to detect irregular cardiac sounds.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 23
    },
    {
        "text": "They optimized the loss function to enhance sensitivity and specificity on the training dataset.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 24
    },
    {
        "text": "This model underwent testing in the 2016 Physio Net computing competition, yielding a final prediction specificity of 95% and sensitivity of 73% [35].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 25
    },
    {
        "text": "Keywords Machine learning (ML), IoMT, healthcare; supervised learning, chronic kidney disease (CKD), convolutional neural networks, adaptive boosting (AdaBoost), COVID-19, deep learning (DL).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 26
    },
    {
        "text": "In [36], a DL-based technique was developed for diagnosing cardiotocographic fetal health based on multiclass morphologic patterns.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 27
    },
    {
        "text": "This model aimed to categorize patterns in individuals with pregnancy complications.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 28
    },
    {
        "text": "Initial computational results displayed an accuracy of 88.02%, precision of 85.01%, and F-score of 85% [36].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 29
    },
    {
        "text": "Overfitting was addressed using various dropout strategies, leading to an increased training time, which they noted as a trade-off for achieving heightened accuracy.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 30
    },
    {
        "text": "(2012) employed Support Vector Machine (SVM) to create predictive systems for cardiac arrest within 72 hours [37].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 31
    },
    {
        "text": "In a Cleveland dataset study, Shah et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 32
    },
    {
        "text": "However, recent studies highlight Generative Adversarial Network (GAN) superiority for both balanced and imbalanced datasets.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 33
    },
    {
        "text": "1.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 34
    },
    {
        "text": "Researchers have introduced GAN-based models [44, 45, 46].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 35
    },
    {
        "text": "(2021) introduced CAB, a GAN-based approach addressing imbalance-related issues, achieving 99.71% accuracy in arrhythmia patients [44].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 36
    },
    {
        "text": "Additionally, most models lack sufficient explain ability during the final prediction, which hampers their understanding and trustworthiness.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 37
    },
    {
        "text": "3.3 Kidney Disease Detection Chronic Kidney Disease (CKD) refers to a condition wherein the kidneys experience damage, leading to an impaired blood filtration process.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 38
    },
    {
        "text": "The kidneys' primary function involves International Journal of Computer Applications (0975 – 8887) Volume 185 – No.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 39
    },
    {
        "text": "36, October 2023 13 extracting excess water and waste from the blood to generate urine.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 40
    },
    {
        "text": "In cases of CKD, the kidneys fail to effectively eliminate waste, resulting in its accumulation within the body.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 41
    },
    {
        "text": "This ailment earns its \"chronic\" status due to the gradual and extended nature of the damage it inflicts over time.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 42
    },
    {
        "text": "CKD stands as a prevalent global health concern, potentially giving rise to various health complications.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 43
    },
    {
        "text": "The origins of CKD are diverse, encompassing factors like diabetes, elevated blood pressure, and heart disease.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 44
    },
    {
        "text": "Firstly, in [48], the authors conducted their research on clinical and blood biochemical measurements from 551 patients with proteinuria.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 45
    },
    {
        "text": "Medical diagnosis entails determining the illness or conditions that account for an individual's symptoms and indicators, usually relying on their medical background and physical assessment.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 46
    },
    {
        "text": "The models ElasNet, lasso, ridge, and LR showed superior predictive performance, achieving a mean AUC and precision above 87% and 80%, respectively.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 47
    },
    {
        "text": "LR ranked first, attaining an AUC of 87.3%, with a recall and specificity of 83% and 82%, respectively.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 48
    },
    {
        "text": "ElasNet achieved the highest recall (0.85), while Extra Gradient Boosting (XGB) demonstrated the highest specificity (0.83).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 49
    },
    {
        "text": "LR exhibited the highest accuracy at 97%, outperforming DT (96.25%) and k-NN (71.25%).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 50
    },
    {
        "text": "However, this process can be challenging as many symptoms are ambiguous and require expertise from trained health professionals.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 51
    },
    {
        "text": "The most significant features were collected using Chi-Square Test.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 52
    },
    {
        "text": "The model's performance was evaluated on two sets of data: one containing all attributes and another containing only selected features.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 53
    },
    {
        "text": "Within the realm of feature selection methods, three common approaches are often employed: Wrapper, Filter, and Embedded.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 54
    },
    {
        "text": "These methods serve the purpose of identifying and selecting the most crucial features for a given task or problem.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 55
    },
    {
        "text": "The model was trained using various machine learning classifiers, including Artificial Neural Networks (ANN), C5.0, Logistic Regression (LR), Linear Support Vector Machine (LSVM), K-Nearest Neighbors (KNN), and Random Forest (RF).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 56
    },
    {
        "text": "Based on the experimental findings, it was observed that the LSVM algorithm attained the maximum level of accuracy, reaching 98.86%, when applied to the SMOTE technique with all features included.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 57
    },
    {
        "text": "SMOTE is widely regarded as an effective method for addressing class imbalance in datasets.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 58
    },
    {
        "text": "This becomes particularly problematic in countries like Bangladesh and India, where there is a scarcity of healthcare professionals, making it difficult to provide proper diagnostic procedures for a large population of patients.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 59
    },
    {
        "text": "The utilization of SMOTE in conjunction with feature selection by LASSO regression yielded superior outcomes compared to the LASSO regression model without the implementation of SMOTE [54].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 60
    },
    {
        "text": "In their study, Xiao et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 61
    },
    {
        "text": "These algorithms included XGBoost, logistic regression, lasso regression, support vector machine, random forest, ridge regression, neural network, Elastic Net, and KNN.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 62
    },
    {
        "text": "The researchers conducted an evaluation of many performance metrics, including accuracy, ROC curve, precision, and recall.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 63
    },
    {
        "text": "The results indicated that the linear model exhibited the highest level of accuracy.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 64
    },
    {
        "text": "Sujata Drall et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 65
    },
    {
        "text": "[56] worked with the UCI-provided CKD dataset containing 400 instances and 25 attributes.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 66
    },
    {
        "text": "First, data was pre-processed, then missing data was identified and replaced with zero, and the dataset was transformed and applied.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 67
    },
    {
        "text": "After pre-processing, the authors employed an algorithm for significant attributes and identified the five most significant features, followed by the classification algorithms Nave Bayes and KNN.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 68
    },
    {
        "text": "Additionally, medical tests required for diagnosis can be expensive and unaffordable for low-income individuals [1-3].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 69
    },
    {
        "text": "The obtained result KNN was the most accurate.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 70
    },
    {
        "text": "Furthermore, a research study [57] employed classifiers such as extra-trees (ET), AdaBoost, KNN, GBoost, XGB, DT, Gaussian Naïve Bayes (NB), and RF.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 71
    },
    {
        "text": "Among them, KNN and Extra Trees classifiers (ET) showed the best performance with accuracies of 99% and 98%, respectively.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 72
    },
    {
        "text": "In addition, ANN-based regression analysis for managing sparse medical datasets was proposed in [58].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 73
    },
    {
        "text": "To improve upon the pre-existing radial basis function (RBF) input-doubling technique, they incorporated new variables into the output signal calculation algorithm.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 74
    },
    {
        "text": "Similarly, in [59], a new input doubling method based on the classical iterative RBF neural network was designed.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 75
    },
    {
        "text": "The highest accuracy of the proposed method was validated by experimenting with a small medical dataset, using Mean Absolute Error and Root Mean Squared Error.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 76
    },
    {
        "text": "In [60], an innovative method for data augmentation with enhanced disease categorization was implemented that was based on generative adversarial networks (GAN).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 77
    },
    {
        "text": "Experiments were conducted on the NIH chest X-ray image dataset, and the test accuracy of CNN model was 60.3%.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 78
    },
    {
        "text": "Due to human error, over diagnosis can occur, leading to unnecessary treatment and negatively impacting both the patient's health and the economy.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 79
    },
    {
        "text": "However, the online GAN-augmented CNN model showed improved performance, achieving a test accuracy of 65.3%.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 80
    },
    {
        "text": "The study mainly concentrated on probabilistic, tree-based, and ensemble learning-based models.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 81
    },
    {
        "text": "Several algorithms were evaluated, including SVM, Logistic Regression (LR), Stochastic Gradient Descent (SGD), Artificial Neural Network (ANN), and k-NN.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 82
    },
    {
        "text": "3.4 Breast Cancer Detection Breast cancer is the leading cancer in females worldwide, caused by abnormal growth of cells in the breast.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 83
    },
    {
        "text": "Various techniques, including breast screening or mammography, have been introduced for accurate diagnosis.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 84
    },
    {
        "text": "Mammography uses X-rays to check the nipple status of women, but early detection of small cancer cells remains challenging.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 85
    },
    {
        "text": "Mammography requires doctors to analyze a large volume of imaging data, reducing accuracy and leading to time-consuming procedures with potential for misdiagnosis.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 86
    },
    {
        "text": "As medical research advances, new systems are being developed for improved breast cancer detection.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 87
    },
    {
        "text": "Reports suggest that a significant number of people experience at least one diagnostic mistake during their lifetime.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 88
    },
    {
        "text": "A denotes Accuracy, P denotes Precision, SP denotes Specificity and Se denotes Sensitivity.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 89
    },
    {
        "text": "Dataset Models A (%) P (%) SP (%) SE (%) [62] WBC SVM - - 92.68% 94.44% LR - - 90.48% 94.37% DT - - 92.31% 91.89% RF - - 94.59% 90.79% DNN - - 91.11% 98.53% [63] WBC NB 93% 90% - 90% LR 97% 100% - 92% [64] WBC SVM 97.14% 95.65% 92.3% 100% KNN 97.14% 97.82% 95.83% 97.82% RF 95.71% 97.77% 95.83% 95.68% LR 95.71% 97.82% 95.65% 95.74% [65] WDBC (569) KNN 96% 93% (B), 100% (M) - 100%, 89% SVM 95% 97%, 92% - 94%, 96% DT 97% 97%, 98% - 99%, 96% NB 90% 92%, 88% - 97%, 89% LR 96% 97%, 96% - 97%, 96% [66] WBC (699) MLP 95.44% 95.4% - 95.4% Voted Perceptron 90.98% 89.9% - 88.2% [67] WBC (699) KNN 97.51% - - - NB 96.19% - - - 4.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 90
    },
    {
        "text": "Even though numerous hospitals and healthcare institutions have collected extensive patient data, the availability of real-world data for worldwide research purposes is limited due to the constraints imposed by data privacy regulations.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 91
    },
    {
        "text": "Often, clinical data is subject to noise or missing values, resulting in a significant time investment required to render such data trainable.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 92
    },
    {
        "text": "The problem of adversarial attack is a significant challenge within the context of illness datasets.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 93
    },
    {
        "text": "Atikur Rahman Department of Industrial, Manufacturing and Systems Engineering University of Texas at El Paso El Paso, TX 79968, USA Sifat Ibtisum Department of Computer Science Missouri University of Science and Technology, Rolla, Missouri Ehsan Bazgir Department of Electrical Engineering San Francisco Bay University Fremont, CA 94539, USA Tumpa Barai Department of CSE European University Bangladesh Dhaka, Bangladesh ABSTRACT The global need for effective disease diagnosis remains substantial, given the complexities of various disease mechanisms and diverse patient symptoms.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 94
    },
    {
        "text": "Several factors contribute to misdiagnosis, including the lack of noticeable symptoms, the presence of rare diseases, and diseases being mistakenly omitted from consideration [4, 5].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 95
    },
    {
        "text": "For example, the misdiagnosis of a patient with stomach cancer as a non-cancer patient can have significant consequences.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 96
    },
    {
        "text": "The majority of machine learning models, including logistic regression (LR), exhibited high levels of performance when trained on labelled data.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 97
    },
    {
        "text": "Nevertheless, the performance of comparable algorithms experienced a notable decrease when exposed to the unlabeled data.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 98
    },
    {
        "text": "However, it should be noted that certain widely-used algorithms, such as K-means clustering, SVM, and K-Nearest Neighbors (KNN), may experience a decline in performance when applied to multidimensional data.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 99
    },
    {
        "text": "The issues discussed in the preceding part may provide valuable insights for future scholars and practitioners, guiding their future endeavors.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 100
    },
    {
        "text": "The utilization of generative adversarial networks (GANs) has gained significant prominence within the realm of deep learning.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 101
    },
    {
        "text": "By employing this methodology, it becomes feasible to produce artificial data that has a striking resemblance to authentic data.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 102
    },
    {
        "text": "Hence, the utilization of GANs could potentially serve as a viable solution for addressing challenges related to limited availability of data.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 103
    },
    {
        "text": "The progression of contemporary technology has facilitated the acquisition of data with high resolutions and multiple attributes.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 104
    },
    {
        "text": "Although the conventional ML approach may not yield satisfactory results when applied to high-quality data, employing a mix of many ML models could prove to be a viable solution for effectively managing such data with many dimensions.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 105
    },
    {
        "text": "It has the potential to enhance diagnostic accuracy, facilitate the discovery of trends and patterns in patient data, streamline administrative processes, and make possible patient-specific treatment plans.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 106
    },
    {
        "text": "Both supervised and unsupervised learning have their advantages and disadvantages in the medical field.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 107
    },
    {
        "text": "The task at hand, the amount of data at hand, and the resources at your disposal will all dictate the style of learning you employ.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 108
    },
    {
        "text": "Further investigation into the constraints discussed in the paper's final two sections would be very welcome.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 109
    },
    {
        "text": "Future MLBDD research could also center on issues such optimizing big data sets that include numerical, categorical, and picture data, as well as multiclass classification with highly imbalanced data and highly missing data, and the explanation and interpretation of multiclass data classification utilizing XAI.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 110
    },
    {
        "text": "Its popularity is growing, and it is becoming increasingly utilized in healthcare to improve diagnostic accuracy and safety.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 111
    },
    {
        "text": "6.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 112
    },
    {
        "text": "REFERENCES [1] McPhee, S.J.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 113
    },
    {
        "text": "; Papadakis, M.A.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 114
    },
    {
        "text": "; Rabow, M.W.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 115
    },
    {
        "text": "(Eds.)",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 116
    },
    {
        "text": "Current Medical Diagnosis & Treatment; McGraw-Hill Medical: New York, NY, USA, 2010.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 117
    },
    {
        "text": "[2] Ahsan, M.M.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 118
    },
    {
        "text": "; Ahad, M.T.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 119
    },
    {
        "text": "; Soma, F.A.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 120
    },
    {
        "text": "ML serves as a robust mechanism enabling machines to learn autonomously, eliminating the requirement for explicit programming.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 121
    },
    {
        "text": "; Rahman, A.; Siddique, Z.; Huebner, P. Detecting SARS-CoV-2 From Chest X-ray Using Artificial Intelligence.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 122
    },
    {
        "text": "[3] Coon, E.R.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 123
    },
    {
        "text": "; Quinonez, R.A.; Moyer, V.A.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 124
    },
    {
        "text": "; Schroeder, A.R.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 125
    },
    {
        "text": "Overdiagnosis: How our compulsion for diagnosis may be harming children.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 126
    },
    {
        "text": "Pediatrics 2014, 134, 1013–1023.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 127
    },
    {
        "text": "[4] Balogh, E.P.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 128
    },
    {
        "text": "; Miller, B.T.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 129
    },
    {
        "text": "; Ball, J.R.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 130
    },
    {
        "text": "It harnesses sophisticated algorithms and statistical methods to analyze data and formulate predictions, departing from traditional rule-based systems.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 131
    },
    {
        "text": "Improving Diagnosis in Health Care; National Academic Press: Washington, DC, USA, 2015.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 132
    },
    {
        "text": "[5] Ahsan, M.M.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 133
    },
    {
        "text": "; Siddique, Z.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 134
    },
    {
        "text": "Machine Learning-Based Heart Disease Diagnosis: A Systematic Literature Review.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 135
    },
    {
        "text": "arXiv 2021, arXiv:2112.06459 [6] Dhillon, A.; Singh, A.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 136
    },
    {
        "text": "J. Biol.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 137
    },
    {
        "text": "Today World 2019, 8, 1–10.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 138
    },
    {
        "text": "The accuracy of machine learning predictions heavily depends on the quality and relevance of the dataset used.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 139
    },
    {
        "text": "In Handbook of Research on Emerging Trends and Applications of Machine Learning; IGI Global: Hershey, PA, USA, 2020; pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 140
    },
    {
        "text": "403–424.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 141
    },
    {
        "text": "Prod.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 142
    },
    {
        "text": "Manuf.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 143
    },
    {
        "text": "Res.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 144
    },
    {
        "text": "2016, 4, 23–45.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 145
    },
    {
        "text": "[9] Chen, M.; Hao, Y.; Hwang, K.; Wang, L.; Wang, L. Disease prediction by machine learning over big data from healthcare communities.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 146
    },
    {
        "text": "Its applications span various industries, including finance, retail, and healthcare [6, 7], where it presents significant opportunities for disease diagnosis and treatment.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 147
    },
    {
        "text": "[10] Ngiam, K.Y.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 148
    },
    {
        "text": "Lancet Oncol.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 149
    },
    {
        "text": "2019, 20, e262–e273.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 150
    },
    {
        "text": "Rev.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 151
    },
    {
        "text": "One of the notable features of machine learning is its continuous improvement in data prediction and classification.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 152
    },
    {
        "text": "; Zhou, X.S.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 153
    },
    {
        "text": "Multi-instance deep learning: Discover discriminative local anatomies for bodypart recognition.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 154
    },
    {
        "text": "IEEE Trans.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 155
    },
    {
        "text": "Imaging 2016, 35, 1332–1343.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 156
    },
    {
        "text": "[13] Anthimopoulos, M.; Christodoulidis, S.; Ebner, L.; Christe, A.; Mougiakakou, S. Lung pattern classification for interstitial lung diseases using a deep convolutional neural network.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 157
    },
    {
        "text": "IEEE Trans.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 158
    },
    {
        "text": "Imaging 2016, 35, 1207–1216.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 159
    },
    {
        "text": "As more data is gathered, the prediction models become more adept at making accurate decisions.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 160
    },
    {
        "text": "; Price, A.; Rueckert, D. A deep cascade of convolutional neural networks for MR image reconstruction.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 161
    },
    {
        "text": "In Proceedings of the Information Processing in Medical Imaging: 25th International Conference, IPMI 2017, Boone, NC, USA, 25–30 June 2017; Springer: Berlin/Heidelberg, Germany; pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 162
    },
    {
        "text": "647–658.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 163
    },
    {
        "text": "Rodeo: Robust de-aliasing autoencoder for real-time medical image reconstruction.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 164
    },
    {
        "text": "Pattern Recognit.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 165
    },
    {
        "text": "2017, 63, 499–510.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 166
    },
    {
        "text": "[16] Kamal, Tamanna, Fabiha Islam, and Mobasshira Zaman.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 167
    },
    {
        "text": "\"Designing a Warehouse with RFID and Firebase Based Android Application.\"",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 168
    },
    {
        "text": "Journal of Industrial Mechanics 4.1 (2019): 11-19.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 169
    },
    {
        "text": "\"Anthropomorphic investigation into improved furniture fabrication and fitting for students in a Bangladeshi university.\"",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 170
    },
    {
        "text": "Journal of The Institution of Engineers (India): Series C 103.4 (2022): 613-622.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 171
    },
    {
        "text": "[18] Ibtisum, Sifat.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 172
    },
    {
        "text": "\"A Comparative Study on Different Big Data Tools.\"",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 173
    },
    {
        "text": "[19] Parvez, M. S., et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 174
    },
    {
        "text": "\"Are library furniture dimensions appropriate for anthropometric measurements of university students?.\"",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 175
    },
    {
        "text": "[20] Hossain, Md Zakir, et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 176
    },
    {
        "text": "\"Evaluating the Effectiveness of a Portable Wind Generator that Produces Electricity using Wind Flow from Moving Vehicles.\"",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 177
    },
    {
        "text": "\"Data analytics for novel coronavirus disease.\"",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 178
    },
    {
        "text": "informatics in medicine unlocked 20 (2020): 100374.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 179
    },
    {
        "text": "A conference ¬presentation The 30th International Conference on Machine Learning, 2013.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 180
    },
    {
        "text": "Transl Cancer Res 2018;7:803–16.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 181
    },
    {
        "text": "[24] Davenport, T., & Kalakota, R. (2019).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 182
    },
    {
        "text": "The potential for artificial intelligence in healthcare.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 183
    },
    {
        "text": "Future healthcare journal, 6(2), 94.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 184
    },
    {
        "text": "Federated learning for smart healthcare: A survey.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 185
    },
    {
        "text": "ACM Computing Surveys (CSUR), 55(3), 1-37.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 186
    },
    {
        "text": "A Review on Explainable Artificial Intelligence for Healthcare: Why, How, and When?.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 187
    },
    {
        "text": "IEEE Transactions on Artificial Intelligence.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 188
    },
    {
        "text": "It has demonstrated exceptional results in various medical tasks, such as identifying body organs from medical images [12], classifying interstitial lung diseases [13], reconstructing medical images [14, 15], and segmenting brain tumors [15].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 189
    },
    {
        "text": "Explainable Artificial Intelligence (XAI) with IoHT for Smart Healthcare: A Review.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 190
    },
    {
        "text": "Interpretable Cognitive Internet of Things for Healthcare, 1-24.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 191
    },
    {
        "text": "Federated learning: Applications, challenges and future directions.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 192
    },
    {
        "text": "International Journal of Hybrid Intelligent Systems, 18(1-2), 19-35.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 193
    },
    {
        "text": "12 Applications and challenges of AI-driven IoHT for combating pandemics: a review (pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 194
    },
    {
        "text": "213-230).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 195
    },
    {
        "text": "Berlin, Boston: De Gruyter.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 196
    },
    {
        "text": "Applications and challenges of cloud integrated IoMT.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 197
    },
    {
        "text": "Cognitive Internet of Medical Things for Smart Healthcare: Services and Applications, 67-85.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 198
    },
    {
        "text": "[31] Ryu, S.-E., Shin, D.-H., Chung, K.: Prediction model of dementia risk based on xgboost using derived variable extraction and hyper parameter optimization.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 199
    },
    {
        "text": "IEEE Access 8, 177708–177720 (2020) [32] Facal, D., Valladares-Rodriguez, S., Lojo-Seoane, C., Pereiro, A.X., Anido-Rifon, L., Juncos-Rabadán, O.: Machine learning approaches to studying the role of cognitive reserve in conversion from mild cognitive impairment to dementia.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 200
    },
    {
        "text": "International journal of geriatric psychiatry 34(7), 941–949 (2019) [33] Bharati, S., Podder, P., Thanh, D.N.H.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 201
    },
    {
        "text": "et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 202
    },
    {
        "text": "Dementia classification using MR imaging and clinical data with voting based machine learning models.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 203
    },
    {
        "text": "Multimed Tools Appl 81, 25971–25992 (2022).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 204
    },
    {
        "text": "https://doi.org/10.1007/s11042-022-12754-x [34] Ansari, A.Q.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 205
    },
    {
        "text": "Automated diagnosis of coronary heart disease using neuro-fuzzy integrated system.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 206
    },
    {
        "text": "1379–1384.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 207
    },
    {
        "text": "[35] Ahsan, M.M.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 208
    },
    {
        "text": "; Siddique, Z.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 209
    },
    {
        "text": "Effect of data scaling methods on machine Learning algorithms and model performance.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 210
    },
    {
        "text": "Technologies 2021, 9, 52.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 211
    },
    {
        "text": "[36] Rubin, J.; Abreu, R.; Ganguli, A.; Nelaturi, S.; Matei, I.; Sricharan, K. Recognizing abnormal heart sounds using deep learning.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 212
    },
    {
        "text": "arXiv 2017, arXiv:1707.04642.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 213
    },
    {
        "text": "[37] Miao, J.H.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 214
    },
    {
        "text": "; Miao, K.H.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 215
    },
    {
        "text": "Cardiotocographic diagnosis of fetal health based on multiclass morphologic pattern predictions using deep learning classification.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 216
    },
    {
        "text": "Int.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 217
    },
    {
        "text": "AI IN HEALTHCARE AND MEDICINE The utilization of AI and the related technologies is becoming more widespread in both the business sector and society.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 218
    },
    {
        "text": "J. Adv.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 219
    },
    {
        "text": "An intelligent scoring system and its application to cardiac arrest prediction.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 220
    },
    {
        "text": "IEEE Transactions on Information Technology in Biomedicine, 16(6):1324–1331, 2012.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 221
    },
    {
        "text": "Heart disease prediction using machine learning techniques.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 222
    },
    {
        "text": "This trend is now extending to the healthcare domain.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 223
    },
    {
        "text": "Left ventricle landmark localization and identification in cardiac mri by deep metric learning-assisted cnn regression.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 224
    },
    {
        "text": "Neurocomputing, 399:153–170, 2020.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 225
    },
    {
        "text": "[41] LD Sharma and RK Sunkaria.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 226
    },
    {
        "text": "Myocardial infarction detection and localization using optimal features based lead specific approach.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 227
    },
    {
        "text": "[42] John Minou, John Mantas, Flora Malamateniou, and Daphne Kaitelidou.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 228
    },
    {
        "text": "The aforementioned technologies has the capacity to revolutionize various facets of patient care, as well as administrative procedures within provider, payer, and pharmaceutical entities.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 229
    },
    {
        "text": "[43] Kemal Polat.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 230
    },
    {
        "text": "Similarity-based attribute weighting methods via clustering algorithms in the classification of imbalanced medical datasets.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 231
    },
    {
        "text": "Neural Computing and Applications, 30(3):987–1013, 2018.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 232
    },
    {
        "text": "[44] Konstantinos P Exarchos, Clara Carpegianni, Georgios Rigas, Themis P Exarchos, Federico Vozzi, Antonis Sakellarios, Paolo Marraccini, Katerina Naka, Lambros Michalis, Oberdan Parodi, et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 233
    },
    {
        "text": "A multiscale approach for modeling atherosclerosis progression.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 234
    },
    {
        "text": "IEEE journal of biomedical and health informatics, 19(2):709–719, 2014.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 235
    },
    {
        "text": "Cab: Classifying arrhythmias based on imbalanced sensor data.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 236
    },
    {
        "text": "Machine learning is a statistical methodology utilized to effectively fit models to data and acquire knowledge through the process of training models with data.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 237
    },
    {
        "text": "Multimedia Tools and Applications, pages 1–59, 2021.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 238
    },
    {
        "text": "[47] Riskyana Dewi Intan Puspitasari, M Anwar Ma’sum, Machmud R Alhamidi, Wisnu Jatmiko, et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 239
    },
    {
        "text": "Generative adversarial networks for unbalanced fetal heart rate signal classification.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 240
    },
    {
        "text": "ICT Express, 2021.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 241
    },
    {
        "text": "J. Transl.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 242
    },
    {
        "text": "Machine learning is widely recognized as a prevalent manifestation of artificial intelligence.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 243
    },
    {
        "text": "In Proceedings of the 2020 15th International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP), Bangkok, Thailand, 18–20 November 2020; pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 244
    },
    {
        "text": "1–6.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 245
    },
    {
        "text": "[50] Ifraz, G.M.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 246
    },
    {
        "text": "; Rashid, M.H.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 247
    },
    {
        "text": "Math.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 248
    },
    {
        "text": "In the field of healthcare, precision medicine is a widely employed application of traditional machine learning.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 249
    },
    {
        "text": "Available online: https://www.kaggle.com/datasets/abhia1999/chronic-kidney-disease (accessed on 27 June 2022).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 250
    },
    {
        "text": "[52] Islam, M.A.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 251
    },
    {
        "text": "In Proceedings of the 2020 3rd International Conference on Intelligent Sustainable Systems (ICISS), Palladam, India, 3–5 December 2020; pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 252
    },
    {
        "text": "952–957.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 253
    },
    {
        "text": "[53] Yashfi, S.Y.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 254
    },
    {
        "text": "It involves the prediction of treatment outcomes for patients by considering a range of patient features and the contextual factors around the therapy.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 255
    },
    {
        "text": "; Islam, M.A.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 256
    },
    {
        "text": "1–5.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 257
    },
    {
        "text": "17, p. 119, Dec. 2019.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 258
    },
    {
        "text": "J. Manage.,Technol.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 259
    },
    {
        "text": "Eng., vol.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 260
    },
    {
        "text": "8, pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 261
    },
    {
        "text": "[57] Baidya, D.; Umaima, U.; Islam, M.N.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 262
    },
    {
        "text": "; Shamrat, F.J.M.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 263
    },
    {
        "text": "1305–1310.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 264
    },
    {
        "text": "[58] Izonin, I.; Tkachenko, R.; Dronyuk, I.; Tkachenko, P.; Gregus, M.; Rashkevych, M. Predictive modeling based on small data in clinical medicine: RBF-based additive input-doubling method.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 265
    },
    {
        "text": "Math.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 266
    },
    {
        "text": "Eng.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 267
    },
    {
        "text": "[59] Izonin, I.; Tkachenko, R.; Fedushko, S.; Koziy, D.; Zub, K.; Vovk, O. RBF-Based Input Doubling Method for Small Medical Data Processing.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 268
    },
    {
        "text": "In Proceedings of the International Conference on Artificial Intelligence and Logistics Engineering, Kyiv, Ukraine, 20–22 February 2022; Springer: Berlin/Heidelberg, Germany, 2021; pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 269
    },
    {
        "text": "Its origins can be traced back to the 1960s.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 270
    },
    {
        "text": "23–31.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 271
    },
    {
        "text": "In Advancement of Machine Intelligence in Interactive Medical Image Analysis; Springer: Berlin/Heidelberg, Germany, 2020; pp.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 272
    },
    {
        "text": "229–239.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 273
    },
    {
        "text": "Big Data Cogn.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 274
    },
    {
        "text": "2022, 6, 98. https://doi.org/10.3390/bdcc6030098 [62] Chang, YH., Chung, CY.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 275
    },
    {
        "text": "Neural networks have been effectively employed in categorization tasks, such as predicting the likelihood of a patient developing a specific disease.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 276
    },
    {
        "text": "In: Lin, KP., Magjarevic, R., de Carvalho, P. (eds) Future Trends in Biomedical and Health Informatics and Cybersecurity in Medical Devices.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 277
    },
    {
        "text": "ICBHI 2019.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 278
    },
    {
        "text": "IFMBE Proceedings, vol 74.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 279
    },
    {
        "text": "Springer, Cham.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 280
    },
    {
        "text": "[63] Z.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 281
    },
    {
        "text": "500-508, doi: 10.1109/EIT48999.2020.9208315.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 282
    },
    {
        "text": "[64] Islam, M.M., Haque, M.R., Iqbal, H. et al.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 283
    },
    {
        "text": "The framework adopts a perspective that analyses problems by considering the inputs, outputs, and weights of variables, sometimes referred to as \"features,\" which establish the associations between inputs and outcomes.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 284
    },
    {
        "text": "1, 290 (2020).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 285
    },
    {
        "text": "https://doi.org/10.1007/s42979-020-00305-w [65] Nemade, V., & Fegade, V. (2023).",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 286
    },
    {
        "text": "1-3, doi: 10.1109/EBBT.2019.8741990.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 287
    },
    {
        "text": "1-4, doi: 10.1109/EBBT.2018.8391453.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 288
    },
    {
        "text": "IJCATM : www.ijcaonline.org",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 289
    },
    {
        "text": "The most intricate manifestations of machine learning encompass deep learning, which pertains to neural network models characterized by numerous tiers of features or variables that facilitate the prediction of events.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 290
    },
    {
        "text": "The quicker processing capabilities of contemporary graphics processing units and cloud infrastructures have enabled the discovery of several latent features inside these models, perhaps amounting to thousands.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 291
    },
    {
        "text": "However, there is a scarcity of research focused on ML algorithms for enhancing the accuracy and computational efficiency.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 292
    },
    {
        "text": "The amalgamation of these technologies exhibits potential for enhanced diagnostic precision compared to the preceding iteration of automated image analysis tools, commonly referred to as computer-aided detection (CAD) [23, 24].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 293
    },
    {
        "text": "The current centered solution in modern healthcare networks is inefficient in terms of communication latency and lacks high network scalability due to the growing volumes of health data and the proliferation of IoMT driven devices.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 294
    },
    {
        "text": "Moreover, the dependence on a centralized server or third-party entity for data learning gives rise to significant privacy concerns, such as the potential leakage of user information and the risk of data breaches.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 295
    },
    {
        "text": "This assertion holds special validity within the realm of e-healthcare, as health-related data is characterized by its high sensitivity and privacy, hence necessitating adherence to health standards.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 296
    },
    {
        "text": "This research investigates the capacity of machine learning algorithms to improve the transmission of heart rate data in time series healthcare metrics, concentrating particularly on optimizing accuracy and efficiency.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 297
    },
    {
        "text": "In the present scenario, federated learning (FL) has emerged as a viable method for achieving cost-effective smart healthcare applications while enhancing privacy protection [25, 26].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 298
    },
    {
        "text": "From a conceptual standpoint, FL is an AI methodology that facilitates the development of AI models of superior quality.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 299
    },
    {
        "text": "This is achieved by combining and averaging local updates obtained from numerous health data clients, such as Internet of Medical Things (IoMT) devices [27, 28].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 300
    },
    {
        "text": "Notably, Florida accomplishes this without necessitating direct access to the individual data stored locally.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 301
    },
    {
        "text": "This measure has the potential to hinder the disclosure of sensitive user information and user preferences, thereby reducing the dangers associated with privacy leakage.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 302
    },
    {
        "text": "In addition, the utilization of FL in the healthcare domain allows for the aggregation of substantial computational and dataset resources from various health data clients, thereby enhancing the quality of AI model training, particularly in terms of accuracy.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 303
    },
    {
        "text": "This improvement may not be attainable through the implementation of centralized AI approaches that rely on smaller datasets and have limited computational capabilities [29, 30].",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 304
    },
    {
        "text": "3.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 305
    },
    {
        "text": "This span encompasses domains as diverse as leveraging ML for personalized social media recommendations to its adoption for streamlining industrial processes through automation.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 306
    },
    {
        "text": "This phenomenon is particularly advantageous, positioning ML as a latent advantage within the healthcare industry.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 307
    },
    {
        "text": "The sector grapples with an abundance of unstructured data, including patient records, historical treatment methods, and familial medical histories.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 308
    },
    {
        "text": "The factors under consideration include the algorithm utilized, the types of diseases targeted, the data types employed, the applications, and the evaluation metrics.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 309
    },
    {
        "text": "36, October 2023 12 focusing on its detection using ML since 2020, which also received priority in our investigation.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 310
    },
    {
        "text": "We briefly discuss severe diseases like heart disease, kidney disease, breast cancer, and Dementia.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 311
    },
    {
        "text": "AD is a chronic brain disorder with neurobiological origins that gradually leads to the demise of brain cells.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 312
    },
    {
        "text": "Patients may exhibit personality shifts, paranoia, and sleep disturbances.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 313
    },
    {
        "text": "Basic functions like bladder control and maintaining head position become challenging.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 314
    },
    {
        "text": "Even simple actions, such as sitting in a chair, become unmanageable.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 315
    },
    {
        "text": "Table 1: ML in Dementia Diagnosis Ref.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 316
    },
    {
        "text": "Dataset Model Accuracy (%) Specificity (%) Recall (%) [31] OASIS (373 samples, 10 variables) XGB 85.61 81.40 77.20 [32] 169 Samples, 14 variables RF 92 88 88 [33] OASIS RF 89.29 - 89 XGB 89.39 - 89 GB 91.02 - 91 Voting 1 (Soft) 91.17 - 91 Efforts are underway to detect AD early, aiming to slow the abnormal brain degeneration, lower healthcare costs, and enhance treatment outcomes.",
        "paperTitle": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review",
        "doi": "10.5120/ijca2023923147",
        "chunk_index_in_doc": 317
    },
    {
        "text": "19, 1–7. 50, 1–16. 6, 94–98. 15, 1–10. 7, 59–67. 36, 700–710. 25, 137–166. 267, 1–38. U.S.A. 116, 22071–22080. 3, 92–109. (Santa Clara, CA), 1368–1377. 14, 156–180. 1, 206–215. 15, 118–138. 10, 1–13.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 0
    },
    {
        "text": "J. Statist. J. Espinosa, J. J. Eur. A. ACM Comput. J. Comput. J. J. Comput.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 1
    },
    {
        "text": "(2015) and Holzinger et al. (2018) and Carvalho et al. doi: 10.1109/INES.2018.8523922 Ahmad, M. A., Eckert, C., Teredesai, A., and McKelvey, G. (2018). doi: 10.1109/CEEC.2018.8674234 Alvarez-Melis, D., and Jaakkola, T. S. (2018). Arcidiacono, G. (2017). Berendt, B., and Preibusch, S. (2017). doi: 10.1089/big.201 6.0055 Bhardwaj, A., Bhattacherjee, S., Chavan, A., Deshpande, A., Elmore, A. J., Madden, S., et al. Caruana, R., Lou, Y., Gehrke, J., Koch, P., Sturm, M., and Elhadad, N. (2015). doi: 10.1145/2783258.2788613 Carvalho, D. V., Pereira, E. M., and Cardoso, J. S. (2019). doi: 10.1109/CBMS.2009.5255394 Chandler, N., and Oestreich, T. (2015). Chavent, M., Liquet, B., Kuentz, V., and Saracco, J. doi: 10.18637/jss.v050.i13 Chen, T., and Guestrin, C. (2016). doi: 10.1145/2939672.29 39785 Darlington, K. W. (2011). doi: 10.1177/2158244011408618 Davenport, T., and Kalakota, R. (2019). doi: 10.7861/futurehosp.6-2-94 Dawson, D., Schleiger, E., Horton, J., McLaughlin, J., Robinson, C., Quezada, G., et al. Doshi-Velez, F., and Kim, B. A., and Armour, F. (2016). doi: 10.1109/HICSS.2016.141 EU (2016). Fahmy, A. F., Mohamed, H. K., and Yousef, A. H. (2017). doi: 10.1145/2594473.2594475 Fujimaki, R. (2020). Z., Bajwa, A., Specter, M., and Kagal, L. (2018). doi: 10.1109/DSAA.2018.00018 Gilpin, L. H., Testart, C., Fruchter, N., and Adebayo, J. doi: 10.1089/big.2016.0007 Goodfellow, I., Bengio, Y., and Courville, A. Gosiewska, A., and Biecek, P. (2020). Gosiewska, A., Woznica, K., and Biecek, P. (2020). Grady, N. W., Underwood, M., Roy, A., and Chang, W. L. (2014). 51, 93:1–93:42. doi: 10.1145/3236009 Hansen, L. K., and Rieger, L. (2019). Huang, W., McGregor, C., and James, A. doi: 10.1007/978-3-540-71080-6_21 Kolyshkina, I., and Simoff, S. (2019). H. Jin, S. Wong, L. Liu, et al. doi: 10.1007/978-981-15-1699-3_13 Lage, I., Chen, E., He, J., Narayanan, M., Kim, B., Gershman, S. J., et al. Larson, D., and Chang, V. (2016). doi: 10.1016/j.ijinfomgt.2016.04.013 Lipton, Z. C. (2018). ACM Queue 16, 30:31–30:57. doi: 10.1145/3236386.3241340 Lundberg, S. M., and Lee, S. I. Mariscal, G., Marbán, O., and Fernández, C. (2010). doi: 10.1017/S0269888910000032 Mi, J. X., Li, A. D., and Zhou, L. F. (2020). doi: 10.1145/3287560.3287574 Molnar, C., Casalicchio, G., and Bischl, B. Murdoch, W. J., Singh, C., Kumbier, K., Abbasi-Asl, R., and Yu, B. doi: 10.1073/pnas.1900654116 NewVantage Partners LLC (2021). Pradeep, S., and Kallimani, J. S. (2017). doi: 10.1109/RBME.2020.3013489 Ransbotham, S., Kiron, D., and Prentice, P. K. (2015). Ribeiro, M. T., Singh, S., and Guestrin, C. (2016). doi: 10.1145/2939672.2939778 Roberts, J. doi: 10.1038/s42256-019-0048-x Saltz, J. S. (2015). doi: 10.1109/BigData.2015.7363988 Saltz, J. S., and Shamshurin, I. doi: 10.1109/BigData.2016.7840936 Saltz, J. S., Shamshurin, I., and Crowston, K. (2017). doi: 10.24251/HICSS.2017.120 Samek, W., and Müller, K. R. (2019). doi: 10.1007/978-3-030-28954-6_1 Schäfer, F., Zeiselmair, C., Becker, J., and Otten, H. (2018). doi: 10.1109/ITMC.2018.8691266 Shearer, C. (2000). doi: 10.1002/wi dm.1379 Studer, S., Bui, T. B., Drescher, C., Hanuschkin, A., Winkler, L., Peters, S., et al. Sun, W., Nasraoui, O., and Shafto, P. (2020). doi: 10.1371/journal.pone.0235502 vander Meulen R, and Thomas, M. (2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 2
    },
    {
        "text": "Murdoch et al. Molnar et al. Murdoch et al. Murdoch et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 3
    },
    {
        "text": "High Proportion of Data Science Project Failures Recent reports, which include healthcare-related organizations, estimate that up to 85% of data science/ML/AI projects do not achieve their stated goals. In this type of environment, AI/ML project failure is simply not acceptable.” On the other hand, the NewVantage Partners survey (NewVantage Partners LLC, 2021) emphasized that, over the 10 years of conducting these surveys, organizations continue to struggle with their transformation into data-driven organizations, with only 29% achieving transformational business outcomes. A number of sources (e.g., vander Meulen and Thomas, 2018; Kaggle, 2020; NewVantage Partners LLC, 2021) established that a key reason for these failures is linked to the lack of proper process and methodology in areas, such as requirement gathering, realistic project timeline establishment, task coordination, communication, and designing a suitable project management framework (see also Goodwin, 2011; Stieglitz, 2012; Espinosa and Armour, 2016). Most Data Science Projects Fail, But Yours Doesn’t Have To. Available online at: https://www.datanami.com/2020/10/01/most- data-science-projects-fail-but-yours-doesnt-have-to/ Gao, J., Koronios, A., and Selle, S. (2015). Reasons Why Data Projects Fail. Available online at: http://i2t.icesi.edu.co/ASUM-DM_External/index.htm Jain, P. (2019).Top 5 Reasons for Data Science Project Failure. Big Data and AI Executive Survey 2021: The Journey to Becoming Data-Driven: A Progress Report on the State of Corporate Data Initiatives. 4 Reasons Why Most Data Science Projects Fail. 7 Sure-Fire Ways to Fail at Data Analytics.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 4
    },
    {
        "text": "ORIGINAL RESEARCH published: 26 May 2021 doi: 10.3389/fdata.2021.660206 Frontiers in Big Data | www.frontiersin.org 1 May 2021 | Volume 4 | Article 660206 Edited by: Kok-Leong Ong, La Trobe University, Australia Reviewed by: Md. “Towards a process view on critical success factors in big data analytics projects,” in Proceedings of the 21st Americas Conference on Information Systems (AMCIS), 1–14. “Big data: challenges, practices and technologies: NIST big data public working group workshop at IEEE big data 2014,” in Proceedings of IEEE International Conference on Big Data (Big Data 2014), 11–15. “The need for new processes, methodologies and tools to support big data teams and improve big data project effectiveness,” in Proceedings of 2015 IEEE International Conference on Big Data (Big Data), 2066–2071. “Big data team process methodologies: a literature review and the identification of key factors for a project’s success,” in Proceedings of 2016 IEEE International Conference on Big Data (Big Data), 2872–2879. Frontiers in Big Data | www.frontiersin.org 16 May 2021 | Volume 4 | Article 660206",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 5
    },
    {
        "text": "Anisur Rahman, Charles Sturt University, Australia Yafei Han, Massachusetts Institute of Technology, United States *Correspondence: Inna Kolyshkina inna@analytikk.com Specialty section: This article was submitted to Medicine and Public Health, a section of the journal Frontiers in Big Data Received: 29 January 2021 Accepted: 07 April 2021 Published: 26 May 2021 Citation: Kolyshkina I and Simoff S (2021) Interpretability of Machine Learning Solutions in Public Healthcare: The CRISP-ML Approach. Big Data 4:660206. doi: 10.3389/fdata.2021.660206 Interpretability of Machine Learning Solutions in Public Healthcare: The CRISP-ML Approach Inna Kolyshkina 1* and Simeon Simoff 2,3 1 Analytikk Consulting, Sydney, NSW, Australia, 2 School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, NSW, Australia, 3MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, NSW, Australia Public healthcare has a history of cautious adoption for artificial intelligence (AI) systems. As a result, the area of interpretability and explainability of ML is gaining significant research momentum. This limits the practicality of using ML in the health domain: the issues with explaining the outcomes of ML algorithms to medical practitioners and policy makers in public health has been a recognized obstacle to the broader adoption of data science approaches in this domain. This study builds on the earlier work which introduced CRISP-ML, a methodology that determines the interpretability level required by stakeholders for a successful real-world solution and then helps in achieving it. CRISP-ML was built on the strengths of CRISP-DM, addressing the gaps in handling interpretability. This study elaborates on the CRISP-ML methodology on the determination, measurement, and achievement of the necessary level of interpretability of ML solutions in the Public Healthcare sector. It demonstrates how CRISP-ML addressed the problems with data diversity, the unstructured nature of data, and relatively low linkage between diverse data sets in the healthcare domain. The characteristics of the case study, used in the study, are typical for healthcare data, and CRISP-ML managed to deliver on these issues, ensuring the required level of interpretability of the ML solutions discussed in the project. The approach used ensured that interpretability requirements were met, taking into account public healthcare specifics, regulatory requirements, project stakeholders, project objectives, and data characteristics. Keywords: machine learning, interpretability, public health, data sciencemethodology, CRISP-ML, necessary level of interpretability, interpretability matrix, cross-industry standard process Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare 1. In this context, public healthcare sets priority requirements toward the robustness, security (Qayyum et al., 2021), and interpretability (Stiglic et al., 2020) of ML solutions. While the early AI solutions for healthcare, like expert systems, possessed limited explanatory mechanisms (Darlington, 2011), these mechanisms proved to have an important role in clinical decision-making and, hence, made healthcare practitioners, clinicians, health economists, patients, and other stakeholders aware about the need to have such capabilities. Healthcare domain imposes a broad spectrum of unique challenges to contemporary ML solutions, placing much higher demands with respect to interpretability, comprehensibility, explainability, fidelity, and performance of ML solutions (Ahmad et al., 2018). Among these properties of ML solutions, interpretability is particularly important for human-centric areas like healthcare, where it is crucial for the end users to not only have access to an accurate model but also to trust the validity and accuracy of the model, as well as understand how the model works, what recommendation has been made by the model, and why. Consequently, the interpretability of such solutions and the explainability of the impact of the judgements they assist to make or have made and, where needed, the rationale of recommended actions and behavior are becoming essential requirements of contemporary analytics, especially in society-critical domains of health, medical analysis, automation, defense, security, finance, and planning. (2019), tend to use interpretability and explainability interchangeably. They also report that the interpretability of ML solutions and the underlying models is not well-defined. The study related to interpretability is scattered throughout a number of disciplines, such as AI, ML, human-computer interaction (HCI), visualization, cognition, and social sciences (Miller, 2019), to name a few of the areas. (2019), have clarified some differences and relationships between interpretability and explainability in the context of ML and AI. In these domains, interpretability refers to the degree of human interpretability of a given model, including “black box” models (Mittelstadt et al., 2019). Machine interpretability of the outcomes of ML algorithms is treated separately. Explanability refers primarily to the number of ways to communicate an ML solution to others (Hansen and Rieger, 2019), i.e., the “ways of exchanging information about a phenomenon, in this case the functionality of a model or the rationale and criteria for a decision, to different stakeholders.” Both properties of ML solutions are central to the broader adoption of such solutions in diverse high-stake healthcare scenarios, e.g., predicting the risk of complications to the health condition of a patient or the impact of treatment change.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 6
    },
    {
        "text": "While some authors (for instance, Hansen and Rieger, 2019; Mittelstadt et al., 2019; Samek and Müller, 2019) consider interpretability as an important component of explainability of ML solutions in AI, we view interpretability and explainability as complementary to each other, with interpretability being fundamental in ensuring trust in the results, transparency of the approach, confidence in deploying the results, and, where needed, quality of the maintenance of ML solutions. Further, in this study, we used the term interpretability in a broader sense, which subsumes communication and information exchange aspects of explainability. We considered two connected aspects of the development of the overall concept of interpretability in ML solutions: 1. methods, which include the range of interpretable ML algorithms and interpretability solutions for AI/ML algorithms; 2. methodologies in data science, which consider explicitly the achievement of the necessary (for the project) interpretability of the ML solutions. There is a wide collection of interpretable ML methods and methods for the interpretation of ML models. (2019) provide extensive systematic overviews with elaborate frameworks of the state- of-the-art of interpretability methods. (2020) provide Frontiers in Big Data | www.frontiersin.org 2 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare broader taxonomy and comparative experiments, which can help practitioners in selecting suitable models with complementary features for addressing interpretability problems inML solutions. Model interpretability and explainability are crucial for clinical and healthcare practice, especially, since not only non- linear models but also inherently more interpretable ones, like decision trees, if large and complex, become difficult to comprehend (Ahmad et al., 2018). On the other hand, working with data in the healthcare domain is complex at every step, starting from establishing and finding the relevant, typically numerous, diverse, and heterogeneous data sources required to address the research objective; integrating andmapping these data sources; identifying and resolving data quality issues; pre-processing and feature engineering without losing information or distorting it; and finally using the resulting high-dimensional, complex, sometimes unstructured, data to build a high-performing interpretable model. This complexity further supports the argument for the development of ML methodologies which explicitly embed interpretability through the data science project life cycle and ensure the achievement of the level of interpretability of ML solutions that had been agreed for the project. Interpretability of an ML solution can serve a variety of stakeholders involved in data science projects in connection with the implementation of their outcomes. Interpretability of an ML solution can serve a variety of stakeholders, involved in data science projects and related to the implementation of their outcomes in algorithmic decision making (Berendt and Preibusch, 2017). This study is focused on addressing the methodological challenges and opportunities of broad embedding of interpretability (including the selection of methods of interpretability that are appropriate for a project, given its objectives and constraints). CHALLENGES AND OPPORTUNITIES IN CREATING METHODOLOGIES WHICH CONSISTENTLY EMBED INTERPRETABILITY In order to progress with the adoption of ML in healthcare, a consistent and comprehensive methodology is needed: first, to minimize the risk of project failures, and second, to establish and ensure the needed level of interpretability of the ML solution while addressing the above-discussed diverse requirements to ML solutions. The rationale supporting these needs is built on a broader set of arguments about: – the high proportion of data science project failures, including those in healthcare; – the need to support an agreed level of interpretability and explainability of ML solutions; – the need for consistent measurement and evaluation of interpretability of ML solutions; and – the emerging need for standard methodology, which explicitly embeds mechanisms to manage the achievement of the level of interpretability of ML solutions required by stakeholders through the project. Further, in this section, we use these arguments as dimensions around which we elaborate the challenges and opportunities for the design of cross-industry data science methodology, which is capable of handling interpretability of ML solutions under the complexity of the healthcare domain. Earlier works have suggested (see, e.g., Saltz, 2015) that improved methodologies are needed as the existing ones do not cover many important aspects and tasks, including those related to interpretability (Mariscal et al., 2010). A recent Gartner Consulting report also emphasizes the role of processes and methodology (Chandler and Oestreich, 2015) and practitioners agree with this view (for examples and analyses from diverse practical perspectives see Frontiers in Big Data | www.frontiersin.org 3 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare Goodson, 2016; Arcidiacono, 2017; Roberts, 2017; Violino, 2017; Jain, 2019). Support for the Required Level of Interpretability and Explainability of ML Solutions In parallel with the above-discussed tendencies, there is pressure on the creation of frameworks/methodologies, which can ensure the necessary interpretability for sufficient explainability of the output of the ML solutions.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 7
    },
    {
        "text": "While it has been suggested, in recent years, that it is only a matter of time before ML will be universally used in healthcare, building ML solutions in the health domain proves to be challenging (Ahmad et al., 2018). On the one hand, the demands for explainability, model fidelity, and performance in general in healthcare are much higher than in most other domains (Ahmad et al., 2018). In order to build the trust in ML solutions and incorporate them in routine clinical and healthcare practice, medical professionals need to clearly understand how and why an ML solution-driven decision has been made (Holzinger et al., 2017; Vellido, 2020). This is further affected by the fact that the ML algorithms that achieve a high level of predictive performance, e.g., boosted trees (Chen and Guestrin, 2016) or deep neural networks (Goodfellow et al., 2016), are quite complex and usually difficult to interpret. In fact, some researchers argue that performance and interpretability of an algorithm are in reverse dependence (Ahmad et al., 2018; Molnar et al., 2019). Additionally, while there are a number of techniques aiming to explain the output of the models that are not directly interpretable, as many authors note (e.g., Holzinger et al., 2017; Gilpin et al., 2019; Rudin, 2019; Gosiewska et al., 2020), current explanatory approaches, while promising, do not seem to be sufficiently mature. Further, Gosiewska and Biecek (2020) showed that current popular methods for explaining the output of ML models, like SHAP (Lundberg and Lee, 2017) and LIME (Ribeiro et al., 2016), produce inconsistent results, while Alvarez-Melis and Jaakkola (2018) found that the currently popular interpretability frameworks, particularly model-agnostic perturbation-based methods, are often not robust to small changes of the input, which clearly is not acceptable in the health domain. These developments increased the pressure on creation of frameworks and methodologies, which can ensure sufficient interpretability of ML solutions. Major technology developers, including Google, IBM, and Microsoft, recommend responsible interpretability practices (see, e.g., Google, 2019), including the development of common design principles for human-interpretable machine learning solutions (Lage et al., 2019). Consistent Measurement and Evaluation of Interpretability of ML Solutions While there are a number of suggested approaches to measuring interpretability (Molnar et al., 2019), a consensus on the ways of measuring or evaluating the level of interpretability has not been reached. (2019) found that the best type of explanation metrics is not clear. (2019) mentioned that, currently, there is confusion about the interpretability notion and a lack of clarity about how the proposed interpretation approaches can be evaluated and compared against each other and how to choose a suitable interpretation method for a given issue and audience. (2019) further note that there is limited guidance on how interpretability can actually be used in data science life cycles. The Emerging Need for Standard Methodology for Handling Interpretability Having a good methodology is important for the success of a data science project. In the more recent years, variations of CRISP-DM tailored for the healthcare (Catley et al., Frontiers in Big Data | www.frontiersin.org 4 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare 2009) and medical domain, such as CRISP-MED-DM (Niaksu, 2015), have been suggested. This overall lack of consensus has provided an opportunity to reflect on the philosophy of the CRISP-DM methodology and create a comprehensive data science methodology, through which interpretability is embedded consistently into an ML solution. Such methodology faces a list of requirements: – It has to take into account the different perspectives and aspects of interpretability, including model and process explainability and interpretability; – It has to consider the desiderata of explainable AI (fidelity, understandability, sufficiency, low construction overhead, and efficiency) as summarized in Hansen and Rieger (2019); – It needs to support consistent interaction of local and global interpretability of ML solutions with other established key factors in data science projects, including predictive accuracy, bias, noise, sensitivity, faithfulness, and domain specifics; In addition, healthcare researchers have indicated that the choice of interpretable models depends on the use case (Ahmad et al., 2018). In order to standardize the expectations for interpretability, some of these requirements have been addressed in the recently proposed CRISP-ML methodology (Kolyshkina and Simoff, 2019). In section 3, we will briefly discuss the major concepts differentiating CRISP-ML methodology. The CRISP- ML approach includes the concepts of necessary level of interpretability (NLI) and interpretability matrix (IM), described in detail by Kolyshkina and Simoff (2019), and therefore aligns well with the view of health researchers that the choice of interpretable models depends upon the application and use case for which explanations are required (Ahmad et al., 2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 8
    },
    {
        "text": "To illustrate that, in section 4, we present a use case in the public health field that illustrates the typical challenges met and the ways CRISP-ML helped to address and resolve them. CRISP-ML METHODOLOGY—TOWARD INTERPRETABILITY-CENTRIC CREATION OF ML SOLUTIONS The CRISP-ML methodology (Kolyshkina and Simoff, 2019) of building interpretability of an ML solution is based on revision and update of CRISP-DM to address the opportunities discussed in section 2. CRISP-ML accommodates the necessary elements to work with diverse ML techniques and create the right level of interpretability through the whole ML solution creation process. Its seven stages are described in Figure 1), which is an updated version of the CRISP- ML methodology diagram in the study by Kolyshkina and Simoff (2019). Central to CRISP-ML is the concept of necessary level of interpretability of an ML solution. From this view point, CRISP- ML can be differentiated as a methodology of establishing and building the necessary level of interpretability of a business ML solution. In line with Google’s guidelines on the responsible AI practices in the interpretability area (Google, 2019) and expanding on the approach proposed by Gleicher (2016), we have specified the concept of minimal necessary level of interpretability of a business ML solution as the combination of the degree of accuracy of the underlying algorithm and the extent of understanding the inputs, inner workings, the outputs, the user interface, and the deployment aspects of the solution, which is required to achieve the project goals. We then describe an ML solution as sufficiently interpretable or not based on whether or not it achieved the required level of interpretability. In other cases, when an ML solution is used in order to inform business decisions about policy, strategy, or interventions aimed to improve the business outcome of interest, then it is necessary to understand and trust the internal logic of the model that is of most value, while individual predictions are not the focus of the stakeholders. In this project, it was Frontiers in Big Data | www.frontiersin.org 5 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare FIGURE 1 | Conceptual framework of CRISP-ML methodology. The recently published CRISP-ML(Q) (Studer et al., 2020) proposes an incremental extension of CRISP-DM with the monitoring and maintenance phases. While the study mentions “model explainability” referring to the technical aspects of the underlying model, it does not consider interpretability and explainability in a systematic way as CRISP-ML (Kolyshkina and Simoff, 2019). Interpretability is now one of the most important and quickly developing universal requirements, not only a “best practice” requirement in some industries. CRISP-ML (Kolyshkina and Simoff, 2019) ensures that the necessary interpretability level is identified at the requirement collection stage. CRISP-ML (Kolyshkina and Simoff, 2019) includes stages 3 and 4 (data predictive potential assessment and data enrichment in Figure 1), which are not present in CRISP-ML(Q) (Studer et al., 2020). In Kolyshkina and Simoff (2019), the individual stages of the CRISP-MLmethodology were presented in detail. There, the emphasis was on the versatility of CRISP- ML as a industry-neutral methodology, including its approach to interpretability. In this study, we focus on a single case study from health-related domain in order to present a comprehensive coverage of each stage and the connections between the stages, and provide examples of how the required level of interpretability of the solution is achieved through carefully crafted involvement of the stakeholders as well as decisions made at each stage. This study does not provide comparative evaluation of CRISP-ML methodology in comparison to CRISP- DM (Shearer, 2000), ASUM-DM (IBM Analytics, 2015), TDSP (Microsoft, 2020), and other methodologies discussed by Kolyshkina and Simoff (2019). The purpose of the study is to demonstrate, in a robust way, the mechanics of explicit management of interpretability in ML through the project structure and life cycle of a data science methodology. The structure of the CRISP-ML process methodology has embedded flexibility in it, indicated by the cycles, which link the model-centric stages back to the early data-centric stages, as shown in Figure 1. Changes inevitably occur in any project over the course of the project life cycle, and CRISP-ML reflects that. These factors can be global, such Frontiers in Big Data | www.frontiersin.org 6 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare as environmental, political, or legislative factors; organization- specific (e.g., updates in the organizational IT structure, the way of data storage or changes in the stakeholder team), or they could be related to the progress in ML and ML-related technical areas (e.g., the advent of a new, better performing predictive algorithm).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 9
    },
    {
        "text": "In this study, we present the stages of CRISP-ML in a rigid manner, around the backbone of the CRISP-ML process, represented by the solid black triangle arrows in Figure 1 to maintain the emphasis on the mechanisms for handling interpretability in each of these steps, rather than exploring the iterative nature of the approach. As a result, we are able to illustrate in more depth how we sustain the level of interpretability through the process structure of the project. The study complements the study by Kolyshkina and Simoff (2019), where, through the examples drawn from a variety of cases, we demonstrated the versatility of CRISP-ML. CASE STUDY ILLUSTRATING THE ACHIEVEMENT OF THE NLI OF MACHINE LEARNING SOLUTION In this study, we will describe a detailed real-world case study in which, by going through each project stage, we illustrate how CRISP-ML facilitates data science project stakeholders in establishing and achieving the necessary level of interpretability of ML solution. They illustrate the approach and the content of the interpretability mechanisms of CRISP-ML. We place a particular focus on the aspects and stages of CRISP-ML from the perspective of demonstrating the flow and impact of interpretability requirements and on how they have been translated into the necessary level of interpretability of the finalML solution. Further, the structure of this section follows the stages of CRISP-ML process structure in Figure 1. Building the Project Interpretability Matrix: An Overall Approach Interpretability matrix is usually built at Stage 1 of the project as part of the requirement collection process. Data science practitioners recognize Stage 1 as crucial for the overall project success (see, e.g., PMI, 2017), as well as from the solution interpretability building perspective (Kolyshkina and Simoff, 2019). Kolyshkina and Simoff (2019) demonstrated the CRISP-ML stages consistently applied to different projects across a number of industries, data sets, and data types. Interpretability-Related Aspects of the Project Charter: Business Objectives, Main Stakeholders, and Interpretability Level We will describe in more detail the aspects of the project charter that were directly related to this study, specifically the established business objectives, main stakeholders, and the established necessary interpretability requirements. Frontiers in Big Data | www.frontiersin.org 7 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare 3. Ensure that the overall ML solution is easy to understand and implement by the Information Technology (IT) team of the organization and to monitor/update the Business Intelligence (BI) team of the organization. The established necessary interpretability level. The necessary interpretability level (Kolyshkina and Simoff, 2019) was established as follows. In each cell of the matrix, we showed what needs to be done by each stakeholder at each project stage to ensure that the required level of solution interpretability is achieved. We define the extent of involvement of a stakeholder group needed to achieve the necessary interpretability level in a particular project stage as follows: – high extent of involvement—the stakeholder group needs to be directly and actively involved in the solution development process to ensure that the NLI is achieved at the stage; – medium extent of involvement—the stakeholder group needs to receive detailed regular updates on the progress of the stage and get directly involved in the work from time to time to ensure that the NLI is achieved at the stage. Figure 2 shows a high-level interpretability matrix for the project. Entries to the Project Interpretability Matrix at Each Stage of CRISP-ML Further, we discuss entries to the project IM at each stage of CRISP-ML. Stage 1 The content of the interpretability matrix related to the project initiation and planning stage (i.e., the first row of the matrix) has been discussed in detail above and is summarized in Figure 3. Stages 2–4 Stages 2–4 in Figure 1 are mainly data-related and form the data comprehension, cleansing, and enhancement mega-stage. Frontiers in Big Data | www.frontiersin.org 8 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare FIGURE 2 | High-level interpretability matrix for the project. Further, we consider the content of the interpretability matrix for each of these stages, they are represented by the second, third, and fourth rows of interpretability matrix. Data audit, exploration, and cleansing played a key role in achieving the interpretability level needed for the project. Frontiers in Big Data | www.frontiersin.org 9 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare Figure 4 demonstrates the content of the interpretability matrix at this stage. There was agreement among the experts that the FIGURE 3 | Interpretability matrix content for Stage 1. FIGURE 4 | Interpretability matrix content for Stage 2.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 10
    },
    {
        "text": "Frontiers in Big Data | www.frontiersin.org 10 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare industry “truths” were insufficient to accurately triage claims and that different approaches were needed. Figure 5 shows the content of the interpretability matrix related to the evaluation of the predictive potential of the data (i.e., the third row of the matrix). Figure 6 shows the content of the interpretability matrix related to the data enrichment stage. The fact that the model showed that the FIGURE 5 | Interpretability matrix content for Stage 3. Frontiers in Big Data | www.frontiersin.org 11 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare cost of a claim can be significantly dependent on the providers a worker visited built further trust in the solution, because it confirmed the hunch of domain experts that they previously had not had enough evidence to prove. Stage 5 Figure 7 shows the content of the interpretability matrix for the model building and evaluation stage. To achieve the right interpretability level, it is crucial that modelers choose the right technique that will balance the required outcome interpretability with the required level of accuracy of the model, which is often a challenge (see, e.g., Freitas, 2014), as well as with other requirements/constraints (e.g., the needed functional form of the algorithm). Stage 6 Figure 8 shows how the interpretability matrix reflects the role of interpretability in the formulation of business insights necessary to achieve the project goals and in helping the E and DE to understand the derived business insights and to develop trust in FIGURE 6 | Interpretability matrix content for Stage 4. FIGURE 7 | Interpretability matrix content for Stage 5. Frontiers in Big Data | www.frontiersin.org 12 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare them. CONCLUSIONS This study contributes toward addressing the problem for providing organizations with capabilities to ensure that the ML solutions they develop to improve decision-making are transparent and easy to understand and interpret. In an earlier study (Kolyshkina and Simoff, 2019), we introduced CRISP-ML, a methodology of determining FIGURE 8 | Interpretability matrix content for Stage 6. FIGURE 9 | Interpretability matrix content for Stage 7 includes activities ensuring the achieved interpretability level is maintained during the future utilization of the solution. Frontiers in Big Data | www.frontiersin.org 13 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare the interpretability level required for the successful real- world solution and then achieving it via integration of the interpretability aspects into its overall framework instead of just the algorithm creation stage. CRISP-ML combines practical, common-sense approach with statistical rigor and enables organizations to establish shared understanding across all key stakeholders about the solution and its use and build trust in the solution outputs across all relevant parts of the organization. In this study, we illustrated CRISP-ML with a detailed case study of building an ML solution in the Public Health sector. We showed how the necessary level of solution interpretability was determined and achieved. The study demonstrated how CRISP-ML addressed the problemswith data diversity, unstructured nature of the data, and relatively low linkage between diverse data sets in the healthcare domain (Catley et al., 2009; Niaksu, 2015). The characteristics of the case study which we used are typical for healthcare data, and CRISP-ML managed to deliver on these issues, ensuring the required interpretability of the ML solutions in the project. While we have not completed formal evaluation of CRISP- ML, there are two aspects which indicate that the use of this methodology improves the chances of success of data science projects. On the one hand, CRISP-ML is built on the strengths of CRISP-DM, which made it the preferred and effective methodology (Piatetsky-Shapiro, 2014; Saltz et al., 2017), addressing its identified limitations in previous works (e.g., Mariscal et al., 2010). On the other hand, CRISP-ML has been successfully deployed in a number of recent real-world projects across several industries and fields, including credit risk, insurance, utilities, and sport. It ensured on meeting the interpretability requirements of the organizations, regardless of industry specifics, regulatory requirements, types of stakeholders involved, project objectives, and data characteristics, such as type (structured as well as unstructured), size, or complexity level. CRISP-ML is a living organism and, as such, it responds to the rapid progress in the development of ML algorithms and the evolution of the legislation for their adoption.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 11
    },
    {
        "text": "Consequently, CRISP-ML development includes three directions: (i) the development of a richer set of quantitative measures of interpretability features for human interpretable machine learning, (ii) the development of the methodology and respective protocols for machine interpretation, and (iii) the development of formal process support. The first one is being extended in a way to provide input to the development and evaluation of common design principles for human interpretable ML solutions in line with that described in the study by Lage et al. FUNDING Elements of the study on interpretability in ML solutions are partially supported by the Australian Research Council Discovery Project (grant no. Interpretable machine learning in healthcare. “Towards robust interpretability with self-explaining neural networks,” in Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS’18 (Red Hook, NY: Curran Associates Inc.), 7786–7795. Machine learning interpretability: a survey on methods and metrics. Electronics 8:832. doi: 10.3390/electronics80 80832 Frontiers in Big Data | www.frontiersin.org 14 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare Catley, C., Smith, K., McGregor, C., and Tracy, M. (2009). “Extending crisp-dm to incorporate temporal data mining of multidimensional medical data streams: a neonatal intensive care unit case study,” in 22nd IEEE International Symposium on Computer-Based Medical Systems, 1–5. Designing for explanation in health care applications of expert systems. Towards a rigorous science of interpretable machine learning. Comprehensible classification models: a position paper. “Explaining explanations: an overview of interpretability of machine learning,” in 2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA), 80–89. Google AI: Responsible AI Practices–Interpretability. “Interpretability in intelligent systems– a new concept?” in Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, Volume 11700 of LNAI, eds W. Samek, G. Montvon, A. Vedaldi, L. K. Hansen, and K. R. Müller (Springer Nature), 41–49. (2017).What do we need to build explainable AI systems for the medical domain? “Interpretability of machine learning solutions in industrial decision engineering,” inData Mining, eds T. D. Le, K. L. Ong, Y. Zhao,W. “Human evaluation of models built for interpretability,” in The Proceedings of the Seventh AAAI Conference on Human Computation and Crowdsourcing (HCOMP-19), Vol. The mythos of model interpretability. Review study of interpretation methods for future interpretable machine learning. Explanation in artificial intelligence: insights from the social sciences. “Explaining explanations in AI,” in Proceedings of the Conference on Fairness, Accountability, and Transparency, FAT ’19 (New York, NY: Association for Computing Machinery), 279–288. Quantifying interpretability of arbitrary machine learning models through functional decomposition. Definitions, methods, and applications in interpretable machine learning. Available online at: https://www.bjmc.lu.lv/ fileadmin/user_upload/lu_portal/projekti/bjmc/Contents/3_2_2_Niaksu.pdf Frontiers in Big Data | www.frontiersin.org 15 May 2021 | Volume 4 | Article 660206 Kolyshkina and Simoff Interpretability of Machine Learning in Public Healthcare Niño, M., Blanco, J. M., and Illarramendi, A. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. “Towards explainable artificial intelligence,” in Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, Volume 11700 of LNAI, eds W. Samek, G. Montvon, A. Vedaldi, L. K. Hansen, and K. R. Müller (Springer Nature), 5–22. The CRISP-DM Model: The new blueprint for data mining. Interpretability of machine learning-based prediction models in healthcare. Towards CRISP-ML(Q): a machine learning process model with quality assurance methodology. The importance of interpretability and visualization in machine learning for applications in medicine and health care. “Transparency: motivations and challenges,” in Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, Volume 11700 of LNAI, eds W. Samek, G. Montvon, A. Vedaldi, L. K. Hansen, and K. R. Müller (Springer Nature), 23–40.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 12
    },
    {
        "text": "(2015). (2012). (2014). (2014). (2015). (2015).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 13
    },
    {
        "text": "2. 3. 4. 6. 5.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 14
    },
    {
        "text": "(2018). (2019). (2019). (2019). (2019). (2019). (2019). (2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 15
    },
    {
        "text": "(2017). (2016). (2017). (2017). (2016). (2017).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 16
    },
    {
        "text": "2.2. 2.3. 2.4. 4.2. 4.3.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 17
    },
    {
        "text": "4.2.1. 4.2.1.2. 4.2.2. 4.3.1. 4.3.2. 4.3.2.1. 4.3.2.2. 4.3.2.3. 4.3.3. 4.3.4. 4.3.5.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 18
    },
    {
        "text": "arXiv 1702.08608. arXiv 1903.11420. arXiv 2006.02293. arXiv 1712.09923. arXiv 1904.03867. arXiv 2003.05155.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 19
    },
    {
        "text": "High-Level Project Objectives and Data Description An Australian State Workers Compensation organization sought to predict, at an early stage of a claim, the likelihood of the claim becoming long-term, i.e., a worker staying on income support for 1 year ormore from the date of lodgement. The data that the analysis was to be based upon were identified by the organizational experts, based on the outcomes for about 20,000 claims incurred in the recent years, and included the following information: – injured worker attributes, e.g., date of birth, gender, occupation, average weekly earnings, residential address; – injury attributes, e.g., injury date, the information on the nature, location, mechanism, and agency of injury coded according to the National Type of Occurrence Classification System2; – employer attributes (size, industry classification); – details of all worker’s income support or similar payments. Build an ML system that will explain what factors and to what extent influence the outcome, i.e., claim duration; 2. Allow the organization to derive business insights that will help make data-driven accurate decisions regarding what changes can be done to improve the outcome, i.e., reduce the likelihood of a long claim by a specified percentage; 2Type of Occurrence Classification System (3rd Edition, Revision 1), Australian Government—Australian Safety and Compensation Council, Canberra, 2008, https://www.safeworkaustralia.gov.au/doc/type-occurrence-classification- system-toocs-3rd-edition-may-2008). One such “truth” was that claim duration was influenced principally by nature and location of injury, but in combination with the age of the injured worker, and specifically, older workers tended to have longer duration claims. Therefore, the predictive potential of the initially supplied data, containing claim and worker’s data history, indicated that the data set is insufficient for the project objectives. Based on the DE feedback and results of external research, we enriched the data with additional variables, including: – lag between injury occurrence and claim lodgement (claim reporting lag); – information on the treatment received (e.g., type of providers visited, number of visits, provider specialty); – information on the use of medications and, specifically, on whether a potent opioid was used. Of particular relevance was the incorporation of the prior claim history of claimants, including previous claim count, type and nature of injury, and any similarity with the current injury. An Australian state workplace insurer sought to use their data to establish clear business rules that would identify, at an earlier stage of a claim, those with high probability of becoming serious/long-term.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 20
    },
    {
        "text": "Its application in the Public Healthcare sector follows its successful deployment in a number of recent real-world projects across several industries and fields, including credit risk, insurance, utilities, and sport.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 21
    },
    {
        "text": "For example, Gilpin et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 22
    },
    {
        "text": "The PDR framework (Murdoch et al., 2019), mentioned earlier, is a step in the direction of developing consistent evaluations.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 23
    },
    {
        "text": "To our knowledge, there is no formal standard for methodology in the data science projects (see Saltz and Shamshurin, 2016).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 24
    },
    {
        "text": "Through the years, the CRISP- DM methodology (Shearer, 2000) created in the late 1990s has become a de-facto standard, as evidenced from a range of works (see, e.g., Huang et al., 2014; Niño et al., 2015; Fahmy et al., 2017; Pradeep and Kallimani, 2017; Abasova et al., 2018; Ahmed et al., 2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 25
    },
    {
        "text": "An important factor of its success is the fact that it is industry, tool, and application agnostic (Mariscal et al., 2010).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 26
    },
    {
        "text": "However, the research community has emphasized that, since its creation, CRISP-DM had not been updated to reflect the evolution of the data science process needs (Mariscal et al., 2010; Ahmed et al., 2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 27
    },
    {
        "text": "While various extensions and refined versions of the methodology, including IBM’s Analytics Solutions Unified Method for Data Mining (ASUM-DM) and Microsoft’s Team Data Science Process (TDSP), were proposed to compensate the weaknesses of CRISP-DM, at this stage, none of them has become the standard.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 28
    },
    {
        "text": "The majority of organisations that apply a data analysis methodology prefers extensions of CRISP- DM (Schäfer et al., 2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 29
    },
    {
        "text": "Such extensions are fragmented and either propose additional elements into the data analysis process, or focus on organisational aspects without the necessary integration of domain-related factors (Plotnikova, 2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 30
    },
    {
        "text": "These might be the reasons for the observed decline of its usage as reported in studies by Piatetsky-Shapiro (2014), Bhardwaj et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 31
    },
    {
        "text": "(2015), and Saltz and Shamshurin (2016).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 32
    },
    {
        "text": "Finally, while methodologies from related fields, like the agile approach used in software development, are being considered for use in data science projects, there is no clear clarity on whether they are fully suitable for the purpose, as indicated by Larson and Chang (2016); therefore, we did not include them in the current scope.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 33
    },
    {
        "text": "It follows the CRISP-DM approach in terms of being industry-, tool-, and application-neutral.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 34
    },
    {
        "text": "If this level is not achieved, the solution will be inadequate for the purpose.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 35
    },
    {
        "text": "This level needs to be established and documented at the initiation stage of the project as part of requirement collection (see Stage 1 in Figure 1).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 36
    },
    {
        "text": "Obviously, this level will differ from one project to another depending on the business goals.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 37
    },
    {
        "text": "If individuals are directly and strongly affected by the solution-driven decision, e.g., in medical diagnostics or legal settings, then both the ability to understand and trust the internal logic of the model, as well as the ability of the solution to explain individual predictions, are of highest priority.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 38
    },
    {
        "text": "For example, in one of our projects, an Australian state organization wished to establish what factors influenced the proportion of children with developmental issues and what interventions can be undertaken in specific areas of the state in order to reduce that proportion.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 39
    },
    {
        "text": "The historical, socioeconomic, and geographic data provided for the project was aggregated at a geographic level of high granularity.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 40
    },
    {
        "text": "In other cases, e.g., in the case of an online purchase recommender solution, the overall outcome, such as increase in sales volume, may be of higher importance than interpretability of the model.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 41
    },
    {
        "text": "Similar requirements of solution interpretability were in a project where an organization owned assets that were located in remote areas and were often damaged by birds or animals nests.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 42
    },
    {
        "text": "The organization wished to lower their maintenance cost and planning by identifying as soon as possible the assets where such nests were present instead of doing expensive examination of each asset.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 43
    },
    {
        "text": "This was achieved by building a ML solution that classified Google Earth images of the assets into those with and without nests.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 44
    },
    {
        "text": "important to identify a proportion of assets that were as high as possible with nests on them, while misclassifying an individual asset image was not of great concern.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 45
    },
    {
        "text": "The study concludes with the three main directions for the development of the presented cross-industry standard process.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 46
    },
    {
        "text": "It is also a legal requirement.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 47
    },
    {
        "text": "The methodology then ensures that participants establish the activities for each stakeholder group at each process stage that are required to achieve this level.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 48
    },
    {
        "text": "As indicated in Kolyshkina and Simoff (2019), skipping these important phases can result in potential scope creep and even business project failure.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 49
    },
    {
        "text": "Each stage was illustrated with examples from cases from a diverse range of domains.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 50
    },
    {
        "text": "Broader comparative evaluation of the methodology is the subject of a separate study.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 51
    },
    {
        "text": "Themost typical changes, related to data availability, quality, and analysis findings, occur mostly at stages 2–4, as shown in Figure 1.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 52
    },
    {
        "text": "This is illustrated in our case study and was discussed in detail in the study by Kolyshkina and Simoff (2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 53
    },
    {
        "text": "Less often changes occur at stages 5–7 in Figure 1.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 54
    },
    {
        "text": "From experiential observations, such changes are more likely to occur in longer projects with a volume of work requiring more than 6–8 months for completion.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 55
    },
    {
        "text": "They are usually driven by amendments in project scope and requirements including the necessary level of interpretability (NLI), that are caused by factors external to the analytical part of the project.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 56
    },
    {
        "text": "INTRODUCTION AND BACKGROUND TO THE PROBLEM Contemporary data collection and linking capabilities, combined with the growing diversity of the data-driven artificial intelligence (AI) techniques, including machine learning (ML) techniques, and the broader deployment of these techniques in data science and analytics, have had a profound impact on decision-making across many areas of human endeavors.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 57
    },
    {
        "text": "For consistency of the demonstration, we draw all detailed examples through the study from the specific public health case study.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 58
    },
    {
        "text": "The methodological treatment of interpretability in evolving scenarios and options is beyond the scope of this study.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 59
    },
    {
        "text": "We would like to emphasize that the specific analytic techniques and tools mentioned in the respective stages of the case study are relevant specifically to this particular study.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 60
    },
    {
        "text": "However, there are many other available methods andmethod combinations that can achieve the objectives of this and other projects.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 61
    },
    {
        "text": "All sensitive data and information have been masked and altered to protect privacy and confidentiality, without loss of the sensible aspects relevant to this presentation.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 62
    },
    {
        "text": "4.1.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 63
    },
    {
        "text": "Background.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 64
    },
    {
        "text": "A further requirement was that the prediction model should be easily interpretable by the business.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 65
    },
    {
        "text": "We use the term solution to denote the algorithmic decision-making scenarios involving ML and AI algorithms (Davenport and Kalakota, 2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 66
    },
    {
        "text": "The IM as a structure for capturing and translating interpretability requirements into specific actions and activities is generalized.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 67
    },
    {
        "text": "However, the specific content of its cells depends on the project.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 68
    },
    {
        "text": "It covers the activities needed to start up the data science project: (a) the identification of key stakeholders; (b) documenting project objectives and scope; (c) collecting requirements; (d) agreeing upon initial data; (e) preparing a detailed scope statement; and (f) developing project schedule and plan.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 69
    },
    {
        "text": "The deliverable of this stage was a project charter documenting the above activities.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 70
    },
    {
        "text": "4.2.1.1. Business objectives and main stakeholders.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 71
    },
    {
        "text": "Front.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 72
    },
    {
        "text": "The established objectives included: 1.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 73
    },
    {
        "text": "Be accurate, robust, and work with real-world organizational data; 4.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 74
    },
    {
        "text": "Have easy-to-understand outputs that would make sense to the executive team and end users (case managers) and that the end users could trust; 5.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 75
    },
    {
        "text": "Present the output as business rules that are easy to understand for end users and to deploy, monitor, and update in organizational data.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 76
    },
    {
        "text": "The main stakeholders were identified as follows: Executive team (E); End Users/Domain Experts, i.e., Case management team (DE); Information Technology team who would implement the solution in the organizational data (IT); Business Intelligence team who would monitor the solution performance and update the underlying model (BI); and Modeling team (M).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 77
    },
    {
        "text": "These abbreviations are used further in the descriptions of the stages of the IM.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 78
    },
    {
        "text": "– The E, IT, and DE teams needed to have a clear understanding of all internal and external data inputs to be used: their reliability, quality, and whether the internal inputs were representative of the organizational data that the solution would be deployed on.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 79
    },
    {
        "text": "– The E and DE teams needed to have a clear understanding of the high-level data processing approach (e.g., missing values treatment, aggregation level), as well as high-level modeling approach and its proven validity.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 80
    },
    {
        "text": "– The outputs needed to be provided in the form of easily understandable business rules.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 81
    },
    {
        "text": "The E and DE teams needed to gain a clear understanding of the rules and to be able to assess their business validity and usefulness from the business point of view.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 82
    },
    {
        "text": "– The BI team, who would monitor the solution performance and update it as required, need to have a clear understanding of: – the data processing stage, as well as the modeling algorithm, its validity, and suitability from the ML point of view; – how to assess the solution performance and how the solution needs to be audited, monitored, and updated, as well as how often this should occur.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 83
    },
    {
        "text": "– The IT team, who would deploy the solution needed to have a clear understanding of the format of the output and confirm that it can be deployed in the organizational data within the existing constraints (e.g., resources, cost) and without disrupting the existing IT systems.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 84
    },
    {
        "text": "Creating the Project IM: An Overall Approach The next step is to create and fill out the IM, whose rows show CRISP-ML stages, and columns represent key stakeholders.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 85
    },
    {
        "text": "Matrix cells can be grouped horizontally when there are common requirements for a group of stakeholders.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 86
    },
    {
        "text": "Matrix cells can be grouped vertically when there are common requirements for a specific stakeholder across a number of stages in CRISP-ML.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 87
    },
    {
        "text": "This matrix, once completed, becomes part of the business requirements document.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 88
    },
    {
        "text": "The activities it outlines are integrated into the project plan and are reviewed and updated along with the project plan.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 89
    },
    {
        "text": "4.2.2.1.Definition of stakeholder involvement extent.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 90
    },
    {
        "text": "For example, this can refer to DE and IT providing information helping to better understand data sources and business processes of the organization.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 91
    },
    {
        "text": "These aspects have been emphasized by a number of recent studies, most notably in Caruana et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 92
    },
    {
        "text": "– low extent of involvement—the stakeholder group is kept informed on the general progress of the stage.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 93
    },
    {
        "text": "In Figure 2, green color background indicates high extent of involvement of a stakeholder group, yellow color shows medium extent of involvement, and the cells with no color in the background show low level of involvement.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 94
    },
    {
        "text": "Depending on the project, the coloring of the cells of the IM will vary.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 95
    },
    {
        "text": "For example, if it had not been necessary to provide knowledge transfer (“Ongoing knowledge and skill development”) to the BI team, then their involvement in Stage 2–5 would have been low and the respective cells would have been left with no color in the background.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 96
    },
    {
        "text": "4.2.2.2.High-level IM diagram.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 97
    },
    {
        "text": "Stage 2.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 98
    },
    {
        "text": "This stage established that the data contained characteristics that significantly complicated the modeling, such as a large degree of random variation, multicollinearity, and a highly categorical nature of many potentially important predictors.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 99
    },
    {
        "text": "These findings helped guide the selection of the modeling and data pre-processing approach.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 100
    },
    {
        "text": "(2017), and summarized in the study by Ahmad et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 101
    },
    {
        "text": "Random variation.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 102
    },
    {
        "text": "During workshops with E, DE, and other industry experts, it became clear that there were certain “truths” that pervaded the industry, and we used these to engage with subject matter experts (SME) and promote the value of our modeling project.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 103
    },
    {
        "text": "Our analysis demonstrated the enormous amount of random variation that existed in the data.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 104
    },
    {
        "text": "For example, age, body location, and injury type only explained 3–7% of variation in claim duration.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 105
    },
    {
        "text": "Our exploratory analysis revealed strong random variation in the data, confirming the prevalent view among the workers’ compensation experts that it is the intangible factors, like the injured worker’s mindset and relationship with the employer, that play the key role in the speed of recovery and returning to work.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 106
    },
    {
        "text": "The challenge for the modeling, therefore, was to uncover the predictors that represent these intangibles.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 107
    },
    {
        "text": "Sparseness.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 108
    },
    {
        "text": "Most of the available variables were categorical with large numbers of categories.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 109
    },
    {
        "text": "For example, the variable “Injury Nature” has 143 categories and “Body Location of Injury” has 76 categories.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 110
    },
    {
        "text": "Further, some categories had relatively few observations which made any analysis involving them potentially unreliable and not statistically valid.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 111
    },
    {
        "text": "Such sparseness presented another data challenge.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 112
    },
    {
        "text": "Multicollinearity.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 113
    },
    {
        "text": "There was a high degree of multicollinearity between numerical variables in the data.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 114
    },
    {
        "text": "Data pre-processing.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 115
    },
    {
        "text": "First, we reduced the sparseness among categories by combining some categorical levels in consultation with SMEs to ensure that the changes made business sense.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 116
    },
    {
        "text": "Second, we used a combination of correlation analysis, as well as advanced clustering and feature selection approaches, e.g., Random Forests (see, e.g., Shi and Horvath, 2006) and PCAMIX method using iterative relocation algorithm and ascendant hierarchical clustering (Chavent et al., 2012) to reduce multicollinearity and exclude any redundant variables.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 117
    },
    {
        "text": "Healthcare, similar to government and business digital services, manufacturing with its industrial internet of things and creative industries, experienced the much celebrated manifestations of “big data,” “small data,” “rich data,” and the increased impact of ML solutions operating with these data.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 118
    },
    {
        "text": "Stage 3.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 119
    },
    {
        "text": "This stage is often either omitted or not stated explicitly in other processes/frameworks (Kolyshkina and Simoff, 2019); however, it is crucial for the project success because it establishes whether the information in the data is sufficient for achieving the project goals.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 120
    },
    {
        "text": "To efficiently evaluate what accuracy could be achieved with the initially supplied data, we employed the following different data science methods that have proven their excellence at extracting maximum predictive power from the data: Deep Neural Nets, Random Forests, XGBoost, and Elastic Net.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 121
    },
    {
        "text": "The results were consistent for all the methods used and showed that only a small proportion of the variability of claim duration was explained by the information available in the data.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 122
    },
    {
        "text": "Data enrichment was required.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 123
    },
    {
        "text": "These findings were discussed with DE who then were invited to share their business knowledge about sources that could enrich the initial data predictive power.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 124
    },
    {
        "text": "Stage 4.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 125
    },
    {
        "text": "Data enrichment.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 126
    },
    {
        "text": "We assessed the predictive value of the enriched data in the same way as before (see section 4.3.2.2), and found that there was a significant increase in the proportion of variability explained by the model.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 127
    },
    {
        "text": "Further, the data enrichment was a key step in building further trust of the DE team.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 128
    },
    {
        "text": "This shift has been further accentuated by the growing worldwide commitment of governments, industries, and individual organizations to address their endeavors toward the UnitedNations Sustainable Development Goals1 and by the data- dependent scientific and technological challenges faced by the rapid response to the COVID-19 pandemic.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 129
    },
    {
        "text": "In our case, it was required that the model explained at least 70% of variability.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 130
    },
    {
        "text": "At this stage, the ML techniques to be used for modeling are selected, taking into account the predictive power of the model, its suitability for the domain and the task, and the NLI.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 131
    },
    {
        "text": "The data is pre-processed, and modeled, and the model performance is evaluated.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 132
    },
    {
        "text": "The solution output was required to be produced in the form of business rules, and therefore, the feature engineering methods and modeling algorithms used included rule-based techniques, e.g., decision trees, and association rules- based methods.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 133
    },
    {
        "text": "The later challenges highlight and reinforce the central role of healthcare, backed by science, technology, lateral thinking, and innovative solutions in societal and economic recovery.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 134
    },
    {
        "text": "Modelers, BI and DEs, prepared a detailed presentation for the E, explaining not only the learnings from the solution but also the high-level model structure and its accuracy.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 135
    },
    {
        "text": "Stage 7 The final model provided the mechanism for the organization to allocate claims to risk segments based on the information known at early stages.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 136
    },
    {
        "text": "From the technical point of view, the business rules were confirmed by the E, DE, and IT to be easy to deploy as they are readily expressed as SQL code.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 137
    },
    {
        "text": "Based on this success, a modified version of claims triage was deployed into production.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 138
    },
    {
        "text": "Figure 9 shows the shift of responsibilities for ensuring the achieved interpretability level is maintained during the future use of the solution.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 139
    },
    {
        "text": "At this stage, the deployment was being scheduled, and the monitoring/updating process and schedule was prepared, based on the technical report provided by the M team that included project code, the solution manual, and updating and monitoring recommendations.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 140
    },
    {
        "text": "If needed, the logic behind the decisions can be explained to any external party.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 141
    },
    {
        "text": "Some state-of-the-art overviews, such as Doshi-Velez andKim (2017) and Gilpin et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 142
    },
    {
        "text": "Such capability is essential in many areas, especially in health- related fields.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 143
    },
    {
        "text": "It allows the end users to confidently interpret the ML output use to make successful evidence-based decisions.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 144
    },
    {
        "text": "First, we showed how it was established by working with the key stakeholders (Executive team, end users, IT team, etc.).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 145
    },
    {
        "text": "(2019) related to interpretability, as well 1https://www.un.org/sustainabledevelopment/sustainable-development-goals/ and https://sdgs.un.org/goals.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 146
    },
    {
        "text": "Then, we described how the activities that were required to be included at each stage of building the ML solution to ensure that this level is achieved was determined.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 147
    },
    {
        "text": "Finally, we described how these activities were integrated into each stage.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 148
    },
    {
        "text": "as more method-focused papers, like Lipton (2018) and Molnar et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 149
    },
    {
        "text": "This strategic development adds the necessary agility for the relevance of the presented cross-industry standard process.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 150
    },
    {
        "text": "DATA AVAILABILITY STATEMENT The original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 151
    },
    {
        "text": "AUTHOR CONTRIBUTIONS All authors listed have made a substantial, direct and intellectual contribution to the work, and approved it for publication.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 152
    },
    {
        "text": ": DP180100893).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 153
    },
    {
        "text": "REFERENCES Abasova, J., Janosik, J., Simoncicova, V., and Tanuska, P. (2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 154
    },
    {
        "text": "“Proposal of effective preprocessing techniques of financial data,” in 2018 IEEE 22nd International Conference on Intelligent Engineering Systems (INES) (IEEE), 293–298.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 155
    },
    {
        "text": "IEEE Intell.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 156
    },
    {
        "text": "Inform.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 157
    },
    {
        "text": "Bull.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 158
    },
    {
        "text": "Available online at: https://www.comp.hkbu.edu.hk/~cib/2018/Aug/iib_vol19no1.pdf Ahmed, B., Dannhauser, T., and Philip, N. (2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 159
    },
    {
        "text": "“A lean design thinking methodology (LDTM) for machine learning and modern data projects,” in Proceedings of 2018 10th Computer Science and Electronic Engineering (CEEC) (IEEE), 11–14.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 160
    },
    {
        "text": "Comparative research about high failure rate of it projects and opportunities to improve.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 161
    },
    {
        "text": "PM World J. VI, 1–10.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 162
    },
    {
        "text": "Available online at: https://pmworldlibrary.net/wp-content/uploads/2017/02/pmwj55- Feb2017-Arcidiacono-high-failure-rate-of-it-projects-featured-paper.pdf Athey, S. (2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 163
    },
    {
        "text": "“The impact of machine learning on economics,” in The Economics of Artificial Intelligence: An Agenda, eds A. Agrawal, J. Gans, and A. Goldfarb (Chicago, IL: University of Chicago Press), 507–547.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 164
    },
    {
        "text": "Toward accountable discrimination- aware data mining: the importance of keeping the human in the loop and under the looking glass.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 165
    },
    {
        "text": "Big Data 5, 135–152.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 166
    },
    {
        "text": "“DataHub: collaborative data science and & dataset version management at scale,” in Proceedings of the 7th Biennial Conference on Innovative Data Systems Research (CIDR’15), January 4–7, 2015 (Asilomar, CA).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 167
    },
    {
        "text": "“Intelligible models for healthcare: predicting pneumonia risk and hospital 30-day readmission,” in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’15 (New York, NY: Association for Computing Machinery), 1721–1730.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 168
    },
    {
        "text": "Use Analytic Business Processes to Drive Business Performance.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 169
    },
    {
        "text": "Technical report, Gartner.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 170
    },
    {
        "text": "In addition, the current research seems to focus on particular categories or techniques instead of addressing the overall concept of interpretability.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 171
    },
    {
        "text": "Clustofvar: an R package for the clustering of variables.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 172
    },
    {
        "text": "Softw.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 173
    },
    {
        "text": "“Xgboost: a scalable tree boosting system,” in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’16 (New York, NY: Association for Computing Machinery), 785–794.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 174
    },
    {
        "text": "SAGE Open 1, 1–9.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 175
    },
    {
        "text": "Recent systematic review studies, Gilpin et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 176
    },
    {
        "text": "Digital technology: the potential for artificial intelligence in healthcare.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 177
    },
    {
        "text": "Future Healthc.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 178
    },
    {
        "text": "Artificial Intelligence: Australia’s Ethics Framework.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 179
    },
    {
        "text": "Technical report, Data61 CSIRO, Australia.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 180
    },
    {
        "text": "(2018) and Mittelstadt et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 181
    },
    {
        "text": "“The big data analytics gold rush: a research framework for coordination and governance,” in Proceedings of the 49th Hawaii International Conference on System Sciences (HICSS), 1112–1121.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 182
    },
    {
        "text": "General data protection regulation (GDPR).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 183
    },
    {
        "text": "Off.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 184
    },
    {
        "text": "The rapid growth of data collection and linking capabilities combined with the increasing diversity of the data-driven AI techniques, including machine learning (ML), has brought both ubiquitous opportunities for data analytics projects and increased demands for the regulation and accountability of the outcomes of these projects.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 185
    },
    {
        "text": "Union L 119.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 186
    },
    {
        "text": "“A data mining experimentation framework to improve six sigma projects,” in 2017 13th International Computer Engineering Conference (ICENCO), 243–249.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 187
    },
    {
        "text": "doi: 10.1109/ICENCO.2017.8289795 Freitas, A.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 188
    },
    {
        "text": "SIGKDD Explor.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 189
    },
    {
        "text": "Newslett.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 190
    },
    {
        "text": "Datanami.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 191
    },
    {
        "text": "Gilpin, L. H., Bau, D., Yuan, B.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 192
    },
    {
        "text": "Explaining explanations to society.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 193
    },
    {
        "text": "CoRR abs/1901.06560.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 194
    },
    {
        "text": "Gleicher, M. (2016).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 195
    },
    {
        "text": "A framework for considering comprehensibility in modeling.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 196
    },
    {
        "text": "Big Data 4, 75–88.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 197
    },
    {
        "text": "Deep Learning.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 198
    },
    {
        "text": "MIT Press.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 199
    },
    {
        "text": "Goodson, M. (2016).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 200
    },
    {
        "text": "KDnuggets.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 201
    },
    {
        "text": "Goodwin, B.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 202
    },
    {
        "text": "(2011).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 203
    },
    {
        "text": "Poor Communication to Blame for Business Intelligence Failure, Says Gartner.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 204
    },
    {
        "text": "Computer Weekly.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 205
    },
    {
        "text": "Google (2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 206
    },
    {
        "text": "Technical report, Google AI.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 207
    },
    {
        "text": "Do not trust additive explanations.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 208
    },
    {
        "text": "Interpretable meta-measure for model performance.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 209
    },
    {
        "text": "doi: 10.1109/BigData.2014.7004470 Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., and Pedreschi, D. (2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 210
    },
    {
        "text": "A survey of methods for explaining black box models.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 211
    },
    {
        "text": "Surv.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 212
    },
    {
        "text": "doi: 10.1007/978-3-030-28954-6_3 Holzinger, A., Biemann, C., Pattichis, C. S., and Kell, D. B.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 213
    },
    {
        "text": "“A comprehensive framework design for continuous quality improvement within the neonatal intensive care unit: integration of the SPOE, CRISP-DM and PaJMa models,” in IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), 289–292.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 214
    },
    {
        "text": "doi: 10.1109/BHI.2014.6864360 IBM Analytics (2015).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 215
    },
    {
        "text": "IBM Analytics Solutions Unified Method (ASUM).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 216
    },
    {
        "text": "Medium: Data Series.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 217
    },
    {
        "text": "Kaggle (2020).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 218
    },
    {
        "text": "State of Machine Learning and Data Science 2020 Survey.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 219
    },
    {
        "text": "Technical report, Kaggle.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 220
    },
    {
        "text": "Available online at: https://www.kaggle.com/c/kaggle-survey- 2020 Kennedy, P., Simoff, S. J., Catchpoole, D. R., Skillicorn, D. B., Ubaudi, F., and Al-Oqaily, A.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 221
    },
    {
        "text": "(2008).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 222
    },
    {
        "text": "“Integrative visual data mining of biomedical data: investigating cases in chronic fatigue syndrome and acute lymphoblastic leukaemia,” in Visual Data Mining: Theory, Techniqus and Tools for Visual Analytics, Volume 4404 of LNCS, eds S. J. Simoff, M. H. Böhlen, and A. Mazeika (Berlin; Heidelberg:Springer), 367–388.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 223
    },
    {
        "text": "(Singapore: Springer Singapore), 156–170.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 224
    },
    {
        "text": "A review and future direction of agile, business intelligence, analytics and data science.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 225
    },
    {
        "text": "Int.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 226
    },
    {
        "text": "Inform.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 227
    },
    {
        "text": "Manage.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 228
    },
    {
        "text": "“A unified approach to interpreting model predictions,” in Advances in Neural Information Processing Systems 30, eds I. Guyon, U. V. Luxburg, S. Bengio, H.Wallach, R. Fergus, S. Vishwanathan, et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 229
    },
    {
        "text": "(Curran Associates, Inc.), 4765–4774.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 230
    },
    {
        "text": "(2019) provide a compact and systematic approach toward their categorization and evaluation.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 231
    },
    {
        "text": "A survey of data mining and knowledge discovery process models and methodologies.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 232
    },
    {
        "text": "Knowl.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 233
    },
    {
        "text": "Eng.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 234
    },
    {
        "text": "Rev.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 235
    },
    {
        "text": "IEEE Access 8, 191969–191985.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 236
    },
    {
        "text": "doi: 10.1109/ACCESS.2020.3032756 Microsoft (2020).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 237
    },
    {
        "text": "Methods are categorized into model-based and post-hoc interpretation methods.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 238
    },
    {
        "text": "Team Data Science Process.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 239
    },
    {
        "text": "Microsoft.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 240
    },
    {
        "text": "Miller, T. (2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 241
    },
    {
        "text": "Artif.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 242
    },
    {
        "text": "Intell.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 243
    },
    {
        "text": "doi: 10.1016/j.artint.2018.07.007 Mittelstadt, B., Russell, C., andWachter, S. (2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 244
    },
    {
        "text": "They are evaluated using predictive accuracy, descriptive accuracy, and relevancy, the PDR framework (Murdoch et al., 2019), where relevancy is evaluated against human audience.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 245
    },
    {
        "text": "Proc.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 246
    },
    {
        "text": "Natl.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 247
    },
    {
        "text": "Acad.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 248
    },
    {
        "text": "Sci.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 249
    },
    {
        "text": "The framework also provides common terminology for practitioners.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 250
    },
    {
        "text": "Technical report.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 251
    },
    {
        "text": "Boston, MA; New York, NY; San Francisco, CA; Raleigh, NC: NewVantagePartners LLC.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 252
    },
    {
        "text": "Niaksu, O.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 253
    },
    {
        "text": "Crisp data mining methodology extension for medical domain.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 254
    },
    {
        "text": "Baltic J. Mod.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 255
    },
    {
        "text": "Guidotti et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 256
    },
    {
        "text": "“Business understanding, challenges and issues of Big Data Analytics for the servitization of a capital equipment manufacturer,” in 2015 IEEE International Conference on Big Data, Oct 29–Nov 01, 2015, eds H. Ho, B. C. Ooi, M. J. Zaki, X. Hu, L. Haas, V. Kumar, et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 257
    },
    {
        "text": "Piatetsky-Shapiro, G. (2014).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 258
    },
    {
        "text": "CRISP-DM, still the top methodology for analytics, data mining, or data science projects.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 259
    },
    {
        "text": "KDnuggets News 14.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 260
    },
    {
        "text": "Plotnikova, V. (2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 261
    },
    {
        "text": "“Towards a data mining methodology for the banking domain,” in Proceedings of the Doctoral Consortium Papers Presented at the 30th International Conference on Advanced Information Systems Engineering (CAiSE 2018), eds M. Kirikova, A. Lupeikiene, and E. Teniente, 46–54.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 262
    },
    {
        "text": "PMI (2017).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 263
    },
    {
        "text": "PMBOKr Guide, 6th Edn.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 264
    },
    {
        "text": "Project Management Institute.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 265
    },
    {
        "text": "“A survey on various challenges and aspects in handling big data,” in Proceedings of the 2017 International Conference on Electrical, Electronics, Communication, Computer, and Optimization Techniques (ICEECCOT), 1–5.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 266
    },
    {
        "text": "doi: 10.1109/ICEECCOT.2017.8284606 Qayyum, A., Qadir, J., Bilal, M., and Al-Fuqaha, A.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 267
    },
    {
        "text": "(2021).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 268
    },
    {
        "text": "Secure and robust machine learning for healthcare: a survey.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 269
    },
    {
        "text": "IEEE Rev.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 270
    },
    {
        "text": "Biomed.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 271
    },
    {
        "text": "Eng.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 272
    },
    {
        "text": "Minding the Analytics Gap.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 273
    },
    {
        "text": "MIT Sloan Management Review.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 274
    },
    {
        "text": "“Why should I trust you?”: explaining the predictions of any classifier,” in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’16) (New York, NY: ACM), 1135–1144.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 275
    },
    {
        "text": "Mi et al.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 276
    },
    {
        "text": "CIO Dive.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 277
    },
    {
        "text": "Rudin, C. (2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 278
    },
    {
        "text": "Nat.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 279
    },
    {
        "text": "Mach.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 280
    },
    {
        "text": "Intell.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 281
    },
    {
        "text": "“Comapring data science project management methodologies via a controlled experiment,” in HICSS.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 282
    },
    {
        "text": "“Synthesizing CRISP-DM and quality management: a data mining approach for production processes,” in 2018 IEEE International Conference on Technology Management, Operations and Decisions (ICTMOD), 190–195.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 283
    },
    {
        "text": "Data Warehousing 5, 13–22.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 284
    },
    {
        "text": "Available online at: https://mineracaodedados.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 285
    },
    {
        "text": "files.wordpress.com/2012/04/the-crisp-dm-model-the-new-blueprint-for- data-mining-shearer-colin.pdf Shi, T., and Horvath, S. (2006).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 286
    },
    {
        "text": "Unsupervised learning with random forest predictors.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 287
    },
    {
        "text": "Graph.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 288
    },
    {
        "text": "Stat.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 289
    },
    {
        "text": "doi: 10.1198/106186006X94072 Stieglitz, C. (2012).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 290
    },
    {
        "text": "“Beginning at the end-requirements gathering lessons from a flowchart junkie,” in PMIr Global Congress 2012–North America, Vancouver, British Columbia, Canada (Newtown Square, PA: Project Management Institute).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 291
    },
    {
        "text": "Available online at: https://www.pmi.org/learning/ library/requirements-gathering-lessons-flowchart-junkie-5981 Stiglic, G., Kocbek, P., Fijacko, N., Zitnik, M., Verbert, K., and Cilar, L. (2020).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 292
    },
    {
        "text": "WIREs Data Mining Knowl.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 293
    },
    {
        "text": "Discov.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 294
    },
    {
        "text": "(2020).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 295
    },
    {
        "text": "While there has been some progress in the development of ML methods, the methodological side has shown limited progress.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 296
    },
    {
        "text": "Evolution and impact of bias in human and machine learning algorithm interaction.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 297
    },
    {
        "text": "PLoS ONE 15:e0235502.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 298
    },
    {
        "text": "Gartner Survey Shows Organizations Are Slow to Advance in Data and Analytics.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 299
    },
    {
        "text": "Gartner Press Release.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 300
    },
    {
        "text": "Vellido, A.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 301
    },
    {
        "text": "(2020).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 302
    },
    {
        "text": "Neural Comput.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 303
    },
    {
        "text": "Appl.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 304
    },
    {
        "text": "32, 18069–18083.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 305
    },
    {
        "text": "doi: 10.1007/s00521-019- 04051-w Violino, B.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 306
    },
    {
        "text": "CIO.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 307
    },
    {
        "text": "Wallace, N., and Castro, D. (2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 308
    },
    {
        "text": "The Impact of the EU’s New Data Protection Regulation on AI.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 309
    },
    {
        "text": "Technical report, Center for Data Innovation.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 310
    },
    {
        "text": "Weller, A.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 311
    },
    {
        "text": "doi: 10.1007/978-3-030-28 954-6_2 Conflict of Interest: IK was employed by the company Analytikk Consulting Services.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 312
    },
    {
        "text": "The remaining author declares that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 313
    },
    {
        "text": "Copyright © 2021 Kolyshkina and Simoff.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 314
    },
    {
        "text": "This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 315
    },
    {
        "text": "The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 316
    },
    {
        "text": "No use, distribution or reproduction is permitted which does not comply with these terms.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 317
    },
    {
        "text": "For instance, the human-centric visual analytics methodology “Extract- Explain-Generate” for interrogating biomedical data (Kennedy et al., 2008) explicitly relates different stakeholders (molecular biologist, clinician, analysts, and managers) with specific areas of knowledge extraction and understanding associated with the management of patients.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 318
    },
    {
        "text": "2.1.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 319
    },
    {
        "text": "The latest NewVantage Partners Big Data and AI Executive Survey, based on the responses from C-Executives from 85 blue-chip companies of which 22% are from Healthcare and Life Sciences, noted that only 39% of companies are managing data as an asset (NewVantage Partners LLC, 2021).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 320
    },
    {
        "text": "Fujimaki (2020) emphasized that “the economic downturn caused by the COVID-19 pandemic has placed increased pressure on data science and BI teams to deliver more with less.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 321
    },
    {
        "text": "Only 24% have created a data-driven organization, a decline from 37.8%, and only 24% have forged a data culture (NewVantage Partners LLC, 2021), a result which, to a certain extent, is counterintuitive to the overall expectation of the impact of AI technologies to decision- making and which projected benefits from the adoption of such technologies.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 322
    },
    {
        "text": "Further, studies have shown that the biased focus on the tools and systems has limited the ability to gain value from the effort of organizational analytics effort (Ransbotham et al., 2015) and that data science projects need to increase their focus on process and task coordination (Grady et al., 2014; Gao et al., 2015; Espinosa and Armour, 2016).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 323
    },
    {
        "text": "(2019) found that the reliability of some of these methods deteriorates if the number of features is large or if the level of feature interactions is high, which is often the case in health data.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 324
    },
    {
        "text": "There is a firm recognition of the impact of ML solutions in economics, including health economics, especially in addressing “predictive policy” problems (Athey, 2019).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 325
    },
    {
        "text": "Many authors (e.g., Holzinger et al., 2017; Dawson et al., 2019; Rudin, 2019) note that in the high-stake areas (e.g., medical field, healthcare) solutions, in which the inner workings are not transparent (Weller, 2019), can be unfair, unreliable, inaccurate, and even harmful.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 326
    },
    {
        "text": "Such views are reflected in the legislation on data-driven algorithmic decision-making, which affects citizens across the world.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 327
    },
    {
        "text": "The European Union’s General Data Protection Regulation (GDPR) (EU, 2016), which entered into force in May 2018, is an example of such early legislation.",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 328
    },
    {
        "text": "In the context of the emerging algorithmic economy, there are also warnings to policymakers to be aware of the potential impact of legislations like GDPR on the development of new AI and ML solutions (Wallace and Castro, 2018).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 329
    },
    {
        "text": "In healthcare, such pressure is amplified by the nature of the interactive processes, wherein neither humans nor the algorithms operate with unbiased data (Sun et al., 2020).",
        "paperTitle": "Interpretability of machine learning solutions in public healthcare : the CRISP-ML approach",
        "doi": "10.3389/fdata.2021.660206",
        "chunk_index_in_doc": 330
    },
    {
        "text": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 900 | P a g e Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management Ashwini M. Save1, Tatwadarshi P. Nagarhalli2, Kirtida Naik3, Manish Rana4, Sunny Sall5, Anas Dange6, Shabina Sayed 7 1Vidyavardhini's College of Engineering and Technology (VCET), Vasai, Mumbai, India 2Vidyavardhini's College of Engineering and Technology(VCET), Vasai, Mumbai, India 3Viva institute of Technology (VIT), Shrigaon,Virar, Mumbai, India 4St. John College of Engineering & Management (SJCEM) Palghar, Mumbai, India 5St. John College of Engineering & Management (SJCEM) Palghar, Mumbai, India 6Universal College of Engineering (UCE),Vasai Mumbai, India 7M.H. Saboo Siddik College Of Engineering (MHSSCE), Byculla, Mumbai-India KEYWORDS Machine Learning (ML), Disease Prediction, Chronic Disease Management, Healthcare Accessibility, Ethical Considerations etc. ABSTRACT: The integration of advanced machine learning (ML) techniques into public health systems offers transformative potential for improving disease prediction, prevention, and management. With the increasing availability of large datasets and computational power, ML has emerged as a powerful tool to extract insights and make data-driven decisions in healthcare. This paper explores the application of various machine learning models, such as supervised learning, deep learning, and reinforcement learning, in addressing key challenges in public health. We discuss the impact of ML in areas such as epidemiology, chronic disease management, healthcare accessibility, and health outcomes prediction. Furthermore, we highlight the ethical considerations, data privacy concerns, and the potential for bias in ML systems when used in public health. This study also evaluates the effectiveness of novel ML techniques in reducing healthcare costs, improving patient care, and guiding public health policy development. Through case studies and a review of recent advancements, the paper presents recommendations for optimizing ML algorithms for more accurate, equitable, and efficient public health interventions. Introduction 1. Overview of Public Health Challenges Public health faces a multitude of global challenges, many of which are compounded by increasing populations, urbanization, and climate change. Pandemics, such as the recent COVID-19 crisis, highlight the vulnerabilities of health systems worldwide and underscore the need for rapid, data-driven responses. Chronic diseases, including diabetes, heart disease, and cancer, continue to burden health systems, leading to millions of preventable deaths each year. Ashwini M. Save: Associate Professor of Information Technology, Vidyavardhini’s College of Engineering and Technology, Vasai Road-401202, INDIA. E-Mail: ashwini.save@gmail.com. Tatwadarshi P. Nagarhalli: Associate Professor of Artificial Intelligence and Data Science , Vidyavardhini’s College of Engineering and Technology, Vasai Road-401202, INDIA. E-Mail: tatwadarshipn@gmail.com 3Ms. Kirtida Naik: Assistant Professor of Computer Engineering, Viva Institute of Technology (VIT) Shirgaon, Virar-401305, INDIA. E-Mail: kirtidanaik.28@gmail.com 4Dr. Manish Rana: Associate Professor of Information Technology, St. John College of Engineering & Management (SJCEM) Palghar-401404, INDIA. E-Mail: dr.manish_rana@yahoo.co.in. Sunny Sall: Assistant Professor of Computer Engineering, St. John College of Engineering & Management (SJCEM) Palghar-401404, INDIA. E-Mail: sunny_sall@yahoo.co.in. 6 Mr. Anas Dange: Assistant Professor of Artificila Intelligence and Machine Learning (AIML), Universal College of Engineering (UCE) Vasai-401208, INDIA. E-Mail: anas.dange@gmail.com. 7 Dr. Shabina Sayed: Assistant Professor of Information Technology, M.H. Saboo Siddik College Of Engineering (MHSSCE), Mumbai-400011, INDIA. E-Mail: Shabina.sayed@mhssce.ac.in. Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 901 | P a g e Healthcare disparities, driven by socioeconomic factors, geography, and access to care, exacerbate these challenges, leaving certain populations more vulnerable to poor health outcomes. Emerging health threats, such as antibiotic resistance and new infectious diseases, further complicate efforts to ensure global health security. Machine learning (ML) has the potential to address many of these challenges by harnessing large-scale health data. With access to electronic health records (EHRs), genetic data, real-time surveillance data from wearables and mobile apps, and public health reports, ML algorithms can analyze complex datasets to identify patterns, predict disease outbreaks, and personalize treatment plans. By utilizing this data, ML can improve early diagnosis, streamline resource allocation, and enhance public health decision-making, ultimately leading to better health outcomes and more equitable healthcare delivery. Relevance of Machine Learning Machine learning (ML) is a subset of artificial intelligence (AI) that enables computers to learn from data without being explicitly programmed. In the context of public health, ML plays a critical role in improving healthcare delivery and outcomes by analyzing large and diverse datasets. Predictive modeling, one of the key applications of ML, involves using historical and real-time data to forecast future events, such as disease outbreaks, patient admissions, or health outcomes. Pattern recognition enables ML to detect hidden relationships and trends in health data that may be too complex for traditional statistical methods. Additionally, ML’s ability to automate decision-making processes allows health systems to respond faster and more accurately, reducing human error and improving efficiency.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 0
    },
    {
        "text": "ML’s relevance to public health lies in its capacity to process vast amounts of health-related data and provide actionable insights. By integrating ML into health systems, policymakers, healthcare providers, and researchers can make more informed, data-driven decisions, from predicting the spread of infectious diseases to personalizing treatments for chronic conditions. As healthcare systems continue to evolve, ML’s ability to analyze diverse health data will become increasingly vital in addressing global health challenges and achieving more effective, equitable, and sustainable healthcare outcomes. Key Areas Where Machine Learning is Impacting Public Health 1. Epidemiological Prediction and Surveillance Disease Outbreak Prediction: Machine learning (ML) has become an invaluable tool in predicting disease outbreaks by analyzing large datasets and recognizing patterns that can signal the onset of an epidemic. Time series forecasting models and deep learning algorithms, such as recurrent neural networks (RNNs) and long short-term memory (LSTM) networks, can process historical data on disease prevalence, social behavior, climate patterns, and population movement to predict future outbreaks. For example, during the COVID-19 pandemic, ML models helped predict infection rates, hospital admissions, and regional hotspots based on real-time data. Similarly, ML has been used to predict seasonal outbreaks like influenza, giving public health officials the ability to implement timely preventive measures and allocate resources effectively. Surveillance Systems: Machine learning is also revolutionizing real-time disease surveillance. Mobile health applications, wearable devices, and big data sources such as social media activity or search engine queries can feed continuous data into ML models to monitor and track disease trends. For example, ML-driven systems can analyze data from wearable sensors to detect early signs of infectious diseases in individuals before they show symptoms, allowing for early intervention. Furthermore, big data sources can be used to identify clusters of diseases or health anomalies, facilitating rapid responses and targeted public health interventions. By providing timely and accurate surveillance, ML enhances global and local disease monitoring capabilities. Chronic Disease Management Diabetes, Cardiovascular Disease, and Cancer: ML models have made significant contributions to managing chronic diseases like diabetes, cardiovascular disease, and cancer Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 902 | P a g e by predicting patient outcomes and optimizing treatment plans. Supervised learning algorithms, including decision trees, support vector machines (SVM), and ensemble methods, are used to predict the progression of diseases based on historical health data, patient demographics, and lifestyle factors. For instance, ML models can identify high-risk individuals for diabetes by analyzing their medical history, blood sugar levels, and other factors. In the case of cardiovascular diseases, predictive models can assess the likelihood of a patient experiencing heart attacks or strokes and recommend preventive measures. Similarly, cancer detection models, which analyze medical imaging data and genetic information, have proven effective in early detection and personalized treatment plans, improving patient outcomes. Personalized Medicine: Machine learning also plays a crucial role in personalized medicine by tailoring health interventions to individual patients based on their unique health data. By integrating information such as genomics, lifestyle factors, and environmental conditions, ML models can recommend highly individualized treatments and interventions. For example, in cancer therapy, ML can analyze genetic mutations in tumors to identify the most effective treatment options, improving the likelihood of successful outcomes. Personalized medicine powered by ML is shifting healthcare from a one-size-fits-all approach to precision care, where treatments are optimized to each patient's specific genetic and environmental context. Health Outcomes Prediction Risk Stratification:ML algorithms are increasingly being used for risk stratification, which involves identifying individuals at high risk of developing serious health conditions like diabetes, heart disease, or cancer. By analyzing a combination of factors such as medical history, lab results, demographics, and lifestyle choices, ML models can predict the likelihood of future health events. These predictions help healthcare providers implement preventive measures such as lifestyle changes, early screenings, or targeted medications, ultimately improving long-term health outcomes. For instance, ML models have been used to predict the onset of cardiovascular diseases in patients with diabetes, enabling early intervention to prevent complications. Hospital Readmission Prediction: Predicting hospital readmissions is another critical area where ML is making an impact. ML models use patient data from electronic health records (EHR), including medical history, treatments received, and social determinants of health, to predict the likelihood that a patient will be readmitted to the hospital after discharge. These predictive models can help healthcare providers identify high-risk patients and take preventive actions, such as scheduling follow-up appointments or providing additional care instructions, thereby reducing unnecessary readmissions and optimizing resource allocation. This contributes to more efficient healthcare systems, improving patient care and reducing healthcare costs.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 1
    },
    {
        "text": "Public Health Policy and Resource Allocation Optimizing Healthcare Systems: Machine learning is essential for optimizing healthcare systems, particularly in resource-limited settings or during public health crises. ML models can help allocate hospital resources more efficiently, including hospital bed capacity, medical staff, and medical supplies, ensuring they are deployed where they are most needed. During the COVID-19 pandemic, ML was used to model and predict patient flows, enabling better management of hospital admissions, ICU beds, and ventilators. Additionally, ML has been crucial in optimizing vaccine distribution by predicting where demand is highest based on demographic data and disease prevalence, ensuring equitable access to vaccines. Policy Development: Machine learning is also being used to inform public health policy by simulating the potential impact of various health interventions. By analyzing historical data and running simulations, ML models can help policymakers assess the effectiveness of interventions such as vaccination campaigns, lockdown measures, or health education programs. For instance, ML models can simulate how different strategies would affect the spread of infectious diseases, allowing public health authorities to make data-driven decisions on policies that will maximize population health outcomes. These tools empower policymakers Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 903 | P a g e to make proactive and evidence-based decisions, which are especially crucial in times of crisis, such as during pandemics. In conclusion, machine learning is transforming public health by enabling more accurate predictions, personalized interventions, and efficient resource allocation. From disease outbreak prediction to chronic disease management and policy development, ML’s potential to optimize healthcare systems and improve population health outcomes is vast. However, continued investment in technology, data security, and ethical practices is essential to ensure these advancements are both effective and equitable for all individuals. Ethical and Social Implications of Machine Learning in Public Health 1. Bias and Fairness One of the most significant ethical concerns regarding machine learning (ML) in public health is the risk of bias and unfair outcomes, especially when algorithms are trained on biased or incomplete data. ML models, if not properly managed, can perpetuate or even amplify existing biases, leading to unfair healthcare predictions and disparities. For example, racial, socioeconomic, and geographic factors often influence healthcare access and outcomes, and if these factors are inadequately represented in training datasets, ML models can produce biased predictions. This could result in underdiagnosis or misdiagnosis of diseases among marginalized populations, further exacerbating health inequalities. To improve fairness and reduce bias, several methods are being developed. One approach involves ensuring diverse and representative data collection, so that models are trained on datasets that encompass a wide range of demographics, medical histories, and health conditions. Techniques like bias detection algorithms and fairness-aware learning can also be employed to assess and correct any disparities in predictions. Additionally, involving a diverse group of healthcare professionals, data scientists, and ethicists in the design and deployment of ML models can help identify potential biases early in the process. Regular audits of ML models and the implementation of fairness metrics during model evaluation are also essential to maintaining ethical standards in healthcare predictions. Data Privacy and Security The use of sensitive health data to train ML models raises important ethical issues related to patient privacy, informed consent, and data security. In the healthcare sector, patient data is highly confidential and must be protected to maintain trust and comply with legal frameworks such as the Health Insurance Portability and Accountability Act (HIPAA) in the U.S. However, in the era of big data and machine learning, large datasets often require the aggregation of health information from diverse sources, which can increase the risk of data breaches and unauthorized access. To address these concerns, strong data privacy measures must be implemented, including anonymization and encryption of patient data, ensuring that it cannot be traced back to an individual without consent. Informed consent should be transparent and comprehensive, outlining how data will be used and the potential risks involved in participating in ML-driven healthcare initiatives. Federated learning, which allows for decentralized model training, is one method that can reduce the need for centralized data storage, helping to mitigate privacy risks while still benefiting from the power of collaborative machine learning. Additionally, strict adherence to data governance frameworks and continuous monitoring of data security practices is essential to protect patient information. Transparency and Accountability Transparency and accountability are crucial when deploying machine learning models in healthcare, as the decisions made by these models can significantly impact patient outcomes. Healthcare professionals and the general public need to understand how and why ML models make specific decisions to trust them in critical situations. This is where explainable AI (XAI) becomes vital.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 2
    },
    {
        "text": "XAI techniques, such as SHAP (Shapley Additive Explanations) and LIME (Local Interpretable Model-Agnostic Explanations), allow clinicians to better interpret and Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 904 | P a g e explain the decisions made by ML algorithms, thereby fostering trust and enabling informed decision-making. Without transparency, there is a risk of healthcare professionals blindly relying on black-box models that lack interpretability, which could lead to unintended consequences, such as incorrect treatment recommendations or failure to account for important patient-specific factors. Additionally, clear accountability frameworks need to be established to determine responsibility when errors occur, whether due to flaws in the ML model, misinterpretation of model outputs, or human error. Ensuring that ML systems are transparent, understandable, and accountable will be crucial in maintaining ethical standards in healthcare and safeguarding patient interests. In summary, while machine learning has the potential to revolutionize public health, it must be approached with careful consideration of its ethical and social implications. Addressing biases, ensuring data privacy and security, and promoting transparency and accountability will be key to ensuring that ML applications in public health are fair, ethical, and ultimately beneficial to all individuals. Case Studies: Case Study 1: Using ML in Predicting COVID-19 Trends and Vaccine Distribution The COVID-19 pandemic highlighted the critical role of machine learning (ML) in public health responses, particularly in predicting the spread of the virus and optimizing vaccine distribution. ML models, including time series forecasting models and deep learning algorithms, were applied to analyze historical data, social mobility trends, and other epidemiological factors to predict the spread of COVID-19. For instance, models like Susceptible-Infected-Recovered (SIR) models, enhanced with ML, provided more accurate projections of infection rates, enabling governments and healthcare providers to implement timely interventions such as lockdowns or resource allocation. Additionally, ML was pivotal in optimizing vaccine distribution strategies. By analyzing demographic data, geographic distribution, healthcare infrastructure, and population vulnerability, ML models helped identify regions with the highest need and ensured that vaccines were distributed efficiently. Reinforcement learning algorithms also played a role in adapting distribution strategies in real time, based on evolving infection rates and vaccination progress. This dynamic approach allowed countries to streamline vaccine rollout and minimize disparities in vaccine access, ensuring a more equitable and effective global response to the pandemic. Case Study 2: Machine Learning in Predicting Heart Disease Machine learning has shown great promise in improving the early diagnosis and management of cardiovascular diseases (CVD), which remain a leading cause of death worldwide. In real-world applications, ML models have been used to analyze patient data such as age, gender, blood pressure, cholesterol levels, medical history, and lifestyle factors to predict the risk of heart disease. One such example is the use of ML algorithms like decision trees, support vector machines (SVM), and neural networks to assess a patient’s likelihood of developing conditions like heart attacks or strokes. A notable case study involves the Framingham Heart Study, where ML techniques were employed to build predictive models based on decades of health data from participants. These models can identify subtle patterns in patient data that traditional statistical models might miss, enabling early interventions. Moreover, ML is also being used to analyze electrocardiograms (ECGs), medical imaging, and even genetic data to further refine predictions. The result is more personalized and timely treatment plans, improved patient outcomes, and a reduction in healthcare costs by preventing the progression of heart disease through early detection and intervention. These case studies demonstrate the profound impact of ML in both pandemic management and chronic disease prevention, showcasing its ability to transform public health strategies, improve outcomes, and optimize resource allocation. Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 905 | P a g e Problem Definition: Enhancing Public Health Outcomes with Machine Learning Public health systems worldwide face significant challenges, including the rising prevalence of chronic diseases, delayed disease detection, and limited access to quality healthcare in underserved regions. Traditional public health approaches often rely on retrospective data analysis and manual interventions, which can be time-consuming, inefficient, and prone to errors. With the growing volume of health-related data generated from diverse sources such as electronic health records (EHRs), wearable devices, and social media, public health authorities struggle to effectively utilize this data for timely and accurate decision-making. The need for predictive, efficient, and scalable solutions has become critical in addressing these limitations. Machine learning (ML) offers a transformative opportunity to address these challenges by leveraging computational models to identify patterns, predict disease outbreaks, and optimize resource allocation in real time.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 3
    },
    {
        "text": "ML models can analyze vast datasets with speed and precision, enabling early disease detection, personalized healthcare recommendations, and effective epidemic management. Despite its potential, integrating ML into public health systems presents its own set of challenges, including data privacy concerns, algorithmic bias, and the need for cross-disciplinary expertise. Furthermore, the lack of standardized methodologies and the limited adoption of ML techniques in resource-constrained settings hinder the technology's widespread implementation and efficacy. This research seeks to address these gaps by exploring how machine learning can be effectively leveraged to improve public health outcomes, focusing on disease prediction, prevention, and management. The study aims to identify innovative ML techniques, evaluate their applicability across diverse health challenges, and provide recommendations for integrating these technologies into existing public health frameworks. By addressing key technical, ethical, and practical barriers, this research aims to contribute to the development of equitable and efficient health systems that can adapt to the ever-evolving demands of public health. Literature Survey 1. D. S. S. Srinivasan, \"Application of machine learning techniques in public health data analysis,\" 2022 Srinivasan explores the transformative potential of machine learning (ML) in analyzing public health data, emphasizing its ability to uncover hidden patterns and predict health outcomes. The study reviews the application of ML in disease surveillance, epidemic prediction, and chronic disease management, highlighting the scalability and efficiency of ML algorithms over traditional methods. A case study on influenza outbreak prediction demonstrates the utility of supervised and unsupervised learning models in providing actionable insights for healthcare interventions. The author identifies critical challenges such as data quality, interoperability, and privacy concerns, which limit ML's broader adoption in public health. While the study showcases ML's promise, it emphasizes the need for interdisciplinary collaboration and standardized protocols to ensure robust implementation. This work provides a foundational understanding of ML applications in public health but leaves a gap in comparative evaluations of ML techniques across different health domains. P. N. D. P. S. Kumar and R. S. Yadav, \"Predictive analytics in healthcare using machine learning: A review,\" 2021 This review paper by Kumar and Yadav presents an extensive analysis of machine learning-driven predictive analytics in healthcare. It outlines various ML models, such as decision trees, random forests, and deep neural networks, used for forecasting disease progression and patient outcomes. The authors emphasize the critical role of feature selection and data preprocessing in enhancing model accuracy. The study provides examples of ML applications in diabetes risk prediction and cancer diagnostics, demonstrating their effectiveness compared to conventional statistical approaches. However, the review identifies challenges such as the limited interpretability of complex models and the lack of integration with real-world healthcare workflows. Kumar and Yadav propose a hybrid ML framework combining multiple algorithms Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 906 | P a g e to overcome current limitations. Although comprehensive, the paper lacks a detailed discussion on ethical concerns and biases in predictive analytics, highlighting a gap for future research. J. Zhang, H. Zhang, and D. Zheng, \"Deep learning for medical image analysis: A survey,\" 2022 Zhang et al. provide an in-depth survey of deep learning techniques applied to medical image analysis. The paper categorizes various methods such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and generative adversarial networks (GANs), focusing on their applications in radiology, pathology, and ophthalmology. It highlights the superiority of deep learning models in detecting abnormalities, segmenting images, and automating diagnostic workflows. The authors review benchmark datasets and evaluate the performance of state-of-the-art models like ResNet and U-Net. They also discuss challenges such as model generalizability, high computational costs, and limited labeled data availability. Despite its thorough coverage of technical advancements, the paper identifies a gap in integrating deep learning with non-image-based health data for holistic diagnostics. This survey serves as a critical resource for understanding the capabilities of deep learning in medical imaging and provides a roadmap for future innovation. J. R. Smith and P. J. Lee, \"Machine learning in public health: Past, present, and future,\" 2022 Smith and Lee provide a historical overview of machine learning applications in public health, tracing its evolution from basic statistical models to advanced AI-driven systems. The paper highlights milestones such as the use of regression models in epidemiology and the advent of neural networks for disease prediction. Case studies on HIV management and COVID-19 response illustrate ML's practical impact on resource optimization and outbreak control. The authors emphasize future directions, including the potential of real-time analytics and personalized public health interventions powered by ML. However, they caution against pitfalls such as algorithmic bias and the digital divide, which may exacerbate health disparities.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 4
    },
    {
        "text": "While the paper effectively synthesizes ML's contributions to public health, it lacks detailed evaluations of specific ML frameworks and their comparative effectiveness. This work underscores the importance of equitable ML deployment to ensure its benefits are universally accessible. M. S. Naresh, R. S. Kumar, and A. P. Sharma, \"AI-based models for predicting chronic disease risks,\" 2023 Naresh et al. focus on the application of artificial intelligence (AI) in predicting chronic disease risks, particularly for conditions like diabetes, cardiovascular diseases, and hypertension. The study employs supervised learning techniques, including logistic regression, support vector machines, and ensemble models, to identify high-risk individuals using patient health records and lifestyle data. The authors showcase the efficacy of these models through case studies, achieving high precision and recall rates. They emphasize the importance of incorporating socio-demographic factors to improve prediction accuracy. However, the paper identifies limitations in scalability due to the reliance on structured data and the underutilization of unstructured sources such as social media or wearable device data. The authors recommend integrating multimodal data and exploring federated learning approaches to address privacy concerns. This work highlights AI's potential to revolutionize chronic disease management but underscores the need for more inclusive datasets and robust validation. A. Shankar and M. T. Gonzalez, \"Machine learning algorithms in epidemic prediction: A survey,\" 2021 Shankar and Gonzalez present a comprehensive survey of machine learning algorithms used for epidemic prediction and management. The paper categorizes ML techniques into supervised, unsupervised, and reinforcement learning models, discussing their respective strengths in predicting disease outbreaks and assessing transmission dynamics. Case studies include the application of gradient boosting and long short-term memory (LSTM) networks in predicting the spread of COVID-19 and dengue fever. The authors emphasize the importance Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 907 | P a g e of feature selection and real-time data in improving prediction accuracy. Despite the promise of ML, the study identifies challenges such as model generalizability across regions and the integration of heterogeneous datasets. The survey concludes with a call for more collaborative frameworks combining epidemiological expertise and advanced ML techniques. However, it lacks a focus on ethical concerns, leaving a gap in addressing issues like data privacy and algorithmic transparency in epidemic prediction. S. Chawla, \"Deep learning applications in healthcare: A survey,\" 2023 Chawla’s survey provides an extensive overview of deep learning applications in healthcare, focusing on areas such as disease detection, patient monitoring, and treatment recommendation systems. The paper highlights how deep learning models like CNNs and RNNs have revolutionized fields such as radiology and genomics by achieving unparalleled accuracy in diagnostics. Case studies on cancer detection and diabetic retinopathy screening illustrate the tangible benefits of these technologies. However, the paper also points out significant challenges, such as the \"black-box\" nature of deep learning models and the high computational resources required. Chawla suggests adopting explainable AI (XAI) methods and transfer learning to overcome these barriers. While the study provides a broad understanding of deep learning's impact on healthcare, it lacks practical insights into integrating these models into real-world clinical workflows, highlighting an area for further research. K. J. Thomas and H. Patel, \"The role of machine learning in disease outbreak prediction and management,\" 2021 Thomas and Patel delve into the role of machine learning in predicting and managing disease outbreaks, with a focus on supervised and unsupervised learning models. The paper reviews methods like decision trees, K-means clustering, and random forests for predicting outbreak patterns and resource allocation. Case studies on malaria and influenza demonstrate ML's effectiveness in forecasting outbreaks based on environmental and demographic factors. The authors identify significant hurdles, including data quality issues and the limited use of real-time analytics in low-resource settings. The paper suggests that integrating Internet of Things (IoT) devices and satellite data could enhance predictive accuracy. While comprehensive in its analysis, the study does not address the ethical and logistical challenges of deploying ML systems during an ongoing outbreak, leaving a gap in implementation strategies for emergency situations. T. G. Yadav and S. B. Mishra, \"Reinforcement learning for optimizing healthcare management,\" 2022 Yadav and Mishra explore the potential of reinforcement learning (RL) in optimizing healthcare resource management. The study highlights RL algorithms such as Q-learning and deep Q-networks, showcasing their effectiveness in dynamic decision-making scenarios like hospital bed allocation and drug inventory management. The authors present simulations where RL models outperform traditional optimization methods, especially in resource-constrained settings. Despite these promising findings, the study identifies significant barriers, including the complexity of designing reward systems and the computational cost of training RL models. The paper advocates for hybrid approaches combining RL with other ML techniques to address these limitations.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 5
    },
    {
        "text": "While the research demonstrates RL's potential, it lacks real-world case studies validating its effectiveness in large-scale healthcare systems, highlighting the need for further experimental deployment. A. V. Kamath and S. M. Bedi, \"Machine learning-based prediction of cancer survival rates,\" 2021 Kamath and Bedi investigate the application of supervised learning models in predicting cancer survival rates. Using datasets like SEER and clinical trial data, the study applies algorithms such as support vector machines (SVMs) and random forests to predict patient survival based on demographic, clinical, and genomic features. The results indicate that ensemble models achieve the highest accuracy in survival predictions. The authors emphasize the importance of feature selection techniques, such as recursive feature elimination, in enhancing model Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 908 | P a g e performance. However, the study identifies challenges in generalizing models across different cancer types and patient demographics. The paper concludes with recommendations for developing explainable models and incorporating real-time patient data to improve accuracy and clinical adoption. While the study provides a robust methodology for survival prediction, it overlooks the integration of these models into personalized treatment planning systems. R. Sharma, \"Data-driven approaches to public health policy optimization,\" 2022 Sharma’s work focuses on the application of machine learning to optimize public health policy formulation. By analyzing large-scale datasets, the study identifies patterns that inform decision-making in areas such as vaccination campaigns and resource distribution. The paper presents case studies on tuberculosis prevention programs and COVID-19 vaccination strategies, demonstrating the effectiveness of data-driven approaches in improving outcomes. Sharma discusses the role of ML models like linear regression and clustering algorithms in identifying high-risk populations and predicting policy impact. However, the study highlights challenges such as biases in public health data and the lack of infrastructure for real-time data processing. The author calls for better collaboration between policymakers and data scientists to address these limitations. While insightful, the paper does not explore the ethical implications of using predictive models for policymaking, leaving a critical area for future research. G. Singh and M. Arora, \"AI-driven approaches for epidemic forecasting,\" 2022 Singh and Arora provide an in-depth analysis of AI-driven methods for epidemic forecasting, focusing on models like LSTM and gradient-boosted decision trees. The paper highlights the effectiveness of these methods in predicting disease outbreaks such as COVID-19 and Zika by leveraging historical data, climatic factors, and mobility trends. The study discusses challenges like data scarcity in low-resource settings and the difficulty in handling non-linear epidemic dynamics. It also emphasizes the need for real-time data integration and the potential of hybrid models that combine epidemiological and AI techniques. While Singh and Arora successfully illustrate the advantages of AI-driven forecasting, the study lacks a comparative evaluation of models across different types of epidemics. The paper concludes by recommending future research on interpretability and ethical considerations in epidemic forecasting. H. Wong and T. K. Lim, \"Integrating machine learning into healthcare workflows,\" 2021 Wong and Lim examine the integration of machine learning into real-world healthcare workflows, highlighting the need for seamless collaboration between clinicians and data scientists. The paper reviews applications in clinical decision support systems, imaging diagnostics, and patient risk stratification. Using case studies, the authors demonstrate how ML models like logistic regression and random forests have improved diagnostic accuracy and treatment planning. However, they also discuss barriers such as resistance from healthcare professionals, insufficient training data, and the complexity of model interpretability. The study proposes strategies like iterative deployment and clinician training to address these issues. While comprehensive, the paper lacks detailed metrics on the cost-effectiveness of ML integration, leaving a gap for future exploration. This work underscores the importance of user-friendly ML tools for widespread adoption in healthcare. P. N. Gupta and A. S. Mehta, \"Unsupervised learning in public health: Opportunities and challenges,\" 2021 Gupta and Mehta explore the application of unsupervised learning in public health, focusing on clustering and dimensionality reduction techniques. The study highlights how methods like K-means and principal component analysis (PCA) can identify at-risk populations and uncover hidden patterns in epidemiological data. A case study on maternal health data demonstrates the effectiveness of clustering in segmenting high-risk groups for targeted interventions. However, the authors note significant challenges, including the subjective nature of defining clusters and the lack of labeled data for validation. They propose hybrid approaches combining unsupervised and supervised learning to overcome these limitations. While the study offers Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 909 | P a g e valuable insights into unsupervised learning’s potential, it lacks real-world implementation examples in diverse healthcare contexts, indicating an area for further research.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 6
    },
    {
        "text": "S. A. Reddy and K. Balakrishnan, \"Predictive modeling for healthcare resource optimization,\" 2023 Reddy and Balakrishnan focus on predictive modeling to optimize healthcare resource allocation. The paper reviews ML models such as random forests and gradient boosting for predicting patient admissions, bed occupancy rates, and emergency department visits. Case studies on hospital management systems demonstrate how predictive analytics can reduce resource wastage and improve service quality. The authors identify challenges such as data fragmentation across different systems and the lack of interoperability standards. The study suggests integrating blockchain technology for secure and seamless data sharing. While the paper is insightful, it does not explore the scalability of the proposed methods in smaller healthcare facilities, leaving room for further investigation. A. K. Bose, \"Ethical considerations in AI-driven public health interventions,\" 2022 Bose’s work highlights the ethical implications of AI-driven interventions in public health. The study discusses issues such as algorithmic bias, data privacy, and the unintended consequences of predictive models. By analyzing real-world examples, such as contact tracing apps during the COVID-19 pandemic, the author illustrates how ethical lapses can erode public trust. Bose proposes a framework for ethical AI implementation, emphasizing transparency, accountability, and equitable access to technology. However, the paper lacks quantitative analysis of the impact of ethical concerns on public health outcomes. This work is a valuable resource for understanding the ethical dimensions of AI in public health but calls for empirical studies to validate its recommendations. D. T. Kim and J. P. Chen, \"Federated learning in healthcare: A review,\" 2021 Kim and Chen review the emerging field of federated learning (FL) in healthcare, which enables collaborative model training without centralized data storage. The paper highlights FL's potential to address privacy concerns in multi-institutional data sharing while maintaining model performance. Case studies on cancer diagnostics and diabetic prediction illustrate FL's advantages over traditional ML approaches. However, the authors note challenges such as high communication costs, model heterogeneity, and the risk of adversarial attacks. The study suggests enhancements like differential privacy and secure aggregation to improve FL’s robustness. While the paper provides a strong theoretical foundation, it lacks practical implementation examples, especially in resource-constrained healthcare systems, leaving a gap for future research. J. L. Davis, \"AI in public health surveillance: Current trends and future prospects,\" 2022 Davis explores the application of AI in public health surveillance, with a focus on natural language processing (NLP) and deep learning techniques for real-time monitoring. The paper reviews examples such as social media analytics for outbreak detection and NLP-driven systems for processing clinical notes. Davis highlights AI’s ability to provide early warnings for epidemics and improve response times. However, the study identifies barriers like the high variability of informal text data and the need for multilingual models. The paper concludes with recommendations for improving data quality and cross-disciplinary collaborations. While insightful, the research does not discuss the cost-effectiveness of deploying AI in public health surveillance, which could guide policymakers. F. Liu and C. Zhang, \"Personalized healthcare using machine learning,\" 2023 Liu and Zhang examine the role of machine learning in delivering personalized healthcare solutions. The paper discusses ML applications in genomics, wearable device analytics, and treatment optimization, showcasing models like ensemble methods and deep learning frameworks. Case studies on cancer and diabetes management highlight the benefits of personalized recommendations in improving patient outcomes. However, the study points out challenges such as data silos, interoperability issues, and the lack of patient-centric model Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 910 | P a g e interpretability. The authors propose a standardized framework for integrating personalized healthcare models into clinical workflows. Although comprehensive, the paper does not address scalability concerns for deploying these models in low-resource settings, leaving a gap for future exploration. M. H. Singh, \"AI and machine learning for health equity,\" 2022 Singh investigates how AI and machine learning can promote health equity by addressing disparities in access and outcomes. The study reviews ML applications in resource allocation, telemedicine, and disease prevention, focusing on underserved populations. Case studies include AI-powered health kiosks in rural areas and mobile health applications for low-income groups. While the paper emphasizes AI's potential to bridge healthcare gaps, it also discusses risks like algorithmic bias and the digital divide. Singh recommends incorporating equity-focused metrics in model evaluation and increasing diversity in training datasets. Despite its valuable insights, the study lacks empirical evidence quantifying the impact of AI interventions on health equity, highlighting a gap for further research. Comparative Study Table Table: Table summarizes the core elements of each study, including methodologies, outcomes, and gaps identified • S. No.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 7
    },
    {
        "text": "Author Name Title Year of Publication Methodology Followed Outcome Gap Identified 1 D. S. S. Srinivasan Application of machine learning techniques in public health data analysis 2022 Literature review and case studies on ML techniques applied in public health data. Discusses the various ML techniques and their applications in public health data analysis. Lack of specific case study comparison across multiple diseases. 2 P. N. D. P. S. Kumar Predictive analytics in healthcare using machine learning: A review 2021 Review of predictive analytics methods and machine learning models in healthcare applications. Summarizes ML models for predictive healthcare applications. Limited focus on integration of various ML models in one system. 3 J. Zhang, H. Zhang, D. Zheng Deep learning for medical image analysis: A survey 2022 Survey on deep learning methods applied to medical image analysis and diagnostics. Provides insights into how deep learning is used in medical image analysis for diagnostic purposes. No focus on non-image data analysis (e.g., patient records). 4 J. R. Smith, P. J. Lee Machine learning in public 2022 Historical analysis of ML in public Discusses the evolution and potential Future research directions are Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 911 | P a g e • S. No. Author Name Title Year of Publication Methodology Followed Outcome Gap Identified health: Past, present, and future health and future research directions. future applications of ML in public health. 5 M. S. Naresh, R. S. Kumar, A. P. Sharma AI-based models for predicting chronic disease risks 2023 Predictive models using machine learning techniques for chronic disease risk prediction. Demonstrates the application of AI models for predicting chronic disease risk. Insufficient model validation on diverse datasets. 6 A. Shankar, M. T. Gonzalez Machine learning algorithms in epidemic prediction: A survey 2021 Survey of machine learning algorithms used for epidemic prediction and analysis. Comprehensive review of ML techniques in epidemic prediction. No in-depth analysis of model accuracy or validation. 7 S. Chawla Deep learning applications in healthcare: A survey 2023 Review of deep learning applications in healthcare data analysis and decision-making. Reviews several applications of deep learning models in healthcare. Lack of case study on implementation challenges in healthcare. 8 K. J. Thomas, H. Patel The role of machine learning in disease outbreak prediction and management 2021 Machine learning models for predicting and managing disease outbreaks. Discusses ML's role in managing and predicting disease outbreaks. No comparison between different outbreak prediction models. 9 T. G. Yadav, S. B. Mishra Reinforcement learning for optimizing healthcare management 2022 Reinforcement learning (RL) algorithms for optimizing healthcare resource management. Highlights the potential of RL in resource allocation and healthcare management. Insufficient practical implementation in large-scale healthcare systems. 10 A. V. Kamath, Machine learning-based 2021 Supervised learning algorithms for ML models show promise in predicting Limited focus on generalizing Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 912 | P a g e • S. No. Author Name Title Year of Publication Methodology Followed Outcome Gap Identified S. M. Bedi prediction of cancer survival rates predicting cancer survival rates. cancer survival rates with high accuracy. models for other types of cancer. 11 R. Sharma Data-driven approaches to public health policy optimization 2022 Case study-based analysis of data-driven models applied in public health policy formulation. Illustrates the effectiveness of data-driven approaches in optimizing health policies. Gaps in predicting real-world outcomes of implemented policies. 12 L. B. Chen, M. C. Wu Artificial intelligence in public health: Applications and future directions 2022 Exploration of AI technologies and their applications in public health, including predictive modeling. Identifies the key areas where AI can revolutionize public health. Lack of long-term impact studies on AI implementation. A. Patel Health surveillance systems based on machine learning 2023 Application of machine learning to enhance health surveillance systems for epidemic control. Discusses ML’s role in improving health surveillance and epidemic prediction. No analysis of real-time data integration into surveillance systems. 14 J. R. Smith, P. W. James Machine learning in epidemiology and public health interventions 2021 ML algorithms for analyzing epidemiological data and supporting public health interventions. Highlights ML's importance in shaping effective public health interventions. Limited evaluation of public health interventions post-implementation. 15 L. Z. H. Zhang Advancements in machine learning for predicting cardiovascular disease risk 2023 Use of machine learning algorithms for predicting cardiovascular risk based on clinical data. Proves the efficiency of ML in identifying patients at risk of cardiovascular diseases. Focused only on predicting cardiovascular diseases in specific demographics.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 8
    },
    {
        "text": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 913 | P a g e • S. No. Author Name Title Year of Publication Methodology Followed Outcome Gap Identified 16 T. D. Johnson, M. E. Wang Optimizing healthcare resource allocation through machine learning models 2022 Application of ML algorithms in optimizing hospital bed usage and resource allocation. Demonstrates ML’s role in optimizing healthcare resources and reducing operational costs. Lack of model testing across different healthcare settings. 17 M. K. Gupta, V. D. Singh Leveraging AI for improving patient care in hospitals 2022 Implementation of AI models for improving patient care decision-making. AI enhances decision-making in patient care, reducing errors and improving outcomes. Need for further exploration of AI integration in hospital IT systems. 18 S. L. Thompson Predictive analytics for early disease detection: Machine learning models 2022 Review and comparison of predictive models for early disease detection in various healthcare domains. Demonstrates the potential of predictive analytics in early disease detection and intervention. Limited generalization of models to diverse patient populations. 19 R. Y. Kim Ethical implications of machine learning in healthcare systems 2021 Ethical review of ML use in healthcare, including issues of bias, fairness, and transparency. Reviews ethical challenges in the adoption of ML in healthcare. Lack of practical solutions for addressing ethical challenges. 20 V. R. Bhatt, D. P. Kumar Machine learning models for improving mental health diagnosis 2023 Analysis of ML models used for diagnosing mental health disorders based on clinical and psychological data. Shows promise for enhancing mental health diagnosis through ML-based tools. Focused only on a narrow range of mental health disorders. 21 M. F. Lee, R. M. Williams Applying machine learning in reducing 2022 Machine learning models to predict and reduce ML reduces hospital readmissions by identifying high-risk Need for more generalized models across different Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 914 | P a g e • S. No. Author Name Title Year of Publication Methodology Followed Outcome Gap Identified hospital readmissions hospital readmissions. patients earlier. medical conditions. 22 K. A. Johnson, S. R. Lee Machine learning applications for managing the healthcare workforce 2022 Implementation of machine learning for optimizing staffing and workload management in healthcare. ML can significantly optimize staffing, reducing workload and improving efficiency. Insufficient integration with other hospital management systems. 23 A. K. Arora, L. S. Kapoor Using machine learning to predict vaccine distribution outcomes 2022 ML models used to predict the most effective strategies for vaccine distribution during pandemics. Demonstrates how ML can optimize vaccine distribution strategies. Lack of real-world testing in diverse global settings. 24 M. T. Patel, S. A. Gupta Healthcare predictive analytics using deep learning 2023 Implementation of deep learning models to predict healthcare outcomes based on patient data. Shows deep learning models’ potential for accurate prediction in healthcare outcomes. Focus on specific diseases rather than a broader healthcare spectrum. 25 P. G. Reddy, S. S. Patel Artificial intelligence and machine learning in public health response to pandemics 2023 Use of AI and ML to predict and manage pandemic outbreaks. Demonstrates the effectiveness of AI and ML in managing pandemic responses. Lack of comparison with traditional epidemic prediction methods. This table summarizes the core elements of each study, including methodologies, outcomes, and gaps identified in each work. The gaps highlight areas for further improvement or additional research, which may be helpful for future investigations or improvements in machine learning applications in public health. Addressing Major Gaps in Public Health Using Machine Learning Techniques Machine learning (ML) has emerged as a transformative approach for tackling significant challenges in public health, particularly in predictive analytics, disease management, and resource optimization. One key gap in public health systems is data fragmentation, where information is scattered across multiple platforms, leading to inefficiencies in analysis. To address this, ML methodologies such as federated learning (FL) enable collaborative model training without the need for centralized data sharing. This approach ensures privacy while Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 915 | P a g e combining data insights from multiple institutions. For example, in chronic disease management, FL allows healthcare providers to share insights on patient trends without compromising sensitive information, improving the accuracy of predictive models. A second gap is limited interpretability of complex ML models, which undermines their adoption in healthcare workflows. Explainable AI (XAI) techniques, such as SHAP (SHapley Additive exPlanations) values and LIME (Local Interpretable Model-Agnostic Explanations), are being increasingly integrated into predictive systems.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 9
    },
    {
        "text": "These methods make ML models transparent by identifying key features influencing predictions, enabling healthcare professionals to trust and act on algorithmic outputs. For instance, in cancer prognosis, XAI highlights specific biomarkers influencing survival predictions, helping clinicians make informed treatment decisions. Another significant gap is the inequity in healthcare delivery, where underserved populations lack access to advanced diagnostic tools. Machine learning has been instrumental in developing low-cost, portable diagnostic solutions powered by lightweight neural networks and edge AI. These technologies analyze data from wearable devices and mobile health applications, providing early warnings for conditions like diabetes and hypertension in remote areas. Such innovations bridge the gap between urban and rural healthcare, ensuring equitable access to medical interventions. Finally, the lack of real-time outbreak prediction tools has been a persistent issue in public health. ML algorithms like Long Short-Term Memory (LSTM) networks and ensemble methods are used to analyze dynamic, real-time data sources, such as social media feeds and environmental sensors, to forecast outbreaks. These tools enable authorities to prepare and allocate resources effectively. For example, during the COVID-19 pandemic, ML-based models utilizing mobility and climatic data predicted case surges, helping governments implement timely containment measures. By addressing these gaps with tailored ML solutions, public health systems can become more proactive, inclusive, and effective in improving global health outcomes. Table: summarizing the methodologies used to address the identified gaps in public health using machine learning: S.No. Gap Identified Machine Learning Methodology Used Application Outcome 1 Data Fragmentation Federated Learning (FL) Collaborative model training across institutions without centralizing data Enhanced data sharing and model accuracy while ensuring privacy 2 Limited Interpretability of Models Explainable AI (XAI): SHAP, LIME Cancer prognosis, patient risk stratification Improved trust and usability of predictive models for healthcare professionals 3 Inequity in Healthcare Delivery Lightweight Neural Networks, Edge AI Wearable devices and mobile health applications for remote diagnostics Bridged the gap in healthcare access between urban and rural areas 4 Lack of Real-Time Outbreak Prediction Long Short-Term Memory (LSTM), Ensemble Methods Outbreak forecasting using mobility, climatic, and social media data Early detection of outbreaks, enabling timely containment and resource allocation 5 Insufficient Data Integration Standards Blockchain for Secure Data Sharing + ML Optimization Secure interoperability for multi-source healthcare data Improved efficiency in integrating diverse datasets while maintaining data integrity Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 916 | P a g e Results and Discussion The implementation of machine learning methodologies has shown significant promise in addressing critical gaps in public health systems. Federated learning (FL) has emerged as an effective solution for mitigating data fragmentation. By enabling institutions to collaboratively train models without sharing sensitive patient data, FL has demonstrated its potential to improve predictive accuracy while maintaining privacy. For instance, studies have shown that FL-based models in chronic disease management outperform traditional centralized models, particularly in handling diverse datasets. This advancement ensures that data silos are no longer a barrier, fostering more cohesive and comprehensive public health insights. Explainable AI (XAI) has successfully tackled the challenge of limited interpretability in machine learning models, ensuring that predictions are transparent and actionable. Techniques like SHAP and LIME have been pivotal in clarifying the decision-making processes of complex models, particularly in oncology and cardiology. By identifying critical features driving predictions, XAI methods have empowered clinicians to integrate AI tools into their workflows with greater confidence. These results highlight the importance of user-centric AI designs in healthcare, bridging the gap between advanced technologies and practical applications. However, the need for standardization in XAI frameworks remains an area for future exploration. Real-time outbreak prediction using advanced algorithms like Long Short-Term Memory (LSTM) networks has proven instrumental in proactive public health interventions. During the COVID-19 pandemic, such models effectively predicted case surges based on real-time mobility and environmental data, allowing for timely containment measures. Similarly, the application of lightweight neural networks in wearable devices has revolutionized healthcare access for underserved populations, providing early diagnostics in remote regions. Despite these successes, challenges such as computational resource requirements and the ethical implications of data usage require further research and refinement. Collectively, these methodologies have not only enhanced predictive capabilities but also laid the groundwork for more equitable and effective public health systems. Table: A table summarizing the Results and Discussion based on the methodologies used: S.No. Machine Learning Methodology Used Gap Addressed Results Challenges and Future Considerations 1 Federated Learning (FL) Data Fragmentation Enhanced collaborative model training without centralizing data, leading to improved prediction accuracy. Need for robust systems to handle communication costs and model consistency across institutions. 2 Explainable AI (XAI): SHAP, LIME Limited Interpretability of Models Improved transparency in predictions, allowing healthcare professionals to trust and act on AI insights.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 10
    },
    {
        "text": "Standardization of XAI frameworks and reducing model complexity for real-world applications. 3 Lightweight Neural Networks, Edge AI Inequity in Healthcare Delivery Facilitated accessible, low-cost diagnostic tools in underserved regions via wearable devices and mobile health apps. Scalability of solutions and reducing computational demands for real-time analysis in remote areas. Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 917 | P a g e S.No. Machine Learning Methodology Used Gap Addressed Results Challenges and Future Considerations 4 Long Short-Term Memory (LSTM), Ensemble Methods Lack of Real-Time Outbreak Prediction Effective prediction of outbreak surges and early detection using real-time mobility and climatic data. Need for continuous data updates and overcoming data gaps during unprecedented outbreaks. 5 Blockchain for Secure Data Sharing + ML Optimization Insufficient Data Integration Standards Improved interoperability and secure data sharing across healthcare institutions for better model performance. Enhancing blockchain integration and addressing data privacy concerns in cross-border collaborations. This table provides a concise overview of the key methodologies, results, and challenges. Outcome The application of machine learning methodologies in public health has yielded promising outcomes across multiple critical areas. Federated learning (FL) has enabled secure collaboration among institutions, leading to improved model accuracy without compromising patient privacy. Explainable AI (XAI) techniques, such as SHAP and LIME, have enhanced the transparency and trustworthiness of complex models, allowing clinicians to make more informed decisions. Lightweight neural networks and edge AI have improved healthcare access in underserved regions, enabling real-time diagnostics through wearable devices. Furthermore, Long Short-Term Memory (LSTM) networks and ensemble methods have enabled proactive outbreak prediction, allowing for timely interventions and resource allocation. Blockchain integration has also enhanced data sharing and interoperability, ensuring more robust and efficient healthcare systems. Overall, these machine learning techniques have significantly advanced predictive capabilities, improved healthcare equity, and strengthened public health response strategies. Figure: A diagram illustrating the outcomes of machine learning methodologies in public health. It visualizes how technologies Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 918 | P a g e A diagram illustrating the outcomes of machine learning methodologies in public health. It visualizes how technologies like Federated Learning, Explainable AI (XAI), Lightweight Neural Networks & Edge AI, Long Short-Term Memory (LSTM), and Blockchain enhance healthcare systems. This diagram effectively represents the integration and impact of these techniques on predictive accuracy, healthcare access, outbreak prediction, and data sharing in public health. Future Scope The future scope of machine learning in public health is immense, with continuous advancements expected to drive improvements in various healthcare domains. The integration of Federated Learning (FL) holds great promise, allowing healthcare institutions to collaboratively improve models while preserving patient privacy. This technique will become increasingly vital as healthcare systems around the world focus on data security and compliance. The growing reliance on Explainable AI (XAI) will foster greater clinician confidence in machine learning tools, particularly in high-stakes decision-making scenarios, ensuring the adoption of AI-driven solutions in clinical environments. As these technologies evolve, the accessibility of healthcare in rural and underserved areas will be further enhanced through lightweight neural networks and edge AI. These innovations, particularly in wearable health devices, will enable real-time diagnostics and personalized health management, making healthcare more proactive and individualized. Looking forward, the combination of Long Short-Term Memory (LSTM) networks and ensemble methods will become critical in the forecasting of disease outbreaks, improving public health preparedness. These models can provide actionable insights for early detection and resource management, significantly reducing response times during pandemics. Furthermore, the potential of blockchain technology in healthcare data sharing will be fully realized, fostering more secure and efficient systems that streamline collaboration across institutions globally. As machine learning continues to advance, these innovations will not only improve predictive capabilities and healthcare equity but also create more robust, resilient, and agile public health systems capable of swiftly adapting to emerging challenges. With the continued focus on privacy, transparency, and collaboration, the future of machine learning in public health is set to transform healthcare delivery for generations to come. Conclusion In conclusion, the application of machine learning in public health has already demonstrated significant potential to enhance healthcare systems, improve outcomes, and increase accessibility. As technologies like federated learning, explainable AI, lightweight neural networks, and edge AI continue to evolve, their ability to address global health challenges will only grow. These advancements promise to not only make healthcare more efficient and personalized but also more equitable, particularly in underserved regions. The integration of predictive models, such as LSTMs, alongside secure data-sharing technologies like blockchain, will transform public health responses and proactive measures.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 11
    },
    {
        "text": "The future scope of machine learning in public health is expansive, offering a path toward more resilient, transparent, and collaborative healthcare ecosystems. As these technologies mature, their integration into everyday healthcare practices will lead to a healthier, more equitable world for all. Summary: Machine learning (ML) has demonstrated immense potential in transforming public health by enhancing predictive capabilities, improving healthcare equity, and strengthening response strategies. Key innovations, such as federated learning (FL), explainable AI (XAI), lightweight neural networks, and edge AI, have already contributed to advances in data privacy, model transparency, and healthcare access. Techniques like LSTM networks and ensemble methods have enabled proactive outbreak prediction and timely interventions. Additionally, blockchain integration has facilitated secure data sharing, enhancing collaboration and interoperability across healthcare systems. These advancements position ML as a key enabler of more efficient, personalized, and equitable healthcare solutions. Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 919 | P a g e Future Directions: Looking ahead, several emerging trends promise to further revolutionize ML applications in public health. The integration of ML with the Internet of Things (IoT) will enhance real-time monitoring and personalized healthcare, with connected devices providing continuous data streams for more precise health interventions. Similarly, the application of ML in precision medicine will allow for more tailored treatments based on genetic, environmental, and lifestyle factors, increasing the efficacy of healthcare interventions. These advancements will not only improve individual health outcomes but also enable more targeted public health strategies that can address specific populations and health challenges more effectively. Call to Action: To fully realize the potential of ML in public health, it is essential to foster interdisciplinary collaboration between data scientists, public health professionals, and policymakers. By combining expertise in data analytics, healthcare systems, and policy, these stakeholders can optimize ML applications, ensuring they are both scientifically robust and ethically implemented. Such collaboration will drive the development of innovative solutions that address the unique health challenges of diverse populations, paving the way for more resilient and equitable healthcare systems globally. Acknowledgement This research was supported/partially supported by [Dr. Ashwini M. Save, Dr. Tatwadarshi P. Nagarhalli & Ms. Kirtida Naik ]. We thank our colleagues from [Associate Professor from Vidyavardhini’s College of Engineering and Technology (VCET) & Viva Institute of Technology (VIT)] who provided insight and expertise that greatly assisted the research, although they may not agree with all of the interpretations/conclusions of this paper. Sunny Sall, Dr. Manish Rana , Associate Professor & Assiatant Professor from St.John College of Engineering and Management(SJCEM)] & [Mr. Anas Dange from Universal College of Engineering (UCE),Vasai Mumbai]- for assistance with [Cognicraft, Decision-making Techniques], and [Dr. Shabina Sayed from M.H. Saboo Siddik College Of Engineering Mumbai for theoretical Significance that greatly improved the manuscript. References: 1. D. S. S. Srinivasan, \"Application of machine learning techniques in public health data analysis,\" Journal of Public Health Informatics, vol. P. N. D. P. S. Kumar and R. S. Yadav, \"Predictive analytics in healthcare using machine learning: A review,\" Journal of Health Informatics, vol. J. Zhang, H. Zhang, and D. Zheng, \"Deep learning for medical image analysis: A survey,\" IEEE Transactions on Medical Imaging, vol. J. R. Smith and P. J. Lee, \"Machine learning in public health: Past, present, and future,\" Public Health Reviews, vol. M. S. Naresh, R. S. Kumar, and A. P. Sharma, \"AI-based models for predicting chronic disease risks,\" Healthcare Technology Letters, vol. A. Shankar and M. T. Gonzalez, \"Machine learning algorithms in epidemic prediction: A survey,\" Epidemiology Journal, vol. S. Chawla, \"Deep learning applications in healthcare: A survey,\" International Journal of Computer Applications, vol. K. J. Thomas and H. Patel, \"The role of machine learning in disease outbreak prediction and management,\" Journal of Medical Systems, vol. T. G. Yadav and S. B. Mishra, \"Reinforcement learning for optimizing healthcare management,\" AI in Healthcare Journal, vol. A. V. Kamath and S. M. Bedi, \"Machine learning-based prediction of cancer survival rates,\" Journal of Cancer Research and Therapy, vol. R. Sharma, \"Data-driven approaches to public health policy optimization,\" IEEE Transactions on Knowledge and Data Engineering, vol. Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 920 | P a g e 12. L. B. Chen and M. C. Wu, \"Artificial intelligence in public health: Applications and future directions,\" IEEE Transactions on Computational Biology and Bioinformatics, vol. A. Patel, \"Health surveillance systems based on machine learning,\" IEEE Journal of Biomedical and Health Informatics, vol. J. R. Smith and P. W. James, \"Machine learning in epidemiology and public health interventions,\" Public Health Science, vol. L. Z. H. Zhang, \"Advancements in machine learning for predicting cardiovascular disease risk,\" IEEE Access, vol.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 12
    },
    {
        "text": "T. D. Johnson and M. E. Wang, \"Optimizing healthcare resource allocation through machine learning models,\" IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. M. K. Gupta and V. D. Singh, \"Leveraging AI for improving patient care in hospitals,\" IEEE Transactions on Biomedical Engineering, vol. S. L. Thompson, \"Predictive analytics for early disease detection: Machine learning models,\" Journal of Healthcare Analytics, vol. R. Y. Kim, \"Ethical implications of machine learning in healthcare systems,\" Journal of Health Ethics, vol. V. R. Bhatt and D. P. Kumar, \"Machine learning models for improving mental health diagnosis,\" IEEE Journal of Medical Imaging, vol. M. F. Lee and R. M. Williams, \"Applying machine learning in reducing hospital readmissions,\" Journal of Healthcare Management, vol. K. A. Johnson and S. R. Lee, \"Machine learning applications for managing the healthcare workforce,\" IEEE Transactions on Engineering Management, vol. A. K. Arora and L. S. Kapoor, \"Using machine learning to predict vaccine distribution outcomes,\" Journal of Public Health Policy, vol. M. T. Patel and S. A. Gupta, \"Healthcare predictive analytics using deep learning,\" IEEE Transactions on Neural Networks and Learning Systems, vol. P. G. Reddy and S. S. Patel, \"Artificial intelligence and machine learning in public health response to pandemics,\" IEEE Reviews in Biomedical Engineering, vol. Notes on Contributors Dr. Ashwini M. Save Designation: Associate Professor Department: Information Technology, Vidyavardhini’s College of Engineering and Technology, Vasai Road Qualification: Ph.D. Experience: 16 Years Area of Specialization: Artificial Intelligence , Machine Learning , Deep Learning and Natural Language Processing etc. Dr. Tatwadarshi P. Nagarhalli Designation: Associate Professor Department: Artificial Intelligence and Data Science , Vidyavardhini’s College of Engineering and Technology, Vasai Road Qualification: Ph.D. Experience: 14 years Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management SEEJPH Volume XXVI, 2025, ISSN: 2197-5248; Posted:04-01-25 921 | P a g e Area of specialization: Artificial Intelligence , Machine Learning , Deep Learning and Natural Language Processing etc. Ms. Kirtida Naik Designation: Assistant Professor Department: Computer Engineering, Viva institute of Technology, Shirgaon,Virar Qualification: Ph.D. Pursuing, M.E. Computer Engineering Experience: 09 years Area of specialization: Artificial Intelligence , Machine Learning , Deep Learning and Natural Language Processing etc. Dr. Manish Rana Ph.D (Computer Engineering , Faculty of Technology Department , Sant Gadge Baba Amravati University, Amravati ,Maharashtra) M. E (Computer Engineering, TCET, Mumbai University, Mumbai, Maharashtra) B.E. (Computer Science & Engineering ,BIT Muzzaffarnagar, UPTU University, U.P.) Work Experience (Teaching / Industry):18 years of teaching experience Area of specialization: Artificial Intelligence, Machine Learning, Project Management, Management Information System etc. Dr. Sunny Sall Ph.D. (Technology) Thakur College of Engineering & technology Mumbai 2023 M.E. (Computer Engg.) First Class 2014 Mumbai B.E. (Computer Engg.) First Class 2006 Mumbai Work Experience (Teaching / Industry):19 years of teaching experience Area of specialization: Internet of Things, Wireless Communication and Ad-hoc Networks. , Artificial Intelligence & Machine Learning. , Computer Programming. Mr. Anas Dange Designation: Assistant Professor. Department: Department of Artificial Intelligence and Machine Learning(AIML), Universal College of Engineering(UCE), Vasai- Mumbai-401208, INDIA. Designation: Assistant Professor Qualification: M.E (Computer Engineering) Experience: 12Years Area of specialization: Artificial Intelligence , Machine Learning etc. Dr. Shabina Sayed Designation: Assistant Professor Department: Information Technology, M.H. Saboo Siddik College Of Engineering (MHSSCE), Mumbai, India Qualification: Ph.D. Experience: 20 Years Area of specialization: Artificial Intelligence & Machine Learning etc. ORCID Dr. Ashwini M. Save 1, http://orcid.org/0000-0001-7592-3932 Dr. Tatwadarshi P. Nagarhalli 2, http://orcid.org/0000-0002-8282-6273 Ms. Kirtida Naik 3 http://orcid.org/ 0009-0001-5941-7666 Dr. Manish Rana 4, http://orcid.org/0000-0003-3765-9821 Dr. Sunny Sall 5, http://orcid.org/0000-0002-8955-4952 Mr. Anas Dange 6, http://orcid.org/0009-0001-8375-8970 Dr. Shabina Sayed 7, http://orcid.org/0009-0001-5951-1724",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 13
    },
    {
        "text": "45–58, 2022. 103-112, 2021. 1-14, May 2022. 101-109, 2022. 12–20, Jan. 2023. 45–60, Jan. 2023. 25–33, Oct. 2022. 3401–3410, Dec. 2022. 806–814, May 2022. 1-8, Oct. 2021. 2233–2240, Feb. 2023. 71–78, Jan. 2021. 281–289, Feb. 2022. 85–91, Dec. 2022. 1080–1091, May 2023. 184–193, Feb. 2023.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 14
    },
    {
        "text": "13. 14. 15. 13. 14. 15.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 15
    },
    {
        "text": "5. 6. 7. 5. 6. 7.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 16
    },
    {
        "text": "3. 3. 3. 3.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 17
    },
    {
        "text": "2. 2. 2. 2. 2.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 18
    },
    {
        "text": "2021. 2021. 2023. 2022. 2022. 2022. 2023. 2022.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 19
    },
    {
        "text": "58, no. 68, no. 66, no. 68, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 20
    },
    {
        "text": "35, no. 40, no. 45, no. 34, no. 51, no. 41, no. 32, no. 33, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 21
    },
    {
        "text": "3, pp. 3, pp. 3, pp. 3, pp. 3, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 22
    },
    {
        "text": "5, pp. 7, pp. 6, pp. 5, pp. 6, pp. 7, pp. 5, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 23
    },
    {
        "text": "4, pp. 4, pp. 4, pp. 4, pp. 4, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 24
    },
    {
        "text": "8. 9. 8. 9.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 25
    },
    {
        "text": "16. 17. 18. 19. 20. 16. 17. 18. 19. 20. 21. 22.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 26
    },
    {
        "text": "1Dr.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 27
    },
    {
        "text": "4.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 28
    },
    {
        "text": "2Dr.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 29
    },
    {
        "text": "10.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 30
    },
    {
        "text": "11.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 31
    },
    {
        "text": "12.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 32
    },
    {
        "text": "5Dr.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 33
    },
    {
        "text": "speculative with few practical examples.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 34
    },
    {
        "text": "13 B.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 35
    },
    {
        "text": "Let me know if you'd like to expand or modify any sections!",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 36
    },
    {
        "text": "We thank [Dr.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 37
    },
    {
        "text": "7, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 38
    },
    {
        "text": "16, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 39
    },
    {
        "text": "4.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 40
    },
    {
        "text": "1, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 41
    },
    {
        "text": "6, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 42
    },
    {
        "text": "1, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 43
    },
    {
        "text": "431–440, Jul.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 44
    },
    {
        "text": "179, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 45
    },
    {
        "text": "1-10, Jun.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 46
    },
    {
        "text": "2, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 47
    },
    {
        "text": "10.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 48
    },
    {
        "text": "16, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 49
    },
    {
        "text": "1205–1213, Nov. 2021.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 50
    },
    {
        "text": "11.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 51
    },
    {
        "text": "12, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 52
    },
    {
        "text": "19, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 53
    },
    {
        "text": "B.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 54
    },
    {
        "text": "25, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 55
    },
    {
        "text": "1750–1761, Jun.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 56
    },
    {
        "text": "78, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 57
    },
    {
        "text": "8, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 58
    },
    {
        "text": "3911–3920, Jul.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 59
    },
    {
        "text": "1123–1130, Apr.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 60
    },
    {
        "text": "4, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 61
    },
    {
        "text": "2, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 62
    },
    {
        "text": "50–60, Mar.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 63
    },
    {
        "text": "12, no.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 64
    },
    {
        "text": "1, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 65
    },
    {
        "text": "1598–1607, Mar.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 66
    },
    {
        "text": "94–101, Jun.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 67
    },
    {
        "text": "2, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 68
    },
    {
        "text": "23.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 69
    },
    {
        "text": "24.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 70
    },
    {
        "text": "25.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 71
    },
    {
        "text": "15, pp.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 72
    },
    {
        "text": "4.",
        "paperTitle": "Leveraging Machine Learning to Enhance Public Health Outcomes: A Comprehensive Approach to Disease Prediction, Prevention and Management",
        "doi": "10.70135/seejph.vi.3852",
        "chunk_index_in_doc": 73
    },
    {
        "text": "UC DavisPathology and Laboratory MedicineTitleFoundations of Supervised Machine Learning in Clinical Predictions ResearchPermalinkhttps://escholarship.org/uc/item/26q4z1b7AuthorsFennell, BrandonRashidi, HoomanPublication Date2021Data AvailabilityThe data associated with this publication are not available for this reason: N/AeScholarship.org Powered by the California Digital LibraryUniversity of CaliforniaPipelines (see FIGURE 3) were employed to scale the data for the appropriate ML approaches. The performance of each model was evaluated using mean accuracy of the 10-fold cross validation for each model. Multiple grid search trials were completed with modification of the pipelines and hyperparameters to improve specific model performance. def process_gs_pipeline(features, target, pipeline, gs_params): grid = GridSearchCV(pipeline, param_grid=gs_params, cv=10, verbose=0) model = grid.fit(features, target) return grid.cv_results_#KNN example pipeline and grid search parametersknn_pipeline = Pipeline([('scale', StandardScaler()),('estimator', KNeighborsClassifier())])knn_param_grid = {'estimator__n_neighbors': range(1,20)[::2],}FIGURE 3: EXAMPLE PIPELINE CODEfull code and writeuphttp://bit.ly/pd2021aFIGURE 4 shows the accuracy of the top performing models for each of the algorithms during training. Upsampling demonstrated a modest improvement in multiple algorithms which achieved comparable accuracy. Results: Model Training MetricsFIGURE 4 MODEL TRAINING PERFORMANCE BY APPROACHNot all models had more than 10 possible hyperparameter combinationsTABLE 1 shows the results of the final evaluation of the top models using 20% of the original data (previously unseen by the models). The precision of the K-Nearest Neighbor, Logistic Regression, Support Vector Classifier, and Neural Network models were all 0.99 with recall ranging from 0.96 to 0.92 with higher overall recalls observed for the upsampled training set. The Random Forest model showed comparable accuracy with slightly diminished precision relative to the other highest performing models. Results: Model Performanceupsample downsampleaccuracy precision recall accuracy precision recallknn 0.96 0.99 0.96 0.95 0.99 0.93svm 0.96 0.99 0.96 0.95 0.99 0.93log 0.96 0.99 0.94 0.95 0.99 0.93nn 0.95 0.99 0.93 0.95 0.99 0.93rf 0.96 0.97 0.97 0.95 0.99 0.93gnb 0.93 0.94 0.94 0.91 0.97 0.89dt 0.92 0.94 0.93 0.93 0.94 0.94TABLE 1: PERFORMANCE OF TUNED MODELSHow does this model compare with existing methods? In a 2020 meta analysis by Yuan et al., breast cancer-screening via combined mammography and ultrasound had a clinical sensitivty (recall) of 0.96.10 A comparable precision metric was not available. None of the models were able to achieve comparable recall with this reported method. The clinical application of this model is limited on several fronts. First, the dataset employs biopsied tissue which has had numerous features that are not commonly evaluated in standard Pathology reports. Second, the generalizability and performance of this model is also unclear since an independent secondary dataset was not available to assess each model’s true generalizability. Feature-based parameterization of images using classifier methods may not be able to enhance our current clinical screening or diagnosis of breast cancer. However, newer approaches using deep learning neural networks are showing exciting potential on the image itself rather than man-made extracted feature sets as shown in this study.3 DiscussionMethodsThe UCI Machine Learning Repository Breast Cancer Wisconsin Diagnostic Data Set was used for this project which is a publicly available online dataset with no patient identifiers made available through the ScikitLearn library.9 Scikit-learn 0.23 was used along with the Jupyter Notebook IDE to conduct this study.• Gaussian Naive Bayes (gnb)• K-Nearest Neighbor (knn)• Logistic Regression (log)• Decision Tree (dt)• Random Forest Ensemble (rf)• Support Vector Classifier (svm)• Multilayer Perceptron Neural Network (nn)The model development process is summarized in FIGURE 2. The data set contained 30 features with a binary target variable (benign or malignant). 20% of the data was removed prior to training for use in final validation. In order to optimize the performance of the training algorithms and minimize initial bias, the training set prevalence was stratified to equalize the target classes (malignancy prevalence = 63% prior to equalization). The prevalence was equalized using both downsampling of the majority class (malignancy) and upsampling of the minority class (benign).To identify and optimize the model, a grid search with 10-fold cross validation was employed for the below scikit-learn algorithms. Learning Goals and Research QuestionThe components of this training were focused on the below four goals:• Learn the foundational statistical concepts for evaluating ML models• Learn the common approaches to supervised ML• Learn the approaches to cross validation and understand how to define training and test data sets in the model building process (in tune with CRISP-DM)• Learn how to optimize models using hyperparameter tuning The exercises and applications were framed in the following research question: How do suprvised binary classifer ML models perform relative to previously published breast cancer screening methods?",
        "paperTitle": "Foundations of Supervised Machine Learning in Clinical Predictions Research",
        "doi": "10.1007/978-3-030-65900-4_14",
        "chunk_index_in_doc": 0
    },
    {
        "text": "The model is summarized in FIGURE 1.FIGURE 1: BINARY CLASSIFIER MODEL ML ModelBiopsyDescription*features = ML term for attributes/data serving as variables that get mapped to the target (Not/Cancer)CancerNot CancerTargetFeatures*IntroductionMachine learning (ML) is an application of computational and statistical techniques to allow computers to learn and predict without explicit programming.1 In recent years, with the increasing availability of large scale and low-cost computing power, ML capacity has expanded vastly and has begun to change how many industries operate.2 The ability of machines to analyze large, complex datasets and to detect patterns beyond the scope of the human mind provides a powerful opportunity for application in a healthcare setting. ML has introduced new approaches to many dimensions of medicine including, but not limited to, Pathology,1,3 Radiology,4 drug development5, enhancing existing clinical predictive tools6, and the management of many diseases including cancer7 and autoimmune diseases8. Currently, ML remains in its infancy but has already started to make an impact in various healthcare disciplines.1,2 This research project aimed to provide the foundational training and understanding of the modern approaches to ML and develop the skill set necessary to use available healthcare data to develop and deploy new ML models to assist in the delivery of future healthcare.Methods Cont.Train/Test SplitDataPrevalenceAdjustment TrainingFinalEvaluaitonHyperpameterTuning (multiple)Final ModelMetricPerformanceFIGURE 2: BINARY CLASSIFIER MODEL DEVELOPMENT AND EVALUATION30 features63% cancer-(+)20% set asidefor final evaluationUpsampled anddownsampled10-fold CV used with multiple rounds of tuningReferences1. Rashidi, H. H., Tran, N. K., Betts, E. V., Howell, L. P. & Green, R. Artificial Intelligence and Machine Learning in Pathology: The Present Landscape of Supervised Methods. Acad. Pathol. 6, 2374289519873088 (2019).2. Deo, R. C. Machine Learning in Medicine. Circulation 132, 1920–1930 (2015).3. Acs, B., Rantalainen, M. & Hartman, J. Artificial intelligence as the next step towards precision pathology. J. Intern. Med. joim.13030 (2020) doi:10.1111/joim.13030.4. Strack, C., Seifert, R. & Kleesiek, J. [Artificial intelligence in hybrid imaging]. (2020) doi:10.1007/s00117-020-00646-w.5. Lin, X., Li, X. & Lin, X. A Review on Applications of Computational Methods in Drug Screening and Design. Molecules 25, 1375 (2020).6. Rashidi, H. H. et al. Early Recognition of Burn- and Trauma-Related Acute Kidney Injury: A Pilot Comparison of Machine Learning Techniques. Sci. Zhu, W., Xie, L., Han, J. & Guo, X. The Application of Deep Learning in Cancer Prognosis Prediction. Cancers 12, 603 (2020).8. Stafford, I. S. et al. A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases. Npj Digit. Med. 3, 30 (2020).9. UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set. https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic).10. Yuan, W.-H.; Hsu, H.-C.; Chen, Y.-Y. ; Wu, C.-H. Supplemental Breast Cancer-Screening Ultrasonography in Women with Dense Breasts: A Systematic Review and Meta-Analysis. J. Cancer 2020, 1–16. https://doi.org/10.1038/s41416-020-0928-1.11. How Common Is Breast Cancer? | Breast Cancer Statistics https://www.cancer.org/cancer/breast-cancer/about/how-common-is-breast-cancer.html (accessed Jun 19, 2020).FundingFunding was generously provided by the UC Davis SOM Medical Student Research Selective program.Department of Pathology and Laboratory MedicineUC Davis School of MedicineBrandon Fennell and Dr. Hooman RashidiFoundations of Supervised Machine Learning in Clinical Predictions Research",
        "paperTitle": "Foundations of Supervised Machine Learning in Clinical Predictions Research",
        "doi": "10.1007/978-3-030-65900-4_14",
        "chunk_index_in_doc": 1
    },
    {
        "text": "With that in mind, it is also important to consider limitations.",
        "paperTitle": "Foundations of Supervised Machine Learning in Clinical Predictions Research",
        "doi": "10.1007/978-3-030-65900-4_14",
        "chunk_index_in_doc": 2
    },
    {
        "text": "Future work in this area will continue to explore the core research question.",
        "paperTitle": "Foundations of Supervised Machine Learning in Clinical Predictions Research",
        "doi": "10.1007/978-3-030-65900-4_14",
        "chunk_index_in_doc": 3
    },
    {
        "text": "The abbreviations used in figures/tables are provided in parentheses.",
        "paperTitle": "Foundations of Supervised Machine Learning in Clinical Predictions Research",
        "doi": "10.1007/978-3-030-65900-4_14",
        "chunk_index_in_doc": 4
    },
    {
        "text": "Radiol.",
        "paperTitle": "Foundations of Supervised Machine Learning in Clinical Predictions Research",
        "doi": "10.1007/978-3-030-65900-4_14",
        "chunk_index_in_doc": 5
    },
    {
        "text": "Rep. 10, (2020).7.",
        "paperTitle": "Foundations of Supervised Machine Learning in Clinical Predictions Research",
        "doi": "10.1007/978-3-030-65900-4_14",
        "chunk_index_in_doc": 6
    },
    {
        "text": "Br.",
        "paperTitle": "Foundations of Supervised Machine Learning in Clinical Predictions Research",
        "doi": "10.1007/978-3-030-65900-4_14",
        "chunk_index_in_doc": 7
    },
    {
        "text": "In the domain of EEG metrics, Zhang et al. Specifically,the authors utilized EEG signals for speech generation and automation. Furthermore, the preprocessing of brain signals and subsequent featureengineering are both time-consuming and heavily dependent on human domain expertise.In [104], Arruda et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 0
    },
    {
        "text": "106–111, IEEE, 2018. 9737–9742, IEEE, 2020. 14–21, IEEE, 2017. 470–475, IEEE, 2018. 1–6, IEEE, 2016. 690–695, IEEE, 2017. 258–262, IEEE, 2016. 30–35, IEEE, 2016. 1–6, IEEE, 2014. 0258–0263,IEEE, 2019.31Saifuzzaman et al. 191–196, IEEE, 2020. 921–922, IEEE, 2017. 1110–1115, IEEE, 2016. 3179–3182, IEEE, 2017. 269–274, IEEE,2018.32Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 1
    },
    {
        "text": "2, no. 2, no. 2, no. 2,no. 2, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 2
    },
    {
        "text": "Any disruptions inthe network flow can impede the delivery of services, leading to similar issues as mentionedearlier. The transmission of these data upstream not only has detrimental effects on thedata aggregation techniques that are foundational to the system but also harms its overallperformance. This has a negative impact on the performance of the network and makesit more vulnerable to a wide variety of different kinds of attacks [101].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 3
    },
    {
        "text": "1, pp. 1, pp. 1, pp. 1, pp. 1, pp. 1, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 4
    },
    {
        "text": "23, no. 22, no. 22, no. 22, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 5
    },
    {
        "text": "[63]11Saifuzzaman et al. 183–196, 2018.Saifuzzaman et al. 1274–1286, 2012.25Saifuzzaman et al. 136–151, 2019.26Saifuzzaman et al. 54, p. 102010, 2020.27Saifuzzaman et al. 131–141, 2020.29Saifuzzaman et al. 1–365, 2019.30Saifuzzaman et al. 1–17, Elsevier, 2019. 657–666, 2014.33Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 6
    },
    {
        "text": "16, no. 16, no. 16, no. 18, no. 16, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 7
    },
    {
        "text": "13, no. 14, no. 14, no. 15, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 8
    },
    {
        "text": "62–69, 2012. 13–30, 2015. 1187–1194, 2015. 1206–1211, 2018. 161–175, 2018. 1–47, 2020. 1, 2020. 3660–3678, 2020. 401–466,2018. 62–65,2019. 128–137, 2018. 269–282, 2017. 7381–7398, 2023. 228–241, 2017. 1–10, 2013. 2750–2762, 2015. 373–382, 2014. 22–26, 2016. 77–95, 2019. 218–229, 2017. 275–285,2019. 1–12, 2015. 629–650,2018. 50–66, 2017. 515–545, 2020. 187–200, 2020. 3184–3216, 2019. 3535–3546, 2016. 591–623, 2020. 1–28, 2022. 1–10, 2022. 479–488, 2018. 36–41, 2015. 815–823, 2017. 1–10, 2019. 57–76, 2019. 153–160, 2015. 81–97,2008. 410–414, 2019. 26–33, 2017. 63–87,2020. 1028–1039, 2019. 1121–1167, 2020. 1243–1263, 2020. 1–11, 2019. 80–91, 2019. 12286–12290, 2020. 16–31, 2019. 1538–1542, 2020. 178–196, 2019. 135–141, 2019. 99–110, 2019. 122–126,2019. 1251–1275, 2020. 245–258, 2017. 340–364, 2020. 95–122, 2020. 16–22, 2020. 2084–2092, 2018. 1–3, 2023. 101–117, 2018. 22, may 2023. 1–9, 2020. 18069–18083, 2020. 138–150, 2018. 234–252,2021.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 9
    },
    {
        "text": "165–173, Springer, 2019. 298–305, Wiley Online Library, 2017. 221–229, Springer, 2021. 232–239, Springer, 2020. 475–486, Springer, 2020. 475–482, Springer, 2020.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 10
    },
    {
        "text": "8, p. 218, 2021. 764, p. 118, 2012. 138, p. 104809, 2023. 128, p. 102283, 2022. 3, p. 764, 2020. 1, p. 139, 2020. 81, p. 106502, 2020. 77, p. 102357, 2022. 13, p. 4895, 2022. 35, p. 100657, 2022. 138, p. 106564, 2020. 4, p. 657, 2019. 101, p. 107991, 2022. 1, p. 69, 2019. 11, p. 100251, 2020.34",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 11
    },
    {
        "text": "Agustine et al. Negra et al. Satija et al. Furthermore,Namasudra et al. Shah et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 12
    },
    {
        "text": "2, pp. 2, pp. 2, pp. 2, pp. 2, pp. 2, pp. 2, pp. 2, pp. 2, pp. 2,pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 13
    },
    {
        "text": "3, pp. 3, pp. 3, pp. 3, pp. 3, pp. 3, pp. 3, pp. 3, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 14
    },
    {
        "text": "7, pp. 6,pp. 6, pp. 7, pp. 5, pp. 5, pp. 5,pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 15
    },
    {
        "text": "4, pp. 4, pp. 4, pp. 4, pp. 4, pp. 4,pp. 4, pp. 4, pp. 4, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 16
    },
    {
        "text": "One major obstacle is the deployment of IoT systems capable ofmanaging massive amounts of data while ensuring robust security measures for data con-fidentiality, integrity, authorization, and authentication. [98] N. Almolhis, A. M. Alashjaee, S. Duraibi, F. Alqahtani, and A. N. Moussa, “Thesecurity issues in iot-cloud: a review,” in 2020 16th IEEE International Colloquium onSignal Processing & Its Applications (CSPA), pp. [100] A. Bhattacharjya, X. Zhong, J. Wang, and X. Li, “Present scenarios of iot projectswith security aspects focused,” Digital Twin Technologies and Smart Cities, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 17
    },
    {
        "text": "Furthermore, enhancing research data for fall detection is challenging dueto the infrequency of such incidents [64].Big Data AnalyticsManaging the enormous quantities of data that are consistently produced by connected med-ical devices is one of the most significant and crucial challenges that smart healthcare hasto overcome. Furthermore, identifying the most cost-effective set of wearabledevices for measuring these monitored parameters is a challenging endeavor, especially giventhe substantial proliferation of options in the contemporary market.The field of IoT smart healthcare encompasses fall-detection services. In response to these challenges, the authors of [102] haveintroduced CTPhone, a fall identification system based on a smart home sensor network.With widespread connectivity, brain-computer interfaces (BCI) have the potential toempower individuals to directly control objects, such as smart home appliances or assistiverobots, using their thoughts. Chambers, “A posture recognition-based fall detection system for monitoring an elderly person in a smart home envi-ronment,” IEEE transactions on information technology in biomedicine, vol. [102] C. C.-H. Hsu, M. Y.-C. Wang, H. C. Shen, R. H.-C. Chiang, and C. H. Wen, “Fallcare+:An iot surveillance system for fall detection,” in 2017 International conference onapplied system innovation (ICASI), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 18
    },
    {
        "text": "Springer Studies in Computational IntelligenceChapter 10Towards Smart Healthcare: Challenges andOpportunities in IoT and MLMunshi Saifuzzaman 1, Tajkia Nuri Ananna 21 Dynamic Solution innovators, Dhaka 1206, Bangladesh2 Department of CSE, Metropolitan University, Sylhet, BangladeshEmail Address of the Corresponding Author: munshisaifuzzaman@gmail.comAbstractThe COVID-19 pandemic and other ongoing health crises have underscored the need forprompt healthcare services worldwide. Intelligent wear-able devices, a key part of modern healthcare, leverage Internet of Things technology tocollect extensive data related to the environment as well as psychological, behavioral, andphysical health. However, managing the substantial data generated by these wearables andother IoT devices in healthcare poses a significant challenge, potentially impeding decision-making processes. Additionally, machine learning, knownfor addressing various big data and networking challenges, has seen increased implementa-tion to enhance IoT systems in healthcare. This chapter focuses exclusively on exploringthe hurdles encountered when integrating ML methods into the IoT healthcare sector. Itoffers a comprehensive summary of current research challenges and potential opportunities,categorized into three scenarios: IoT-based, ML-based, and the implementation of machinelearning methodologies in the IoT-based healthcare industry. This compilation will assistfuture researchers, healthcare professionals, and government agencies by offering valuableinsights into recent smart healthcare advancements.Keywords: Healthcare analytics, machine learning integration, big data analytics, ma-chine learning in healthcare, IoT systems in healthcare, research challenges, opportunities inhealthcare.arXiv:2312.05530v2 [cs.CY] 12 Jan 2024Saifuzzaman et al. Revised on January 12, 202310.1 IntroductionSmart healthcare refers to the implementation of cutting-edge technologies within the health-care sector, including but not limited to the IoT, artificial intelligence (AI), machine learning(ML), deep learning (DL), and data analytics. In recent times, there have been numerous developments in the field of intelligenthealthcare that have been observed globally. These include agile treatment, timely provi-sion of services, remote monitoring of services, and timely response to emergency situations.Nonetheless, this presents the greatest obstacle to satisfying the rising demand for equipmentand smart devices [1]. The resolution of this obstacle was achieved through the implemen-tation of IoT in the healthcare sector. IoT implementation in the medical field has grown inpopularity following advances in technology such as smart cities, smart regions, and smartdevices.The healthcare technology community has shown significant interest and anticipation inthe IoT in recent years. With its practical applications, the healthcare industry stands tobenefit from a wide range of opportunities due to IoT integration. The utilization of millionsof sensors attached to a patient’s body allows for the real-time collection of health data,enabling continuous remote health monitoring. Wireless Body Sensor Networks (WBSN)represent a key technology for patient monitoring [2]. These sensors gather crucial healthdata such as glucose levels, blood pressure, temperature, heart rate, and ECG readings [3].More recent systems incorporate actuators that can modify the external environment andenable notification or alarm systems. The application domain of IoT-based smart healthcarehas seen remarkable advancements. This includes areas such as elderly monitoring, diseaseprediction, fitness tracking, remote monitoring, and disease treatment. These are just a fewexamples of the extensive developments in this field [4, 5, 6].Amid the advancements, a substantial amount of data, commonly referred to as big data,is generated by IoT devices. ML plays a crucial role in this process, particularly in IoT-basedsmart healthcare, where it’s integrated to manage big data analytics [7, 8]. The integration of ML with IoT devices simplifies the monitoring,management, and analysis of medical reports. This capability can expedite the discovery of new therapeutic solutions.Chapter Motivation: Researchers have extensively investigated smart healthcare com-ponents, methodologies, and technologies over the years, leading to a wealth of comprehensivediscussions on the subject. Revised on January 12, 2023below:• To the best of our knowledge, there has been a notable absence of dedicated studies,including book chapters, focusing on smart healthcare challenges and future directionsin recent years.• Our investigation involved searches on prominent digital libraries utilizing the (”sur-vey” OR ”review”) on (”smart healthcare” AND (”Challenges” OR ”Future Direc-tions”)) using ((”IoT” OR ”Internet of Things”) AND (”ML” OR ”Machine Learn-ing”)) keywords. The primary emphasis of our study is to discuss theexisting and ongoing challenges faced by smart healthcare solutions and propose poten-tial resolutions. Notably, smart healthcare technologies that donot align with the primary motivation were deliberately excluded from consideration.Table 10.1: Comparison between recent studies and this work (applying of ML into IoT isrepresented as ML and IOT. means yes and means no)Comparison TypeRecent Studies[10] [11] [12] [13] [14] Our workBook chapterTechnologiesIoT basedML basedApplicationsML and IoTIoT basedML basedChallengesML and IoTIoT basedML basedFuture WorkDirectionsML and IoTReaders are encouraged to delve into this chapter for a comprehensive and current under-standing of the evolving landscape of smart healthcare.Contributions: This chapter extensively discusses the obstacles that impede the progressof smart healthcare using IoT and ML approaches. This chapter extensively discusses the existing smart healthcare applications, researchchallenges, and future work directions in three distinct scenarios: IoT-based, ML-based,and employing ML in IoT-based healthcare.2.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 19
    },
    {
        "text": "While exploring existing smart healthcare applications, we not only provided briefdetails on these applications but also delved into a separate discussion on how ML has3Saifuzzaman et al. Additionally, we highlighted the synergies between ML andIoT, showcasing how this combination has played a crucial role in enhancing healthcaresystems.3. Existing schemes have been explored in order to understand the challenges faced bycurrent researchers developing ML-driven IoT applications.Chapter Organization: The chapter commences with Section 10.2, which explores thereal-life applications of the three individual domains. This section starts by briefly outliningthe applications of IoT-based healthcare (10.2.1), followed by examples of how ML hastransformed the healthcare domain (10.2.2), and concludes by examining the integration ofML in IoT-based smart healthcare solutions (10.2.3). The subsequent section (10.3) providesan in-depth survey summarizing the challenges encountered in IoT and ML-based smarthealthcare. This section is divided into three subsections, with each subsection individuallyrepresenting the three domain-specific smart healthcare open challenges. Finally, the chapterconcludes by outlining domain-specific potential future directions in Section (10.4), as basedon the survey.10.2 Exploring ML and IoT ApplicationsSmart healthcare is a technologically advanced field that revolutionizes conventional medicaland healthcare systems. Its primary objectives are to enhance healthcare services, improvepatient care, and optimize the entire healthcare ecosystem through the integration of cutting-edge technologies, data-driven insights, and interconnected devices. Smart healthcare relies on a va-riety of key components, including IoT devices, wearable and implantable medical devices,AI, electronic health records (EHR), big data analytics, and more. One notablefeature of smart healthcare is its capacity to facilitate remote patient monitoring throughinternet-connected devices. The integration oftechnology in the healthcare sector, known as smart healthcare, is a notable advancement.This approach utilizes technological capabilities to enhance the quality, accessibility, andpatient-centricity of healthcare services. Consequently, it contributes to the enhancement ofhealth outcomes and the optimization of healthcare delivery efficiency.The services provided by smart healthcare based on the target user can be utilized inseveral categories, including clinical/scientific research institutions (e.g., hospitals), regionalhealth decision-making institutions, or individual/family users/personalized service. Thissection provides a brief overview of several IoT-based smart healthcare applications, followedby a discussion of ML-integrated smart healthcare. It concludes with a demonstration ofapplications showcasing the intersection of IoT and ML in various domains.4Saifuzzaman et al. Revised on January 12, 202310.2.1 Practical Uses of IoT in Smart HealthcareThe application of IoT-based smart healthcare can be divided into several based on differentneeds [16]. Various characteristics of IoT possess the potential to revolutionize the healthcaredomain to a great extent. This subsection provides a brief overview of some particularlyimportant examples of IoT-based smart healthcare.Remote Monitoring and Disease DetectionIoT provides continuous remote monitoring through wearable devices, which plays a criti-cal role in early disease detection and prevention. [4] have presented an ECG data monitoring system that involves the attachmentof a bipotential device to the user’s t-shirt, with data transmitted to a smartphone viaBluetooth. Moreover, it facilitates remote consulta-tions via a dedicated mobile application [6].In surgical training and medical operations, IoT has been instrumental in developing ad-vanced solutions like surgical robotics and virtual reality-based training environments. Additionally, smart healthcare systems empower patients to self-monitor their phys-ical condition, as exemplified by the Stress Detection and Alleviation system using wearablemedical sensors for continuous stress level tracking and autonomous stress reduction support[22, 23]. IoT-based healthcare systems leverage virtual assistants as intermediaries, aidingpatients in translating everyday language into medical terms and autonomously providingpertinent information to physicians, optimizing patient management, and enhancing medicalprocedures for more efficient care delivery and time savings.5Saifuzzaman et al. Revised on January 12, 2023Smart Hospitals and Pharmaceutical IndustrySmart hospitals employ IoT-driven intelligent healthcare, utilizing advanced technologies toimprove patient care and offer customized services for medical staff, patients, and adminis-trators. These technologies enable functions like patient monitoring, daily medical personnelmanagement, and tracking of biological specimens and medical instruments within hospitalenvironments. Furthermore, smart healthcare in the pharmaceutical sector optimizes oper-ations such as inventory management, anti-counterfeiting measures, and drug production,benefiting patients with streamlined access to physical examination systems, online appoint-ment scheduling, and enhanced doctor-patient interactions. Automated processes expeditethe patient’s medical journey, while IoT-based solutions contribute to revolutionary advance-ments, aiding in disease research and conducting more effective clinical trials. In particular,continuous real-time monitoring through smart wearable devices proves valuable in trialsrelated to lung disease, offering timely and precise information [30].10.2.2 Practical Uses of ML in Smart HealthcareML and DL have the potential to enhance the intelligence of the smart healthcare domainby leveraging their ability to uncover novel insights from data. This capability can be utilized to ensure effective patient monitoring, de-tect diseases in advance, and enhance overall efficiency in smart healthcare. ML algorithms can play acrucial role in analyzing EHR data to swiftly identify individuals at risk, providing healthcareproviders with real-time and more accurate alerts. Inaddition, effectively managing the vast amount of data generated in the healthcare domaincan only be achieved through the efficient application of ML.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 20
    },
    {
        "text": "There exist multiple domainswithin smart healthcare where integrating ML can enhance the intelligence of healthcaresystems. This subsection provides a brief overview of some particularly notable examples.Remote Monitoring and Emergency careRemote monitoring stands out as a prime feature in smart healthcare, revolutionizing thehealthcare system. The integration of ML into healthcare systems significantly enhancesaccuracy and efficiency. have proposed a context-aware framework,entitled ”Hybrid Real-time Remote Monitoring,” designed for remote patient monitoring,where authors employ a Näıve Bayes classifier in conjunction with the Whale Optimizationalgorithm. Whether predicting and determining the progression of diseasesin patients with chronic illnesses [35] or detecting mosquito-borne diseases earlier [36], ML hasshown the potential to revolutionize traditional healthcare, transforming it into intelligenthealthcare. This transformative potential of ML in predicting and preventing diseases notonly enhances the ability to forecast disease progression but also enables proactive measuresfor early detection and intervention.Precision MedicinePrecision medicine, also known as personalized medicine, is an innovative approach thatutilizes individuals’ genetic, environmental, and lifestyle information to recommend tailoredmedical interventions for each person [37]. Revised on January 12, 2023Recommendation systemDiseaseDiagnosisData aggregationLiving assistanceSecured analysisPredictionSystemActivity monitoring7123456Healthcare Applications using ML and IoTFigure 10.1: ML based IoT Applicationsmous data generated in smart healthcare systems [44, 45]. This fusion of ML and IoT holdssignificant promise for immense progress in smart healthcare. Overall, the integration of MLtechniques with IoT technologies is leading to significant improvements in the field of smarthealthcare by addressing the challenges associated with vast data management and securityconcerns. With services such as real-time disease identification, prediction, and diagnosis,ML has the potential to revolutionize the healthcare industry and has critical importancein remote diagnosis. This section presents some examples of some of the appli-cations of ML in IoT-based smart healthcare. 10.1 presents a detailed visualization ofthe most prominent areas that can be benefited by the integration of ML and IoT in smarthealthcare.Recommendation SystemIn the realm of recommendation systems, many inventions have been proposed utilizing thefusion of IoT and ML. In [46], authors have proposed a recommendation system that uses IoTwearable devices to collect information such as previous history, demographic information,and retrieval of archived data from the sensors attached to the patient and applies various MLtechniques, such as decision trees, logistic regression, and LibSVM, to predict the occurrenceof diseases. The proposed schemereduces the high-dimensional space into a low-dimensional space that lowers the amount oftransmitted data in the network and enhances the network lifetime, which also enhances thequality of the aggregated data.Disease DiagnosisBy combining IoT and ML, it has become feasible to conduct a more precise and currentdisease diagnosis. (2018) employed ML techniques such as SVMs,linear discriminant analysis (LDA), and random forest to classify the activity of a patient[52].Living AssistanceThe successful integration of IoT and ML in the field of ambient assisted living (AAL) hassignificantly enhanced the quality of life for individuals facing various disabilities and re-quiring constant care. The adoption of supervised ML techniques is assessed toovercome the challenges associated with real-time activity recognition.Secured AnalysisAs a result of the sensitive nature of healthcare information, it is critical to ensure itsconfidentiality and security. The authors in [56] have proposed a highly secure system foran IoT-based healthcare environment, which utilizes a range of ML techniques to ensure thesecure classification of patient data.Prediction SystemBy integrating its predictive capabilities with IoT-based smart healthcare, ML is capable ofdeveloping an intelligent disease prediction system. The algorithm analyzes ECG data and makes predictionsabout cardiovascular diseases (CVD) using ML techniques.Activity MonitoringAs mentioned earlier, IoT-enabled home healthcare systems represent a prevalent instanceof smart healthcare solutions. Revised on January 12, 2023Resource ConstraintMaintenance CostService CostNetwork DisconnectionLow LatencyData Management QoSObtaining Relevant InfoResource limitationIoTImbalanced dataLarge Training DatasetComplex DimentionalityPerformance of ML modelsEthical challengesLegal considerationEvolution of MLMLData preparationIoT +MLContinuous LearningData SynchronizationML Model SynchronizationSecurity and PrivacyInteroperabilityDistinguishing True and False SignalsReal-time LearningOpen ChallengesFigure 10.2: The Open Challenges building smart healthcaredemonstrated notable success. Regarding open research challenges,the primary issues in incorporating ML techniques into IoT-based smart healthcare are de-lineated. The challenges are vividly illustrated in Figure 10.2.10.3.1 IoT based SystemsWhile the integration of IoT brings a transformative shift to traditional healthcare systems,it also introduces a host of challenges that must be promptly addressed to fully harnessthe technology’s potential. This section explores the array of challenges encountered byIoT-based smart healthcare solutions.10Saifuzzaman et al. The implementation of IoT devices in smart healthcare, including sensorsand wearable devices, often involves the use of expensive communication technologies andhardware tools. However, the integration of IoT in healthcare aims to enhance medical care whilereducing overall costs. Consequently, a crucial challenge emerges in overcoming this contra-diction by creating devices and sensors that require minimal maintenance.Network Disconnection and Low LatencyNetwork disconnection and low latency tolerance represent significant challenges in any IoT-based system. These issues become even more critical in the context of smart healthcare,where the system is directly linked to a person’s life.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 21
    },
    {
        "text": "Therefore, it is crucial to integrate backup optionsto address such challenges [63].Data ManagementManaging, analyzing, and processing data in the realm of smart healthcare poses significantchallenges due to the diverse nature of IoT devices and the substantial volume of datathey generate. In the field of smart healthcare, there’s a constant influx of massive dataevery second. These architectures are struggling tomeet the computational demands and precise timing constraints associated with the diverseand extensive data generated in smart healthcare [63].Limitations in Energy, Computational, and Storage ResourcesIn the domain of IoT-based smart healthcare, the integration of small wearable devices andsensors introduces a critical concern: power usage. Revised on January 12, 2023Obtaining Relevant InformationA significant hurdle in IoT-based smart healthcare lies in obtaining accurate signals anddata from the user’s or patient’s body. Wearable devices or sensors responsible for gatheringdiverse body measurements, such as respiratory rate, electrocardiogram (ECG) data, andblood pressure, need to be positioned correctly to efficiently capture the relevant information.For instance, identifying breathing abnormalities or monitoring respiratory rates poses achallenge due to the multitude of sounds generated by the upper body. Consequently,distinguishing between various types of signals and selecting the appropriate one proves tobe a challenging task [64].Quality of ServiceThe quality of service provided by an IoT-based healthcare system in fulfilling its tasksdetermines its primary performance metric. Numerous challenges arise in meeting the qualityrequirements of IoT-based applications, including energy efficiency, sensing data quality,network resource consumption, and latency. Consequently, the most critical factors in designing a smarthealthcare system are low latency, high response time, high scalability, and the integrationof backup options.10.3.2 ML based SystemsThe incorporation of ML has had a profound impact on revolutionizing the healthcare do-main, transforming it into a smart and intelligent system. However, implementing ML inthe smart healthcare domain presents several challenges. This subsection provides a conciseoverview of the challenges associated with integrating ML into the realm of smart healthcare.Preparation of Data for ML AlgorithmsPreparing data for ML algorithms is a challenging task, particularly when dealing with physi-ological or health-related data. In healthcare, because ML assumes that classes are normallydistributed, this bias could mean that the model does better at predicting outcomes formore common health conditions but worse on the minority class, which could potentiallyinclude critical conditions [66]. Furthermore, if the model exhibits bias toward a specificclass, it can impact decision-making, lead to false alarms, overlook rare conditions, andultimately have implications for patient health.Complex Dimentionality and Large Training DatasetData collected in the healthcare sector is typically high-dimensional, and while high dimen-sionality often provides relevant information for understanding patient conditions, applyingML algorithms to such data may lead to lower accuracy. Additionally, dealing with the vastamount of healthcare data poses a significant challenge. Several factors contribute tothe overall performance of ML implementations in smart healthcare. Dimensionality: The high dimensionality of data can impact the effectiveness of MLmodels, especially when dealing with complex and varied healthcare datasets.2. Lack of involvement from a medical professional in suchscenarios may pose severe threats and potential harm.Evolution of ML with changing infrastructureHealthcare facilities adapt to patient demands, evolving in management, infrastructure, data,and training requirements. The dynamic nature of healthcare advancement poses a crucialquestion: Will the implemented ML model align and evolve with changing infrastructurewhile maintaining its original prediction logic? [68] Addressing this challenge promptly isimperative.10.3.3 IoT and ML based SystemsIoT and ML have collaborated to bring about significant advancements in the field of smarthealthcare. This section discusses the open research challenges that are associated withML and IoT-based smart healthcare systems.Table 10.2: Open research challengesChallenges Type Issues Relevant workTransmission of Correlated data [69, 70]Resource Management Agreement [71]Resource ScarcityAcceptable level of accuracy [72]Compromisation of transmitted data [73, 74]Management of heterogenous data [75, 76]Security and PrivacyExisting techniques infeasibilityInteroperability [77, 78]Distinguishing True and False Signals [64]Data and ML Model Synchronization [31]Limited energy supplies [79]Success of the underlying applications [80]Energy Algorithms [81, 82]Energy managementOptimizationRouting ApproachNetwork performanceWays of gaining insights [83]Innovative noise removal techniques [84]Underlying topologies [85, 86, 87, 88]Big data AnalyticsPerformance Dynamics anddiverse environments[89, 90, 91, 92, 93]Open Research ChallengesThis section discusses the open research challenges in the domain of IoT and ML-based smarthealthcare. Revised on January 12, 2023Resource ConstraintThe scarcity of resources, including sensors, devices, actuators, and microcontrollers, presentsthe greatest obstacle for the development of smart healthcare. The aforementionedchallenges render ML-based data aggregation methods incapable of maintaining the integrityof the data, thereby resulting in higher energy consumption. The majority of current ML-based data aggregation methods are not energy efficient as a result of these concerns.In addition, effective management of resources is a critical challenge in smart healthcare.Because of the unique qualities of IoT networks, a number of issues related to resourcemanagement, including resource discovery, modeling, provisioning, scheduling, estimation,and monitoring, continue to be of greater importance than they were in the past [71].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 22
    },
    {
        "text": "Inaddition, the process of allocating resources is not nearly as efficiently optimized as it shouldbe to increase the overall quality of the service.Real-time and Continuous LearningIn smart healthcare, sensors continuously gather real-time data, which is then fed into MLalgorithms for analysis. In thisphenomenon, the ML model suddenly forgets what it has learned, leading to a significantreduction in performance [96].Data and ML Model SynchronizationIn the landscape of IoT and ML-based smart healthcare, data from heterogeneous devicesand sensors undergoes collection and transmission to the cloud for ML algorithm applica-tion and analysis. Addressing this significant challenge is crucialfor achieving optimal outcomes in smart healthcare systems.Security and PrivacyIntegration of IoT into healthcare has enabled a number of benefits that were unimaginablejust a few years ago, including individualized and immediate access to medical care, remoteand continuous monitoring, and more. This has been achieved through the collaboration ofhealthcare devices and technology, which provide users with an extensive array of healthcareservices. Between 2023 and 2028, the global healthcare IoT market is projected to expandby 12.32%, culminating in a valuation of around $178 billion by 20281. Despite the ongoingand revolutionary progress in smart healthcare, the security and privacy implications of theimplemented solution must be taken into account due to the sensitive nature of health data[97, 98, 99]. This continues to bea threat as the network continues to expand and a greater number of hardware and softwarevulnerabilities are introduced [73].Furthermore, the inclusion of personally identifiable information in healthcare data, in-cluding but not limited to personal details, family history, electronic medical records, andgenomic data, gives rise to concerns regarding the sensitivity of the data and its owner. Furthermore, the task of safeguardingdata privacy and security is considerably complicated by the fact that the majority of thedevices within the system are heterogeneous and are administered by third parties [75, 76].Due to the limited resources inherent in IoT devices, the existing security features are notfeasible enough to mitigate the issues.InteroperabilityThe combination of ML and the IoT has sped up advancements in medical care; however, thereal obstacle is the absence of global standards that are recognized and approved of by allrelevant authorities. Increasedthroughput, decreased unplanned outages, and lower maintenance costs are some of theadvantages that come along with the use of devices that are interoperable.Distinguishing True and False SignalsVarious wearable devices play a crucial role in smart healthcare, employing different ML1Healthcare IoT - Worldwide, available at: www.statista.com.16Saifuzzaman et al. It is anticipated that the growth of the IoT in the future will be more exag-gerated, which means that a greater quantity of data will be produced that is unstructured,raw, and highly correlated. It is essential to have this in place so thata variety of ML and DL techniques can be utilized to facilitate improved decision-making.In addition, because IoT devices produce real-time data, it is extremely difficult to applyML algorithms to real-time data and carry out a variety of operations in order to respondappropriately.At present, ML-based data aggregation techniques are inadequately optimized in termsof the nature of the data, which hinders their ability to identify outliers while maintainingservice quality and efficiency. Furthermore,existing methodologies fail to adequately support the execution of diverse data analysisoperations in a heterogeneous setting, a significant obstacle given the substantial influenceof heterogeneity in the domain of intelligent healthcare [89, 90, 92].Challenges in Existing SystemsIn this section, various domains have been examined within the realm of H-IoT to ascertainthe challenges encountered by researchers when proposing a new architecture. Revised on January 12, 2023Table 10.3: Challenges considered in various healthcare domains ( means considered andmeans does not)ChallengesConsidered(Metric)Reference (Sensor Level)[46](AR)[102](EEGinformation)[103](CLA)[104](Diagnosissystem)[105](H-IoT QoS)[106]Feature extractionCost-effectivenessPersonalisationEfficiencyUsefulnessBig data analyticsScalabilityMaintainabilityEnvironmental factorsand sentiment statusReal-time dataSecurity and PrivacyAsthana et al. [105] have conducted a case study to assess the feasibility of integratingIoT and ML for enhancing the diabetes management system. EmbeddedML not only limits the advantages of collecting and storing copious raw data but also addsits own financial implications.10.4 Future Work DirectionsThe current state of smart healthcare has reached a level that was unimaginable just a fewyears ago, particularly due to the incorporation of IoT and ML into the process. This section presents potentialdirections for the future based on the challenges that have been covered in the section thatcame before it.10.4.1 IoT based SystemsSmart healthcare based on the IoT encounters various challenges, as extensively discussedin the previous section. Moreover,incorporating contactless feature extraction, along with signal processing techniques likePCA, ICA, filtering, and supervised ML methods, could offer a more robust solution [64].10.4.2 ML based SystemsThe challenges faced by the ML-based healthcare system have been explored in Section10.3.2. This section provides some future research aspects based on these challenges to makethe smart healthcare system more robust and efficient.20Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 23
    },
    {
        "text": "This can be achievedby integrating aggregators at the edge, facilitating a more personalized and context-awarehealthcare approach.Optimization techniques for High Dimentionality and Data ImbalanceTo mitigate challenges like high dimensionality in data and biases arising from data imbal-ance, upcoming research should concentrate on optimizing model architecture, enhancingtraining and validation procedures, and investigating sampling techniques or introducing en-semble learning [118]. It is crucial to ensure that the original data remains unaltered whileaddressing these challenges in order to enhance the effectiveness of ML in smart healthcare.Developing Scalable Platform for Big DataIn order to tackle the challenges associated with handling extensive volumes of medical data,the development of scalable, robust, and elastic cloud platforms is imperative for effectivebig data management in the healthcare domain. By leveraging the parallel processing capabilities inherent in MapRe-duce, healthcare applications can efficiently handle the massive datasets involved in medicalanalytics, paving the way for more effective and scalable ML solutions in the healthcaredomain.Use Open and Interpretable AIOpen and interpretable AI offers a potential solution to address legal, ethical, and socialissues arising from ML in healthcare by focusing on enhancing the understandability ofmachine decisions [117]. Open and interpretable AI addresses various challenges and issues, therebyimproving the overall experience of service delivery, traceability, and confidence in the use ofAI and ML tools in healthcare. Therefore, it is necessary to conduct research on interpretabil-ity and explanatory techniques for ML models within the Smart Healthcare Management(SHM) framework.10.4.3 IoT and ML based SystemsIn this section, we have discussed the future directions of IoT and ML-based smart healthcarechallenges.21Saifuzzaman et al. As a result, it is essential to developan innovative, lightweight, and energy-efficient ML-based data aggregation algorithm becausethe majority of the currently available solutions do not include these characteristics. These schemes should not only be able to solvethe problem of resource constraints that are present in these networks, but they should alsobe able to provide a solution that has an acceptable level of accuracy [72].Continuous Learning for Handling Synchronization IssueAddressing model and data synchronization issues in smart healthcare requires future re-search efforts. [122] have emphasized the need for ML algorithms to facilitatecontinuous learning from clinical data and apply this learning to new data. This in-volves ensuring that when various healthcare systems or devices share information with oneanother, they are able to comprehend the meaning and context of the data in a manner that22Saifuzzaman et al. It is essential for effective communication and collaborationbetween various technologies used in the healthcare field that they speak the same languagewhen exchanging important medical data.Integrating ML and Optimization MethodsIt is crucial to develop tools and methods for big data analytics that can perform analysis andextract the necessary information. Moreimportantly, because IoT devices produce real-time data, utilizing ML techniques for real-time information monitoring and providing prompt responses is a very interesting future areafor research. Furthermore, studies that interlink the two cross domains, i.e., big data an-alytics and healthcare, are still in their early stages, and as a result, the research communityneeds to pay even more attention to these types of studies.10.5 ConclusionsIn the 21st century, IoT has thrived, enhancing daily decision-making and introducing ser-vices like pay-as-you-use models. In recent years, both ML and IoThave independently impacted healthcare, with ML focusing on algorithm development andIoT facilitating real-time monitoring. Researchers are now frequently exploring ML solutionswithin IoT-based healthcare, providing significant benefits in statistical and predictive analy-sis. This chapter provides a comprehensive introduction to IoT-based smart healthcare withML, catering to newcomers interested in exploring this field. The chapter divides into three main sections:IoT-based smart healthcare, ML integration in traditional healthcare, and the synergy ofboth IoT and ML. It discusses real-life applications in these domains, addresses challengesin developing new architectural solutions, and outlines future research directions.Overall, the chapter establishes a strong foundation for researchers keen on practical ap-plications or innovative theoretical approaches in the realm of smart healthcare, providing adeep understanding of the challenges associated with ML and IoT applications. While theinherent and individual capabilities of IoT and ML create an ideal cross-domain synergy fordeveloping IoT and ML-based smart healthcare, several challenges still exist. Firstly, thereare challenges faced by IoT and ML individually in healthcare and other domains. Secondly,issues arise with the cross-domain combination of IoT and ML, as both domains present23Springer Studies in Computational Intelligencevarious complexities. Therefore, future research should primarily address the inherent is-sues of each domain while also tackling the complexities of integrating these two domains.Considering the persistent research challenges, an appropriate approach could lead to thetransformative changes in healthcare that the world anticipates.References[1] D. J. Cook, A. S. Crandall, B. L. Thomas, and N. C. Krishnan, “Casas: A smart homein a box,” Computer, vol. A. Thabit, F. A. Al-Mayali, Q. H. Abbasi, et al., “Wbsn in iot health-based application: toward delay and energy consumption minimization,” Journal ofSensors, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 24
    },
    {
        "text": "[3] A. Abdullah, A. Ismael, A. Rashid, A. Abou-ElNour, and M. Tarique, “Real timewireless health monitoring application using mobile devices,” International Journal ofComputer Networks & Communications (IJCNC), vol. [4] T. Wu, J.-M. Redouté, and M. Yuce, “A wearable, low-power, real-time ecg monitorfor smart t-shirt and iot healthcare applications,” in Advances in Body Area NetworksI: Post-Conference Proceedings of BodyNets 2017, pp. [6] M. Heshmat and A.-R. S. Shehata, “A framework about using internet of things forsmart cancer treatment process,” in Proceedings of the international conference onindustrial engineering and operations management, pp. [7] M. S. Mahdavinejad, M. Rezvan, M. Barekatain, P. Adibi, P. Barnaghi, and A. P.Sheth, “Machine learning for internet of things data analysis: A survey,” Digital Com-munications and Networks, vol. [9] G. C. Babu and S. Shantharajah, “Survey on data analytics techniques in health-care using iot platform,” International Journal of Reasoning-based Intelligent Systems,vol. A. Akour, “Iot for smart cities: Machine learning approaches insmart healthcare—a review,” Future Internet, vol. [11] F. G. Mohammadi, F. Shenavarmasouleh, and H. R. Arabnia, “Applications of machinelearning in healthcare and internet of things (iot): a comprehensive review,” arXivpreprint arXiv:2202.02868, 2022. [12] N. Chawla, “Ai, iot and wearable technology for smart healthcare-a review.,” Interna-tional Journal of Recent Research Aspects, vol. [13] F. Alshehri and G. Muhammad, “A comprehensive survey of the internet of things(iot) and ai-based smart healthcare,” IEEE Access, vol. [14] M. A. Tunc, E. Gures, and I. Shayea, “A survey on iot smart healthcare:Emerging technologies, applications, challenges, and future trends,” arXiv preprintarXiv:2109.02042, 2021. [15] H. Yin, A. O. Akmandor, A. Mosenia, N. K. Jha, et al., “Smart healthcare,” Foun-dations and Trends® in Electronic Design Automation, vol. [16] S. Tian, W. Yang, J. M. Le Grange, P. Wang, W. Huang, and Z. Ye, “Smart healthcare:making medical care more intelligent,” Global Health Journal, vol. [17] M.-L. Liu, L. Tao, and Z. Yan, “Internet of things-based electrocardiogram monitoringsystem,” Chinese Patent, vol. [25] H. Yin and N. K. Jha, “A health decision support system for disease diagnosis basedon wearable medical sensors and machine learning ensembles,” IEEE Transactions onMulti-Scale Computing Systems, vol. [31] M. K. Hassan, A. I. El Desouky, S. M. Elghamrawy, and A. M. Sarhan, “Intelligenthybrid remote patient-monitoring model with cloud-based framework for knowledgediscovery,” Computers & Electrical Engineering, vol. [33] L. Syed, S. Jabeen, S. Manimala, and A. Alsaeedi, “Smart healthcare framework forambient assisted living using iomt and big data analytics techniques,” Future Genera-tion Computer Systems, vol. [42] S. Joshi, H. Kumar, J. Babu, A. Raju, and M. Nihaz, “Healthcare assistant—a toolto predict disease using machine learning,” in International Conference on Micro-Electronics and Telecommunication Engineering, pp. [43] B. Farahani, F. Firouzi, and K. Chakrabarty, “Healthcare iot,” Intelligent Internet ofThings: From Device to Fog and Cloud, pp. [44] S. Tuli, N. Basumatary, S. S. Gill, M. Kahani, R. C. Arya, G. S. Wander, and R. Buyya,“Healthfog: An ensemble deep learning based smart healthcare system for automaticdiagnosis of heart diseases in integrated iot and fog computing environments,” FutureGeneration Computer Systems, vol. Revised on January 12, 2023[46] S. Asthana, A. Megahed, and R. Strong, “A recommendation system for proactivehealth monitoring using iot and wearable technologies,” in 2017 IEEE internationalconference on AI & mobile services (AIMS), pp. [51] K. Pradhan and P. Chawla, “Medical internet of things using machine learning al-gorithms for lung cancer detection,” Journal of Management Analytics, vol. [55] I. Rupasinghe and M. Maduranga, “Towards ambient assisted living (aal): Design ofan iotbased elderly activity monitoring system,” International Journal of Engineeringand Manufacturing (IJEM), vol. [57] P. Gope and T. Hwang, “Bsn-care: A secure iot-based modern healthcare system usingbody sensor network,” IEEE sensors journal, vol. A. Majumder, and D. R. Ucci, “A wireless early prediction sys-tem of cardiac arrest through iot,” in 2017 IEEE 41st annual computer software andapplications conference (COMPSAC), vol. [63] A. Tissaoui and M. Saidi, “Uncertainty in iot for smart healthcare: Challenges, andopportunities,” in The Impact of Digital Technologies on Public Health in Developedand Developing Countries: 18th International Conference, ICOST 2020, Hammamet,Tunisia, June 24–26, 2020, Proceedings 18, pp. [64] L. P. Malasinghe, N. Ramzan, and K. Dahal, “Remote patient monitoring: a compre-hensive study,” Journal of Ambient Intelligence and Humanized Computing, vol. [67] P.-H. C. Chen, Y. Liu, and L. Peng, “How to develop machine learning models forhealthcare,” Nature materials, vol. [73] D. Sharma and R. Tripathi, “Performance of internet of things based healthcare se-cure services and its importance: Issue and challenges,” tech. [76] P. A. Williams and V. McCauley, “Always connected: The security challenges of thehealthcare internet of things,” in 2016 IEEE 3rd World Forum on Internet of Things(WF-IoT), pp. B. Zikria, A. V. Vasilakos, and S. W. Kim, “The futureof healthcare internet of things: a survey of emerging technologies,” IEEE Communi-cations Surveys & Tutorials, vol. [81] S. Selvaraj and S. Sundaravaradhan, “Challenges and opportunities in iot healthcaresystems: a systematic review,” SN Applied Sciences, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 25
    },
    {
        "text": "[97] H. Kaur, M. Atif, and R. Chauhan, “An internet of healthcare things (ioht)-basedhealthcare monitoring system,” in Advances in Intelligent Computing and Communi-cation: Proceedings of ICAC 2019, pp. [105] A. Ara and A. Ara, “Case study: Integrating iot, streaming analytics and machinelearning to improve intelligent diabetes management system,” in 2017 Internationalconference on energy, communication, data analytics and soft computing (ICECDS),pp. [116] J. Amann, A. Blasimme, E. Vayena, D. Frey, V. I. Madai, and P. Consortium, “Ex-plainability for artificial intelligence in healthcare: a multidisciplinary perspective,”BMC medical informatics and decision making, vol. [117] A. Vellido, “The importance of interpretability and visualization in machine learn-ing for applications in medicine and health care,” Neural computing and applications,vol. [120] S. Das and S. Namasudra, “A novel hybrid encryption method to secure healthcaredata in iot-enabled healthcare infrastructure,” Computers and Electrical Engineering,vol. [121] W. Li, Y. Chai, F. Khan, S. R. U. Jan, S. Verma, V. G. Menon, f. Kavita, and X. Li,“A comprehensive survey on machine learning-based big data analytics for iot-enabledsmart healthcare system,” Mobile networks and applications, vol. [123] E. Moghadas, J. Rezazadeh, and R. Farahbakhsh, “An iot patient monitoring basedon fog computing and data mining: Cardiac arrhythmia usecase,” Internet of Things,vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 26
    },
    {
        "text": "ML possesses the capability to effectively handle vast volumes of data and ex-tract meaningful insights from it [43]. Moreover, data may require preprocessingfor storage efficiency or to uphold the quality of data mining processes [65]. In addition to this,gaining useful insights from these data is a challenging task for a variety of ML algorithmsbecause it requires extensive preprocessing of data, which takes a lot of time, and managingthis massive amount of data is very difficult [83]. [65] Y.-H. Hu, W.-C. Lin, C.-F. Tsai, S.-W. Ke, and C.-W. Chen, “An efficient data pre-processing approach for large scale medical data mining,” Technology and Health Care,vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 27
    },
    {
        "text": "70, pp. 93, pp. 69, pp. 100, pp. 75, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 28
    },
    {
        "text": "101, pp. 104, pp. 104, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 29
    },
    {
        "text": "46, no. 53, no. 62, no. 34, no. 29, no. 55, no. 34, no. 32, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 30
    },
    {
        "text": "23, pp. 26, pp. 27, pp. 24, pp. 26, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 31
    },
    {
        "text": "7, no. 7, no. 7, no. 9, no. 6, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 32
    },
    {
        "text": "[8] B. Qian, J. Su, Z. Wen, D. N. Jha, Y. Li, Y. Guan, D. Puthal, P. James, R. Yang,A. [21] M. Yu, A. Rhuma, S. M. Naqvi, L. Wang, and J. [28] J. Andreu-Perez, D. R. Leff, H. M. Ip, and G.-Z. [47] V. Subramaniyaswamy, G. Manogaran, R. Logesh, V. Vijayakumar, N. Chilamkurti,D. [53] G. Matar, J.-M. Lina, J. [115] M. Kim, J. Yun, Y. Cho, K. Shin, R. Jang, H.-j. [122] P. Shah, F. Kendall, S. Khozin, R. Goosen, J. Hu, J. Laramie, M. Ringel, andN.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 33
    },
    {
        "text": "4, no. 3, no. 3,no. 3, no. 4, no. 4, no. 4, no. 4, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 34
    },
    {
        "text": "The traditional healthcare system, centered aroundhospitals and clinics, has proven inadequate in the face of such challenges.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 35
    },
    {
        "text": "Population expansion and a rise in the preva-lence of diseases have combined to necessitate the development of a sophisticated healthcaresystem.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 36
    },
    {
        "text": "have formulated and assesseda SVM model to predict the sensitivity of anticancer drugs using genomic data.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 37
    },
    {
        "text": "They haveproved that by leveraging genomics, it’s possible to predict a patient’s response to cancertreatment.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 38
    },
    {
        "text": "If implemented in clinical settings, this approach could potentially spare non-responders from unnecessary treatments, directing them toward the most effective treatmentbased on their individual genome.Decision Support SystemsDecision support systems are increasingly utilized in the healthcare industry, enhancing theability of doctors and hospitals to deliver improved treatment.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 39
    },
    {
        "text": "While doctors remain the pri-mary decision-makers, these systems enable them to expand their knowledge through healthdata, research databases, and examinations.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 40
    },
    {
        "text": "Decision support systems based on ML canexpedite decision-making, offer treatment suggestions, and provide justifications that helppatients’ family members understand the entire procedure.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 41
    },
    {
        "text": "This not only allows doctorsto allocate more time to communicating with patients but also alleviates the pressure ofacquiring extensive knowledge and facilitates seeking a second opinion on decisions.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 42
    },
    {
        "text": "A po-tential reference is available in [10], where the authors propose initial therapies or treatments.This is particularly valuable in emergency situations where time constraints necessitate swiftdecision-making.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 43
    },
    {
        "text": "Furthermore, by integrating bottleneck attention modules to distinguishbetween abnormal and normal DFU cases, a convolutional neural network (CNN)-basedsystem for diabetic foot ulcers (DFU) has been suggested in [40].10.2.3 Healthcare Applications Using ML and IoTDespite the significant advancements in IoT-based smart healthcare, several persistent chal-lenges hinder its progress.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 44
    },
    {
        "text": "The sensors and devices withinthese systems generate extensive data, often referred to as big data, characterized by highlycorrelated and redundant patterns.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 45
    },
    {
        "text": "To address this issue, ML techniques have emerged aspivotal tools.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 46
    },
    {
        "text": "Various ML and DL techniques, such as convolutionalneural networks, autoencoders (AE), deep belief networks (DBNs), long short-term memory(LSTM), and recurrent neural networks (RNNs), are being integrated to manage the enor-7Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 47
    },
    {
        "text": "Additionally, AI-powered assistive systems facilitate care for traumapatients and aid in their recovery.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 48
    },
    {
        "text": "Fig.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 49
    },
    {
        "text": "Based on the information, a customized recommendation system is developedfrom the output.Data AggregationML techniques are integrated to carry out efficient data aggregation, as data aggregation isa major step in smart healthcare.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 50
    },
    {
        "text": "In [48], authors have proposed a self-organized algorithm8Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 51
    },
    {
        "text": "Revised on January 12, 2023that aggregates healthcare data that has been collected via sensors.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 52
    },
    {
        "text": "An enhanced DL-assisted convolutional neural network (EDCNN) hasbeen integrated into the Internet of Medical Things (IoMT) platform in [50], thereby facil-itating the diagnosis of cardiovascular disease.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 53
    },
    {
        "text": "Furthermore, significant progress has beenachieved in the identification of lung cancer through the implementation of sophisticatedML algorithms and IoT systems [51].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 54
    },
    {
        "text": "Active patient activity recognition and monitoringis another application of ML.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 55
    },
    {
        "text": "In [55], the authors have proposed a system that utilizes wrist-worndevices to collect data, employing a supervised ML algorithm, the Decision Tree Classifier.This algorithm can recognize four different activities: walking, sitting, sleeping, and stand-ing.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 56
    },
    {
        "text": "This real-time activity recognition serves as a constant assistant for individuals withdisabilities or elderly individuals.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 57
    },
    {
        "text": "The authors of [58] have proposed anIoT and ML-integrated cardiac arrest prediction system.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 58
    },
    {
        "text": "The sensor acquires ECG signalscontaining information regarding cardiac activity.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 59
    },
    {
        "text": "Following noise reduction, the acquiredcardiac information is compared to a predetermined threshold in order to make a predictionregarding the outcome.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 60
    },
    {
        "text": "[60] have developed an algorithm for evaluating signalquality that is energy efficient.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 61
    },
    {
        "text": "The incorporation of ML technologies in this domain has9Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 62
    },
    {
        "text": "Authors from [61] introduced a system capable of detectinghuman presence without relying on cameras or motion sensors.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 63
    },
    {
        "text": "This system gathers interac-tion data by monitoring activities like reading or writing across a diverse range of devices,subsequently leveraging multiple ML classification algorithms, including the C4.5 decisiontree, linear support vector classifier (SVC), and random forest, to identify the presence of ahuman.10.3 Research ChallengesIn addressing the research challenges, the section is partitioned into two subsections, namelydomain-specific challenges and open research challenges.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 64
    },
    {
        "text": "Exploring domain-specific chal-lenges involves an examination of recent studies in various healthcare fields, detailing theobstacles addressed within their respective domains.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 65
    },
    {
        "text": "Revised on January 12, 2023Maintenance and Service CostA significant hurdle in IoT-based systems is the substantial cost associated with maintain-ing IoT devices.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 66
    },
    {
        "text": "This results in elevated service and maintenance costs for developing thesedevices.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 67
    },
    {
        "text": "The use of diverse devices and thelarge volume of generated data can create obstacles to receiving timely information.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 68
    },
    {
        "text": "Thisdelay can lead to critical issues, especially in emergencies such as sudden changes in bloodpressure or heart rate during remote monitoring.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 69
    },
    {
        "text": "If data isn’t transmitted promptly, patientsmay miss out on timely treatment, posing significant health risks [14].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 70
    },
    {
        "text": "Additionally, forsmooth operation, IoT devices require consistent network connectivity.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 71
    },
    {
        "text": "Given the numerous devices, data, and potential internet issues, ensuring theseprerequisites in every case is challenging.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 72
    },
    {
        "text": "The challenges lie in efficiently collecting this data, establishing standardizedformats and structures, utilizing suitable data models, and providing semantic descriptionsof their content.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 73
    },
    {
        "text": "Additionally, the prevalent approach of employing cloud-based solutions forhandling and analyzing this data is raising concerns.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 74
    },
    {
        "text": "Ensuring a continuous power sourceis essential for the uninterrupted operation of these devices.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 75
    },
    {
        "text": "Striking a balance betweenthe compact size of these devices and their energy consumption requirements presents asignificant challenge.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 76
    },
    {
        "text": "Meeting energy requirements becomes intricate as there is limited roomto increase the device size to accommodate larger energy sources.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 77
    },
    {
        "text": "Furthermore, restrictedstorage and computational capabilities pose obstacles to implementing complex operations,such as cryptographic models for security.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 78
    },
    {
        "text": "Consequently, a persistent question remains: howto enhance the battery life of IoT devices while preserving their compact size?",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 79
    },
    {
        "text": "Any misplacementof the sensor or device can result in the collection of inaccurate information.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 80
    },
    {
        "text": "The quality of wearable devices or sensors usedin this domain plays a crucial role in determining the system’s accuracy and the relevance ofthe collected information [63].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 81
    },
    {
        "text": "Such data is often collected from diverse sources and exists inunstructured or semi-structured formats.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 82
    },
    {
        "text": "Therefore, prior to applying any ML algorithm, itis crucial to preprocess the data to avoid potential impacts on model training and classifica-tion accuracy.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 83
    },
    {
        "text": "This involves the critical integration of data from different sources, addressingoutliers, noise, missing and inconsistent data, and transforming it into a standardized format.Dimensionality reduction may also be necessary.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 84
    },
    {
        "text": "Given the natureand volume of healthcare data, this process is notably challenging.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 85
    },
    {
        "text": "Additionally, incorpo-rating patient-specific factors, which vary for each patient, poses a considerable challenge toachieve.Imbalanced DataClass imbalance is a prevalent factor in ML, occurring when the distribution of classes withina dataset is uneven.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 86
    },
    {
        "text": "Specifically, one class comprises a significantly larger number of recordsthan the other.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 87
    },
    {
        "text": "In such cases, the implementation of any ML model tends to be biased12Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 88
    },
    {
        "text": "Revised on January 12, 2023toward the majority class.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 89
    },
    {
        "text": "ML algorithms require an adequateamount of accurate data to effectively fulfill their roles.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 90
    },
    {
        "text": "For instance, the application of DLto image-based health data demands a substantial and high-quality training dataset.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 91
    },
    {
        "text": "Ensur-ing the validity and accuracy of the images is crucial.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 92
    },
    {
        "text": "However, obtaining such image data,meeting both quantity and quality requirements, remains a challenging task [67].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 93
    },
    {
        "text": "Further-more, any increase in the size of the training data contributes to the memory complexity ofthe model.Performance of ML modelsCreating an effective model that performs well across diverse healthcare datasets is a world-wide challenge.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 94
    },
    {
        "text": "For instance, convolutional neural networks (CNNs) excel in image-relatedtasks, while recurrent neural networks are proficient in waveform analysis.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 95
    },
    {
        "text": "However, in thecontext of smart healthcare, where data is sourced from various origins, the application of aspecific model may not necessarily yield optimal performance.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 96
    },
    {
        "text": "These include:1.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 97
    },
    {
        "text": "Noisy Data: The presence of noise or irrelevant information in the data can hinder theaccuracy and reliability of ML algorithms.3.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 98
    },
    {
        "text": "Redundant Data: Duplicate or redundant data may lead to inefficiencies in modeltraining and may not contribute substantially to the learning process.4.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 99
    },
    {
        "text": "Outliers: Outliers can significantly influence the performance of ML models by skewingthe training process and affecting the generalization of the model.5.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 100
    },
    {
        "text": "Number of Attributes: The number of attributes or features in datasets can posechallenges, especially when dealing with a large and varied set of healthcare data.Addressing Ethical and Legal ChallengesEntrusting a ML model with the entire responsibility of processing raw medical data ischallenging.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 101
    },
    {
        "text": "Involving a medical professional becomes necessary to categorize and interpretthe medical data.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 102
    },
    {
        "text": "Numerous ethical and legal concerns surround the implementation of ML13Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 103
    },
    {
        "text": "Revised on January 12, 2023in healthcare.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 104
    },
    {
        "text": "For instance, the output of a DL algorithm applied to healthcare data canbe challenging to explain logically.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 105
    },
    {
        "text": "However, there are still a lot of obstacles to overcome because of the inherentcomplexities of the individual fields as well as the complications that arise when combiningthese two fields.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 106
    },
    {
        "text": "The summarization is represented in Table 10.2.14Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 107
    },
    {
        "text": "Because of their relativelytiny size, these devices have limited processing capacity and poor computational capability.As a result, it is difficult to manage the resources by making sure that they are being usedeffectively reference [72, 94, 95].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 108
    },
    {
        "text": "In addition, the data that is produced by these devices withlimited resources is strongly correlated with one another, redundant, and contains patternsthat are quite similar to one another.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 109
    },
    {
        "text": "This data requires preprocessing to extract valuable insightsfor subsequent analysis.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 110
    },
    {
        "text": "Because of this, transmitting various kinds of data overthe network for the purpose of analysis or storage consumes a significant amount of energy,which in turn lowers the quality of service and results in low throughput.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 111
    },
    {
        "text": "This problem ofscarce resources has been mitigated to some extent as a result of the integration of cloudservices with the IoT; however, integration of cloud services leads to increased complexity,greater costs, and a higher level of required maintenance.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 112
    },
    {
        "text": "In addition to this, these datacome from a wide variety of sources, the quality of which may vary, as well as difficulties suchas noisy data, inconsistent data, and a great number of other problems.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 113
    },
    {
        "text": "This scenario persists as data is captured moment by moment inreal time.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 114
    },
    {
        "text": "Continuous learning, or online ML, involves learning from the ever-increasingdata while retaining knowledge from previous datasets.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 115
    },
    {
        "text": "While online ML appears to be animpactful solution, it has constraints, one of which is catastrophic forgetfulness.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 116
    },
    {
        "text": "However, the heterogeneity in sensor internal clock structures introduceschallenges in synchronization, necessitating the implementation of smart gateways.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 117
    },
    {
        "text": "It be-comes imperative to synchronize the collected data on a temporal basis before transmittingit to the cloud for preprocessing, model training, and development.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 118
    },
    {
        "text": "In cases lacking edgedevices, this entire process unfolds in the cloud, where decisions and alerts are generated.Any disruption in network and cloud services poses a severe threat to patients, potentiallyendangering their lives.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 119
    },
    {
        "text": "To mitigate this risk, it is essential to design the system in a waythat ensures data synchronization on local servers.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 120
    },
    {
        "text": "For instance, Hassan et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 121
    },
    {
        "text": "proposed a15Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 122
    },
    {
        "text": "Revised on January 12, 2023hybrid model, acknowledging a drawback involving the downloading and copying of the MLmodel from the cloud to local devices [31].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 123
    },
    {
        "text": "ML techniqueshandle extensive data, learning from it, training systems, facilitating enhanced decision-making, and refining treatment design.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 124
    },
    {
        "text": "This leaves the network susceptible to a variety of threats, including denial ofservice, eavesdropping, Sybil, sinkhole, and sleep deprivation attacks.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 125
    },
    {
        "text": "Anestimated 72% of malicious traffic is directed at healthcare data with the intention of exploit-ing the system [74].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 126
    },
    {
        "text": "Hence, it is critical to ensure the confidentiality and protection of thisdata against hackers through the implementation of diverse security and privacy protocols[100].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 127
    },
    {
        "text": "In addition to these, additional obstacles may include inadequate physical security,misconfigured devices, or network vulnerabilities.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 128
    },
    {
        "text": "Because of the diverse range of applications and application domains,it is becoming an increasingly difficult task to maintain a global collaborative environment,whether the topic at hand is the selection of technologies or algorithms [77, 78].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 129
    },
    {
        "text": "These techniques derive meaningful insights, uncoverpatterns, and reveal concealed information within large datasets.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 130
    },
    {
        "text": "Revised on January 12, 2023algorithms based on the application.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 131
    },
    {
        "text": "However, the challenging aspect lies in accuratelydistinguishing between genuine and false signals.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 132
    },
    {
        "text": "For instance, in a fall detection system, anaccelerometer is typically utilized to identify falls, with a ML algorithm analyzing the dataand sending alerts to caregivers.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 133
    },
    {
        "text": "Yet, differentiating between a fall and a rapid movementor regular activities poses a formidable challenge.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 134
    },
    {
        "text": "The system must exhibit robustness todiscern any sudden movement, such as bending down or picking up an object, to preventthe introduction of false data into the ML algorithm, thereby avoiding the generation ofinaccurate alerts.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 135
    },
    {
        "text": "These data are passed through the network and are used foranalysis as well as decision-making.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 136
    },
    {
        "text": "The data may contain correlations, redundant values,or null values.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 137
    },
    {
        "text": "The key components ofthis layer encompass clustering, classification, association analysis, time series analysis, andoutlier analysis [7, 9].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 138
    },
    {
        "text": "Moreover, the correlation between data aggregation and thefundamental topology of the network is more evident.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 139
    },
    {
        "text": "The efficacy of these methodologies issignificantly influenced by the foundational topologies [85, 86, 87].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 140
    },
    {
        "text": "To improve the quality ofaggregated data and enhance data signal quality, it is critical to reduce noise, which is quitechallenging to accomplish with current methods given the nature of the data.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 141
    },
    {
        "text": "Specifically,recent literature has been reviewed encompassing different metrics, including sensor-leveldata, augmented reality, electroencephalogram (EEG) information, cognitive load assess-ment, diagnostic systems, and H-IoT quality of service (QoS).",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 142
    },
    {
        "text": "The identified challenges havebeen organized and presented in Table 10.3.17Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 143
    },
    {
        "text": "[46] have proposed a recommendation system that employs ML to classifyinput data and associate disorders with corresponding wearable devices.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 144
    },
    {
        "text": "Their architecturaldesign addresses the extraction of an individual’s health conditions and the necessary mea-surements for monitoring.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 145
    },
    {
        "text": "FallCare facesthree prominent issues: (1) constrained computational resources on the Raspberry Pi 2 (RPi2); (2) a lack of live streaming capability for detection, relying on images, fall video clips,or event notifications; and (3) poor scalability and maintainability for updating learningmodels across distributed devices.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 146
    },
    {
        "text": "[103] have proposeda unified DL framework aimed at enabling human-thing cognitive interactivity.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 147
    },
    {
        "text": "Nevertheless, chal-lenges pertaining to the accuracy of signal interpretation and the time-consuming nature ofthese tasks impede the realization of this vision.Raw brain signals can be acquired using var-ious technologies, including electroencephalography, functional near-infrared spectroscopy(fNIR), and magnetoencephalography (MEG).",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 148
    },
    {
        "text": "These signals often exhibit low fidelity, aresusceptible to noise and concentration issues, and therefore pose challenges for accurate sig-nal interpretation.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 149
    },
    {
        "text": "ML algorithms excel at processing extensivebiological data and quickly detecting specific patterns and mutations associated with differentdiseases.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 150
    },
    {
        "text": "have proposed a model for measuring motion using micro-electro-mechanical systems (MEMS) technology, and they determined the device’s location based onthe measured signal.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 151
    },
    {
        "text": "They have extracted the data by addressing time-delayed movementsand random signal lengths before extracting features from the windowed signals.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 152
    },
    {
        "text": "To enhance18Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 153
    },
    {
        "text": "Revised on January 12, 2023system accuracy and reduce computational complexity, Arruda et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 154
    },
    {
        "text": "have implementeda feature selection algorithm to decrease the amount of data requiring processing.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 155
    },
    {
        "text": "Theimprovement in accuracy was contingent on the choice of various classifiers, adjustments tothe feature selection algorithm, or modifications to the window length.Ara et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 156
    },
    {
        "text": "Their vision was to design acost-effective system capable of transmitting large volumes of generated data to the cloud.Furthermore, the authors have aimed to create a versatile tool that is easy to develop andproficient in data analysis and presentation.In a related study by Fafoutis et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 157
    },
    {
        "text": "[106], the authors have sought to extend sensor bat-tery life.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 158
    },
    {
        "text": "To achieve this, the model needed to be energy-efficient.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 159
    },
    {
        "text": "Consequently, they havedeveloped an SVM classifier that effectively segregates essential information from redundantdata, resulting in a remarkable increase in sensor battery life from 13 to 997 days.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 160
    },
    {
        "text": "However,it is essential to note that cost considerations play a pivotal role in this context.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 161
    },
    {
        "text": "However,there are still a number of challenges that need to be addressed, and there are also a greatmany areas that have not yet been discovered but that need to be put into practice asquickly as possible in order to improve this field even further.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 162
    },
    {
        "text": "This section outlines a comprehensive roadmap for future researchbased on the identified challenges.Using Predictive Maintenance ApproachImplementing predictive maintenance procedures is an effective solution to tackle the chal-lenges linked to maintenance costs.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 163
    },
    {
        "text": "In [107], authors have proposed a predictive maintenanceprocess for IoT-enabled manufacturing.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 164
    },
    {
        "text": "They use a convolutional neural network and longshort-term memory for fault prediction and deep reinforcement learning to optimize pro-duction control and schedule maintenance.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 165
    },
    {
        "text": "This approach aims to deliver more precisemaintenance services, leading to an overall reduction in costs.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 166
    },
    {
        "text": "Additionally, developing adockerized blockchain client enables efficient resource utilization and optimized hardwareconfigurations, contributing to lower maintenance costs and enhanced resource efficiency[108].19Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 167
    },
    {
        "text": "These studies have proven beneficial to researchers in shapingtheir future contributions.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 168
    },
    {
        "text": "Revised on January 12, 2023Developing DTN based SystemSingh et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 169
    },
    {
        "text": "[109] have proposed the development of delay-tolerant networks (DTN) as a po-tential solution for network disruptions and latency issues in IoT systems.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 170
    },
    {
        "text": "DTNs, designedto function in challenging conditions and across extensive distances, present a promisingapproach to effectively address both network stability and latency concerns.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 171
    },
    {
        "text": "[110] suggest that integrating ML models can enhance predictive capabil-ities, allowing for the anticipation of network faults before severe disruptions occur.Exploring Alternatives for Data ManagementExploring alternative options for data handling is necessary due to the various challengesposed by existing methods.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 172
    },
    {
        "text": "Hence, future research should focus on leveraging fog computingfor data management, aiming for scalability and diverse data storage formats.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 173
    },
    {
        "text": "Proposedsolutions should include features like data replication to enhance availability for multipleuser applications.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 174
    },
    {
        "text": "It is crucial to address issues such as reliability, information validity, andoverall performance, considering the limited resources of small IoT devices (e.g., storage,processing, and energy capacity) [111].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 175
    },
    {
        "text": "Moreover, researchers have explored the integrationof data trust methods to identify anomalies or untrustworthy data.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 176
    },
    {
        "text": "This approach enhancesdata analysis and improves predictions in smart healthcare systems [112].Introduce Optimization TechniquesTo address the issues of storage, energy, and computational limitations, significant efforts arerequired to optimize and develop effective energy protocols, particularly in fog computingsystems, including virtual and ad hoc fog systems.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 177
    },
    {
        "text": "Consequently, the pivotal question arises: what distinguishes thischapter from others, and why should readers dedicate their time to exploring the founda-tional concepts presented herein?",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 178
    },
    {
        "text": "These efforts should encompass aspectslike network and computing resource optimization, as well as a shift toward environmentallyfriendly energies, such as renewable energy sources [113].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 179
    },
    {
        "text": "Moreover, implementing ResNet50and MobileNetV2 as backbones with quantization techniques has proven to be an efficientand lightweight solution, contributing to the reduction of computational power in IoT-basedsystems [114].Introduce Contact-less Approach for Data CollectionTo address the issue of identifying relevant data, a contactless approach, such as usingcameras for data collection, can be introduced.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 180
    },
    {
        "text": "The field of contactless methods holdssubstantial potential for future research, though it presents several unresolved challenges.Consequently, given the current scenario, a complete shift to a contactless method maynot be a practical option.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 181
    },
    {
        "text": "Hence, a more viable approach could involve a combinationof both contact and contactless methods for enhanced reliability and success.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 182
    },
    {
        "text": "Revised on January 12, 2023Using DL method for Data PreparationExploring future research opportunities, one potential area lies in utilizing solutions basedon DL for addressing data preparation issues.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 183
    },
    {
        "text": "One prominent example is in medical imag-ing, where the reliance on manual efforts for anomaly detection has been a longstandingpractice.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 184
    },
    {
        "text": "DL processes offer a promising solution by automating this detection process,thereby enhancing the accuracy of medical imaging [115].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 185
    },
    {
        "text": "However, the implementation ofDL methods faces a major obstacle in the need for large volumes of data.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 186
    },
    {
        "text": "To address this inquiry, a comparative analysis is outlined2Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 187
    },
    {
        "text": "Therefore, futureresearch must address how DL can be seamlessly integrated while tackling existing issuesor if alternative approaches may be more impactful in this context.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 188
    },
    {
        "text": "Moreover, a crucialaspect is the inclusion of patient-specific factors in data aggregation.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 189
    },
    {
        "text": "Moreover, future research endeavors couldconcentrate on implementing models based on MapReduce [33].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 190
    },
    {
        "text": "MapReduce-based modelsoffer notable advantages, including higher scalability and improved performance throughparallel processing.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 191
    },
    {
        "text": "It aids in building trust, reducing bias, and enhancing human un-derstanding.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 192
    },
    {
        "text": "Revised on January 12, 2023Developing Lightweight and Energy Efficient SolutionSmart healthcare issues, such as high energy consumption and the lack of an effective solutionfor resource management, are of the utmost importance.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 193
    },
    {
        "text": "Inaddition, it is necessary to develop innovative schemes that are able to divide the taskamong the various components of the IoT.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 194
    },
    {
        "text": "Implementingcontinuous learning is challenging in practice, and further research is needed to develop mod-els that can emulate human brain-like thinking processes.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 195
    },
    {
        "text": "Moreover, the exploration of fogcomputing-based solutions has gained popularity in recent times, presenting an avenue forfurther investigation to achieve improved results [123].Utilize Privacy-Enhancing AlgorithmsPreserving the integrity and confidentiality of health records, which contain sensitive in-formation and are susceptible to breaches, is of utmost importance [119].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 196
    },
    {
        "text": "Therefore, it isnecessary to develop energy-efficient and lightweight ML data aggregation algorithms thatare also secure.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 197
    },
    {
        "text": "It is necessary for the solutions to be able to preserve confidentiality anddefend against breaches of privacy using a variety of data privacy protection algorithms[120].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 198
    },
    {
        "text": "Among these, the most relevant review or survey studies are identifiedand summarized in Table 10.1.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 199
    },
    {
        "text": "Integration of various data protection strategies, such as blockchain and differentialprivacy, is also open to consideration.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 200
    },
    {
        "text": "This would result in improved data security.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 201
    },
    {
        "text": "De-veloping improved access control methods is necessary to maintain the safety and securityof the network.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 202
    },
    {
        "text": "Additionally, the devices comprising the IoT should be designed to betamper-resistant, safeguarding them from physical damage [121].Designing Appropriate DevicesAccurately distinguishing between true and false data collected via wearable devices presentsa substantial hurdle in the healthcare domain.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 203
    },
    {
        "text": "Additionally, adaptability is crucial for up-coming projects, especially in scenarios like movement detection where sensors must be ver-satile to accommodate the unique gait data of each individual.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 204
    },
    {
        "text": "Exploring both contact-basedand contactless methods, along with the development of DL models capable of discerningbetween genuine and false values, can be instrumental in addressing these challenges.Ensuring Semantic InteroperabilityBuilding a globally acknowledged standard and protocol infrastructure is an absolute ne-cessity to tackle interoperability issues.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 205
    },
    {
        "text": "One potential approach that could be taken in thefuture is to maintain the semantic interoperability of healthcare information [121].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 206
    },
    {
        "text": "Revised on January 12, 2023is both consistent and accurate.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 207
    },
    {
        "text": "Developing novel noise removal techniques is crucial forpreprocessing the data, enabling more effective analysis and improving the data signal.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 208
    },
    {
        "text": "This could be a topic of study in the near future.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 209
    },
    {
        "text": "In addition, the performancedegradation of data aggregation techniques brought on by the topologies underlying themis a major cause for concern.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 210
    },
    {
        "text": "It is necessary to conduct research on them in a dynamic andheterogeneous environment [89, 90, 92].In addition to the aforementioned pathways, there are some broader areas for futureresearch.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 211
    },
    {
        "text": "For example, no comprehensive investigation has been conducted on these tech-nologies to determine which big data technologies and ML techniques are most applicable toIoT healthcare.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 212
    },
    {
        "text": "The integration of IoT into modern life aims to improvequality of life by incorporating smart devices and technologies.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 213
    },
    {
        "text": "Simultaneously, ML ad-dresses business challenges through predictive analytics.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 214
    },
    {
        "text": "The table illustrates that our chapter addresses the primary objectivesthat were lacking in previous studies.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 215
    },
    {
        "text": "It covers research challengesand offers insights for future contributions.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 216
    },
    {
        "text": "[2] A. Alkhayyat, A.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 217
    },
    {
        "text": "2019, 2019.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 218
    },
    {
        "text": "[5] Y. Fu and J. Liu, “System design for wearable blood oxygen saturation and pulsemeasurement device,” Procedia manufacturing, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 219
    },
    {
        "text": "The aim is to assist future contributors inunderstanding and addressing these challenges.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 220
    },
    {
        "text": "Y. Zomaya, et al., “Orchestrating the development lifecycle of machine learning-based iot applications: A taxonomy and survey,” ACM Computing Surveys (CSUR),vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 221
    },
    {
        "text": "10, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 222
    },
    {
        "text": "3-4, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 223
    },
    {
        "text": "Revised on January 12, 2023[10] T. M. Ghazal, M. K. Hasan, M. T. Alshurideh, H. M. Alzoubi, M. Ahmad, S. S. Akbar,B.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 224
    },
    {
        "text": "Recent interest has grown in applying data analytics for extracting in-formation, gaining insights, and making predictions.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 225
    },
    {
        "text": "Specifically, the contributions of this chaptercan be summarized as follows:1.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 226
    },
    {
        "text": "Al Kurdi, and I.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 227
    },
    {
        "text": "9, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 228
    },
    {
        "text": "12, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 229
    },
    {
        "text": "102, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 230
    },
    {
        "text": "[18] L. Agustine, I. Muljono, P. R. Angka, A. Gunadhi, D. Lestariningsih, and W. A.Weliamto, “Heart rate monitoring device for arrhythmia using pulse oximeter sen-sor based on android,” in 2018 International Conference on Computer Engineering,Network and Intelligent Multimedia (CENIM), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 231
    },
    {
        "text": "[19] J. Cecil, A. Gupta, M. Pirela-Cruz, and P. Ramanathan, “An iomt based cyber train-ing framework for orthopedic surgery using next generation internet technologies,”Informatics in Medicine Unlocked, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 232
    },
    {
        "text": "12, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 233
    },
    {
        "text": "[20] H. Su, S. E. Ovur, Z. Li, Y. Hu, J. Li, A. Knoll, G. Ferrigno, and E. De Momi, “Internetof things (iot)-based collaborative control of a redundant manipulator for teleoperatedminimally invasive surgeries,” in 2020 IEEE international conference on robotics andautomation (ICRA), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 234
    },
    {
        "text": "Revised on January 12, 2023transformed this sector.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 235
    },
    {
        "text": "Revised on January 12, 2023[22] D. Estrin and I. Sim, “Open mhealth architecture: an engine for health care innova-tion,” Science, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 236
    },
    {
        "text": "330, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 237
    },
    {
        "text": "6005, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 238
    },
    {
        "text": "759–760, 2010.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 239
    },
    {
        "text": "[23] A. O. Akmandor and N. K. Jha, “Keep the stress away with soda: Stress detectionand alleviation system,” IEEE Transactions on Multi-Scale Computing Systems, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 240
    },
    {
        "text": "[24] M. A. Wahid, S. H. R. Bukhari, A. Daud, S. E. Awan, and M. A.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 241
    },
    {
        "text": "Z. Raja, “Covict: aniot based architecture for covid-19 detection and contact tracing,” Journal of AmbientIntelligence and Humanized Computing, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 242
    },
    {
        "text": "[26] S. F. Merck, “Chronic disease and mobile technology: an innovative tool for clinicians,”in Nursing Forum, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 243
    },
    {
        "text": "52, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 244
    },
    {
        "text": "[27] R. Willard-Grace, D. DeVore, E. H. Chen, D. Hessler, T. Bodenheimer, and D. H.Thom, “The effectiveness of medical assistant health coaching for low-income patientswith uncontrolled diabetes, hypertension, and hyperlipidemia: protocol for a random-ized controlled trial and baseline characteristics of the study population,” BMC Familypractice, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 245
    },
    {
        "text": "Yang, “From wearable sensors tosmart implants—toward pervasive and personalized healthcare,” IEEE Transactionson Biomedical Engineering, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 246
    },
    {
        "text": "12, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 247
    },
    {
        "text": "[29] M. Sundholm, J. Cheng, B. Zhou, A. Sethi, and P. Lukowicz, “Smart-mat: Recognizingand counting gym exercises with low-cost resistive pressure sensing matrix,” in Pro-ceedings of the 2014 ACM international joint conference on pervasive and ubiquitouscomputing, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 248
    },
    {
        "text": "[30] N. L. Geller, D.-Y.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 249
    },
    {
        "text": "Kim, and X. Tian, “Smart technology in lung disease clinical trials,”Chest, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 250
    },
    {
        "text": "149, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 251
    },
    {
        "text": "1034–1048, 2018.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 252
    },
    {
        "text": "[32] M. K. Hassan, A. I. El Desouky, S. M. Elghamrawy, and A. M. Sarhan, “A hybrid real-time remote monitoring framework with nb-woa algorithm for patients with chronicdiseases,” Future Generation Computer Systems, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 253
    },
    {
        "text": "Revised on January 12, 2023[34] S. P. Chatrati, G. Hossain, A. Goyal, A. Bhan, S. Bhattacharya, D. Gaurav, and S. M.Tiwari, “Smart home health monitoring system for predicting type 2 diabetes andhypertension,” Journal of King Saud University-Computer and Information Sciences,vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 254
    },
    {
        "text": "862–870, 2022.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 255
    },
    {
        "text": "[35] T. Pham, T. Tran, D. Phung, and S. Venkatesh, “Predicting healthcare trajectoriesfrom medical records: A deep learning approach,” Journal of biomedical informatics,vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 256
    },
    {
        "text": "[36] V. Vijayakumar, D. Malathi, V. Subramaniyaswamy, P. Saravanan, and R. Logesh,“Fog computing-based intelligent healthcare system for the detection and preventionof mosquito-borne diseases,” Computers in Human Behavior, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 257
    },
    {
        "text": "[37] [Online; accessed November 22, 2023].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 258
    },
    {
        "text": "[38] Z. Dong, N. Zhang, C. Li, H. Wang, Y. Fang, J. Wang, and X. Zheng, “Anticancerdrug sensitivity prediction in cell lines from baseline gene expression through recursivefeature selection,” BMC cancer, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 259
    },
    {
        "text": "[39] A.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 260
    },
    {
        "text": "A. Kalinin, G. A. Higgins, N. Reamaroon, S. Soroushmehr, A. Allyn-Feuer, I. D.Dinov, K. Najarian, and B. D. Athey, “Deep learning in pharmacogenomics: from generegulation to patient stratification,” Pharmacogenomics, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 261
    },
    {
        "text": "19, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 262
    },
    {
        "text": "[40] S. K. Das, S. Namasudra, A. Kumar, and N. R. Moparthi, “Aespnet: Attention en-hanced stacked parallel network to improve automatic diabetic foot ulcer identifica-tion,” Image and Vision Computing, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 263
    },
    {
        "text": "[41] M. Bhatia and S. K. Sood, “A comprehensive health assessment framework to facili-tate iot-assisted smart workouts: A predictive healthcare perspective,” Computers inIndustry, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 264
    },
    {
        "text": "92, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 265
    },
    {
        "text": "By doing so, it aims tomake healthcare more efficient, adaptable, and customized.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 266
    },
    {
        "text": "[45] T. Ahmad and H. Chen, “A review on machine learning forecasting growth trendsand their real-time applications in different energy systems,” Sustainable Cities andSociety, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 267
    },
    {
        "text": "Malathi, and N. Senthilselvan, “An ontology-driven personalized food recommenda-tion in iot-based healthcare system,” The Journal of Supercomputing, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 268
    },
    {
        "text": "[48] T. Qiu, X. Liu, L. Feng, Y. Zhou, and K. Zheng, “An efficient tree-based self-organizingprotocol for internet of things,” Ieee Access, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 269
    },
    {
        "text": "[49] M. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, “Rate-distortion balanced datacompression for wireless sensor networks,” IEEE Sensors Journal, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 270
    },
    {
        "text": "12,pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 271
    },
    {
        "text": "5072–5083, 2016.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 272
    },
    {
        "text": "[50] Y. Pan, M. Fu, B. Cheng, X. Tao, and J. Guo, “Enhanced deep learning assistedconvolutional neural network for heart disease prediction on the internet of medicalthings platform,” Ieee Access, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 273
    },
    {
        "text": "8, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 274
    },
    {
        "text": "189503–189512, 2020.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 275
    },
    {
        "text": "It goes beyond clin-ical transformations, encompassing the collection, secure storage, and efficient processingof diverse physiological data.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 276
    },
    {
        "text": "[52] R. Negra, I. Jemili, A. Zemmari, M. Mosbah, and A. Belghith, “Wban path lossbased approach for human activity recognition with machine learning techniques,” in2018 14th International Wireless Communications & Mobile Computing Conference(IWCMC), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 277
    },
    {
        "text": "Carrier, A. Riley, and G. Kaddoum, “Internet of things insleep monitoring: An application for posture recognition using supervised learning,”in 2016 IEEE 18th International conference on e-Health networking, applications andservices (Healthcom), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 278
    },
    {
        "text": "[54] N. Gulati and P. D. Kaur, “Friendcare-aal: A robust social iot based alert generationsystem for ambient assisted living,” Journal of Ambient Intelligence and HumanizedComputing, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 279
    },
    {
        "text": "This comprehensive approach facilitates the early detectionof diseases and even preventive measures against various medical conditions.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 280
    },
    {
        "text": "12, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 281
    },
    {
        "text": "[56] F. Khan, A. ur Rehman, M. Usman, Z. Tan, and D. Puthal, “Performance of cognitiveradio sensor networks using hybrid automatic repeat request: Stop-and-wait,” MobileNetworks and Applications, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 282
    },
    {
        "text": "1368–1376, 2015.28Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 283
    },
    {
        "text": "Revised on January 12, 2023[58] Y. ElSaadany, A. J.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 284
    },
    {
        "text": "[59] T. Wood, K. Ramakrishnan, J. Hwang, G. Liu, and W. Zhang, “Toward a software-based network: integrating software defined networking and network function virtual-ization,” IEEE Network, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 285
    },
    {
        "text": "This capability is especially valuable for individuals with dis-abilities and the elderly.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 286
    },
    {
        "text": "[60] U. Satija, B. Ramkumar, and M. S. Manikandan, “Real-time signal quality-awareecg telemetry system for iot-based health care monitoring,” IEEE Internet of ThingsJournal, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 287
    },
    {
        "text": "[61] M. A. Jan, W. Zhang, M. Usman, Z. Tan, F. Khan, and E. Luo, “Smartedge: Anend-to-end encryption framework for an edge-enabled smart city application,” Journalof Network and Computer Applications, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 288
    },
    {
        "text": "137, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 289
    },
    {
        "text": "[62] P. S. Kanagasabai, R. Gautam, and G. Rathna, “Brain-computer interface learningsystem for quadriplegics,” in 2016 IEEE 4th international conference on MOOCs,innovation and technology in education (MITE), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 290
    },
    {
        "text": "Moreover, it has the potential to significantly reduce healthcarecosts while simultaneously enhancing the quality of life for patients [15].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 291
    },
    {
        "text": "10,pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 292
    },
    {
        "text": "[66] R. Bellazzi and B. Zupan, “Predictive data mining in clinical medicine: current issuesand guidelines,” International journal of medical informatics, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 293
    },
    {
        "text": "77, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 294
    },
    {
        "text": "[68] T. Amador, S. Saturnino, A. Veloso, and N. Ziviani, “Early identification of icu pa-tients at risk of complications: Regularization based on robustness and stability ofexplanations,” Artificial Intelligence in Medicine, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 295
    },
    {
        "text": "[69] R. K. Naha, S. Garg, A. Chan, and S. K. Battula, “Deadline-based dynamic resourceallocation and provisioning algorithms in fog-cloud environment,” Future GenerationComputer Systems, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 296
    },
    {
        "text": "Revised on January 12, 2023[70] J. Zhou, Z. Cao, X. Dong, and A. V. Vasilakos, “Security and privacy for cloud-basediot: Challenges,” IEEE Communications Magazine, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 297
    },
    {
        "text": "[71] S. A. Ali, M. Ansari, and M. Alam, “Resource management techniques for cloud-basediot environment,” Internet of Things (IoT) Concepts and Applications, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 298
    },
    {
        "text": "[72] I. H. Khan, M. I. Khan, and S. Khan, “Challenges of iot implementation in smart citydevelopment,” in Smart Cities—Opportunities and Challenges: Select Proceedings ofICSC 2019, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 299
    },
    {
        "text": "rep., Technical report,EasyChair, 2020.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 300
    },
    {
        "text": "[74] M. A. Jan, F. Khan, M. Alam, and M. Usman, “A payload-based mutual authenticationscheme for internet of things,” Future Generation Computer Systems, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 301
    },
    {
        "text": "92, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 302
    },
    {
        "text": "[75] T. Flynn, G. Grispos, W. Glisson, and W. Mahoney, “Knock!",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 303
    },
    {
        "text": "knock!",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 304
    },
    {
        "text": "who is there?investigating data leakage from a medical internet of things hijacking attack,” 2020.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 305
    },
    {
        "text": "[77] F. Khan, “Fairness and throughput improvement in multihop wireless ad hoc net-works,” in 2014 IEEE 27th Canadian Conference on Electrical and Computer Engi-neering (CCECE), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 306
    },
    {
        "text": "[78] Y.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 307
    },
    {
        "text": "A. Qadri, A. Nauman, Y.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 308
    },
    {
        "text": "[79] J.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 309
    },
    {
        "text": "Park, G. Bhat, A. Nk, C. S. Geyik, U. Y. Ogras, and H. G. Lee, “Energy peroperation optimization for energy-harvesting wearable iot devices,” Sensors, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 310
    },
    {
        "text": "20,no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 311
    },
    {
        "text": "[80] S. Abbasian Dehkordi, K. Farajzadeh, J. Rezazadeh, R. Farahbakhsh, K. San-drasegaran, and M. Abbasian Dehkordi, “A survey on data aggregation techniquesin iot sensor networks,” Wireless Networks, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 312
    },
    {
        "text": "[82] M. Mittal, S. Tanwar, B. Agarwal, and L. M. Goyal, “Energy conservation for iot de-vices,” Concepts, Paradigms and Solutions, Studies in Systems, Decision and Control,in Preparation, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 313
    },
    {
        "text": "Revised on January 12, 2023[83] S. S. Gill and R. Buyya, “Bio-inspired algorithms for big data analytics: a survey,taxonomy, and open challenges,” in Big data analytics for intelligent healthcare man-agement, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 314
    },
    {
        "text": "[84] R. Wan, N. Xiong, Q. Hu, H. Wang, and J. Shang, “Similarity-aware data aggregationusing fuzzy c-means approach for wireless sensor networks,” EURASIP Journal onWireless Communications and Networking, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 315
    },
    {
        "text": "2019, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 316
    },
    {
        "text": "[85] G. Qi, H. Wang, M. Haner, C. Weng, S. Chen, and Z. Zhu, “Convolutional neural net-work based detection and judgement of environmental obstacle in vehicle operation,”CAAI Transactions on Intelligence Technology, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 317
    },
    {
        "text": "[86] X. Li, M. Zhao, Y. Liu, L. Li, Z. Ding, and A. Nallanathan, “Secrecy analysis of ambientbackscatter noma systems under i/q imbalance,” IEEE Transactions on VehicularTechnology, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 318
    },
    {
        "text": "69, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 319
    },
    {
        "text": "10, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 320
    },
    {
        "text": "[87] T. Wiens, “Engine speed reduction for hydraulic machinery using predictive algo-rithms,” International Journal of Hydromechatronics, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 321
    },
    {
        "text": "[88] X. Li, Q. Wang, Y. Liu, T. A. Tsiftsis, Z. Ding, and A. Nallanathan, “Uav-aidedmulti-way noma networks with residual hardware impairments,” IEEE Wireless Com-munications Letters, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 322
    },
    {
        "text": "9, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 323
    },
    {
        "text": "Continuous remote monitoring throughwearable devices plays a critical role in early disease detection and prevention.Wu et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 324
    },
    {
        "text": "[89] M. Shokri and K. Tavakoli, “A review on the artificial neural network approach toanalysis and prediction of seismic damage in infrastructure,” International Journal ofHydromechatronics, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 325
    },
    {
        "text": "[90] X. Xue, J. Lu, and J. Chen, “Using nsga-iii for optimising biomedical ontology align-ment,” CAAI Transactions on Intelligence Technology, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 326
    },
    {
        "text": "[91] J. Ma, “Numerical modelling of underwater structural impact damage problems basedon the material point method,” International Journal of Hydromechatronics, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 327
    },
    {
        "text": "[92] F. Khan, A. ur Rehman, and M. A. Jan, “A secured and reliable communicationscheme in cognitive hybrid arq-aided smart city,” Computers & Electrical Engineering,vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 328
    },
    {
        "text": "[93] Y. Tingting, W. Junqian, W. Lintai, and X. Yong, “Three-stage network for age es-timation,” CAAI Transactions on Intelligence Technology, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 329
    },
    {
        "text": "[94] M. Ishtiaq, A. U. Rehman, F. Khan, A. Salam, et al., “Performance investigation of sr-harq transmission scheme in realistic cognitive radio system,” in 2019 IEEE 9th AnnualComputing and Communication Workshop and Conference (CCWC), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 330
    },
    {
        "text": "This setup empowers healthcare professionals to detect unusual disease signs,enabling timely intervention and treatment for patients.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 331
    },
    {
        "text": "Revised on January 12, 2023[95] F. Hussain, S. A. Hassan, R. Hussain, and E. Hossain, “Machine learning for resourcemanagement in cellular and iot networks: Potentials, current solutions, and open chal-lenges,” IEEE communications surveys & tutorials, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 332
    },
    {
        "text": "[96] D. Hassabis, D. Kumaran, C. Summerfield, and M. Botvinick, “Neuroscience-inspiredartificial intelligence,” Neuron, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 333
    },
    {
        "text": "95, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 334
    },
    {
        "text": "[99] S. Bansal and D. Kumar, “Iot ecosystem: A survey on devices, gateways, operatingsystems, middleware and communication,” International Journal of Wireless Informa-tion Networks, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 335
    },
    {
        "text": "[101] K. Yang, Y. Shi, Y. Zhou, Z. Yang, L. Fu, and W. Chen, “Federated machine learningfor intelligent iot via reconfigurable intelligent surface,” IEEE network, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 336
    },
    {
        "text": "[18] have introducedan integrated alert system that issues notifications when oxygen levels surpass predefinedthresholds.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 337
    },
    {
        "text": "[103] X. Zhang, L. Yao, S. Zhang, S. Kanhere, M. Sheng, and Y. Liu, “Internet of thingsmeets brain–computer interface: A unified deep learning framework for enablinghuman-thing cognitive interactivity,” IEEE Internet of Things Journal, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 338
    },
    {
        "text": "[104] D. de Arruda and G. P. Hancke, “Wearable device localisation using machine learn-ing techniques,” in 2016 IEEE 25th International symposium on industrial electronics(ISIE), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 339
    },
    {
        "text": "This alert system can facilitate prompt medical interventions, potentially savinglives.Smart Treatment and Smart Surgical EnvironmentIoT-based methodologies play a crucial role in cancer treatment, as demonstrated by Hesh-mat et al.’s novel technique integrating various stages like chemotherapy and radiotherapy.This system securely stores laboratory test data on a cloud-based server, empowering physi-cians to monitor and regulate prescription dosages.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 340
    },
    {
        "text": "[106] X. Fafoutis, L. Marchegiani, A. Elsts, J. Pope, R. Piechocki, and I. Craddock, “Ex-tending the battery lifetime of wearable sensors with embedded machine learning,” in2018 IEEE 4th World Forum on Internet of Things (WF-IoT), pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 341
    },
    {
        "text": "Revised on January 12, 2023[107] C. Liu, H. Zhu, D. Tang, Q. Nie, T. Zhou, L. Wang, and Y.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 342
    },
    {
        "text": "Song, “Probing anintelligent predictive maintenance approach with deep learning and augmented realityfor machine tools in iot-enabled manufacturing,” Robotics and Computer-IntegratedManufacturing, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 343
    },
    {
        "text": "[108] W. P. Freire, W. S. Melo Jr, V. D. do Nascimento, P. R. Nascimento, and A. O.de Sá, “Towards a secure and scalable maritime monitoring system using blockchainand low-cost iot technology,” Sensors, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 344
    },
    {
        "text": "[109] A. K. Singh, R. Pamula, and G. Srivastava, “An adaptive energy aware dtn-basedcommunication layer for cyber-physical systems,” Sustainable Computing: Informaticsand Systems, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 345
    },
    {
        "text": "[110] S. Namasudra, P. Lorenz, and U. Ghosh, “The new era of computer network by usingmachine learning,” Mobile Networks and Applications, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 346
    },
    {
        "text": "[111] B. Diène, J. J. Rodrigues, O. Diallo, E. H. M. Ndoye, and V. V. Korotaev, “Data man-agement techniques for internet of things,” Mechanical Systems and Signal Processing,vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 347
    },
    {
        "text": "[112] S. Namasudra, S. Dhamodharavadhani, R. Rathipriya, R. G. Crespo, and N. R.Moparthi, “Enhanced neural network-based univariate time-series forecasting modelfor big data,” Big Data, 2023.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 348
    },
    {
        "text": "[113] N. Piovesan, A. F. Gambin, M. Miozzo, M. Rossi, and P. Dini, “Energy sustainableparadigms and methods for future mobile networks: A survey,” Computer Communi-cations, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 349
    },
    {
        "text": "119, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 350
    },
    {
        "text": "[114] K. Manjari, M. Verma, G. Singal, and S. Namasudra, “Qest: Quantized and efficientscene text detector using deep learning,” ACM Trans.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 351
    },
    {
        "text": "Anexemplary advancement is a surgical training framework utilizing virtual reality to simu-late authentic training scenarios, enabling global interaction among surgeons for collabora-tive learning and expertise exchange [19].",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 352
    },
    {
        "text": "Asian Low-Resour.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 353
    },
    {
        "text": "Lang.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 354
    },
    {
        "text": "Inf.Process., vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 355
    },
    {
        "text": "Bae, and N. Kim, “Deep learning inmedical imaging,” Neurospine, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 356
    },
    {
        "text": "20, pp.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 357
    },
    {
        "text": "Notable examples of robotic systems include theDa Vinci system (manufactured by Intuitive Surgical, Sunnyvale, CA, USA), the Sensei Xrobotic catheter system (Hansen Medical, Auris Health, Inc., Redwood City, CA, USA), andthe Flex® robotic system (Medrobotics, Raynham, MA, USA).Virtual Health Platform and AssistantIntelligent healthcare introduces the concept of a readily accessible mHealth platform formedical professionals, patients, and researchers, facilitating remote patient monitoring andoffering telemedicine services.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 358
    },
    {
        "text": "[118] H. Yu and J. Ni, “An improved ensemble learning method for classifying high-dimensional and imbalanced biomedicine data,” IEEE/ACM transactions on compu-tational biology and bioinformatics, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 359
    },
    {
        "text": "11, no.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 360
    },
    {
        "text": "Revised on January 12, 2023[119] S. Namasudra, D. Devi, S. Choudhary, R. Patan, and S. Kallam, “Security, privacy,trust, and anonymity,” Advances of DNA computing in cryptography, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 361
    },
    {
        "text": "This platform supports collaborative efforts for disease re-search.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 362
    },
    {
        "text": "Schork, “Artificial intelligence and machine learning in clinical development: atranslational perspective,” NPJ digital medicine, vol.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 363
    },
    {
        "text": "By applying scientific andmathematical techniques, ML can reveal hidden patterns in data, facilitating more informeddecision-making.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 364
    },
    {
        "text": "An exampleapplication involves the integration of electronic health records to identify patterns in infec-tious diseases, enabling the early detection of potential outbreaks.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 365
    },
    {
        "text": "This proactive approach can significantlyimprove response times and aid in preventing the spread of diseases more effectively.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 366
    },
    {
        "text": "In [32], Hassan et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 367
    },
    {
        "text": "The collaborative use of these techniques aims to improve classification accuracyand achieve faster processing, thereby enhancing the efficiency of real-time patient monitor-ing.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 368
    },
    {
        "text": "Monitoring and analyzing the patient’s glucose and blood pressure readings, supervisedlearning techniques, particularly support vector machines (SVM), predict the presence ofhypertension or abnormal levels of diabetes.Disease Prediction and PreventionWithin the expansive range of tasks that MLcan perform, prediction stands out as one of its6Saifuzzaman et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 369
    },
    {
        "text": "Revised on January 12, 2023most powerful capabilities.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 370
    },
    {
        "text": "The integration of ML with DL has had a profoundimpact on advancing this field.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 371
    },
    {
        "text": "For example, in [38], Dong et al.",
        "paperTitle": "Towards Smart Healthcare: Challenges and Opportunities in IoT and ML",
        "doi": "10.48550/arXiv.2312.05530",
        "chunk_index_in_doc": 372
    },
    {
        "text": "1. 2. 3. 4.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 0
    },
    {
        "text": "00, NO. 00, NO. 00, NO. 00, NO. 00, NO. 00, NO. 00, NO. 00, NO. 00, NO.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 1
    },
    {
        "text": "JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. : BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE 3with minimal vaccine dosing in the early stages of vaccineproduction when production is limited [53]. : BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE 9=D0RGHO'HVHQVLWL]DWLRQ&RQWUDVWLYH/HDUQLQJ'LVHQWDQJOHPHQW/DWHQWHPEHGGLQJ/DWHQWVSDFH$GYHUVDULDO/HDUQLQJ'RZQVWUHDP7DVN<&RQVWUDLQW5HJXODUL]DWLRQE0RGHO&RQVWUDLQW'LVFULPLQDWRU'RZQVWUHDP7DVNFig. : BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE 11VI. : BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE 13and J. Schrouff. Journal of Artificial Intelligence Research, 76:1117–1180,2023. In NIPS, 2016.14 JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. In International Conference onMachine Learning, pages 3384–3393. : BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE 15[115] M. A. Ricci Lara, R. Echeveste, and E. Ferrante.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 2
    },
    {
        "text": "Computers in Biology and Medicine, page 107569, 2023. Journal of biomedicalinformatics, 58:S6–S10, 2015. Pacific Symposium on Biocomputing,26:232–243, 2021. In Proceedings of the annual symposium on computerapplication in medical care, page 261.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 3
    },
    {
        "text": "[6] A. Agarwal, A. Beygelzimer, M. Dudı́k, J. Langford, and H. M.Wallach. [7] S. Ahmed, C. T. Nutt, N. D. Eneanya, P. P. Reese, K. Sivashanker,M. [8] J. Ali, P. Lahoti, and K. P. Gummadi. [9] R. Alizadehsani, M. Roshanzamir, S. Hussain, A. Khosravi, A. Koohes-tani, M. H. Zangooei, M. Abdar, A. Beykikhoshk, A. Shoeibi, A. Zare,M. Panahiazar, S. Nahavandi, D. Srinivasan, A. F. Atiya, and U. R.Acharya. [10] E. Alsentzer, J. R. Murphy, W. Boag, W.-H. Weng, D. Jin, T. Naumann,and M. B. [11] S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. L. Zitnick, andD. [12] I. Banerjee, K. Bhattacharjee, J. L. Burns, H. Trivedi, S. Purkayastha,L. Seyyed-Kalantari, B. N. Patel, R. Shiradkar, and J. Gichoya. [13] B. E. Bejnordi, M. Veta, P. J. van Diest, B. van Ginneken, N. Karsse-meijer, G. J. S. Litjens, J. C. van Dijk, P. Bult, F. Beca, A. H. Beck, D. Wang, A. Khosla,R. Gargeya, H. Irshad, A. Zhong, Q. Dou, Q. Li, H. Chen, H. Lin,P.-A. Heng, C. Hass, E. Bruni, Q. K.-S. Wong, U. Halici, M. Ü.Öner, R. Cetin-Atalay, M. Berseth, V. Khvatkov, A. Vylegzhanin,O. Z. Kraus, M. Shaban, N. M. Rajpoot, R. Awan, K. Sirinukunwat-tana, T. Qaiser, Y.-W. Tsang, D. Tellez, J. Annuscheit, P. Hufnagl,M. Valkonen, K. Kartasalo, L. Latonen, P. Ruusuvuori, K. Liimatainen,S. A. George, S. Demirci, N. Navab,S. A. Kovalev, A. Kalinovsky, V. Liauchuk, G. Bueno, M. del Mi-lagro Fernández-Carrobles, I. Serrano, O. Deniz, D. Racoceanu, andR. [14] R. A. Berk, H. Heidari, S. Jabbari, M. Kearns, and A. Roth. [15] K. Bhanot, M. Qi, J. S. Erickson, I. Guyon, and K. P. Bennett. [16] U. Bhatt, J. Antorán, Y. Zhang, Q. V. Liao, P. Sattigeri, R. Fogliato,G. Melançon, R. Krishnan, J. Stanley, O. Tickoo, et al. [17] B. M. Booth, L. Hickman, S. K. Subburaj, L. Tay, S. E. Woo, andS. [18] S. Boughorbel, F. Jarray, and A. Kadri. [19] F. Branchaud-Charron, P. Atighehchian, P. Rodrı́guez, G. Abuhamad,and A. Lacoste. Brown, N. Tomasev, J. Freyberg, Y. Liu, A. Karthikesalingam,FIRST A. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhari-wal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal,A. Herbert-Voss, G. Krueger, T. J. Henighan, R. Child, A. Ramesh,D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler,M. Radford, I. Sutskever, and D. Amodei. [23] G. Campanella, M. G. Hanna, L. Geneslaw, A. P. Miraflor, V. W. K.Silva, K. J. Busam, E. Brogi, V. E. Reuter, D. S. Klimstra, andT. [24] J. G. Carbonell, R. S. Michalski, and T. M. Mitchell. [25] M. Cascella, J. Montomoli, V. Bellini, and E. Bignami. [27] S. Caton and C. Haas. [28] H. Chang and R. Shokri. Hall, and W. P. Kegelmeyer. [30] I. Chen, F. D. Johansson, and D. Sontag. [31] I. Y. Chen, E. Pierson, S. Rose, S. Joshi, K. Ferryman, and M. Ghas-semi. [33] R. J. Chen, T. Y. Chen, J. Lipková, J. J. Wang, D. F. K. Williamson,M. Y. Lu, S. Sahai, and F. Mahmood. [34] P. Cheng, W. Hao, S. Yuan, S. Si, and L. Carin. [37] E. Chzhen, C. Denis, M. Hebiri, L. Oneto, and M. Pontil. [38] N. C. Codella, D. Gutman, M. E. Celebi, B. Helba, M. A. Marchetti,S. W. Dusza, A. Kalloo, K. Liopyris, N. Mishra, H. Kittler, et al. [39] R. Correa, J. J. Jeong, B. Patel, H. Trivedi, J. W. Gichoya, andI. [40] E. Creager, D. Madras, J.-H. Jacobsen, M. Weis, K. Swersky, T. Pitassi,and R. Zemel. [41] A. D’Amour, H. Srinivasan, J. Atwood, P. Baljekar, D. Sculley, andY. [43] J. Deng, J. Yang, L. Hou, J. Wu, Y. He, M. Zhao, B. Ni, D. Wei,H. Pfister, C. Zhou, et al. [44] C. Denis, R. Elie, M. Hebiri, and F. Hu. [45] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. [46] W. Dieterich, C. Mendoza, and T. Brennan. [47] P. S. Dodds, J. R. Minot, M. V. Arnold, T. Alshaabi, J. L. Adams,D. [49] M. Du, N. Liu, and X. Hu. [50] M. Du, N. Liu, F. Yang, and X. Hu. [51] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. S. Zemel. [52] P. F. Edemekong, P. Annamaraju, and M. J. Haydel. [54] G. J. Escobar, B. J. Turk, A. I. Ragins, J. Ha, B. Hoberman, S. M.Levine, M. A. Ballesca, V. X. Liu, and P. Kipnis. [55] A. Fabris, A. Esuli, A. Moreo, and F. Sebastiani. [56] D. Fan, Y. Wu, and X. Li. [57] R. R. Fletcher, A. Nakeshimana, and O. Olubeko. [58] S. A. Friedler, C. Scheidegger, and S. Venkatasubramanian. A. Aksoy, U. Dogrusoz, G. Dresdner, B. E. Gross, S. O.Sumer, Y. [61] B. Giovanola and S. Tiribelli. [62] B. Glocker, C. Jones, M. Bernhardt, and S. Winzeck. [63] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,S.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 4
    },
    {
        "text": "[64] V. Gorade, S. Mittal, and R. Singhal. [65] D. A. Gutman, N. C. F. Codella, M. E. Celebi, B. Helba, M. A.Marchetti, N. K. Mishra, and A. C. Halpern. [66] S. S. Halabi, L. M. Prevedello, J. Kalpathy-Cramer, A. Bilbily, M. Cicero, I. Pan, L. A. Pereira, R. T. Sousa, N. Abdala,et al. [67] M. Hardt, E. Price, and N. Srebro. [68] M. Hardt, E. Price, and N. Srebro. 0, MONTH 2020[69] H. Heidari, V. Nanda, and K. P. Gummadi. [70] K. C. Heslin, P. L. Owens, Z. Karaca, M. L. Barrett, B. J. Moore, andA. [71] A. Holzinger, G. Langs, H. Denk, K. Zatloukal, and H. Müller. [72] F. M. Howard, J. M. Dolezal, S. E. Kochanny, J. J. Schulte, H. I.-H. Chen, L. R. Heij, D. Huo, R. Nanda, O. I. Olopade, J. N. Kather,N. A. Cipriani, R. L. Grossman, and A. T. Pearson. A. Irvin, P. Rajpurkar, M. Ko, Y. Yu, S. Ciurea-Ilcus, C. Chute,H. Marklund, B. Haghgoo, R. L. Ball, K. S. Shpanskaya, J. Seekins,D. A. Mong, S. S. Halabi, J. K. Sandberg, R. Jones, D. B. Larson,C. Langlotz, B. N. Patel, M. P. Lungren, and A. Ng. [74] S. Jabbour, D. F. Fouhey, E. A. Kazerooni, M. W. Sjoding, andJ. [75] Z. Jiang, X. Han, C. Fan, F. Yang, A. Mostafavi, and X. Hu. [77] A. E. Johnson, T. J. Pollard, L. Shen, H. L. Li-Wei, M. Feng,M. [78] A. E. W. Johnson, T. J. Pollard, S. J. Berkowitz, N. R. Greenbaum,M. P. Lungren, C. ying Deng, R. G. Mark, and S. Horng. [80] N. M. Kinyanjui, T. Odonga, C. Cintas, N. C. Codella, R. Panda,P. [81] V. Kumar, A. Stubbs, S. Shaw, and Ö. [83] M. J. Kusner, J. R. Loftus, C. Russell, and R. Silva. [84] G. H. Kwak and P. Hui. [86] A. J. Larrazabal, N. Nieto, V. Peterson, D. H. Milone, and E. Fer-rante. [87] J.-G. Lee, Y. Roh, H. Song, and S. E. Whang. [88] S. Li, T. Cai, and R. Duan. [89] X. Li, Z. Cui, Y. Wu, L. Gu, and T. Harada. [90] Z. Lin, D. Zhang, Q. Tac, D. Shi, G. Haffari, Q. Wu, M. He, andZ. [91] L. T. Liu, S. Dean, E. Rolf, M. Simchowitz, and M. Hardt. [92] Q. Liu, L. Yu, L. Luo, Q. Dou, and P.-A. [93] H. J. Lowe, T. A. Ferris, P. M. Hernandez, and S. C. Weber. [95] C. Lu, A. Lemay, K. Hoebel, and J. Kalpathy-Cramer. [96] D. Madras, E. Creager, T. Pitassi, and R. Zemel. [97] C. A. McCarty, R. L. Chisholm, C. G. Chute, I. J. Kullo, G. P. Jarvik,E. B. Larson, R. Li, D. R. Masys, M. D. Ritchie, D. M. Roden,et al. [98] N. Mehrabi, F. Morstatter, N. A. Saxena, K. Lerman, and A. G.Galstyan. [99] C. Meng, L. Trinh, N. Xu, and Y. Liu. [102] R. B. Parikh, S. Teeple, and A. S. Navathe. [103] R. C. Petersen, P. S. Aisen, L. A. Beckett, M. C. Donohue, A. C.Gamst, D. J. Harvey, C. R. Jack, W. J. Jagust, L. M. Shaw, A. W.Toga, et al. [104] A. Pfefferbaum, N. M. Zahr, S. A. Sassoon, D. Kwon, K. M. Pohl,and E. V. Sullivan. [106] S. R. Pfohl, T. Duan, D. Y. Ding, and N. H. Shah. [107] S. R. Pfohl, B. J. Marafino, A. Coulet, F. Rodriguez, L. P. Palaniappan,and N. H. Shah. [108] R. Pinot, F. Yger, C. Gouy-Pailler, and J. Atif. [110] E. Puyol-Antón, B. Ruijsink, J. M. Harana, S. K. Piechnik,S. Neubauer, S. E. Petersen, R. Razavi, P. J. Chowienczyk, and A. P.King. [114] J.-F. Rajotte, S. Mukherjee, C. Robinson, A. Ortiz, C. West, J. L.Ferres, and R. T. Ng. [116] O. Ronneberger, P. Fischer, and T. Brox. [117] B. Scherrer, A. Gholipour, and S. Warfield. [118] J. Schrouff, N. Harris, O. Koyejo, I. Alabdulmohsin, E. Schnider,K. Brown, S. Roy, D. Mincu, C. Chen, et al. [119] L. Seyyed-Kalantari, G. Liu, M. B. [120] L. Seyyed-Kalantari, H. Zhang, M. B. McDermott, I. Y. Chen, andM. [121] X. Shen, S. Ma, P. Vemuri, and G. Simon. [122] J. W. Smith, J. E. Everhart, W. Dickson, W. C. Knowler, and R. S.Johannes. [124] A. Tahir, L. Cheng, and H. Liu. [126] P. Tiwald, A. Ebert, and D. Soukup. [128] Y.-H. H. Tsai, M. Q. Ma, H. Zhao, K. Zhang, L.-P. Morency, andR. [129] P. Tschandl, C. Rosendahl, and H. Kittler. [131] T. Wang, J. Zhao, M. Yatskar, K.-W. Chang, and V. Ordonez. [133] X. Wang, Y. Zhang, and R. Zhu. [134] J. R. Williams and N. Razavian. [135] J. Xu, Y. Xiao, W. H. Wang, Y. Ning, E. A. Shenkman, J. Bian, andF. [136] J. N. Xu, Y. Xiao, W. Wang, Y. Ning, E. A. Shenkman, J. Bian, andF.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 5
    },
    {
        "text": "[137] Y. Xu, T. Mo, Q. Feng, P. Zhong, M. Lai, and E. I.-C. Chang. [138] C. Xue, Q. Dou, X. Shi, H. Chen, and P.-A. [139] M. Yuan, V. Kumar, M. A. Ahmad, and A. Teredesai. [141] D. Zhang and J. Wang. [142] H. Zhang, A. X. Lu, M. Abdalla, M. B. A. McDermott, and M. Ghas-semi. [143] Q. Zhao, E. Adeli, and K. M. Pohl.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 6
    },
    {
        "text": "Journal of generalinternal medicine, 36(2):464–471, 2021. Nature Medicine,pages 1–9, 2019. Journal of hospital medicine, 11 Suppl 1:S18–S24,2016. Ebiomedicine, 89, 2023. Medical Care,55:918–923, 2017. Annalsof Internal Medicine, 169:866–872, 2018. Annalsof internal medicine, 169(12):866–872, 2018. Na-ture medicine, 27(12):2176–2182, 2021. Nature medicine, 25(1):44–56, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 7
    },
    {
        "text": "Nature Communications, 14(1):4314, 2023. Nature Communications, 11(1):3673, 2020. Nature Communications, 12, 2021. nature communications,13(1):4581, 2022. Scientific reports, 10(1):2975, 2020. Nature communications,11(1):6010, 2020.Qizhang Feng received the B.Eng.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 8
    },
    {
        "text": "0, MONTH 2020 1Fair Machine Learning in Healthcare: A SurveyQizhang Feng, Mengnan Du, Na Zou, and Xia HuAbstract—The digitization of healthcare data coupled withadvances in computational capabilities has propelled the adoptionof machine learning (ML) in healthcare. In this survey, weanalyze the intersection of fairness in machine learning andhealthcare disparities. We adopt a framework based on theprinciples of distributive justice to categorize fairness concernsinto two distinct classes: equal allocation and equal performance.We provide a critical review of the associated fairness metricsfrom a machine learning standpoint and examine biases and mit-igation strategies across the stages of the ML lifecycle, discussingthe relationship between biases and their countermeasures. Thepaper concludes with a discussion on the pressing challenges thatremain unaddressed in ensuring fairness in healthcare ML, andproposes several new research directions that hold promise fordeveloping ethical and equitable ML applications in healthcare.Impact Statement—Along with the rapid growth in the use ofmachine learning in healthcare in recent years, there has beena growing concern about the fairness problems that come alongwith it. This survey article helps break down the barriers betweenfair machine learning and healthcare, and aims to: 1) improvehealthcare practitioners’ understanding of the bias of machinelearning in healthcare from a computational perspective; 2) assistmachine learning researchers in establishing a clear picture onhow to develop fair algorithms in various healthcare scenariosfrom a healthcare perspective; and 3) increase public trust inmachine learning algorithms and promote the use of machinelearning methods in real-world healthcare settings.Index Terms—Artificial Intelligence, Fairness, Healthcare, Ma-chine Learning.I. INTRODUCTIONW ITH the advent of sophisticated machine learning(ML) applications in healthcare, from medical imageanalysis to electronic health records processing, we stand onthe cusp of a transformative era in medicine [84], [116],[117], [137], [92]. Despite these advancements, there remainsa significant yet understudied challenge: ensuring fairnessin algorithmic decisions, particularly as they relate to theequitable treatment of diverse patient populations [135].Fairness in healthcare ML refers to the equitable distributionof benefits and burdens across all demographic groups, withManuscript submitted June 17, 2022; date of current version Nov 7, 2023.This work is in part supported by NSF grants IIS-1939716 and IIS-1900990.Qizhang Feng is with the Department of Computer Science & Engineering,Texas A&M University, TX 77843, US (e-mail: qf31@tamu.edu).Mengnan Du is with the Department of Data Science, New Jersey Instituteof Technology, NJ 07102, US (e-mail: mengnan.du@njit.edu).Na Zou is with the Department of Engineering Technology & Industrial Dis-tribution, Texas A&M University, TX 77843, US (e-mail: nzou1@tamu.edu).Xia Hu is with the Department of Computer Science, Rice University, TX77251, US (e-mail: xia.hu@rice.edu).This paragraph will include the Associate Editor who handled your paper.particular attention to historically marginalized communities.It encompasses a range of issues, from the allocation ofhealthcare resources to diagnostic accuracy across differentpatient demographics. Notable instances include genetic testswhere AI models disproportionately misrepresent risks for mi-nority groups [102], and diagnostic discrepancies exacerbatedby incomplete medical records among Black and Hispanicpatients [119]. The Covid-19 pandemic has further highlightedthese disparities, intensifying the urgency to address them [61].Recognizing the potential of ML to either perpetuate ormitigate existing disparities, this survey seeks to fill thecritical gap in the literature by providing a comprehensiveanalysis of fairness-oriented ML strategies in healthcare. Weacknowledge the socio-technical nature of fairness challengesin healthcare ML, which encompasses algorithmic aspects andextends to societal, ethical, and regulatory dimensions. Thissurvey synthesizes insights from previous works, includingthe categorization of fairness problems [112] and solutions,and charts a path forward for equitable ML applications inhealthcare. While the domainsof fairness in machine learning and health disparities arewell-researched, their intersection remains nascent. Severalsurveys [112], [33], [57], [136], [31], [115] have attemptedto address fairness problems in machine learning methodsfor healthcare. Thekey point of fair machine learning in healthcare contain bothethical consideration and also technical details. For instance, some works [112],[31] discuss fairness from an ethical standpoint but lack adetailed connection with technical mitigation methods andmetrics for fairness in machine learning. Conversely, anotherline of work [136] provides a technical perspective by cate-gorizing fairness metrics and mitigation methods but does notestablish a strong link with the ethical aspects of healthcarefairness. Additionally, some studies [33] focus narrowly ondata shifts and federated learning, while work [115] limits itsscope to fairness in artificial intelligence for medical imaging.Our survey seeks to establish a comprehensive link betweenthe ethical and technical dimensions of fair machine learningin healthcare. Our survey is motivated by the need to bridgethis evident gap, providing a comprehensive perspective thatties together the ethical considerations and technical detailsof fairness in healthcare machine learning. Specifically, ourcontributions are summarized as follows:1) Connect the ethical and technical aspects of fairness inarXiv:2206.14397v3 [cs.LG] 1 Feb 20242 JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. Classify healthcare fairnessproblems into equal allocation and equal performance,and provide a comprehensive summary of fairness mea-surement methods within the fair machine learning do-main, categorizing them accordingly.2) Provide a comprehensive overview of biases at variousstages of the machine learning model development. Con-duct a structured analysis of fairness mitigation methods,surpassing previous surveys in exhaustiveness.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 9
    },
    {
        "text": "Highlightthe critical gap in current mitigation methods, focusingon the necessity to discuss and analyze their applicabilityto scenarios of equal allocation and equal performance.3) Discuss challenges and opportunities in creating a fairand reliable machine learning ecosystem for healthcare,with an emphasis on the unique aspects of healthcareapplications.The structure of this article is listed as follows. The defini-tion of fairness problems in healthcare is given in Section II.On the basis of this definition, measurements of fairness aregiven in Section III. Similarly, accordingto the same categorization, methods for mitigating fairnessproblems are discussed in Section V. Finally, we highlightthe challenges and opportunities for a fair and trustworthymachine learning healthcare ecosystem based on uniquenessin healthcare applications in Section VI.II. FAIRNESS PROBLEMS IN ML FOR HEALTHCAREBecause of the digitization of medical data collection, wecan now collect large amounts of medical data and developmachine learning algorithms for a variety of medical tasks.First, machine learning models have been used in pioneeringapplications on medical images (e.g., NIH Chest-Xray14,CheXpert, MIMIC-CXR and Chest-Xray8 [132], [73], [78],[119]). However,this raises critical fairness considerations, as the algorithms’decision-making processes must account for diverse patientpopulations and their unique healthcare requirements. Distributive Justice in Machine learning for HealthcareAlthough the use of machine learning techniques in health-care has been shown to correct clinical inadequacies and in-crease operational efficiency by reducing resource waste [127],various fairness problems have also been raised. The problemof fairness in machine learning methods is reflected in thediscrimination of different groups [61]. For example, state-of-the-art convolutional neural network (CNN) classifiers werefound to differ in the true positive rate across protectedattributes (e.g., patient gender, age, race, and insurance type)on 14 diagnostic tasks in 3 well-known public chest x-raydatasets [119].Discrimination can be understood as a distributive prob-lem [85]. In studies developed related to machine learningin healthcare, fairness problems often refer to the unequaldistribution of resources such as medical care, clinical servicesand health facilities [58]. In the context of the fairness problem of machinelearning methods in healthcare, resources often refer to themedical services allocated by the system, or the error rate ofthe predictions it gives. Fairness problems can be grouped intotwo categories based on differences in the resources allocated:equal allocation and equal performance [112].1) Equal Allocation: Machine learning models are oftenused to allocate medical supplies such as vaccines, medicinesand organ transplants. Accordingly, fairness problems of ma-chine learning methods in healthcare occur if the modeldetermines that the allocation of resources is not equal betweengroups. They found thatthe optimal solution to the model was likely to producea controversial distribution strategy of not distributing anyvaccine to certain subgroups.2) Equal Performance: In some medical situations, machinelearning models are used for medical tasks such as diseasediagnosis, mortality prediction and multi-organ segmentation,etc. Consequently, it would be unfair if the performance andresults of machine learning models are not equally accuratein terms of metrics such as accuracy for patients in differentdemographic groups. Thus, suitable metrics are crucial forevaluating the fairness of a machine learning model.III. MEASUREMENT OF FAIRNESSIn the previous section, we introduce the fairness problemsin machine learning for healthcare and categorize them intoequal allocation problems and equal performance problems.Selecting an appropriate fairness metric is critical to measuringthe fairness problem in various healthcare scenarios. In thissection, we first introduce two principles of fairness followingdistributive justice and then summarize the common metricsof fairness that apply to them.To measure the fairness of a given decision algorithm f(·),we define x ∈ Rdx as the nonsensitive features vector andz ∈ Rdz as the sensitive features vector. In the following,we introduce some fairness metrics that follow the principleof equal allocation.• Demographic Parity (DP) is satisfied if a machinelearning algorithm gives equal decision rates for differentdemographic subgroups a and b:P(ŷ = 1 | z = a) = P(ŷ = 1 | z = b), (1)DP can be extended for multi-class classification ap-plication such as image recognition, text categorization,etc [44]:K∑k=1|P(ŷ = k|z = a)− P(ŷ = k|z = b)| = 0, ∀k ∈ [K],(2)where [K] = {1, . For example, an individual’spostal code might be used as a proxy for their income,race, or ethnicity [55].• Fairness through Awareness [51] emphasizes that afair algorithm should make similar decisions for twoindividuals x and x′ with similar non-sensitive attributes:D (f(x), f(x′)) ≤ d (x, x′) (6)Note that the algorithm should satisfy the(D, d)-Lipschitz property.• Counterfactual Fairness [83] is derived from causaltheory. Bias at the different stages in machine learning systems: Red and blue represent two demographic groups. (b) Algorithm bias exists in model development stage, leads to systematical unfair results for certain demographic group. (c) The biases that existat the data collection stage include interaction bias and training-serving skew bias. Interaction bias occurs patients and healthcare professionals interact with machinelearning models. SOURCES OF FAIRNESS PROBLEMSIn this section, we summarize the causes of fairness prob-lems in healthcare machine learning and use the term ‘bias’ todenote them [98].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 10
    },
    {
        "text": "The process of building a machine learning-based healthcare system can be divided into three stages.First, the agency collects relevant clinical data for modeldevelopment. Bias in Data CollectionData collection is the first stage at which bias may beintroduced. The development of machine learning algorithms inhealthcare is currently highly dependent on public biobankdatabases [13], [23]. Another example is that, despitenumerous initiatives, sexual orientation and gender identityhave been largely absent from electronic health records to date.Machine learning-based clinical decision support systems canmisinterpret the lack of access to care as a lower burden ofdisease and therefore produce inaccurate predictions for thesegroups [33].3) Label Bias: Label bias may also be present in data labels,and the quality of the labels can contribute to bias [112].For example, people with low socioeconomic status maybe more likely to be seen in teaching clinics, where doc-umentation or clinical reasoning may be less accurate orsystematically different from the care provided to patients withhigh socioeconomic status. Algorithms based on these datamay reflect practitioner bias and misclassify patients basedon these factors. This can stem from various sources, includinginappropriate intrinsic hypotheses, the structure of the model,and biased loss estimators, all of which can potentially con-tribute to fairness problems [24], [134], [30]. A predominantconcern in this context is algorithmic bias, where the sourceof bias is traceable back to the model itself, systematicallyleading to unfair results for certain groups as depicted inFigure 1. (b).In the discourse of algorithmic fairness, both shortcutlearning and confounding effects epitomize pathways throughwhich machine learning models may inadvertently perpetuatebiases. Confounder-aware approaches and mitigationstrategies, as delineated in seminal works, are therefore criticalin ensuring that machine learning contributes to the fair andjust application of AI in healthcare, and does not inadvertentlyexacerbate existing disparities. For instance, in the field ofradiology, convolutional neural networks (CNNs) have beenfound to exhibit inconsistencies in diagnosis, particularly forunderserved groups such as Hispanic patients and Medicaid re-cipients in the United States, leading to a higher rate of under-diagnosis or misdiagnosis compared to White patients [120].Furthermore, studies suggest that different machine learningalgorithms can exhibit varying degrees of bias when appliedto the same dataset [139]. Bias in Model DeploymentA trained machine learning model can be applied to clinicalpractice when it has passed regulatory authorization. This can lead to fairness problems whenthe model is deployed, even if it satisfies the notion of fairnessin the training dataset. : BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE 7fairness classifiers, and there has been few research on theanalysis of fairness metrics under temporal or spatial datasettransfer. On the other hand, clinicianscan also place too much trust in machine learning models andinappropriately act on inaccurate predictions, which can becalled automation bias [112].V. MITIGATION OF FAIRNESS PROBLEMSA variety of approaches have been developed to addressfairness concerns in machine learning applications within thehealthcare domain. We delineate these approaches across three key stages:data collection, model development, and model deployment.Furthermore, we meticulously align the motivations behindeach mitigation method with the sources of bias identified inthe previous section, providing a cohesive overview of howthese strategies correspond to specific biases encountered inthe machine learning pipeline. Table II presents a taxonomyof mitigation methods utilized in the domain of fair machinelearning for healthcare, detailing the specific tasks, datasets,and data types to which they are applied.A. Mitigating Fairness Problems in Data CollectionData bias can be transferred and embedded in machinelearning models. An instance ofthis is Swarm Learning (SL) which, when evaluated on theSkin ISIC 2018 dataset, exhibited enhanced fairness comparedto centralized training [56]. Mitigating Fairness Problems in Model DevelopmentAs discussed in Section IV-B, algorithmic bias duringthe model development stage can result in machine learningmodels that inherit and potentially amplify biases, leading tofairness problems. Two key drivers of this bias are identified:first, shortcut learning, where models rely on sensitive infor-mation for predictions; and second, optimization processes thatfail to generalize for underrepresented groups.8 JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. For example, removing sensitive attributes from tabular data or removing gender-specific pronouns from textual data.To address these issues, we introduce two categories ofapproaches to mitigate fairness problems during the modeldevelopment stage: model desensitization and model con-straint. Model desensitization involves techniques that reducea model’s reliance on sensitive attributes, thereby preventing itfrom making biased predictions based on those attributes. Onthe other hand, model constraint methods impose restrictionson the model training process to ensure fair treatment of allgroups, especially those underrepresented in the training data.1) Model Desensitization: Model desensitization focuseson preventing models from retaining or utilizing sensitiveattribute information from the data. To effectively mitigate fairness problems, model desensi-tization approaches such as adversarial learning, representationdisentanglement, and contrastive learning aim to eliminate themodels’ ability to discriminate based on sensitive information.Adversarial learning is a widely used method to debias amodel.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 11
    },
    {
        "text": "In addition to the use cases for medical imagedata, adversarial learning has also been used to build fairmachine learning models that can handle EHR data and textualdata [107], [142].Some other model desensitization approaches have beenproposed in the context of general fairness problems instead ofhealthcare. An illustration of methods mitigating the fairness problem in model development stage: (a) Model desensitization removes the ability ofthe model to discriminate between sensitive attribute information. Unlike model desensitizationmethods that implicitly debias the model, model constraintmethods mitigate fairness problems by explicitly incorporatingconstraints into the optimization goal.This often involves adding fairness-specific optimization ob-jectives. For instance, these objectives might directly improvefairness metrics [6] or include regularization terms to enforcenon-discrimination principles or counterfactual fairness [106].One notable approach involves developing an augmentedcounterfactual fairness criterion to reduce biases in ElectronicHealth Record (EHR) data. The optimization objective functioncomprises three components: prediction losses for factual andcounterfactual samples, and an additional regularization termdesigned to meet the proposed fairness criteria [60].Despite their direct approach to addressing fairness, modelconstraint methods are not without drawbacks. Moreover, the impact of reg-ularization strength on fairness metrics can vary, presentingchallenges in balancing performance and fairness.C. Mitigating Fairness Problems in Model DeploymentDeploying machine learning models in clinical settingsoften surfaces biases not apparent during training or test-ing. This section explores three key methods: decisionexplanation, model adjustment, and outcome adjustment, eachaddressing specific biases such as interaction bias and training-serving skew bias.1) Decision Explanation: Fairness in deployed machinelearning systems is not solely a technical challenge but asocio-technical one, where human interaction with the modelis pivotal. To mitigatesuch biases, the application of explainable artificial intelli-gence (XAI) is crucial, enabling users to understand andappropriately trust the model’s decisions.XAI can demystify model predictions, which is criticalwhen balancing the trust in an algorithm’s decisions against therisk of perpetuating unfairness. Forinstance, studies have shown that demographic features candisproportionately influence algorithmic decisions, potentiallyleading to differential treatment across patient groups [99].XAI techniques have revealed such biases by highlightingthe varying importance of sensitive attributes across differentdemographics.Conversely, mistrust in fair models can also undermine theirutility, prompting patients to eschew treatments or withholdinformation [48], [112]. An illustration of methods mitigating the fairness problem in model deployment stage: (a) The decision explanation method offers the explanationto the outcome via XAI tool. (c) The outcome adjustment methodadjusts the original outcome to meet fairness requirement.in the system and among medical professionals [4], [71].Ultimately, integrating fairness-oriented knowledge intoXAI methods not only clarifies model decisions but also guidesthe refinement of models to ensure equitable outcomes [50].The synergistic relationship between fairness and explain-ability in machine learning models is an emergent field ofresearch that warrants further exploration, as will be discussedin Section VI-D.2) Model Adjustment: Training-serving skew bias leads tofairness problem since it violates the assumption that data inthe deployment phase are i.i.d. This conundrum necessitates anuanced approach to calibration, where the trade-offs betweencompeting fairness dimensions are carefully balanced.Thresholding takes a different tack by redefining decisionboundaries. By employing variablethresholds based on sensitive attributes, a model can betuned to fulfill fairness metrics such as equal odds or equalopportunity [68]. For example, applying a lower threshold fora minority group could increase their representation in positivepredictions, aligning with the goal of equal opportunity.Discussion of the applicability of the mitigation method.In this review, we have previously highlighted in Section IIthe need for distinct forms of distributive justice in varioushealthcare settings, specifically equal allocation and equalperformance. And it is important to note that simultaneouslyachieving these fairness constraints can be challenging [98].Only few of existing literature on mitigation methods studytheir applicability to different measures of fairness metric. Few work onfair machine learning for healthcare discuss the applicabilityof appropriate fairness metrics, which is an obstacle to thedeployment of mitigation methods in real healthcare scenariosand may even exacerbate fairness problems. Uncertainty and Fairness in HealthcareMachine learning and probabilistic methods have becomeubiquitous across various domains, with their application inmedical data being particularly critical due to the inherentuncertainty from noise in the data. The advent of new deep learning techniqueshas seen a significant rise in addressing such uncertainties [9].Despite this, the interplay between fairness and uncertaintyhas not been explored thoroughly in research.Uncertainty can play a pivotal role in highlighting fairnessproblems within machine learning applications in healthcare[94], [95]. Themeasurement and communication of uncertainties are crucialfor identifying potential unfairness in model predictions [16].Incorporating model uncertainty into fairness metrics can pro-vide a more comprehensive view of model performance acrossdifferent groups, ensuring that disparities in prediction confi-dence do not go unnoticed [8]. There is a clear need forfurther investigation into how uncertainty impacts the fairnessof machine learning models, a step that is crucial for theresponsible deployment of AI in sensitive sectors.B. Mostcurrent research has focused on fairness problems in machinelearning in static classification scenarios and has not examinedhow these decisions will affect the future [69]. It is oftenassumed that unfairness can be improved better after imposingfairness constraints on machine learning models.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 12
    },
    {
        "text": "Even in a one-step feedback model, ordinary fairness standards generally donot promote improvement over time and may cause harm [91].The key difficulty in alleviating the long-term fairness problemis to simulate the long-term dynamics and predict the futurebenefit [41].Another research challenge is that the healthcare systemis not an isolated system. When machine learning algorithmsare embedded in clinical systems, the diagnostic decisions theymake are collected and combined into new clinical data. We encourage more work on the long-term fairness of machine learning algorithms in healthcare,in particular on equal benefit and feedback loop fairness inclinical applications.C. Only afew works have focused on multimodality fairness problemsin healthcare systems [32]. As previous work has focused on the fairness problem inuni-modal data, we encourage the discovery and mitigation ofbias in healthcare of multimodal data.D. Ethical Machine Learning in HealthcareThe ethical landscape of machine learning within health-care encompasses pivotal concepts such as fairness, inter-pretability, privacy, robustness, and security. Fairness in healthcare AI seeksto ensure equitable treatment and outcomes across diversepatient groups. Conversely, the alliance between robustnessand fairness is more harmonious in healthcare AI. Furthermore, the convergence ofdifferential privacy and adversarial robustness underscores apromising avenue where privacy-preserving techniques alsofortify models against malicious attacks, a duality of par-ticular relevance to safeguarding sensitive health data [108].Yet, the interplay of interpretability, fairness, robustness, andprivacy in healthcare AI is nascent. CONCLUSIONSIn this survey, we have synthesized the existing literatureon the intersection of machine learning and fairness withinhealthcare. Drawing from the foundational work in distributivejustice, we have applied the classification of fairness problemsin healthcare-focused machine learning methods, as identifiedby existing research, into two principal categories: equalallocation and equal performance. This has allowed us tomap the metrics commonly used in fair machine learningto these categories specifically in the healthcare context. Our survey reveals a gap in the critical evaluation ofthe effectiveness of these mitigation methods when appliedto healthcare-specific fairness metrics. We underscore thepressing nature of fairness concerns in healthcare machinelearning applications and propose future research directionsthat promise to address these challenges.VIII. A reductions approach to fair classification. In Proceedings of the 2021 AAAI/ACMConference on AI, Ethics, and Society, pages 336–345, 2021. Theproblem of fairness in synthetic healthcare data. Can active learning preemptively mitigate fairnessissues? Fairness in machine learning: A survey. On the privacy risks of algorithmic fairness. Ethical machine learning in healthcare. Algorithm fairness in ai formedicine and healthcare. Fairness guarantee in multi-class classification. Fairnessthrough awareness. Addressing fairness,bias, and appropriate use of artificial intelligence and machine learningin global health, 2021. On the(im) possibility of fairness. Beyond bias and discrimination:redefining the ai ethics principle of fairness in healthcare machine-learning algorithms. Equality of opportunity in supervisedlearning. Equality of opportunity in supervisedlearning. Distributive justiceand fairness metrics in automated decision-making: How much overlapis there? Machine learningrobustness, fairness, and their convergence. Delayedimpact of fair machine learning. A survey on bias and fairness in machine learning. [105] S. Pfohl, Y. Xu, A. Foryciarz, N. Ignatiadis, J. Genkins, and N. Shah.Net benefit, calibration, threshold selection, and training objectivesfor algorithmic fairness in healthcare. Counterfactualreasoning for fair clinical risk prediction. Proceedings of the 2019 AAAI/ACM Conference on AI,Ethics, and Society, 2019. [112] A. Rajkomar, M. Hardt, M. D. Howell, G. Corrado, and M. H. Chin.Ensuring fairness in machine learning to advance health equity. [113] A. Rajkomar, M. Hardt, M. D. Howell, G. Corrado, and M. H. Chin.Ensuring fairness in machine learning to advance health equity. Addressing fairnessin artificial intelligence for medical imaging. Diagnos-ing failures of fairness transfer across distribution shift in real-worldmedical settings: Supplement. A brief review on algorithmic fairness.Management System Engineering, 1(1):7, 2022. Towards quantification of biasin machine learning for healthcare: A case study of renal failureprediction. Algorithmic fairness in computational medicine. Algorithmic fairness in computational medicine. Assessing fair-ness in classification parity of machine learning models in healthcare.arXiv preprint arXiv:2102.03717, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 13
    },
    {
        "text": "(a) The biases that exist at the datacollection stage include minority bias, missing-data bias and label bias. Minority bias occurs when the sample size of the demographic groups are unbalanced.Missing data bias occurs when data may be missing in a non-random way. For instance, minority bias arisesfrom the imbalanced data of different demographic groups,while missing data bias emerges due to the uneven distributionof unseen data.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 14
    },
    {
        "text": "AUTHOR et al. AUTHOR et al. AUTHOR et al. AUTHOR et al. AUTHOR et al. AUTHOR et al. AUTHOR et al.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 15
    },
    {
        "text": "He is currently work-ing toward the Ph.D. degree in computer engineeringwith DATA Lab, Texas A&M University, TX, USA.His research interests include XAI, machine learningfairness and graph learning.Dr. Mengnan Du is currently an is an AssistantProfessor in the Department of Data Science, NewJersey Institute of Technology (NJIT). Mengnan Duearned his Ph.D. in Computer Science from TexasA&M University. He has previously worked/internedwith Microsoft Research (MSR), Adobe Research,Intel, Baidu Research, Baidu Search Science andJD Explore Academy. She was the recipient of IEEE Irv Kaufman Award and TexasA&M Institute of Data Science Career Initiation Fellow.Dr. Xia “Ben” Hu is an Associate Professor at RiceUniversity in the Department of Computer Science.Dr.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 16
    },
    {
        "text": "Hehas had more than 40 papers published in prestigiousvenues such as NeurIPS, AAAI, KDD, WWW, ICLR, and ICML. He receivedover 2,300 citations with an H-index of 16.Dr. Hu has published over 100 papers in severalmajor academic venues, including NeurIPS, ICLR,KDD, WWW, IJCAI, AAAI, etc. His papers havereceived several Best Paper (Candidate) awards from venues such as WWW,WSDM and ICDM. He is the recipient of NSF CAREER Award and ACMSIGKDD Rising Star Award. His work has been cited more than 12,000 timeswith an h-index of 43.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 17
    },
    {
        "text": "2021. InNAACL, 2019. 2018. 2019. 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 18
    },
    {
        "text": "Particularly, large language models(LLMs) such as GPT-2 and GPT-3 have demonstrated theirutility in medical question-answering tasks, including thosein pain management domains [111], [22]. The recent surgein conversational language models, exemplified by ChatGPT,underscores their transformative potential in healthcare. Recentstudy evaluates the feasibility of ChatGPT across multipleclinical and research scenarios, showcasing the model’s sub-stantial impact and the breadth of its applications in thehealthcare field [25]. The recent surge in conversational lan-guage models, such as ChatGPT, marks a significant shiftin healthcare technology. For example, the visual quest answering task [11]combines computer vision and natural language processing,and the model can answer relevant questions based on medicalimages and clinical notes [90]. [2] A large language model for healthcare — nhs-llmand opengpt.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 19
    },
    {
        "text": "The contrastive learning methodprojects the input data into the latent space and encouragesdata points with various sensitive attributes to be close inthe latent space and data points with the same sensitiveattributes to be scattered. Some work has explored the useof contrastive learning methods to debias the pre-trained textencoder [34], image encoder [64], or to remove the effect ofgender information on self-supervised embedding [128].2) Model Constraint: Addressing another potential driver ofalgorithmic bias—namely, the failure of the optimization goalto generalize to underrepresented groups—model constraintFIRST A. Contrastive learning enforces the samples with various sensitiveattributes to be close in latent space. Conditional contrastive learning: Removing unde-sirable information in self-supervised representations.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 20
    },
    {
        "text": "ArXiv,abs/1803.02453, 2018. ArXiv, abs/2005.14165, 2020. ArXiv,abs/2010.04053, 2020. ArXiv, abs/2011.09625, 2020. ArXiv, abs/2110.00603, 2021. ArXiv, abs/2006.07286, 2020. ArXiv, abs/2111.08711, 2021. ArXiv, abs/1104.3913, 2012. ArXiv, abs/2109.12176, 2021. ArXiv,abs/1901.07042, 2019. ArXiv, abs/1803.04383, 2018. ArXiv,abs/2109.04392, 2021. ArXiv,abs/2107.02716, 2021. ArXiv,abs/2102.06761, 2021. ArXiv, abs/2103.05841, 2021. ArXiv, abs/1907.06260, 2019. ArXiv, abs/2104.03007, 2021. ArXiv, abs/1911.07679, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 21
    },
    {
        "text": "arXiv preprint arXiv:2104.06879, 2021. arXiv preprint arXiv:2105.01441, 2021. arXiv preprint arXiv:2103.04243,2021. arXiv preprintarXiv:2111.10056, 2021. arXiv preprintarXiv:2106.02866, 2021. arXiv preprint arXiv:2109.03150, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 22
    },
    {
        "text": "Equal performance metric is appropriate in thecontext where the accuracy of the machine learning modelis crucial.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 23
    },
    {
        "text": "For instance, the machine learning system can beintroduced to build a monitoring system that is used to alertrapid response teams when hospitalized patients are at highrisk of deterioration [54].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 24
    },
    {
        "text": "If the predictive model imposes ahigh false positive rate on the protected group, patients in theprotected group may lose the opportunity to be identified,which can have serious consequences.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 25
    },
    {
        "text": "However, forcing amodel’s predictions to have one of the performance charac-teristics of equality [67] may have unintended consequences.For example, the model may achieve equal odds by sacrificingthe accuracy of the unprotected group, which underminesthe benefit principle [133].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 26
    },
    {
        "text": "In the following, we introducesome fairness measurements that follow the principle of equalperformance.• Equal Opportunity is preferred when people care moreabout true positive rates.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 27
    },
    {
        "text": "We say that a classifier satisfiesFIRST A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 28
    },
    {
        "text": ": BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE 5equal opportunity if the true positive rate is the sameacross the groups [140]:P{ŷ = 1 | y = 1, z = a} = P{ŷ = 1 | y = 1, z = b}.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 29
    },
    {
        "text": "(8)It can also be referred to as positive predictive valueparity.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 30
    },
    {
        "text": "Similarly, there is negative predictive value parity:P{ŷ = 1 | y = 0, z = a} = P{ŷ = 1 | y = 0, z = b}(9)Predictive value parity is also called sufficiency.• Equalized Odds requires that the decision rates acrossdemographic subgroups be the same when their outcomeis the same [27]:P{ŷ = 1 | z = a, y = 0} = P{ŷ = 1 | z = b, y = 0},P{ŷ = 1 | z = a, y = 1} = P{ŷ = 1 | z = b, y = 1}(10)Equalized Odds requires the algorithm to have equal truepositive rates and equal false positive rates at the sametime.• Treatment Equality requires that the ratio of false nega-tives and false positives be the same for subgroups [14]:P(ŷ = 1|y = 0, z = a))P(ŷ = 0|y = 1, z = a))=P(ŷ = 1|y = 0, z = b))P(ŷ = 0|y = 1, z = b)).(11)IV.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 31
    },
    {
        "text": "Then, developers select and train a suitablemodel for the intended task, based on the data and the typeof task.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 32
    },
    {
        "text": "Finally, the institution involved can license the modelfor implementation in real clinical practice.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 33
    },
    {
        "text": "We present thevarious complex biases that exist in healthcare based on thethree different stages (see the overview in Figure 1).A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 34
    },
    {
        "text": "A machine learning model is trained to fit thedistribution of the training data.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 35
    },
    {
        "text": "When there is bias in the data,the model may perpetuates the bias (as shown in Figure 1.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 36
    },
    {
        "text": "(a)).In the following paragraphs, we review several common typesof data bias in clinical practice.1) Minority Bias: Minority bias occurs when the samplesize of a demographic group is smaller than that of othergroups.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 37
    },
    {
        "text": "However, due to the uneven developmentof medical standards, most of the data collection is done inEurope.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 38
    },
    {
        "text": "This has led to the study of human knowledge of thedisease using biobank repositories that mainly represent indi-viduals of European ancestry.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 39
    },
    {
        "text": "For example, the vast majorityof cases in the Cancer Genome Atlas (TCGA) are made upof whites, representing approximately 82.0% of the cases.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 40
    },
    {
        "text": "Incontrast, a very small proportion of the cases are from black,Asian, and other ethnic minorities [59].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 41
    },
    {
        "text": "In fact, demographicdata such as ethnicity are crucial to determining the mutationalprofile and mechanisms of cancer.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 42
    },
    {
        "text": "As a result, genetic riskmodels perform worse in ethnic minority populations.2) Missing-data Bias: Missing data bias occurs when datamay be missing in a non-random way.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 43
    },
    {
        "text": "Machine learningalgorithms may cause harm to people with missing data inthe dataset.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 44
    },
    {
        "text": "For example, research has found that vulnerablepeople of low socioeconomic status are likely to be seen in apiecemeal fashion or cannot be seen.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 45
    },
    {
        "text": "If patients are identifiedbased on a certain number of ICD codes, records of the samenumber of visits to several different healthcare systems forthese patients may be missing.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 46
    },
    {
        "text": "The choice of inappropriate labels can alsointroduce bias.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 47
    },
    {
        "text": "For example, some models use specific phrasesthat appear in clinical records as proxy labels that indicatethe presence of cardiovascular disease.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 48
    },
    {
        "text": "However, becausewomen have different symptoms of acute coronary syndromes,proxy phrases have different meanings for men and women.As a result, women can receive delayed care, which causesdiscrimination against women.B.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 49
    },
    {
        "text": "Bias in Model DevelopmentBias in the model development phase can lead to machinelearning models perpetuating or even amplifying existing bi-ases in the data.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 50
    },
    {
        "text": "Shortcut learning occurs when models exploit easybut unreliable correlations to make predictions [21], [12],often bypassing more substantive but complex relationships.For instance, a study shows that models can capture andamplify the association between labels and sensitive attributes,6 JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 51
    },
    {
        "text": "The commitment to fair and inclusive AI develop-ment is echoed by governmental bodies, such as the NationalInstitutes of Health, through initiatives like AIM-AHEAD andBridge2AI [20].Distinguishing from related reviews.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 52
    },
    {
        "text": "0, MONTH 2020TABLE IIMITIGATION METHODS CATEGORIZATION.Reference Task Dataset Data TypeData CollectionData RedistributionDiversified Collection[88] Type II Diabetes Risk Prediction eMERGE[97] EHR,Genomic[56] Skin Lesion Classification Skin ISIC 2018[38] Medical ImageData Reweighting[138] Skin Lesion Classification Skin ISIC 2017[65] Medical Image[130] AD Classification ANDI[103] Medical ImageData Resampling [29] Diabetes Classification The Pima Indian Diabetes Dataset[122] EHRSynthetic Data[114] Skin Lesion Classification HAM10000[129] Medical Image[15] Mortality Prediction MIMIC-III[77] EHRData Purification[99] Mortality Prediction MIMIC-IV[76] EHR[100] Health Condition Classification n2c2[81], MIMIC-III[77] EHR, Clinical NoteModel DevelopmentModel DesensitizationAdversarial Learning[39] Radiology Findings Identification Private Medical Image[40] ASCVD Classification Stanford Medicine Research Data Repository[93] EHR[18] In Hospital Mortality Prediction, Patient Membership Prediction MIMIC-III[77] EHR, Clinical Note[143] HIV Diagnosis, Morphological Sex Identification, Bone Age Determination HIV Dataset[104],NCANDA dataset[125],Bone-aging Dataset[66] EHR, MRIDisentanglement [18] Appointment No-show Prediction Private EHRContrastive Learning [64] Chest X-ray Classification NIH-ChestXRay8[132] Medical ImageModel Constraint [106] Inpatient Mortality Prediction, Length of Stay Prediction Stanford Medicine Research Data Repository[93] EHRModel DeploymentDecision Explanation [99] In Hospital Mortality Prediction MIMIC-IV[76] EHRModel Adjustment [74] Congestive Heart Failure Prediction MIMIC-CXR[78], CheXpert[73] Medical ImageOutcome Adjustment [105] Ten-year Atherosclerotic Cardiovascular Disease (ASCVD) Risk Prediction Optum CDM[3] EHReven in balanced datasets [131].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 53
    },
    {
        "text": "The learned model mayamplify the association between label and gender, mimick-ing an imbalanced dataset.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 54
    },
    {
        "text": "This is akin to a model usingconfounding variables that correlate with both the input fea-tures and the output labels, thus rendering the predictionsunfair [143], [43], [62].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 55
    },
    {
        "text": "The recent literature underscores thesimilarity between these phenomena: both are manifestationsof models’ proclivity to capitalize on spurious correlationsrather than causally relevant patterns.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 56
    },
    {
        "text": "Such practices not onlycompromise the equity of the models but also their robustnessand reliability.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 57
    },
    {
        "text": "Typically, machine learningmodels aim to maximize overall predictive performance on thetraining data.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 58
    },
    {
        "text": "This focus may lead to optimizing for individualsthat occur more frequently, while neglecting underrepresentedgroups due to sampling bias.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 59
    },
    {
        "text": "Consequently, a model mayexhibit superior overall performance but fail to generalize wellfor underrepresented groups [30].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 60
    },
    {
        "text": "The study assessed Logistic Re-gression, Random Forest, and XGBoost for their performanceand fairness in healthcare tasks like predicting hospital staysand diagnosing diseases.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 61
    },
    {
        "text": "It highlighted significant variationsin how these algorithms handled sensitive data like race andgender across identical datasets.C.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 62
    },
    {
        "text": "Bias islikely to occur at this stage, and there may contain two typesof bias (as shown in Figure 1(c)).1) Training–serving Skew Bias: The training service skewbias is due to the fact that the data distribution encountered bythe model in the deployment environment is different from thedata distribution at the time of training.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 63
    },
    {
        "text": "This phenomenon isknown as the distributional shift [33], [123].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 64
    },
    {
        "text": "During modeltraining, a strong assumption is that the training and testdatasets are drawn independently and exactly from the samedistribution (i.i.d.).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 65
    },
    {
        "text": "The phenomenon of distributionalshift can occur with racially skewed public biobank datasets,which has a differential impact on ethnic subpopulations.For example, the first AI model to surpass clinical rank inpredicting lymph node metastasis was trained and evaluatedon the CAMELYON16/17 dataset, which is unique to theNetherlands [13], [72].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 66
    },
    {
        "text": "In addition to changes in ethnicity inthe population, changes in medical equipment, such as imagecapture and biometrics, can also lead to bias.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 67
    },
    {
        "text": "For example, inradiology, there may be differences in radiation dose that affectthe signal-to-noise ratio of the images obtained.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 68
    },
    {
        "text": "In pathology,there is also a great deal of heterogeneity in tissue preparation,staining protocols, and specific scanner camera parameters,which has been shown to affect model performance in cancerdiagnostic tasks [33], [26].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 69
    },
    {
        "text": "Data sets may also change inresponse to technological developments or changes in humanbehavior.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 70
    },
    {
        "text": "A typical example includes the migration of ICD-8 toICD-9 [70].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 71
    },
    {
        "text": "Another example is the discontinuation of the Epicsepsis model (ESM) due to changes in patient demographicsas a result of COVID-19 [33].Most of the work has focused on short-term learning ofFIRST A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 72
    },
    {
        "text": "One work [118] uses a causal framing help diagnosefailures of fairness transfer.2) Interaction Bias: This type of bias arises from theinteraction of the model with its users.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 73
    },
    {
        "text": "On the one hand,protected groups may distrust a model’s predictions in lightof a history of exploitation and unethical behavior, believingthat the model is biased against them.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 74
    },
    {
        "text": "This is also referredas informed mistrust bias [61].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 75
    },
    {
        "text": "Yet, a holistic approach that captures both theethical and technical detail is missing in the literature.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 76
    },
    {
        "text": "These methods can be categorized based onthe stage of the machine learning life cycle at which they areapplied.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 77
    },
    {
        "text": "Therefore, we can mitigate fairness problemsduring the data collection phase.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 78
    },
    {
        "text": "These methods are dividedinto two groups, data redistribution methods and data purifi-cation methods.1) Data Redistribution: Data distribution discrepancies, asdiscussed in Section IV-A, often lead to fairness problems inmachine learning models.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 79
    },
    {
        "text": "Several data redistribution techniques aim torectify these imbalances, including diversified collection, datareweighting, data resampling, and data synthesis.a) Diversified Collection: While the direct collectionof more diverse data is a straightforward solution, practicalchallenges like patient privacy and data collection costs oftenhinder such efforts.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 80
    },
    {
        "text": "Federated learning offers a solution byenabling model training across multiple decentralized datasetswithout directly sharing the data [33], [88].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 81
    },
    {
        "text": "However, federated learning doesnot guarantee balanced data.b) Data Reweighting: By assigning importance weightsto training data, reweighting adjusts for data distributionimbalances.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 82
    },
    {
        "text": "Applications of reweighting are seen in skin lesionclassification and Alzheimer’s disease diagnosis [138], [130].A notable drawback is that models trained with weightedsamples might lack robustness, leading to estimator variance.c) Data Resampling: Resampling rectifies underrepresen-tation by adjusting the sub-samples of the original dataset.Techniques like SMOTE combine oversampling of minoritygroups with undersampling of majority ones, proving ben-eficial in tasks like heart failure survival prediction [29].However, such methods may reduce the diversity of datacharacteristics.d) Synthetic Data: Synthetic data, often generated usingalgorithms like GANs, can enhance data distribution [126],[114].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 83
    },
    {
        "text": "By imposing fairness constraints during the generationprocess, biases in synthetic data can be controlled.Synthetic data alleviates data privacy and cost concerns [15],consistent with HIPAA’s stipulations [52].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 84
    },
    {
        "text": "It generates de-identified datasets that preserve statistical properties withoutrevealing personal health information (PHI), thus supportingHIPAA’s objective to protect patient privacy.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 85
    },
    {
        "text": "Federated learn-ing enhances this by allowing institutions to collaborativelytrain models while each entity maintains control over its PHI,a process in harmony with HIPAA’s privacy and security rules.2) Data Purification: Data purification approaches aim tomitigate fairness problems by adjusting data features or labels,often by addressing biases related to sensitive attributes.a) Removing Sensitive Attributes: A common intuitionin data purification is to remove sensitive attributes from thedataset, a method known as fairness through unawareness.However, this approach has limitations, as protected attributescan still be inferred from other features or their combinations,which act as proxy variables correlating with protected groupmembership [99].b) Mitigation in Language Models: In the realm ofNatural Language Processing (NLP), data purification hasbeen explored for clinical notes.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 86
    },
    {
        "text": "One study [100] quantifiedthe “genderedness” of n-grams in clinical notes using cosinesimilarity between word vectors generated by BERT-baseand Clinical BERT word embeddings [45], [10].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 87
    },
    {
        "text": "The mostbiased n-grams were then identified using rank perturbationdispersion (RTD) and subsequently removed from the clinicalnotes [47].c) Addressing Label Bias: Label bias, which occurs whenlabels in the dataset are biased, represents another challenge.Data massaging tackles this by changing the labels of someobjects in the dataset [79].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 88
    },
    {
        "text": "This method’s application inhealthcare remains an area yet to be explored.B.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 89
    },
    {
        "text": "However, Wehave observed that existing works tend to focus on one aspectwhile neglecting the other.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 90
    },
    {
        "text": "0, MONTH 2020'LYHUVLILHGFROOHFWLRQ 5HZHLJKWLQJ 5HVDPSOLQJ 6\\QWKHWLFD'DWD5HGLVWULEXWLRQ2ULJLQDO'DWDVHW6HQVLWLYH$WWULEXWH.HULWLVD\\R0DOHZKRZDV UHFHQWO\\ DGPLWWHG WRWKH (' IRU VXGGHQVWXIILQJ OHDN 7KH UHSDLUWRKLVVWLFNLQJVHHPVWREHKROGLQJZHOO+HKDVDFRRODQG IULHQGO\\ GLVSRVLWLRQDOWKRXJK KH GLG FRPSODLQDERXW WKH GLIILFXOWLHV RIEHLQJJUHHQKHVKH0DOHKLPZRPDQXWHULQHIHPDOE'DWD3XULILFDWLRQFig.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 91
    },
    {
        "text": "An illustration of methods mitigating the fairness problem in data collection stage: (a) Data redistribution methods adjust the distribution ofthe data.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 92
    },
    {
        "text": "The diversified collection method collects data from other hospitals.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 93
    },
    {
        "text": "The reweighting method assigns the weights to minority data.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 94
    },
    {
        "text": "The resamplingmethod seeks to create fair training samples in the sampling strategy.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 95
    },
    {
        "text": "The synthetic method generates fake data.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 96
    },
    {
        "text": "(b) Data purification methods remove sensitiveinformation directly from the data.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 97
    },
    {
        "text": "Simply removing sensitiveattributes from the data features is not a failproof solution,as machine learning models have shown the capability todifferentiate sensitive information even in their absence [89],[80].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 98
    },
    {
        "text": "Specifically, the goal of adversarial learning is to allowthe model to complete downstream tasks while not predictingsensitive attributes.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 99
    },
    {
        "text": "Adversarial learning is first introducedin Generative Adversarial Networks (GANs) [63] and thenapplied to fair machine learning [96].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 100
    },
    {
        "text": "Adversarial learninggenerally contains two branches: one is for downstream tasks,while the other is to remove sensitive attribute information:minθmaxϕL(D; θ) + Ladv(D;ϕ), (12)where D is the training dataset.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 101
    },
    {
        "text": "θ is the parameter forthe downstream task and ϕ is the parameter for adversarialclassification.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 102
    },
    {
        "text": "L is the normal object function and Ladv is theadversarial object function that indicates the error in predictingsensitive attributes.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 103
    },
    {
        "text": "Adversarial learning is applied to debias amodel for the diagnosis of chest X-ray and mammograms [39].The authors use CNN with two branches, where one predictsthe classification target and the other predicts the sensitiveattributes.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 104
    },
    {
        "text": "The training has two steps.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 105
    },
    {
        "text": "The first step minimizesthe loss for both branches.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 106
    },
    {
        "text": "In the second step, a flipped signgradient of adversarial branch is backpropagated, with theaim of suppressing learning of protected variables.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 107
    },
    {
        "text": "Similarstrategy is used to reduce the confounding effect from sensitiveattribute [143].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 108
    },
    {
        "text": "The disentanglement method assumes that the en-tangled information from the input space could be disentangledin the latent embedding space.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 109
    },
    {
        "text": "To make downstream tasks fair,the disentanglement method separates and removes sensitiveinformation from the latent embedding space.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 110
    },
    {
        "text": "Existing workhas explored the use of the Variational Autoencoder (VAE) toachieve group and subgroup fairness with respect to multiplesensitive attributes [40], [18].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 111
    },
    {
        "text": "Adversarial learning disables the model of predicting sensitive attributes.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 112
    },
    {
        "text": "Disentanglementmethod separates and removes the sensitive attribute information from latent embedding.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 113
    },
    {
        "text": "(b) Model constraint methods add additional constraints or regularization term.methods take a direct approach.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 114
    },
    {
        "text": "This method requires the machinelearning model to make consistent predictions for a patientand a counterfactual version of the patient after alteringthe sensitive attribute.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 115
    },
    {
        "text": "It has beenobserved that stringent optimization constraints can sometimesreduce predictive performance.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 116
    },
    {
        "text": "Constructing entirely unbiased models from the outsetis challenging and resource-intensive.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 117
    },
    {
        "text": "Thus, post-deploymentmitigation strategies are essential for addressing biases as theyemerge.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 118
    },
    {
        "text": "Interaction bias, as delineated in Section IV-C2,contributes to unfair outcomes during deployment.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 119
    },
    {
        "text": "It is particularly important inhealthcare, where decisions have profound implications.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 120
    },
    {
        "text": "Addressing this, research indicatesthat clear explanations of model decisions can foster trust both10 JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 121
    },
    {
        "text": "0, MONTH 2020F2XWFRPH$GMXVWPHQWE0RGHO$GMXVWPHQWD'HFLVLRQ([SODQDWLRQFig.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 122
    },
    {
        "text": "(b) The model adjustment method fine-tunes the last few layers of the deployed mode.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 123
    },
    {
        "text": "with the data in the trainingphase.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 124
    },
    {
        "text": "The model adjustment method, such as transfer learn-ing, seeks to solve this problem by fine-tuning part of themodel.Since naively retraining the entire model can be expensiveand impossible, transfer learning can provide a simple andeffective way to mitigate the problem [74].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 125
    },
    {
        "text": "This work proposessolving the shortcut problem where the model relies on simpleand shallow features (e.g.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 126
    },
    {
        "text": "the sensitive attribute) to make thedecision.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 127
    },
    {
        "text": "Specifically, the training pipeline contains two stages.The authors first train the model on a biased dataset.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 128
    },
    {
        "text": "Thenthe model is tuned on a new unbiased dataset with only thelast few layers being fine-tuned.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 129
    },
    {
        "text": "The results show that theproposed approach improves the generalization performancein older people.3) Outcome Adjustment: Outcome adjustment strategies areemployed to enhance fairness for protected groups by alteringthe model’s outputs or decision boundaries [105].Calibration, for instance, aims to align the proportion ofpositive predictions with the actual rate of positive outcomesacross various subgroups [42].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 130
    },
    {
        "text": "Fairness in this context de-mands that such alignment is maintained across both pro-tected and non-protected subgroups alike [27].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 131
    },
    {
        "text": "Nevertheless,the challenge arises when calibration efforts confront theincompatibility between different fairness standards.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 132
    },
    {
        "text": "Notably,attempts to calibrate across multiple protected groups oftenfind themselves at odds with criteria like equalized oddsor disparate impact [109].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 133
    },
    {
        "text": "0, MONTH 2020healthcare by adopting the concept of distributive justicefrom works [112], [82].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 134
    },
    {
        "text": "It can be particularly effective in situations wherethe model’s default decision threshold does not accommo-date the protected group adequately.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 135
    },
    {
        "text": "Forexample, the model constraint approach [6] offers flexibilityin satisfying either equal allocation or equal performance, asthe fairness constraint can be incorporated as an optimizationobjective.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 136
    },
    {
        "text": "Recent studies have also demonstrated the effec-tiveness of certain model desensitization methods in ensuringeither equal allocation or equal performance through appro-priate optimization.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 137
    },
    {
        "text": "For instance, some work [96] proposedthe use of adversarial objects to achieve demographic parityand equalized of odds.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 138
    },
    {
        "text": "However, the previous two work arein the field of general fair machine learning.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 139
    },
    {
        "text": "As a result, weadvocate for additional research efforts to conduct detailedexperiments and discussions on the suitability of differentfairness metrics for different mitigation methods in order toensure their effective implementation in healthcare settings.FIRST A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 140
    },
    {
        "text": "RESEARCH CHALLENGESDespite current progress, there are numerous research chal-lenges that must be addressed before machine learning meth-ods can be used in clinical practice.A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 141
    },
    {
        "text": "Capturing and analyzingthe uncertainty in data and models is paramount, more soin high-stakes environments such as clinical settings.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 142
    },
    {
        "text": "In suchcontexts, physicians might leverage the quantified uncertaintyto prioritize manual review of cases that the model deemshighly uncertain.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 143
    },
    {
        "text": "Addressing epistemic uncertainty, which arises fromincomplete knowledge, often involves integrating more datainto the model.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 144
    },
    {
        "text": "On the other hand, aleatoric uncertainty, whichis inherent and irreducible, demands distinct strategies.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 145
    },
    {
        "text": "An understanding of aleatoricuncertainty can lead to models that are inherently fairer,offering improved outcomes for underrepresented groups inthe data [124].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 146
    },
    {
        "text": "Furthermore, active learning techniques, whichfocus on the selection of diverse and representative dataduring model training, have been proposed as a means topreemptively mitigate bias [19].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 147
    },
    {
        "text": "Long-term Fairness in HealthcareAnother distributive justice called equal outcome or equalbenefit is not mentioned in Section II-A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 148
    },
    {
        "text": "It refers to theassurance that protected groups have the same benefit fromthe deployment of machine learning models.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 149
    },
    {
        "text": "The gap betweenequal allocation and equal benefit occurs when a fair decisioncannot guarantee fair benefit to patients in the future.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 150
    },
    {
        "text": "However, thisis not the case in healthcare settings in practice.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 151
    },
    {
        "text": "Thesedata then have an impact on the performance of future machinelearning algorithms.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 152
    },
    {
        "text": "This is also called a feedback loop.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 153
    },
    {
        "text": "Whenbias appears in the feedback loop, it can exacerbate the biasor create new biases and further compromise the benefit ofcertain demographic groups.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 154
    },
    {
        "text": "A similar feedback loop has beendiscussed in the context of the recommender system [141].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 155
    },
    {
        "text": "Tothe best of our knowledge, no research has been conductedon the long-term fairness problem in the context of thehealthcare domain.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 156
    },
    {
        "text": "Fairness of Multi-modality Model for HealthcareA research question is described as multimodal when it in-cludes multiple data types.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 157
    },
    {
        "text": "The human experience of the worldis multimodal.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 158
    },
    {
        "text": "However, these methodscan perpetuate or even exacerbate existing disparities, leading tofairness concerns such as the unequal distribution of resourcesand diagnostic inaccuracies among different demographic groups.Addressing these fairness problem is paramount to preventfurther entrenchment of social injustices.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 159
    },
    {
        "text": "Multi-modal machine learning aims to buildmodels that can process and correlate information from multi-ple modalities, thus enabling advances in artificial intelligencein understanding the world around us.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 160
    },
    {
        "text": "One of the key drivingforces of the intelligent medical system is the multimodalmethod.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 161
    },
    {
        "text": "The combination of different modalities of healthcaredata, each providing information about a patient’s treatmentfrom a specific perspective, overlays and complements eachother to further improve the accuracy of diagnosis and treat-ment.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 162
    },
    {
        "text": "However, multimodal modelsface more serious bias and fairness problems than uni-modalmodels, despite improvements in performance [17].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 163
    },
    {
        "text": "The forms in which bias existsvary across modality data, as do the methods used to mitigateit.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 164
    },
    {
        "text": "These facets aredeeply intertwined, with their relationships characterized byboth synergy and tension.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 165
    },
    {
        "text": "Then the biases at various stages of modeldevelopment are introduced in Section IV.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 166
    },
    {
        "text": "Interpretability contributes to this goal bydemystifying model predictions, thereby fostering trust andenabling the identification of potential biases—critical in aclinical setting [49], [72], [99].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 167
    },
    {
        "text": "However, the pursuit of fair-ness may inadvertently conflict with privacy, particularly for12 JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 168
    },
    {
        "text": "0, MONTH 2020underprivileged groups who may suffer disproportionate pri-vacy losses [28].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 169
    },
    {
        "text": "Robustfair training aims to inoculate models against perturbationsthat could skew decision-making, thus safeguarding equitableoutcomes [87].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 170
    },
    {
        "text": "This is paramount in clinical environmentswhere decisions must remain stable despite data variabilityand adversarial conditions.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 171
    },
    {
        "text": "Research often probesthese dimensions in isolation, seldom navigating their inter-sections.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 172
    },
    {
        "text": "Given their mutual reinforcement and constraints,an integrated approach is imperative.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 173
    },
    {
        "text": "Advancing multi-facetedethical frameworks that concurrently address these dimensionswill be instrumental in realizing the full potential of AI inhealthcare—delivering models that are not only technicallyproficient but also ethically sound and clinically viable.VII.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 174
    },
    {
        "text": "Wehave delineated biases according to the three distinct stagesof the machine learning lifecycle: data collection, modeldevelopment, and model deployment.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 175
    },
    {
        "text": "For each stage, wehave discussed targeted mitigation methods and examinedtheir interconnections with the sources of bias they aim toaddress.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 176
    },
    {
        "text": "ACKNOWLEDGEMENTWe extend our sincere thanks for the support from theNational Institutes of Health (NIH) grant 1OT2OD032581-02-211 and the National Science Foundation (NSF) grantsIIS 1900990, 1939716, and 2239257, which have significantlycontributed to this survey paper.REFERENCES[1] Azure health bot — microsoft azure.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 177
    },
    {
        "text": "https://azure.microsoft.com/en-us/products/bot-services/health-bot.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 178
    },
    {
        "text": "(Accessed on 01/02/2024).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 179
    },
    {
        "text": "https://aiforhealthcare.substack.com/p/a-large-language-model-for-healthcare.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 180
    },
    {
        "text": "(Accessed on 01/02/2024).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 181
    },
    {
        "text": "[3] Optum - health services innovation company.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 182
    },
    {
        "text": "https://www.optum.com/.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 183
    },
    {
        "text": "(Accessed on 11/07/2023).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 184
    },
    {
        "text": "[4] A. Adadi and M. Berrada.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 185
    },
    {
        "text": "Peeking inside the black-box: A survey onexplainable artificial intelligence (xai).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 186
    },
    {
        "text": "For example, a large-scale study built a deep neuralnetwork on the NIH Chest-XRay14 dataset and the CheXpertdataset to diagnose various chest diseases [86].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 187
    },
    {
        "text": "IEEE Access, 6:52138–52160,2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 188
    },
    {
        "text": "[5] A. S. Adamson and A. Smith.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 189
    },
    {
        "text": "Machine learning and health caredisparities in dermatology.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 190
    },
    {
        "text": "JAMA dermatology, 154(11):1247–1248,2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 191
    },
    {
        "text": "Morse, T. Sequist, and M. L. Mendu.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 192
    },
    {
        "text": "Examining the potentialimpact of race multiplier utilization in estimated glomerular filtrationrate calculation on african-american care outcomes.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 193
    },
    {
        "text": "Second, ma-chine learning models have also been applied to the structuredelectronic health record (EHR), which contains informationon demographics, diagnoses, laboratory tests, medications, etc.For instance, a gradient boosting model was used to predictcardiovascular disease risk based on the Stanford Transla-tional Research Integrated Database Environment (STRIDE8) dataset [101].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 194
    },
    {
        "text": "Accounting for model uncertaintyin algorithmic discrimination.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 195
    },
    {
        "text": "Handling of uncertainty in medical data using machinelearning and probability theory techniques: a review of 30 years(1991–2020).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 196
    },
    {
        "text": "Annals of Operations Research, pages 1 – 42, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 197
    },
    {
        "text": "A. McDermott.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 198
    },
    {
        "text": "Third, advancements in natural languageprocessing (NLP) have greatly enhanced our ability to processunstructured electronic health record (EHR) data, such asclinical narratives, medical examinations, clinical laboratoryreports, surgical notes, and discharge summaries.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 199
    },
    {
        "text": "Publicly available clinical bert embeddings.ArXiv, abs/1904.03323, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 200
    },
    {
        "text": "Parikh.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 201
    },
    {
        "text": "Vqa: Visual question answering.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 202
    },
    {
        "text": "In Proceedings of theIEEE international conference on computer vision, pages 2425–2433,2015.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 203
    },
    {
        "text": "“short-cuts” causing bias in radiology artificial intelligence: causes, evaluationand mitigation.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 204
    },
    {
        "text": "Journal of the American College of Radiology, 2023.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 205
    },
    {
        "text": "These NLPmethods facilitate a range of critical tasks including medicalconcept extraction, disease inference, and clinical decisionsupport [35], [142], [100].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 206
    },
    {
        "text": "A. van der Laak, M. Hermsen, Q. F.Manson, M. C. A. Balkenhol, O. G. F. Geessink, N. Stathonikos,M.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 207
    },
    {
        "text": "Albarqouni, B. Mungal, A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 208
    },
    {
        "text": "Watanabe, S. Seno, Y. Takenaka, H. Matsuda, H. A. Phoulady,V.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 209
    },
    {
        "text": "Venâncio.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 210
    },
    {
        "text": "Diagnostic assessment of deep learning algorithms fordetection of lymph node metastases in women with breast cancer.JAMA, 318:2199–2210, 2017.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 211
    },
    {
        "text": "Fairnessin criminal justice risk assessments: The state of the art.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 212
    },
    {
        "text": "SociologicalMethods & Research, 50:3 – 44, 2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 213
    },
    {
        "text": "Entropy, 23, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 214
    },
    {
        "text": "Uncertaintyas a form of transparency: Measuring, communicating, and usinguncertainty.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 215
    },
    {
        "text": "In Proceedings of the 2021 AAAI/ACM Conference onAI, Ethics, and Society, pages 401–413, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 216
    },
    {
        "text": "K. D’Mello.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 217
    },
    {
        "text": "Bias and fairness in multimodal machine learning: Acase study of automated video interviews.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 218
    },
    {
        "text": "Proceedings of the 2021International Conference on Multimodal Interaction, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 219
    },
    {
        "text": "Fairness in tabnet modelby disentangled representation for the prediction of hospital no-show.arXiv preprint arXiv:2103.04048, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 220
    },
    {
        "text": "[20] J. Brogan.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 221
    },
    {
        "text": "The next era of biomedical research: Prioritizing healthequity in the age of digital medicine.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 222
    },
    {
        "text": "Voices in Bioethics, 7, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 223
    },
    {
        "text": "[21] A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 224
    },
    {
        "text": "Detecting shortcut learning for fair medical ai usingshortcut testing.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 225
    },
    {
        "text": "[22] T. B.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 226
    },
    {
        "text": "Litwin, S. Gray, B.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 227
    },
    {
        "text": "Chess, J. Clark, C. Berner, S. McCandlish,A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 228
    },
    {
        "text": "Language models are few-shot learners.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 229
    },
    {
        "text": "Notably, Microsoft’s Azure HealthBot [1] and NHS-LLM [2] represent pioneering applicationsof LLMs in healthcare.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 230
    },
    {
        "text": "J. Fuchs.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 231
    },
    {
        "text": "Clinical-grade computational pathology using weaklysupervised deep learning on whole slide images.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 232
    },
    {
        "text": "An overview ofmachine learning.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 233
    },
    {
        "text": "Machine learning, pages 3–23, 1983.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 234
    },
    {
        "text": "Evaluating thefeasibility of chatgpt in healthcare: an analysis of multiple clinical andresearch scenarios.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 235
    },
    {
        "text": "Journal of Medical Systems, 47(1):33, 2023.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 236
    },
    {
        "text": "[26] D. C. Castro, I. Walker, and B. Glocker.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 237
    },
    {
        "text": "These models are designed to assistusers in assessing healthcare needs, particularly when theyare uncertain about the severity of their condition.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 238
    },
    {
        "text": "Causality matters in medicalimaging.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 239
    },
    {
        "text": "In2021 IEEE European Symposium on Security and Privacy (EuroS&P),pages 292–303.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 240
    },
    {
        "text": "IEEE, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 241
    },
    {
        "text": "[29] N. Chawla, K. Bowyer, L. O.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 242
    },
    {
        "text": "Smote:Synthetic minority over-sampling technique.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 243
    },
    {
        "text": "J. Artif.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 244
    },
    {
        "text": "Intell.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 245
    },
    {
        "text": "Res.,16:321–357, 2002.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 246
    },
    {
        "text": "Why is my classifierdiscriminatory?",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 247
    },
    {
        "text": "Advances in neural information processing systems,31, 2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 248
    },
    {
        "text": "Thisis crucial to ensure equitable access and outcomes acrossdifferent demographics, thus avoiding exacerbation of existingdisparities in healthcare [25].A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 249
    },
    {
        "text": "Annual review ofbiomedical data science, 4:123–144, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 250
    },
    {
        "text": "[32] J. Chen, I. Berlot-Attwell, S. Hossain, X. Wang, and F. Rudzicz.Exploring text specific and blackbox fairness algorithms in multimodalclinical nlp.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 251
    },
    {
        "text": "Fairfil: Contrastiveneural debiasing method for pretrained text encoders, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 252
    },
    {
        "text": "[35] Y. Choi, C. Y.-I.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 253
    },
    {
        "text": "Chiu, and D. Sontag.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 254
    },
    {
        "text": "Learning low-dimensionalrepresentations of medical concepts.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 255
    },
    {
        "text": "AMIA Summits on TranslationalScience Proceedings, 2016:41, 2016.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 256
    },
    {
        "text": "[36] A. Chouldechova.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 257
    },
    {
        "text": "Fair prediction with disparate impact: A study of biasin recidivism prediction instruments.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 258
    },
    {
        "text": "Big data, 5(2):153–163, 2017.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 259
    },
    {
        "text": "Fairregression with wasserstein barycenters.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 260
    },
    {
        "text": "Skinlesion analysis toward melanoma detection: A challenge at the 2017international symposium on biomedical imaging (isbi), hosted by theinternational skin imaging collaboration (isic).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 261
    },
    {
        "text": "In 2018 IEEE 15thinternational symposium on biomedical imaging (ISBI 2018), pages168–172.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 262
    },
    {
        "text": "IEEE, 2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 263
    },
    {
        "text": "Banerjee.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 264
    },
    {
        "text": "Two-step adversarial debiasing with partial learning -medical image case-studies.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 265
    },
    {
        "text": "Flexibly fair representation learning by disentanglement.In International conference on machine learning, pages 1436–1445.PMLR, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 266
    },
    {
        "text": "Halpern.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 267
    },
    {
        "text": "Fairness is not static: deeper understanding of long termfairness via simulation studies.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 268
    },
    {
        "text": "In Proceedings of the 2020 Conferenceon Fairness, Accountability, and Transparency, pages 525–534, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 269
    },
    {
        "text": "[42] A. P. Dawid.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 270
    },
    {
        "text": "The well-calibrated bayesian.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 271
    },
    {
        "text": "Journal of the AmericanStatistical Association, 77:605–610, 1982.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 272
    },
    {
        "text": "Genopathomic profiling identifies signaturesfor immunotherapy response of lung adenocarcinoma via confounder-aware representation learning.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 273
    },
    {
        "text": "Iscience, 25(11), 2022.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 274
    },
    {
        "text": "Bert: Pre-trainingof deep bidirectional transformers for language understanding.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 275
    },
    {
        "text": "Compas risk scales:Demonstrating accuracy equity and predictive parity.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 276
    },
    {
        "text": "Distributive justice is concerned withthe distribution of resources among members of a society, andthe underlying idea of distributive justice theories are distri-bution principles and metrics of justice [82].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 277
    },
    {
        "text": "Northpointe Inc,7(4), 2016.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 278
    },
    {
        "text": "R. Dewhurst, T. J.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 279
    },
    {
        "text": "Gray, M. R. Frank, A. J. Reagan, and C. M.Danforth.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 280
    },
    {
        "text": "Allotaxonometry and rank-turbulence divergence: a uni-versal instrument for comparing complex systems.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 281
    },
    {
        "text": "arXiv preprintarXiv:2002.09770, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 282
    },
    {
        "text": "[48] J.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 283
    },
    {
        "text": "Dodge, Q. V. Liao, Y. Zhang, R. K. E. Bellamy, and C. Dugan.Explaining models: an empirical study of how explanations impactfairness judgment.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 284
    },
    {
        "text": "Proceedings of the 24th International Conferenceon Intelligent User Interfaces, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 285
    },
    {
        "text": "The distributionprinciples specify how resources should be distributed [85].The justice metric specifies the type of resources to be allo-cated [82].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 286
    },
    {
        "text": "Techniques for interpretable machinelearning.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 287
    },
    {
        "text": "Communications of the ACM, 63(1):68–77, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 288
    },
    {
        "text": "Learning credible deep neuralnetworks with rationale regularization.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 289
    },
    {
        "text": "2019 IEEE InternationalConference on Data Mining (ICDM), pages 150–159, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 290
    },
    {
        "text": "Health insuranceportability and accountability act.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 291
    },
    {
        "text": "[53] S. Enayati and O. Y. Özaltın.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 292
    },
    {
        "text": "Optimal influenza vaccine distributionwith equity.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 293
    },
    {
        "text": "European Journal of Operational Research, 283(2):714–725, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 294
    },
    {
        "text": "Piloting electronicmedical record-based early detection of inpatient deterioration in com-munity hospitals.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 295
    },
    {
        "text": "Measuring fair-ness under unawareness of sensitive attributes: A quantification-basedapproach.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 296
    },
    {
        "text": "On the fairness of swarm learning in skinlesion classification.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 297
    },
    {
        "text": "arXiv preprint arXiv:1609.07236, 2016.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 298
    },
    {
        "text": "[59] J. Gao, B.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 299
    },
    {
        "text": "Sun, A. S. Jacobsen, R. Sinha, E. Larsson, E. G. Cerami,C.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 300
    },
    {
        "text": "Sander, and N. D. Schultz.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 301
    },
    {
        "text": "Integrative analysis of complex cancergenomics and clinical profiles using the cbioportal.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 302
    },
    {
        "text": "Science Signaling,6:pl1 – pl1, 2013.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 303
    },
    {
        "text": "[60] S. Garg, V. Perot, N. Limtiaco, A. Taly, E. H. Chi, and A. Beutel.Counterfactual fairness in text classification through robustness, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 304
    },
    {
        "text": "AI & society, pages 1–15, 2022.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 305
    },
    {
        "text": "Algorithmicencoding of protected characteristics in chest x-ray disease detectionmodels.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 306
    },
    {
        "text": "For example, a recently published work focused onbuilding models to help determine which patients with chronickidney disease should undergo kidney transplantation.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 307
    },
    {
        "text": "Ozair, A. Courville, and Y. Bengio.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 308
    },
    {
        "text": "Generative adversarial networks,2014.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 309
    },
    {
        "text": "Pacl: Patient-aware contrastivelearning through metadata refinement for generalized early diseasediagnosis.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 310
    },
    {
        "text": "Skin lesion analysistoward melanoma detection: A challenge at the 2017 internationalsymposium on biomedical imaging (isbi), hosted by the internationalskin imaging collaboration (isic).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 311
    },
    {
        "text": "2018 IEEE 15th InternationalSymposium on Biomedical Imaging (ISBI 2018), pages 168–172, 2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 312
    },
    {
        "text": "Thestudy found that the model was biased towards black patientsand tended to classify black patients as having more severekidney disease [7].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 313
    },
    {
        "text": "B. Mamonov,A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 314
    },
    {
        "text": "The rsna pediatric bone age machine learning challenge.Radiology, 290(2):498–503, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 315
    },
    {
        "text": "Advances in neural information processing systems, 29:3315–3323, 2016.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 316
    },
    {
        "text": "Another study examined how to effectivelycombat influenza in the early stages of an influenza outbreakFIRST A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 317
    },
    {
        "text": "On the long-term impact ofalgorithmic decision policies: Effort unfairness and feature segregationthrough social learning, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 318
    },
    {
        "text": "Elixhauser.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 319
    },
    {
        "text": "Trends in opioid-related inpatient stays shifted after theus transitioned to icd-10-cm diagnosis coding in 2015.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 320
    },
    {
        "text": "Caus-ability and explainability of artificial intelligence in medicine.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 321
    },
    {
        "text": "WileyInterdisciplinary Reviews.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 322
    },
    {
        "text": "Data Mining and Knowledge Discovery, 9,2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 323
    },
    {
        "text": "The impact of site-specific digital histology signatures on deep learning model accuracyand bias.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 324
    },
    {
        "text": "[73] J.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 325
    },
    {
        "text": "Chexpert: A largechest radiograph dataset with uncertainty labels and expert comparison.In AAAI, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 326
    },
    {
        "text": "Wiens.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 327
    },
    {
        "text": "Deep learning applied to chest x-rays: Exploiting andpreventing shortcuts.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 328
    },
    {
        "text": "In MLHC, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 329
    },
    {
        "text": "General-ized demographic parity for group fairness.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 330
    },
    {
        "text": "In International Conferenceon Learning Representations, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 331
    },
    {
        "text": "[76] A. Johnson, L. Bulgarelli, T. Pollard, S. Horng, L. Celi, and R. Mark.Mimic-iv (version 0.4), physionet, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 332
    },
    {
        "text": "Ghassemi, B. Moody, P. Szolovits, L. A. Celi, and R. G. Mark.Mimic-iii, a freely accessible critical care database.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 333
    },
    {
        "text": "Scientific data,3(1):1–9, 2016.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 334
    },
    {
        "text": "Mimic-cxr: Alarge publicly available database of labeled chest radiographs.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 335
    },
    {
        "text": "[79] F. Kamiran and T. Calders.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 336
    },
    {
        "text": "Data preprocessing techniques for classi-fication without discrimination.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 337
    },
    {
        "text": "Knowledge and Information Systems,33:1–33, 2011.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 338
    },
    {
        "text": "Sattigeri, and K. R. Varshney.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 339
    },
    {
        "text": "Fairness of classifiers across skintones in dermatology.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 340
    },
    {
        "text": "In International Conference on Medical Im-age Computing and Computer-Assisted Intervention, pages 320–329.Springer, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 341
    },
    {
        "text": "Uzuner.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 342
    },
    {
        "text": "Creation of a newlongitudinal corpus of clinical narratives.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 343
    },
    {
        "text": "[82] M. Kuppler, C. Kern, R. L. Bach, and F. Kreuter.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 344
    },
    {
        "text": "A recent study discovered that, despitehaving similar accuracy to board-certified dermatologists, ma-chine learning algorithms used to classify images of benignand malignant moles are less accurate in the diagnostic taskof melanoma on dark skin [5].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 345
    },
    {
        "text": "Counterfactualfairness.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 346
    },
    {
        "text": "In NIPS, 2017.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 347
    },
    {
        "text": "Deephealth: Review and challenges of artificialintelligence in health informatics.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 348
    },
    {
        "text": "arXiv: Learning, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 349
    },
    {
        "text": "[85] J. Lamont.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 350
    },
    {
        "text": "Distributive justice.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 351
    },
    {
        "text": "Routledge, 2017.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 352
    },
    {
        "text": "Another study analyzes thesex/racial bias in AI-based cine CMR segmentation usinga large-scale database [110].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 353
    },
    {
        "text": "Gender imbalance in medical imaging datasets produces biasedclassifiers for computer-aided diagnosis.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 354
    },
    {
        "text": "Proceedings of the NationalAcademy of Sciences of the United States of America, 117:12592 –12594, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 355
    },
    {
        "text": "In Proceedings of the 27thACM SIGKDD Conference on Knowledge Discovery & Data Mining,pages 4046–4047, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 356
    },
    {
        "text": "Targeting underrepresented populations inprecision medicine: A federated transfer learning approach.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 357
    },
    {
        "text": "The Annalsof Applied Statistics, 17(4):2970–2992, 2023.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 358
    },
    {
        "text": "Estimating and improvingfairness with adversarial learning.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 359
    },
    {
        "text": "It is shown that state-of-the-art deep learning models for automatic segmentation of theventricle and myocardium based on cine short-axis CMR hadstatistically significant differences in errors between races.Different healthcare settings require different kinds ofdistributive justice.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 360
    },
    {
        "text": "Ge.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 361
    },
    {
        "text": "Medical visual question answering: A survey.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 362
    },
    {
        "text": "Heng.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 363
    },
    {
        "text": "The various distributive justice optionsmake it extremely difficult for ML models to satisfy allconditions [46], [36].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 364
    },
    {
        "text": "Semi-supervised med-ical image classification with relation-driven self-ensembling model.IEEE Transactions on Medical Imaging, 39:3429–3440, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 365
    },
    {
        "text": "Stride–anintegrated standards-based translational research informatics platform.In AMIA Annual Symposium Proceedings, volume 2009, page 391.American Medical Informatics Association, 2009.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 366
    },
    {
        "text": "[94] C. Lu, A. Lemay, K. Chang, K. Hoebel, and J. Kalpathy-Cramer.Fair conformal predictors for applications in medical imaging.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 367
    },
    {
        "text": "Evaluating sub-group disparity using epistemic uncertainty in mammography.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 368
    },
    {
        "text": "Learning adversariallyfair and transferable representations.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 369
    },
    {
        "text": "PMLR, 2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 370
    },
    {
        "text": "The emerge network: a consortium of biorepositories linked toelectronic medical records data for conducting genomic studies.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 371
    },
    {
        "text": "BMCmedical genomics, 4:1–11, 2011.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 372
    },
    {
        "text": "ACMComputing Surveys (CSUR), 54:1 – 35, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 373
    },
    {
        "text": "Mimic-if: Interpretability andfairness evaluation of deep learning models on mimic-iv dataset.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 374
    },
    {
        "text": "[100] J. R. Minot, N. Cheney, M. E. Maier, D. C. Elbers, C. M. Danforth,and P. S. Dodds.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 375
    },
    {
        "text": "Interpretable bias mitigation for textual data:Reducing gender bias in patient notes while maintaining classificationperformance.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 376
    },
    {
        "text": "[101] M. Nguyen.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 377
    },
    {
        "text": "Predicting cardiovascular risk using electronic healthrecords.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 378
    },
    {
        "text": "Addressing bias in artificialintelligence in health care.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 379
    },
    {
        "text": "JAMA, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 380
    },
    {
        "text": "Alzheimer’s disease neuroimaging initiative (adni): clinicalcharacterization.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 381
    },
    {
        "text": "Neurology, 74(3):201–209, 2010.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 382
    },
    {
        "text": "Accelerated and premature aging characteriz-ing regional cortical volume loss in human immunodeficiency virusinfection: contributions from alcohol, substance use, and hepatitisc coinfection.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 383
    },
    {
        "text": "Biological Psychiatry: Cognitive Neuroscience andNeuroimaging, 3(10):844–859, 2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 384
    },
    {
        "text": "In Proceedings of the 2022ACM Conference on Fairness, Accountability, and Transparency, pages1039–1052, 2022.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 385
    },
    {
        "text": "In most cases, onlyone sensitive feature is considered, so we use z when dz =1.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 386
    },
    {
        "text": "Creating fair models of atherosclerotic cardiovasculardisease risk.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 387
    },
    {
        "text": "A unified view ondifferential privacy and robustness to adversarial examples.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 388
    },
    {
        "text": "arXivpreprint arXiv:1906.07982, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 389
    },
    {
        "text": "[109] G. Pleiss, M. Raghavan, F. Wu, J. M. Kleinberg, and K. Q. Weinberger.On fairness and calibration.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 390
    },
    {
        "text": "In NIPS, 2017.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 391
    },
    {
        "text": "The prediction of the model f(·) with input x as ŷ =f(x), and y is the corresponding ground truth label.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 392
    },
    {
        "text": "Fairness in cardiac magnetic resonance imaging: Assessing sexand racial bias in deep learning-based segmentation.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 393
    },
    {
        "text": "In medRxiv, 2021.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 394
    },
    {
        "text": "[111] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever.Language models are unsupervised multitask learners.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 395
    },
    {
        "text": "In thissurvey, we mainly focus on the binary classification problem,while many works go beyond it into multi-class classificationtask, regression task, segmentation task with their own uniquemetric.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 396
    },
    {
        "text": "Reducing bias and increasing utility by federatedgenerative modeling of medical images using a centralized adversary.arXiv preprint arXiv:2101.07235, 2021.FIRST A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 397
    },
    {
        "text": "U-net: Convolutional networksfor biomedical image segmentation.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 398
    },
    {
        "text": "In International Conference onMedical image computing and computer-assisted intervention, pages234–241.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 399
    },
    {
        "text": "Springer, 2015.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 400
    },
    {
        "text": "Other symbols and definitions can be found in Table I.A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 401
    },
    {
        "text": "Super-resolution recon-struction to increase the spatial resolution of diffusion weighted imagesfrom orthogonal anisotropic acquisitions.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 402
    },
    {
        "text": "Medical image analysis, 167:1465–76, 2012.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 403
    },
    {
        "text": "Opsahl-Ong, A.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 404
    },
    {
        "text": "A. McDermott, and M. Ghassemi.Chexclusion: Fairness gaps in deep chest x-ray classifiers.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 405
    },
    {
        "text": "PacificSymposium on Biocomputing.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 406
    },
    {
        "text": "Equal AllocationEqual allocation is suitable in the healthcare setting whenresources should be distributed proportionally to patients inprotected groups.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 407
    },
    {
        "text": "Ghassemi.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 408
    },
    {
        "text": "Underdiagnosis bias of artificial intelligence algorithmsapplied to chest radiographs in under-served patient populations.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 409
    },
    {
        "text": "Challenges and oppor-tunities with causal discovery algorithms: application to alzheimer’spathophysiology.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 410
    },
    {
        "text": "Using the adap learning algorithm to forecast the onset ofdiabetes mellitus.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 411
    },
    {
        "text": "Equal allocation is also applicable when thelabel is historically biased [113].",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 412
    },
    {
        "text": "American Medical InformaticsAssociation, 1988.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 413
    },
    {
        "text": "[123] A. Subbaswamy and S. Saria.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 414
    },
    {
        "text": "From development to deployment:dataset shift, causality, and shift-stable models in health ai.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 415
    },
    {
        "text": "Biostatis-tics, 21(2):345–352, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 416
    },
    {
        "text": "Fairness through aleatoric uncertainty.arXiv preprint arXiv:2304.03646, 2023.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 417
    },
    {
        "text": "[125] R. J. Tibshirani and B. Efron.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 418
    },
    {
        "text": "An introduction to the bootstrap.Monographs on statistics and applied probability, 57(1), 1993.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 419
    },
    {
        "text": "For example, if historicallyAfrican American women have been sent for such proceduresat unduly low rates, then a ‘correct’ prediction based onhistorical data would underestimate the status of these women.From a computational point of view, it is desirable thatthe decisions made by the model differ as little as possiblebetween the different demographic groups.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 420
    },
    {
        "text": "Representative & fair syntheticdata.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 421
    },
    {
        "text": "[127] E. J. Topol.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 422
    },
    {
        "text": "High-performance medicine: the convergence of humanand artificial intelligence.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 423
    },
    {
        "text": "Salakhutdinov.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 424
    },
    {
        "text": "The ham10000 dataset,a large collection of multi-source dermatoscopic images of commonpigmented skin lesions.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 425
    },
    {
        "text": "Scientific Data, 5, 2018.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 426
    },
    {
        "text": "[130] C. Wachinger and M. Reuter.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 427
    },
    {
        "text": "Domain adaptation for alzheimer’sdisease diagnostics.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 428
    },
    {
        "text": "NeuroImage, 139:470–479, 2016.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 429
    },
    {
        "text": "Balanceddatasets are not enough: Estimating and mitigating gender bias in deepimage representations.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 430
    },
    {
        "text": "In Proceedings of the IEEE/CVF InternationalConference on Computer Vision, pages 5310–5319, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 431
    },
    {
        "text": "[132] X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers.Chestx-ray8: Hospital-scale chest x-ray database and benchmarks onweakly-supervised classification and localization of common thoraxdiseases.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 432
    },
    {
        "text": "2017 IEEE Conference on Computer Vision and PatternRecognition (CVPR), pages 3462–3471, 2017.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 433
    },
    {
        "text": ".",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 434
    },
    {
        "text": "Wang.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 435
    },
    {
        "text": "medRxiv,2022.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 436
    },
    {
        "text": ".",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 437
    },
    {
        "text": "Wang.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 438
    },
    {
        "text": "In medRxiv,2022.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 439
    },
    {
        "text": "Deeplearning of feature representation with multiple instance learning formedical image analysis.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 440
    },
    {
        "text": "2014 IEEE International Conference onAcoustics, Speech and Signal Processing (ICASSP), pages 1626–1630,2014.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 441
    },
    {
        "text": "Heng.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 442
    },
    {
        "text": "Robust learningat noisy labeled medical images: Applied to skin lesion classification.2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI2019), pages 1280–1283, 2019.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 443
    },
    {
        "text": ",K} indicates K number of classes.An alternative definition can constitute the summationwith a maximum.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 444
    },
    {
        "text": "[140] M. B. Zafar, I. Valera, M. Gomez-Rodriguez, and K. P. Gummadi.Fairness beyond disparate treatment & disparate impact: Learningclassification without disparate mistreatment.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 445
    },
    {
        "text": "Proceedings of the 26thInternational Conference on World Wide Web, 2017.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 446
    },
    {
        "text": "Recommendation fairness: From static todynamic.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 447
    },
    {
        "text": "Hurtful words: quantifying biases in clinical contextual wordembeddings.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 448
    },
    {
        "text": "Proceedings of the ACM Conference on Health, Inference,and Learning, 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 449
    },
    {
        "text": "DP can also be applied to the regressionmodel rather than to the classification model [37]:supt∈R|P(ŷ ≤ t|z = a)− P(ŷ ≤ t|z = b)| = 0.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 450
    },
    {
        "text": "Training confounder-free deeplearning models for medical applications.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 451
    },
    {
        "text": "degree inElectrical Engineering and Automation from theHuazhong University of Science and Technology,Hubei, China, in 2017, and the master’s degree inElectrical and Computer Engineering from DukeUniversity, NC, USA, in 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 452
    },
    {
        "text": "His research covers a widerange of trustworthy machine learning topics, suchas model explainability, fairness, and robustness.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 453
    },
    {
        "text": "(3)• General Demographic Parity (GDP) [75] extends thedemographic parity on the continuous sensitive attribute:∆GDP = Ez [|E[ŷ | z]− E[ŷ]|] , (4)where E[ŷ | s] is the local average prediction of themodel conditioned on the sensitive attribute, and E[ŷ]is the global prediction average.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 454
    },
    {
        "text": "Na Zou is currently a Corrie&Jim Furber’64 assistant professor in Engineering Technologyand Industrial Distribution at Texas A&M Univer-sity.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 455
    },
    {
        "text": "She was an Instructional Assistant Professorin Industrial and Systems Engineering at TexasA&M University from 2016 to 2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 456
    },
    {
        "text": "She holds botha Ph.D. in Industrial Engineering and a MSE inCivil, Environmental and Sustainable Engineeringfrom Arizona State University.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 457
    },
    {
        "text": "Her research focuseson fair and interpretable machine learning, transferlearning, network modeling and inference, supportedby NSF and industrial sponsors.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 458
    },
    {
        "text": "The research projects have resulted inpublications at prestigious journals such as Technometrics, IISE Transactionsand ACM Transactions, including one Best Paper Finalist and one BestStudent Paper Finalist at INFORMS QSR section and two featured articles atISE Magazine.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 459
    },
    {
        "text": "An open-sourcepackage developed by his group, namely AutoKeras,has become the most used automated deep learningsystem on Github (with over 8,000 stars and 1,000forks).",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 460
    },
    {
        "text": "GDP degenerates intoweighted demographic parity for the categorical sensitiveattribute.• Fairness through Unawareness (FTU) [83] defines analgorithm as FTU fair as long as sensitive attributes arenot used by the decision-making algorithm f(·):P(ŷ | x, z) = P(ŷ | x) (5)FTU will fail even if no sensitive attributes are present inthe data, if a combination of non-sensitive features canact as a proxy for them.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 461
    },
    {
        "text": "Also, his work on deep collaborative filter-ing, anomaly detection and knowledge graphs havebeen included in the TensorFlow package, Apple16 JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 462
    },
    {
        "text": "0, MONTH 2020production system and Bing production system, respectively.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 463
    },
    {
        "text": "He was the conference General Co-Chair for WSDM2020.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 464
    },
    {
        "text": "The intuition of counterfactual fairness is that afair algorithm should provide the same decision for areal-world individual and its corresponding one in thecounterfactual world:P[ŷ{z←a} = c | x, z = a]= P[ŷ{z←b} = c | x, z = a](7)Achieving consensus on causal graphs is challengingdue to the complexity of causal structure discovery,4 JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 465
    },
    {
        "text": "0, MONTH 2020'DWD&ROOHFWLRQ 0RGHO'HYHORSPHQW 0RGHO'HSOR\\PHQW0LVVLQJGDWDELDV,QWHUDFWLRQELDV)HDWXUHV /DEHOV7UDLQLQJ'DWD &OLQLFDO'DWD7UDLQLQJ±VHUYLQJVNHZELDV0LQRULW\\ELDV$OJRULWKPELDV/DEHOELDVD E F'HPRJUDSKLF*URXS 'HPRJUDSKLF*URXSFig.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 466
    },
    {
        "text": "Label bias occurs when the quality of labels varies between different demographicgroups.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 467
    },
    {
        "text": "Training-serving skew bias occurs when the distribution of data in thedeployment stage differs from the distribution of data in the training phase.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 468
    },
    {
        "text": "Please refer to section IV for further details.TABLE IMAIN SYMBOLS AND DEFINITIONS.Symbol Definitionf(·) A machine learning model that maps attributes to predictions.x ∈ Rdx The non-sensitive attributes with a dimension of dx.z ∈ Rdz The sensitive attribute.z The sensitive attribute when dz = 1.ŷ ∈ {0, 1} A binary prediction that indicates negative and positive outcomes for 0 and 1, respectively.y ∈ {0, 1} A binary ground truth that indicates negative and positive outcomes for 0 and 1, respectively.ŷ{z←a} A prediction in the counterfactual world if z = a.D The training dataset.d(·, ·) Distance of two individuals in the attribute space.D(·, ·) Distance of two individuals in the prediction space.θ Parameters θ of the backbone network.ϕ Parameters ϕ of the adversarial network.Aϕ(·) Adversarial network with parameters ϕL(D; θ) The downstream task loss.Ladv(D;ϕ) The adversarial loss.particularly without existing knowledge of causality.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 469
    },
    {
        "text": "Thiscomplexity can lead to the incorrect assumption of causalstructures from statistical model outputs, resulting invarying interpretations and difficulty in standardizingcausal graphs [121].B.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 470
    },
    {
        "text": "Equal PerformanceEqual performance means that a model is guaranteed to beequally accurate for patients in protected and non-protectedgroups.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 471
    },
    {
        "text": "The concept of accuracy can include equal sensitivity(also called equal opportunity [140]), equalized odds, andequal positive predictive value [36], or broader metrics suchas AUC, etc.",
        "paperTitle": "Fair Machine Learning in Healthcare: A Review",
        "doi": "10.48550/arXiv.2206.14397",
        "chunk_index_in_doc": 472
    },
    {
        "text": "Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication. Content may change prior to final publication.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 0
    },
    {
        "text": "This work is licensed under a Creative Commons Attribution 4.0 License. forThis work is licensed under a Creative Commons Attribution 4.0 License. 1282–1291,2007.This work is licensed under a Creative Commons Attribution 4.0 License. 31 314–31 338, 2015.This work is licensed under a Creative Commons Attribution 4.0 License. 129–133.This work is licensed under a Creative Commons Attribution 4.0 License. 338–340, 2011.This work is licensed under a Creative Commons Attribution 4.0 License. 156 694–156 706,2019.This work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 1
    },
    {
        "text": "ACM, 2016, pp. ACM, 2015, pp. ACM, 2017, pp. ACM, 2019, pp. ACM, 2017, pp. ACM, 2016, pp. ACM, 2017,pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 2
    },
    {
        "text": "2, no. 1, no. 1,no. 1. 1, no. 1, no. 1, no. 2, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 3
    },
    {
        "text": "4, p. 93, 2017. 7639, p. 115, 2017. 3, p. 15, 2009. 9, p. 1581, 2019. 63, pp.700–709, 2017. 7587, p. 484, 2016. 6, p. 395, 2012. 1, p. e30412, 2012. 11, p.226, 2018. 2, pp.72–82, 2008. 3, p. 034003, 2014. 3, p. 91, 2017. 4, p. e0174944, 2017. 01, p. 1, 2017. 2, p.117693510600200030, 2006. 11, p. e0207192, 2018. 1, p. 12, 2018. 2, pp.49–58, 2019. 12, p.245, 2018. 1, p. 20, 2019. 2, p. e19, 2018. 3, pp.4307–4316, 2018. 100, p. 120, 2017. 2, pp.330–333, 2015. 83, pp.70–86, 2019. 4, pp.731–740, 2016.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 4
    },
    {
        "text": "Springer,2015, pp. Springer, 2017, pp. Springer, 2018, pp. Springer, 2020, pp. Springer, 2019, pp. Springer, 2017, pp. Springer, 2018, pp. Springer,2018, pp. Springer, 2013, pp. Springer, 2015, pp. Springer, 2019, pp. Springer,2017, pp. Springer, 2018, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 5
    },
    {
        "text": "9, no. 7, no. 8, no. 9, no. 7, no. 9,no. 6, no. 6, no. 6, no. 10, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 6
    },
    {
        "text": "13, no. 15, no. 12, no. 13, no. 12,no. 13, no. 13, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 7
    },
    {
        "text": "318, no. 316, no. 542, no. 363, no. 189, no. 287, no. 306, no. 174, no. 139, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 8
    },
    {
        "text": "35, no. 35, no. 41, no. 42, no. 35, no. 36,no. 35, no. 40, no. 42, no. 37, no. 38, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 9
    },
    {
        "text": "1332–1343, 2016. 1207–1216, 2016. 1236–1246, 2017. 1287–1289, 2019. 1196–1206,2016. 1195–1200. 1352–1363, 2016. 1668–1675, 2014. 1322–1333. 1427–1432, 2018. 1333–1345, 2017. 1175–1191. 1211–1228. 1337–1340, 2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 10
    },
    {
        "text": "25, no. 25, no. 25, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 11
    },
    {
        "text": "For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. For more information, see https://creativecommons.org/licenses/by/4.0/.This article has been accepted for publication in a future issue of this journal, but has not been fully edited.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 12
    },
    {
        "text": "19, no. 17, no. 19,no. 17, no. 21, no. 23, no. 20, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 13
    },
    {
        "text": "18–31, 2017. 1–15, 2019. 8–20, 2017. 1–3, 2019. 1–11, 2019. 1––17, 2019. 10,2019. 82–90,2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 14
    },
    {
        "text": "35–51. 19–35. 19–38.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 15
    },
    {
        "text": "137–141. 144–151. 192–197.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 16
    },
    {
        "text": "158, pp. 194, pp. 112, pp. 139, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 17
    },
    {
        "text": "14, pp. 12, pp. 12, pp. 12, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 18
    },
    {
        "text": "99–124, 2016. 98–111. 94–103. 97–117. 99–112.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 19
    },
    {
        "text": "588–599. 647–658. 499–510, 2017. 2402–2410, 2016. 259–273, 2019. 450–472. 673–681. 565–571. 2524–2535, 2017. 378–396, 2017. 221–248, 2017. 457–466. 372–387. 506–519. 387–402. 49 135–49 149, 2019. 354–367. 114–127, 2019. 593–599. 619–636. 582–597. 453–464. 446–454. 516–524. 2572–2581, 2018.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 20
    },
    {
        "text": "2, pp. 2, pp. 2, pp. 2, pp. 2, pp. 2,pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 21
    },
    {
        "text": "3,pp. 3, pp. 3, pp. 3, pp. 3, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 22
    },
    {
        "text": "IEEE, 2018, pp. IEEE, 2018, pp. IEEE,2018, pp. IEEE, 2019, pp. IEEE, 2017, pp. IEEE, 2018, pp. IEEE, 2017, pp. IEEE, 2019, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 23
    },
    {
        "text": "5, pp. 5, pp. 5, pp. 5, pp. 5, pp. 5, pp. 5, pp. 5, pp. 5, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 24
    },
    {
        "text": "7, pp. 7, pp. 7, pp. 7, pp. 7,pp. 7, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 25
    },
    {
        "text": "6, pp. 6, pp. 6, pp. 6, pp. 6, pp. 6, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 26
    },
    {
        "text": "IEEE, 2016, pp. IEEE, 2016, pp. IEEE, 2016,pp. IEEE, 2016,pp. IEEE, 2016, pp. IEEE, 2016,pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 27
    },
    {
        "text": "400–407, 2017.Adnan Qayyum is currently working towards Ph.D.in Computer Science at the Information Technol-ogy University (ITU) Punjab, Pakistan. His researchinterests include healthcare, deep/machine learning,and security of machine learning. He received theBachelor’s degree in Electrical (Computer) Engi-neering from COMSATS Institute of InformationTechnology, Wah, Pakistan, in 2014 and M.S. de-gree in Computer Engineering (Signal and ImageProcessing) from the University of Engineering andTechnology, Taxila, Pakistan, in 2016.Junaid Qadir is the director of the IHSAN—ICTD;Human Development; Systems; Big Data Analytics;Networks—Research Lab and the Chairperson ofthe Electrical Engineering Department at the Infor-mation Technology University (ITU) of Punjab inLahore, Pakistan. His primary research interests arein the areas of computer systems and networking,applied machine learning, using ICT for develop-ment (ICT4D); and engineering education. He holds a PhD inBig Data Analytics from UWE, Bristol. Duringhis PhD, he developed a simulation platform forUK largest construction firm (Balfour Beatty) inwhich hybrid AI models (i.e. Dr Bilal has multi-disciplinary research interests that spanacross fields of Construction Informatics, Digital Health, Image Processing,Scientific Visualisation, AI, Computer Vision, Natural Language Processing,Geospatial Analysis Mining and Web-of-Data technologies. He is currently a professor at theInformation and Computing Technology division,college of Science and Engineering, Hamad BinKhalifa University (HBKU). He is a senior member of the IEEEand an ABET Program Evaluator (PEV). He serves on editorial boards ofmultiple journals including IEEE Communications Letter and IEEE NetworkMagazine.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 28
    },
    {
        "text": "Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering1Secure and Robust Machine Learning forHealthcare: A SurveyAdnan Qayyum1, Junaid Qadir1, Muhammad Bilal2, and Ala Al-Fuqaha3∗1 Information Technology University (ITU), Punjab, Lahore, Pakistan2 University of the West England (UWE), Bristol, United Kingdom3 Hamad Bin Khalifa University (HBKU), Doha, QatarAbstract— Recent years have witnessed widespread adoptionof machine learning (ML)/deep learning (DL) techniques due totheir superior performance for a variety of healthcare applica-tions ranging from the prediction of cardiac arrest from one-dimensional heart signals to computer-aided diagnosis (CADx)using multi-dimensional medical images. Notwithstanding theimpressive performance of ML/DL, there are still lingeringdoubts regarding the robustness of ML/DL in healthcare settings(which is traditionally considered quite challenging due to themyriad security and privacy issues involved), especially in lightof recent results that have shown that ML/DL are vulnerableto adversarial attacks. In this paper, we present an overviewof various application areas in healthcare that leverage suchtechniques from security and privacy point of view and presentassociated challenges. In addition, we present potential methodsto ensure secure and privacy-preserving ML for healthcareapplications. INTRODUCTIONWe are living in the age of algorithms, in which machinelearning (ML)/deep learning (DL) systems have transformedmultiple industries such as manufacturing, transportation, andgovernance. Due tothe extensive deployment of ML/DL algorithms in variousdomains (e.g., social media), such technology has becomeinseparable from our routine life. ML/DL algorithms arenow beginning to influence healthcare as well—a field thathas traditionally been impervious to large-scale technologicaldisruptions [1]. ML/DL techniques have shown outstandingresults recently in versatile tasks such as recognition of bodyorgans from medical images [2], classification of interstitiallung diseases [3], detection of lungs nodules [4], medicalimage reconstruction [5], [6], and brain tumor segmentation[7], to name a few.It is highly expected that intelligent software will assistradiologists and physicians in examining patients in the nearfuture [8] and ML will revolutionize the medical research andpractice [9]. Clinical medicine has emerged as a exciting appli-cation area for ML/DL models, and these models have alreadyachieved human-level performance in clinical pathology [10],radiology [11], ophthalmology [12], and dermatology [13].Email:aalfuqaha@hbku.edu.qaSome of these studies have even reported that DL modelsoutperform human physicians on average. The aspect of betterperformance of DL models in comparison with humans has ledto the development of computer-aided diagnosis systems—forinstance, the U.S. Food and Drug Administration (FDA) in2018 has announced the approval of an intelligent diagnosissystem to detect certain diabetes-related eye problems frommedical images that will not require any human intervention.1The potential of ML models for healthcare applications isalso benefitting from the progress in concomitantly-advancingtechnologies like cloud/edge computing, mobile communi-cation, and big data technology [14]. Together with thesetechnologies, ML/DL is capable of producing highly accuratepredictive outcomes and can facilitate the human-centered in-telligent solutions [15]. Along with other benefits like enablingremote healthcare services for rural and low-income zones,these technologies can play a vital role in revitalizing thehealthcare industry.Notwithstanding the impressive performance of DL algo-rithms, many recent studies have raised concerns about thesecurity and robustness of ML models—for instance, Szegedyet al. demonstrated for the first time that DL models are strictlyvulnerable to carefully crafted adversarial examples [20].Similarly, various types of data and model poisoning attackshave been proposed against DL systems [21] and differentdefenses against such strategies have been proposed in theliterature [19]. However, the robustness of defense methodsis also questionable and different studies have shown thatmost of the defense techniques fail against a particular attack.The discovery of the fact that DL models are neither securenor robust hinders significantly their practical deployment insecurity-critical applications like predictive healthcare which isessentially life-critical. For instance, researchers have alreadydemonstrated the threat of adversarial attacks on ML-basedmedical systems [22], [17]. Therefore, ensuring the integrityand security of DL models and health data are paramount tothe widespread adoption of ML/DL in the industry.Before moving further, we will elaborate upon the two keyterms on which this survey is focused—namely, security androbustness—particularly in the context of ML/DL models.Security is concerned with the possible threats/attacks thatcan be realized on an ML/DL system influencing it to get1https://tinyurl.com/FDA-AI-diabetic-eyeThis work is licensed under a Creative Commons Attribution 4.0 License. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering2TABLE I: Comparison of this paper with existing review and survey papers on secure, private, robust ML/DL for healthcareapplications. (Covered:√; Not covered: ×; Partially covered: ≈)Year Authors Highlights TypeApplicationsof ML inHealthcareConventionalChallengesPrivacyChallengesAdversarialMLSecure &PrivateML MethodsSolutions forAdversarialML AttacksOpenResearchIssues2017 Miotto etal. [16]Presented a review of DL applica-tions in healthcare and the chal-lenges and imitations in terms ofease-of-understanding of outcomesto human experts.Review ≈ √ ≈ × × × ×2018 Papangelouet al. [17]Provided an understanding of ad-versarial examples in clinical ap-plications and introduced the con-cept of adversarial patients in thecontext of counterfactual models inclinical trials.PositionPaper× × × √ × × √2019 Kim et al. [18]Provided a review of different ad-versarial attacks and defenses withtheir applications in ML basedmedical image analysis.Review ≈ × × √ × √ ×2019 Yuan et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 29
    },
    {
        "text": "[19]Provides an overview of literatureon adversarial attacks and defensesin general.Survey × × × √ × √ ×2020 Our Paper Presents a comprehensive survey ofvarious security challenges associ-ated with the application of ML/DLin healthcare systems and outlinesrobust solutions.Survey√ √ √ √ √ √ √intended behavior or outcome, whereas robustness defines thecapability of the ML/DL system to survive under such attacks.Security is analyzed along two dimensions: (a) the attacks onML/DL systems attempting to get the control of the systemor to get the intended behavior/outcome; (b) the attacks tryingto learn about the training data, i.e., privacy attacks. On theother hand, robustness is also analyzed along two axes: (a)the survivability of ML/DL systems under attacks attemptingto influence them (i.e., robustness to attacks like adversarialML attacks); (b) the resistance to privacy attacks. Note thatthe robustness is a relative term and the effectiveness of thesystem varies according to the nature of the attack, i.e., anML/DL system might be robust under a particular attack butvulnerable to a different attack.In this paper, we present a comprehensive survey of existingliterature on the security and robustness of ML/DL modelswhen used for building healthcare systems with a specificfocus on the above-mentioned dimensions. We note here thatthe aim of this paper is to provide an in-depth survey ofvarious security challenges associated with the application ofML/DL in healthcare systems and to provide a taxonomyof potential solutions to overcome these issues. Along withdiscussing security and robustness challenges of using ML/DLmodels, we also briefly elaborate on various general challengesand sources of vulnerabilities that hinder the safe and robustapplication of ML/DL in healthcare applications. In addition,potential solutions to address security, privacy, and robustnesschallenges are presented in this paper. In summary, the fol-lowing are the specific contributions of this paper.1) We present an overview of diverse literature on ap-plications of ML/DL techniques by categorizing it tofour major tasks in healthcare, i.e., prognosis, diagnosis,treatment, and clinical workflow.2) We formulate the ML pipeline for data-driven healthcareapplications and describe different sources of vulnera-bilities at each stage that raises security and robustnesschallenges.3) We present an overview of various security and robust-ness challenges associated with the adoption of ML/DLmodels for healthcare applications.4) We present a taxonomy of different solutions that canbe used for ensuring secure and robust application ofML/DL techniques for healthcare applications.5) Finally, we highlight various open research issues thatrequire further investigation.A comparison of this paper with existing surveys and reviewpapers on the security of ML/DL models in healthcare systemsis also presented in Table I.Organization of the Paper: The rest of the paper is organizedas follows. In Section II, various applications of ML and DLtechniques in healthcare are discussed. Section III presents theML pipeline in data-driven healthcare and various sources ofvulnerabilities along with different challenges associated withthe use of ML. Different potential solutions to ensure secureand privacy-preserving ML are discussed in Section IV andvarious open research issues are outlined in Section V. Finally,we conclude the paper in Section VI.II. ML FOR HEALTHCARE: APPLICATIONSIn this section, various prominent applications of ML inhealthcare are discussed.A. ML in Healthcare: The Big PictureThe major phases for developing a ML-based healthcaresystem are illustrated in Figure 1 and major types of ML/DLthat can be used in healthcare applications are briefly describednext.1) Unsupervised Learning: The ML techniques utilizingunlabelled data are known as unsupervised learning methods.Widely used examples of unsupervised learning methods area clustering of data points using a similarity metric anddimensionality reduction to project high dimensional data tolower-dimensional subspaces (sometimes also referred to asfeature selection). Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering3Fig. 1: The illustration of major phases for development of machine learning (ML) based healthcare systems.used for anomaly detection, e.g., clustering [23]. Classicalexamples of unsupervised learning methods in healthcareinclude the prediction of heart diseases using clustering [24]and prediction of hepatitis disease using principal componentanalysis (PCA) which is a dimensionality reduction technique[25].2) Supervised Learning: Such methods that build or mapthe association between the inputs and outputs using labeledtraining data are characterized as supervised learning methods.If the output is discrete then the task is called classificationand for a continuous value output, the task is called regres-sion. Classical examples of supervised learning methods inhealthcare include the classification of different types of lungdiseases (nodules) [4] and recognition of different body organsfrom medical images [2]. A systematic review of supervised and unsupervisedlearning techniques can be found in [26].3) Semi-supervised Learning: Semi-supervised learningmethods are useful when both labelled and unlabelled samplesare available for training, typically, a small amount of labelleddata and a large amount of unlabelled data. Semi-supervisedlearning techniques can be particularly useful for a varietyof healthcare applications as acquiring a sufficient amountof labelled data for model training is difficult in healthcare.Different facets of semi-supervised learning using differentlearning techniques have been proposed in the literature. Forinstance, a semi-supervised clustering method for healthcaredata is presented in [27] and a semi-supervised ML approachfor activity recognition using sensors data is presented in[28].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 30
    },
    {
        "text": "In [29], [30], authors applied a semi-supervised learningmethod to medical image segmentation.4) Reinforcement Learning: Methods that learn a policyfunction given a set of observations, actions, and rewards inresponse to actions performed over time fall in the class ofreinforcement learning (RL) [31]. RL has a great potentialto transform many healthcare applications and recently, it hasbeen used for context-aware symptoms checking for diseasediagnosis [32]. Furthermore, the potential of using RL forhealthcare applications can be seen through the recent exampleof the Go game, where a computer using RL with theintegration of supervised and unsupervised learning methodsdefeated a human champion player [33].B. Applications of ML in HealthcareHealthcare service providers generate a large amount ofheterogeneous data and information daily, making it difficultfor the “traditional methods” to analyze and process it. In addition, there are heterogeneous sources of datathat can augment healthcare data such as genomics, medicaldata, data from social media, and environmental data, etc. Thefour major applications of healthcare that can benefit fromML/DL techniques are prognosis, diagnosis, treatment, andclinical workflow, which are described next.1) Applications of ML in Prognosis: Prognosis is the pro-cess of predicting the expected development of a disease inclinical practice. It also includes identification of symptomsand signs related to a specific disease and whether they willbecome worse, improve, or remain stable over time and identi-fication of potential associated health problems, complications,ability to perform routine activities, and the likelihood ofsurvival. As in clinical setting, multi-modal patients’ datais collected, e.g., phenotypic, genomic, proteomic, pathologytests results, and medical images, etc., which can empowerthe ML models to facilitate disease prognosis, diagnosis andtreatment [34]. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering4Fig. 2: Illustration of heterogeneous sources contributing tohealthcare data.types of cancers, e.g., brain tumor [35] and lung nodules [36].However, the potential applications ML for disease progno-sis, i.e., prediction of disease symptoms, risks, survivability,and recurrence have been exploited under recent translationalresearch efforts that aim to enable personalized medicine.However, the field of personalized medicine is nascent thatrequires extensive development of adjacent fields like bioinfor-matics, strong validation strategies, and demonstrably robustapplications of ML thus to achieve the huge and translationalimpact.2) Applications of ML in Diagnosis:a) Electronic Health Records (EHRs): Hospitals andother healthcare service providers are producing a large col-lection of electronic health records (EHRs) on a daily basisand comprise of structured and unstructured data that containsa complete medication history of patients. ML-based methodshave been utilized for the extraction of clinical features forfacilitating the diagnosis process [37]. For example, a semi-supervised approach for the extraction of diagnosis informa-tion from unstructured EHRs is presented in [38]. The useof ML for the diagnosis of diabetes from EHRs is presentedin [39]. In [40], features robustness using EHRs data for theyear of care for each record is examined for two tasks, i.e.,mortality prediction and length-of-stay and authors showedthat prediction performance gets degraded when ML modelsare trained on historical data and tested on unseen (future)data.b) ML in Medical Image Analysis: In medical imageanalysis, ML techniques are used for efficient and effective ex-traction of information from medical images that are acquiredusing different imaging modalities such as magnetic resonanceimaging (MRI), computed tomography (CT), ultrasound, andpositron emission tomography (PET), etc. A taxonomyof key medical imaging modalities is presented in Figure3. The key purpose of medical image analysis is to assistclinicians and radiologists for efficient diagnosis and prognosisof the diseases. The prominent tasks in medical image analysisinclude detection, classification, segmentation, retrieval, recon-struction, and image registration which are discussed next.Moreover, fully automated intelligent medical image diagnosissystems are expected to be part of next-generation healthcaresystems.• Enhancement: Enhancement of degraded medical imagesis an important pre-processing step that directly effectsthe diagnosis process. There are many sources of noiseand disturbances encountered in the medical image acqui-sition process which degrade the quality and significanceof the resultant images. Becausemovements can cause false artifacts in image acquisi-tion, the complete process has to be repeated usuallymultiple times to produce significantly useful images.Also, depending on the body area being scanned and thenumber of images to be taken, patients might be askedto hold their breath during short scans [42]. Inthe literature, different DL models are used for denoisingmedical images such as convolutional denoising autoen-coders [43] and GANs. In addition, GANs have beensuccessfully used for cleaning motion artifacts introducedin multi-shot MRI images [14]. Whereas, DL based methods have shown theirpotential for this task and various studies have beenpresented in the literature for the detection of diseases.For instance, a locality-sensitive approach utilizing CNNfor the detection and classification of nuclei colon cancerin histopathological images is presented in [45]. A hybridmethod utilizing handcrafted features and a CNN modelfor the detection of mitosis in breast cancer images ispresented in [46].• Classification DL models in particular, convolutionalneural networks (CNNs) have proven to give high per-formance in medical image classification tasks whencompared with other state-of-the-art non-learning basedtechniques. Modality classification, recognizing differentbody organs, and abnormalities from medical imagesThis work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 31
    },
    {
        "text": "Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering5Fig. 3: A typology of commonly used medical imaging modalities (adapted from [41]).using CNNs have been extensively studied in the liter-ature. In [2], an approach using CNN for multi-instancerecognition of different body organs is presented and aCNN based method for classification of interstitial lungdiseases (ILDs) is presented in [3]. In another study,a CNN model is trained for the classification of lungnodules [4].Transfer learning approaches have also been used formedical image classification [47]. In transfer learning,a pre-trained DL model (typically trained on naturalimages) is fine-tuned on a comparatively small dataset ofmedical images. For instance,results obtained by transfer learning in [48] and [49] arecontradictory.• Segmentation: The segmentation of tissues and organsin medical images enables quantitative analysis of ab-normalities in terms of clinical parameters, e.g., auto-matically measuring the volume and shape of cancer inbrain images. In addition, the extraction of such clinicallysignificant features is an important and foremost step incomputer-aided detection and diagnosis systems that wediscuss later in this section. Addressingthe problem of segmentation utilizing various DL models(e.g, CNN and recurrent neural network (RNN) [50]) iswidely studied in the literature and the common archi-tecture used for segmentation of medical images is U-net[51]. as well as segmentationof volumetric images [52]. An overview of various DLmodels for segmentation of medical images is presentedin [53].• Reconstruction: The process of generating interpretableimages from raw data acquired from the imaging sensor isknown as medical image reconstruction. Thus in medical imagereconstruction, we aim to reduce image acquisition timeand storage space.Research on medical image reconstruction using deepmodels is drastically increasing and various DL modelssuch as CNNs [54] and autoencoders [6] have beenextensively used for the reconstruction of MRI andCT images. Recently, generative adversarial networks(GANs) have been widely used for the reconstruction ofmedical images and have produced outstanding results.For instance, a GAN based MRI reconstruction methodis presented in [55] that also cleans the motion artifacts.• Image Registration: Image registration is the process ofmapping input images with respect to a reference imageand it is the first step in image fusion. Image registrationhas many potential applications in medical image analysisas described in detail by El-Gamal et al. In [58],a framework for deformable image registration namedas Quicksilver is proposed that uses the large deforma-This work is licensed under a Creative Commons Attribution 4.0 License. Similarly, an unsupervisedlearning based methods for deformable image registrationis presented in . This trend is true formedical imaging as well, every hospital and clinic havingradiology services are producing thousands of medicalimages daily in diverse modalities, resulting in the growthof large-scale multi-modal medical image repositories.Thus making it difficult to manage and query suchhuge databases. In particular, it is more challenging formulti-modal medical data. To facilitate the productionand management of multi-modal medical data, traditionalmethods are not sufficient and various ML/DL techniquesare proposed in the literature [60], [61].In routine practice, clinicians usually compare the currentcases with the previous ones, mainly to effectively planthe diagnosis and treatment of the patient being examined.In this regard, identifying modality (i.e., modality classifi-cation discussed above) is of great significance as it servesas an initial tool to facilitate the process of comparisonand an efficient modality classification system will reducethe search space by only looking for relevant images inthe collections of the desired modality.3) Applications of ML in Treatment:a) Image Interpretation: As discussed above, medicalimages are widely used in the routine clinical practice andthe analysis and interpretation of these images are performedby expert physicians and radiologists. To narrate the findingsregarding images being studied, they write textual radiologyreports about each body organ that was examined in theconducted study. In [62], a naturallanguage processing based method is proposed for annotatingclinical radiology reports. A multi-task ML based frameworkis proposed for automatic tagging and description of medicalimages [63]. In a similar study [64], an end-to-end architecturedeveloped with the integration of CNN and RNN is presentedfor thorax disease classification and reporting in chest X-rays. Continuous health monitoring usingwearable devices, IoT sensors, and smartphones is gaininginterest among people. In a typical setting of continuous healthmonitoring, health data is collected using a wearable deviceand smartphone and then transmitted to the cloud for analysisusing an ML/DL technique. Simi-larly, a review of different ML techniques for human activityrecognition with application to remote monitoring of patientsusing wearable devices is presented in [67]. The sharing ofhealth data with clouds for further analysis raises many privacyand security challenges that we discuss in the next section.4) Applications of ML in Clinical Workflows:a) Disease Prediction and Diagnosis: The early predic-tion and diagnosis of diseases from medical data are oneof the exciting applications of ML. For instance, the case ofcardiovascular risk prediction using different ML algorithmswith clinical data is studied in [68] and the study concludedthat ML techniques improved the prediction efficacy. A surveyof various ML techniques for the detection and diagnosis ofdifferent diseases (such as diabetes, dengue, hepatitis, heart,and liver) is presented in [69].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 32
    },
    {
        "text": "The potential of using ML-based methods for prediction and prognosis of cancer ishighlighted in [70].b) ML in Computer-Aided Detection or Diagnosis: Thecomputer-aided detection (CADe) or computer-aided diagnosis(CADx) systems are being developed mainly for the auto-matic interpretation of medical images that would assist theradiologist in their clinical practice. However, anytask in medical image and signal analysis automated by theapplication of ML/DL models can be deemed as a CADe orCADx systems, e.g., automation detection of fatty liver inultrasound kurtosis imaging [71].c) Clinical Reinforcement Learning: In reinforcementlearning, the key objective is to learn a policy function formaking precise decisions in an uncertain environment tomaximise accumulated reward. The performance evaluationof different RL techniques (i.e., Q-value iteration, tabular Q-learning, fitted Q-iteration (FQI), and deep Q-learning) for thetreatment of sepsis in ICU using real-world medical datasetis presented in [73]. The dataset containstrajectories of a patient’s physiological state and the providedtreatments by clinicians at each time, along with the outcome(i.e., survival or mortality). Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering7Fig. 4: The pipeline for data-driven predictive clinical care and various sources of vulnerabilities at each stage.and tabular Q-learning can learn effective policies for sepsistreatment and their performance is comparable with a complexcontinuous state-space method, i.e., deep Q-learning.d) ML for Clinical Time-Series Data: One of the tasks inclinical workflows is the modeling of clinical time-series data.Applications of clinical time-series modeling include predic-tion of clinical interventions in intensive care units (ICUs)using CNN and LSTM [74], mortality prediction in patientswith traumatic brain injury (TBI) [75], and estimation of meanarterial blood pressure (ABP) and intracranial pressure (ICP)which are important indicators cerebrovascular autoregulation(CA) in TBI patients. In a similar study, the problem of unexpected respiratorydecompensation using ML techniques is investigated in [77].e) Clinical Natural Language Processing: Clinical notesare a widely used tool by the clinicians to communicate patientstate. The use of clinical text is crucial as it often containsthe most important information. The progress in clinical NLPtechniques is envisioned to be incorporated in future clinicalsoftware for extracting relevant information from unstructuredclinical notes for improving clinical practice and research[78]. Clinical NLP offers unique challenges such as the useof acronyms, language disparity, partial structure, and qualityvariance, etc. The challenges and opportunities of clinical NLPfor languages other than English along with a review of clinicalNLP techniques is presented in [79]. In [80], authors presenteda toolkit named CLAMP that provides different state of theart NLP techniques for clinical text analysis.f) Clinical Speech and Audio Processing: In the clinicalenvironment, clinicians have to do a lot of documentation, i.e.,preparing clinical notes, discharge summaries, and radiologyreports, etc. To overcome such challenges, clinicalspeech and audio processing offer new opportunities suchas speech interfaces for interaction less services, automatictranscription of patient conversations, and synthesis of clin-ical notes, etc. There are many benefits for using speechand audio processing tools in the clinical environment foreach stakeholder, i.e., patients (speech is a new modalityfor determining patient state), clinicians (efficiency and time-saving), and healthcare industry (enhance productivity andcost reduction). In clinical speech processing, disfluency and utterancesegmentation are two well-known challenges of clinical speechprocessing.III. SECURE, PRIVATE, AND ROBUST ML FORHEALTHCARE: CHALLENGESIn this section, we analyze the security and robustness ofML/DL models in healthcare settings and present variousassociated challenges.A. Sources of Vulnerabilities in ML PipelineML application in healthcare settings suffers from variousprivacy and security challenges that we will thoroughly discussin this section. In addition, the three major phases of MLmodel development along with different potential sources ofvulnerabilities causing such challenges in each step of the MLpipeline are depicted in Figure 4.1) Vulnerabilities in Data Collection: Training of ML/DLmodels for clinical decision support requires the collectionof a large amount of data (in formats such as EHRs, medicalimages, radiology reports, etc. Althoughin practice, medical data is carefully collected to ensure theeffectiveness of the diagnosis, however, there can be manysources of vulnerabilities that can affect the proper (expected)This work is licensed under a Creative Commons Attribution 4.0 License. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering8functionality of the underlying ML/DL systems, a few of themare described next.Instrumental and Environmental Noise: The collected dataoften contains many artifacts that arise due to instrumental andenvironmental disturbances. This modalityis highly sensitive to motion, and even slight movement of thesubject’s head or respiration can cause undesirable artifactsin the resultant image [14], thereby increasing the risk ofmisdiagnosis [85].Unqualified Personnel: Healthcare ecosystems are ex-tremely interdisciplinary and comprise of technical and non-technical personnel and often lack qualified workers that candevelop and maintain ML/DL systems. As for the efficientapplication of data-driven healthcare, workers with strongstatistical and computational backgrounds are required, e.g.,engineers and data scientists. On the contrary, the clinicalusability of ML/DL based systems is extremely important.Considering this aspect, hospitals tend to rely solely onphysician-researchers who lack computational expertise todevelop such systems [86].2) Vulnerabilities Due to Data Annotation: Most applica-tions of ML/DL in healthcare systems are supervised ML taskswhich require an abundance of labelled training data.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 33
    },
    {
        "text": "Ideally, this task shallmostly be performed by experienced clinicians (physiciansor radiologists) to prepare domain-enriched datasets whichare crucial to the development of useful ML/DL models inhealthcare systems. The literature has revealed that trainingML/DL models without a sound grip of the domain couldbe disastrous [87]. Some specific data annotation-based vulnerabilities are discussed as below:Ambiguous Ground Truth: In medical datasets, the groundtruth is often ambiguous, e.g., medical image classificationtask [22] and even expert clinicians disagree on well-defineddiagnostic tasks [88]. This problem becomes more adversewith the presence of malicious users who want to perturbdata, making the diagnosis difficult and causing difficultiesin detecting its influence even with a human expert review.Improper Annotation: The annotation of data samples pro-cess for life-critical healthcare applications should be informedby proper guidelines and various privacy and legal considera-tions [89]. Most widely used healthcare datasets are annotatedfor coarse-grained labels whereas real-life utility of ML/DLis to highlight rare, fine-grained and hidden strata withinthe clinical environment. This inability to perform labellingappropriately can lead to various efficiency challenges that arediscussed next.Efficiency Challenges: The collections of healthcare dataon which ML/DL models are built suffer from various issuesthat arise several efficiency challenges. In particular, one major limitation of the efficientapplication of DL approaches in healthcare is the unavail-ability of large-scale datasets, as health data is often smallin size. Therefore, most ML/DL algorithmscan not be efficiently trained and optimized for such life-threatening healthcare task. (b) Data Augmentation: To circumvent the problem of avail-ability of large scale medical datasets, one commonlyfollowed method is data augmentation in which vari-ous techniques (such as cropping, filliping, rotation, andtranslation, etc.) However, the use of data augmentation might reducethe robustness of the developed ML/DL based system,for example, it is highly likely that the distribution oftransformed data diverges from the underlying actual dis-tribution of the training data which is unknown generallyand there are no statistical and probabilistical guaranteesfor having same distribution of the training data. Theliterature suggest that Guassain data augmentation doesnot improves the adversarial robustness of the modelsagainst iterative attacks [92]. If a class imbalanced dataset is used fortraining of the model then it will be reflected in themodel’s outcomes in terms of bias to certain categories.Biases in models’ predictions in healthcare settings willhave profound consequences and should, therefore, bemitigated. Missing val-ues and observations significantly affect the performanceof ML/DL techniques.3) Vulnerabilities in Model Training: The vulnerabilitiesregarding model training include improper or incomplete train-ing, privacy breaches, model poisoning and stealing. Moreover, ML/DL models have been foundstrictly vulnerable to various security and privacy threats suchas adversarial attacks [20], model [93] and data poisoningattacks [94], etc. The vulnerabilities of ML/DL systems hindertheir efficient deployment for security-critical applications(such as digital forensic, bio-metrics, etc.) Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering9critical applications (such as self-driving cars and healthcare,etc.). Various security threats associated with ML/DLsystems are thoroughly described in the next section.4) Vulnerabilities in Deployment Phase: The deploymentof ML/DL techniques in a clinical environment essentiallyinvolves human-centric decisions. In such settings, the per-formance of the underlying DL model degrades significantly.Moreover, in predictive healthcare, ML models are developedusing historical patient data and are usually tested on the newpatients which raise questions about the efficacy of the MLpredictions. Moreover, such differences can be exploited forgenerating adversarial examples [95].Incomplete Data: In realistic settings, data collected forproviding patient care may contain missing observations orvariables, e.g., EHRs. Both problems can havesevere outcomes in actual healthcare settings, therefore, thehealthcare data should be complete and compact in all aspectsto ensure accurate predictions of outcomes.5) Vulnerabilities in Testing Phase: Vulnerabilities in thetesting phase are concerned with the interpretation of theresults from the underlying ML/DL systems that includemisinterpretation, false positive, and false-negative outcomes.False-positive and false-negative outcomes are due to incom-plete/inefficient training of the model or due to incompletedata fed for the inference that we have discussed in the earliersection. Finally, the true essence of ML empowered healthcareis not just about turning a crank but it demands the cautiousapplication of analytical methods [96].B. The Security of ML: An OverviewIn this section, we provide an overview of ML securityparticularly from the perspective of healthcare and highlightvarious associated security challenges with the use of ML.1) Security Threats: The security threats on ML systemscan be broadly categorized into three dimensions, i.e., influ-ence attacks, security violations, and attack specificity [97]. Ataxonomy of these security threats on ML systems is depictedin Figure 5.Fig. 5: A taxonomy of different security threats on ML/DLmodels. (a) Influence: Influence attacks can be of two types: (1)causative: the one that attempts to get control overtraining data; (2) exploratory: the one that exploits themiss-classification of the ML model without interveningthe model training.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 34
    },
    {
        "text": "(b) Security Violation: It is concerned with the availabilityand integrity of the services and can be categorized intothree types: (1) integrity attack: It attempts to increasethe false-negative rate of the deployed model (classifier)when the model is given harmful inputs; (2) availabilityattack: Unlike integrity attack, it tries to achieve anincrease in the false-positive rate of the classifier in re-sponse to benign inputs; (3) privacy violation attack: It isconcerned with the unveiling of sensitive and confidentialinformation of the training data, trained model or both. (c) Attack Specificity: The specificity of an attack can bedefined in two ways: (1) targeted attack: whether theattack is intended for a specific input sample or a groupof samples; (2) indiscriminate attack: it causes the MLmodel to fail indiscriminately.The first axis in the taxonomy of the attacks on ML/DLsystems (as shown in Figure 5) defines the capabilities of theadversaries, e.g., whether they are able to modify trainingprocess by injecting poisoned data or not (i.e., attemptingaccess to training data). The second dimensionof attacks is concerned with the type of security violationsthat an adversary can perform, e.g., trying to learn about theprivacy of users in training data or attempting to increase thefalse-negative or false-positive rate of the classifier. Each typeof security violation is severely problematic for healthcareapplications, i.e., preserving the privacy of users is a matterof high concern, and models with minimum uncertainty arehighly desirable. The attacker might be interestedin attempting a targeted attack, e.g., forcing the classifier toclassify a given input sample to a target class (e.g., bypassingThis work is licensed under a Creative Commons Attribution 4.0 License. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering10disease detection system by influencing the detector to identifythe input as benign), or, he might intend to break down theclassifier in an indiscriminate manner.2) Adversarial Machine Learning (ML): Adversarial at-tacks are the result of recent efforts for identifying vulner-abilities in ML/DL models training and inference. Adversarialattacks have appeared as one of the biggest security threats toML/DL systems [20], [98], [99], [100], [101]. In adversarialattacks, the key goal of an adversary is to generate adversarialexamples by adding small carefully crafted (unnoticeable)perturbation into the actual (non-modified) input samples toevade the integrity of the ML/DL system. In general, thereare two types of adversarial attacks that are described next. (a) Poisoning Attacks: Adversarial attacks affecting themodel training, i.e., manipulating the training data tomislead the learning of ML/DL model are known aspoisoning attacks [93]. (b) Evasion Attacks: Adversarial attacks on the inferencephase of the training process are known as evasionattacks [102]. In such attacks, an attacker manipulatesthe test data to compromise the integrity of the ML/DLmodel to harmful inputs.In healthcare applications, poisoning attacks are highlyrelevant because direct manipulation of the training data maybe difficult or even impossible in some cases. Therefore, the detection of poisoning attacksis critical for the robust application of ML/DL in healthcareapplications. For instance, systematic poisoning attacks againstsix conventional ML models that were developed for hypothy-roid diagnosis are presented in [103], where the objective ofthe attacker was to prevent hypothyroid diagnosis.Similarly, a few researchers have highlighted the threatof these attacks to ML/DL models in healthcare settingsand we provide insights from such articles in this section.Unlike adversarial examples created for evading ML/DL mod-els in other settings, the concept of adversarial patients forhealthcare applications is introduced in [17]. The authorsargue that rather than intentional adversarial examples, thecaution should be for unintentional adversarial patients thatcan lead to severe ethical issues. In recent studies, white box andblack box adversarial attacks have been demonstrated againstthree clinical applications; namely, fundoscopy, dermoscopy,and chest X-ray analysis [22], [104]. Furthermore, in [104],authors highlighted various potential incentives for adversariesvia adversarial attacks in clinical trials that will rise withthe increasing use of ML in the future, particularly, with theemergence of computer-aided diagnosis and decision supportsystems.Adversarial ML is a major dilemma for the security andprivacy of ML/DL models deployed in healthcare biometricsapplications and can lead to sever unintended circumstances.Biometrics can provide many advantages, e.g., fraud detec-tion, protection of confidential medical records, and securingmedical facilities and equipment, etc. In this regard, differentbiometrics technologies such as palm vein readers, fingerprint,ECG, and iris scanners [105], and face recognition have greatpotential to be deployed in healthcare systems. It is verycommon to use ML/DL techniques for building healthcarebiometric systems, which are themselves vulnerable to securityand privacy attacks [106], [107], [108]. ML for Healthcare: ChallengesIn this section, we discuss various challenges which hindersthe applicability of ML/DL systems in practical healthcareapplications.1) Safety Challenges: Excellent performance in a con-trolled lab environment (which is a common ML communitypractice) is not evidence of safety. Safety of ML/DL is thedetermination of how safe the ML/DL system is for patients.There should be a constant thought of safety throughout theML/DL lifecycle. Majority of routine clinicians tasks aremundane, and patients they encounter have common healthconditions.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 35
    },
    {
        "text": "EnablingML/DL to performing well on hidden strata, outliers, edge, andsubtle cases is key to ensure the safety of current AI systems.2) Privacy Challenges: Privacy is one of the major chal-lenges in data-driven healthcare which is concerned with theuse of users’ data by the ML/DL systems for making pre-dictions. The users (i.e., patients) expect that their healthcareservice providers are following necessary safety measures tosafeguard their inherent right to the privacy of their confiden-tial information, e.g., age, sex, date of birth, and health data.Potential privacy threats can be of two types, i.e., unveilingconfidential information and malicious use of data (potentiallyby unauthorized agents).Privacy depends upon the characteristics and nature of thedata being collected, the environment it has been created in,and patients’ demographics. Therefore, mitigation of privacybreaches using the appropriate technique(s) is critical as suchbreaches can directly harm the patients. The confidential datashould be anonymized to prevent privacy breaches such as (re-)identification of the individuals [109]. Moreover, necessaryattention should be paid to understand privacy concerns ateach stage of data processing and the transfer of data amongdifferent departments within a hospital should be communi-cated in a secure environment.Privacy challenges also arise with adoption of ML/DL tech-niques for building biometric healthcare systems either offline(e.g., face or fingerprint recognition based system to protectmedical facilities and equipment [110]) or online systems,e.g., real-time medical systems [111] and use of biometricsfor authentication of medical IoT devices [112], etc. Thesecurity and privacy of such systems are of utmost importance;therefore, worst-case robustness test should be performed forbiometrically secure healthcare systems. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering11systems robustness and can distinguish from a system thatnever fails and a system that fails once in billion trails.3) Ethical Challenges: In user-centric applications of MLsuch as healthcare, it is important to ensure the ethical useof data. Moreover, understand-ing how data collection can harm a patient’s well-being anddignity is an important consideration in this regard. Furthermore, toensure fair and ethical operation of automated systems, it isimperative to have a clear understanding of the AI system inuncertain and complex scenarios [113].4) Causality is Challenging: Understanding causality isimportant in healthcare because most of the crucial healthcareproblems require causal reasoning, i.e., “what if?” [114]. In healthcare, learning is often solely basedon observational data and asking causal questions by learningfrom observational data is quite challenging which requiresbuilding causal models.DL models are black-box which lacks fundamental under-lying theory and these models essentially work by exploitingpatterns and correlations without considering any causal link[116]. In predictivehealthcare, the absence of causal relation can raise questionsabout the conclusions that can be drawn from outcomes of DLmodels. Furthermore, fairness in decision making can betterbe enforced through the lens of causal reasoning [117], [118].The estimation of the causal effect of some variable(s) ona target output (e.g., target class in multi-class classificationproblem) is important to ensure fair predictions.5) Regulatory and Policy Challenges: The full potentialof ML/DL systems (which essentially constitutes software asa medical device) in actual healthcare settings can only berealized by addressing regulatory and policy challenges. Theliterature suggests that the regulatory guidelines are neededfor both medical ML/DL systems and their integration inactual clinical settings [131]. Therefore, the integration of AI-empowered ML/DL systems in the actual clinical environmentshould be in compliance with the policies and regulationsdefined by the government and regulatory agencies. However,existing regulations are not suitable for certifying systemswhich are ever-evolving such as ML/DL empowered systemsbecause yet another key challenge with the use of ML/DLalgorithms in clinical practice is to determine how thesemodels should be implemented and regulated since thesemodels will incorporate learning from the new patient data[132]. In addition, the objective clinical evaluation of ML/DLsystems for particular clinical settings is crucial to ensuresafe, effective, and robust operation that does not harm thepatients in either way. Data scientist and AI engineers shouldbe employed in hospitals for assessing AI systems regularlyto ensure it is still safe, relevant, and working fine.6) Availability of Good Quality Data: The availability ofrepresentative, diverse and high-quality data is one of themajor challenges in healthcare. For instance, the amountof data available to the research community is very smallin size and limited in scope as compared to the heteroge-neous collections of large-scale multi-modal patient data beinggenerated on daily basis by different small and large sizehealthcare institutions. However, the development of goodquality data that resembles real clinical settings is on theother very challenging and requires resources for managementand maintenance. The availability of high-quality data caneffectively serve the intended purpose of disease predictionand decision making for planning treatment.The data collected in practice suffer from different issuessuch as subjectivity, redundancy, and bias. As the ML/DLmodels perform inferences by solely learning the latent factorsof the data on which they are trained, therefore, the effect ofdata generated by the undesirable past practices of hospitalswill be reflected in the outcomes of the algorithm.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 36
    },
    {
        "text": "It has been shown that a model could depict racial biasby producing varying outcomes for different subpopulations[133] and the training data can also introduce its own modelingchallenges [134], [135].7) Lack of Data Standardization and Exchange: MedicalML/DL system shall facilitate a deep understanding of theunderlying healthcare task, which (in most cases) can only beachieved by utilising other forms of patients data. This calls for the integration and dataexchange between all healthcare systems. Despite extensiveresearch on data exchange standards for healthcare, there isa huge ignorance in following those standards in healthcareIT systems which broadly affects the quality and efficacy ofhealthcare data, accumulated through these systems. Thereare numerous guidelines to perform specific medical inter-ventions like imaging studies (i.e., with define exposure andpositioning) to ensure the significance of the data clinically.However, current healthcare IT systems largely ignore stan-dards and clinicians barely follow well-established guidelines.As a result, data integration and exchange efforts acrossdifferent specialities and organisations fail. Data integrationto match diverse patients’ medical records is crucial to deliverhigh-value patient care. The lack of appetite to implementdata exchange standards in wider healthcare industry hindersthe efficacy of ML/DL systems as multi-modal data is vitalto ensure the deep understanding of algorithms, and willundoubtedly enhance the performance of physicians towardsclinical decisions using data driven insights.8) Distribution Shifts: The problem of data distributionshifts is yet another major challenge and perhaps one of themost challenging problems to solve [136]. In clinical practice,training and testing data distributions can diverge due to manyreasons, e.g., medical data is generated by different institutionsusing different devices for patients having complicated cases.This work is licensed under a Creative Commons Attribution 4.0 License. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering12TABLE II: Summary of the state of the art data secure and privacy preserving methods in healthcare settings.Authors Goal Method ML Model(s) Medical Dataset(s)David et al. [119]Security & PrivacyCommodity based cryptography. [122] Paillier homomorphic encryption. Naı¨ve Bayes, SVM, NeuralNetwork, and FKNN–CBRIndian Liver PatientTakabi et al. [123] Homomorphic encryption. [124] Homomorphic encryption basedsecure logistic regression.Logistic Regression Five medical datasets hav-ing binary classes.Bogdanov et al. [128] Encryption using random maskingtechnique.Non-linear support vector ma-chine (SVM)Pima Indians diabetesdatabase.Choudhury et al. [129] Differential privacy and federatedlearning.SVM, Perceptron, and logisticregression.MIMIC III databaseLiu et al. [130] Federated learning. The eICU database.Due to this issue, ML/DL models developed using availablepublic databases (by the scientific community and academi-cians) do not give expected performance when deployed in anactual clinical environment. However, this assumption is not valid inpractice, and models trained under such an assumption fail togeneralize to other domains In contrast, the life-critical natureof clinical applications demands a smooth and safe operationof ML/DL techniques.9) Updating Hospital Infrastructure is Hard: Healthcare ITsystems are mostly proprietary and operate in silos, which re-sults in the revision, fixing, and update of software being costlyand time-consuming. The difficulties in updating hospitalsoftware infrastructure can raise many vulnerabilities with theuse of modern tools like ML/DL systems.IV. SECURE, PRIVATE, AND ROBUST ML FORHEALTHCARE: SOLUTIONSIn this section, we present an overview of various proposedmethods to ensure secure, private, and robust ML for health-care applications. A summary of articles focused on the topicof “secure and privacy-preserving ML for healthcare” is pre-sented in Table II and various approaches for secure, private,and robust ML are described next. In addition, a taxonomyof commonly used approaches for secure, private, and robustML is presented in Figure 6 and described individually next.A. Privacy-Preserving MLPreserving the privacy of the user in healthcare isparamount, as it is a user-centric application and involvesthe collection of personal data and any breach of privacy canlead to unavoidable consequences. Preserving privacy meansthat ML model training and inference should not reveal anyadditional information about the subjects from whom data wascollected. In general, ML/DL requires training data stored ona central repository (e.g., cloud) that may include the users’private data which raises various threats and to address suchconcerns data anonymization techniques are used. However, ithas been reported in the literature that meaningful informationcan be inferred about individuals’ private data even when thedata is anonymized [137].Various efforts in the literature have addressed the privacyissues with the use of ML. Three different protocols for thetwo-server model are presented in [138], where the privatedata is distributed among two non-colluding servers by thedata owners and then those servers train the ML modelson the joint data by following secure two-party computation(2PC). Furthermore, different techniques have been proposedto perform secure arithmetic operations in the secure multi-party computational environment and alternatives to nonlinearactivation functions used in ML models such as softmax andsigmoid are also proposed. Similarly, various techniques forprivacy-preserving ML such as cryptographic and differentialprivacy approaches are discussed in [109]. Here we brieflydiscuss the widely used methods for preserving privacy.1) Cryptographic Approaches: Cryptographic approachesare used in the scenarios where the ML model requires en-crypted data (for training and testing purposes) from multipleThis work is licensed under a Creative Commons Attribution 4.0 License. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering13Fig.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 37
    },
    {
        "text": "6: A taxonomy of commonly used approaches for secure, private, and robust ML.parties. The widely used methods include homomorphic en-cryption, secret sharing, garbled circuits, and secure processorswhich are briefly described next. (a) Homomorphic Encryption: It enables computations onencrypted data with operations such as addition andmultiplication which can be used as a basis for computingcomplex functions. (b) Garbled Circuits: Garbled circuits are used in caseswhere two parties (let’s assume Alice and Bob) wantto get results computed using their private data. The use of homomorphic encryption andgarbled circuits to build cryptographic blocks for develop-ing three classification techniques; namely, Naı¨ve Bayes,decision trees, and hyperplane decision is presented in[144], where the goal is to protect ML models and newsamples submitted for inference. Asecret sharing paradigm for computing privacy-preservingparallelized principal component analysis (PCA) is pre-sented in [125]. In a similar study [142], a protocol isdeveloped using the “secret sharing” strategy for ag-gregating model updates received from multiple inputparties, the updates are used for training of the ML model.A privacy-preserving emotion recognition framework ispresented in [143]. However, these processors arebeing utilized in privacy-preserving computation, e.g.,Intel SGXprocessor. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering14TABLE III: The comparisons of different techniques that can be used for privacy-preserving machine learning (ML).Technique Methodology Papers Advantage (s) Limitation (s)HomomorphicEncryptionComputations are performed on en-crypted data that is encrypted usingdifferent cryptographic approaches. [139], [140], [141] Can be used for outsourcing computa-tions on private data.Slow and computationally intensive andcan only receive input from one entity.Multi-PartyComputationComputations are performed on se-cret inputs from multiple parties. [125], [142], [143] Fast and less overhead and can receiveinput from multiple parties and ensuresthe correctness of input and privacy.It becomes slow with a large number ofparticipating parties.Garbled Cir-cuitsGarbled circuits are used in caseswhere two parties want to get re-sults computed using their privatedata. [144], [145], [138] Secure computation on the private dataof multiple parties.Low latency, as it requires the compu-tation of expensive operations.SecureProcessorsCollaboration between multipledata owners is performed throughan SGX-enabled data center. [146], [147], [148] Adversaries can get control over dataand software except the SGX-processorbeing used for computations.Adversaries can get control over dataand software.DifferentialPrivacyRandom statistical noise is addedto each attribute, to protect privacy. [127], [149], [150] Highly practical, as no computationaloverhead is involved because no en-cryption is performed.Addition of noise effects precision andhas some limitations from security per-spectives.FederatedLearningA shared model is collaborativelytrained from distributed data with-out sharing the data itself. [151], [152], [130] Less communication overhead, as localdata is not required to be transmittedand enables collaborative learning.Parameters optimization in federatedlearning is challenging.SGX-enabled data center. All types of communicationsbetween the data owners and the enclave were performedby establishing independently a secure channel (i.e., anindividual channel for each data owner).2) Differential Privacy: Differential privacy refers to themechanism of adding perturbation into the datasets to pro-tect private data. The idea of adding adequate noise in thedatabase for preserving privacy was first introduced by C.Dwork in 2006 [153]. Differential privacy constitutes a strongstandard for guaranteeing privacy for algorithms performinganalysis on aggregate databases and it is defined in termsof the application-specific concept of neighbor datasets [154].Differential privacy is particularly useful for applications likehealthcare due to its several properties such as group privacy,composability, and robustness to auxiliary information. Groupprivacy implies elegant degradation of privacy guaranteeswhen datasets contain correlated samples. To avoid privacy breaches, theresearchers can also explore encrypted and noisy datasets forbuilding ML empowered healthcare applications [155].Various approaches for differential privacy have been pro-posed in the literature, e.g., private aggregation of teacherensembles (PATE) for private ML [156], differentially pri-vate stochastic gradient descent (DP-SGD) algorithm [154],moments accountant [157], hyperparameter selection [158],Laplace [159] and exponential noise differential privacy mech-anisms [160], [161]. For instance, privacy-preserving dis-tributed DL for clinical data using differential privacy thatincorporates the idea of cyclical weight transfer is presentedin [127].3) Federated Learning: The idea of federated learning (FL)has been recently proposed by Google Inc. [162]. The proposed framework is named SplitNN that doesnot require sharing of patients’ critical data with the server.A framework of federated autonomous deep learning (FADL)using distributed EHR is presented in [130]. A comparisonof different privacy preserving techniques discussed above ispresented in Table III.B. Countermeasures Against Adversarial AttacksIn the recent literature, countermeasures against adversarialattacks are categorized into three classes: (1) modifying model;(2) modifying data; and (3) adding an auxiliary model(s) [163].A taxonomy of such methods is presented in Figure 7 and arediscussed next.1) Modifying Model: The modifying model includes meth-ods that modify the parameters or features of the trained MLmodel, widely used methods include the following:• Defensive Distillation: The distillation of neural networkswas first introduced by Hinton et al. to defend againstadversarial attacks, also known as defensive distillation[165]. However,in a later study, Carlini and Wagner demonstrated thattheir proposed adversarial attack (named as C&W attack)evaded the defensive distillation method [166].• Network Verification: The techniques verifying certainproperties of DL models in response to input samples areknown as network verification methods.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 38
    },
    {
        "text": "The key goal isto restrain adversarial examples while checking whetherthe input satisfied or violated certain properties. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering15Fig. 7: Taxonomy of Adversarial Defenses (Modified from [163]). Defenses are categorized into three categories: (1) ModifyingData; (2) Modifying Model; and (3) Adding Auxiliary Model(s).satisfiability modulo theory (SMT) to make deep modelsresilient against adversarial attacks.• Gradient Regularization: The idea of using input gra-dient regularization for defending adversarial exampleswas proposed by Ross et al. They trained thedifferentiable models by regularizing the variation in theresults with respect to the change in the input due towhich small adversarial perturbations were not able toaffect the output of DL models. However, this methodincreases the complexity of the training process by afactor of two.• Classifier Robustifying: In this method, classificationmodels are developed that are robust to adversarial attacksrather than building a detection strategy for such attacks.In [169], authors exploited the uncertainty around theadversarial examples and proposed a hybrid model byutilizing Gaussian processes (GPs) with RBF kernels ontop of DNNs to make them robust against adversarialattacks. In a similar study, a robust model is proposedfor MNIST classification that uses analysis by synthesisthrough learned class-conditional data distribution.• Interpretable ML: It includes those methods that aimat explaining and interpreting the outcomes of ML/DLmodels for robustifying them against adversarial attacks.An approach utilizing the interpretability of deep modelsfor the detection of adversarial examples for face recog-nition task is presented in a recent study [170]. However, Nicholas Carlinidemonstrated that the aforementioned method utilizingthe interpretability of deep models is not resilient to un-targeted adversarial examples generated using L∞ norm[171].• Masking ML Model: In a recent study [172], a methodfor secure learning is presented in which the problem ofadversarial ML is formulated as learning and maskingproblem. The masking of the deep model was performedby introducing noise in the logit output which success-fully deafened attacks with low distortions.2) Modifying Data: It includes those methods that aimat either modifying the data or its features, commonly usedmethods are described next:• Adversarial (Re-)training: This is a very basic methodthat was originally proposed by Goodfellow et al. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering16making deep models robust to adversarial examples [98].In this method, the ML/DL models are trained (or re-trained) using an augmented training set that includesadversarial examples. Various studies have used thismethod for evaluating the robustness of DL classifiersusing different datasets, e.g., MNIST [173] and ImageNet[167]. However, it has been reported in the literaturethat this method fails to defend against iterative adver-sarial perturbation generation methods like basic iterativemethod (BIM) [174].• Input Reconstruction: The method of transforming ad-versarial examples into legitimate ones by cleaning theadversarial noise is known as input reconstruction. In [175], denoising autoencoder isused for the cleaning of adversarial examples.• Feature Squeezing: Xu et al. [176] proposed featuresqueezing as a defense method against adversarial ex-amples by squeezing the input feature space that an ad-versary can exploit to construct adversarial examples. Moreover, the performanceevaluation of the proposed defense was performed usingeleven state of the art adversarial perturbation generationmethods using three benchmark datasets (i.e., CIFAR10,MNIST, and ImageNet). [178] that aims at masking themost sensitive features of the input that are susceptibleto adversarial perturbations. The authors added a maskinglayer right before the classification layer (i.e., softmax)that sets the corresponding weights of the sensitive neu-rons to zero.• Developing Adversarially Robust Features: To developadversarially robust features, the connections betweenthe metric of interest and natural spectral geometricalproperty of the dataset has been leveraged in [179].Furthermore, the authors provided empirical evidenceabout the effectiveness of using a spectral approach fordeveloping adversarially robust features.• Manifold Projection: The method of projecting inputsamples on the manifold learned by the generative modelsis known as manifold projection. [180] usedgenerative models to clean adversarial noise (pertur-bations) from the adversarial images then the cleanedimages are used as the input to the non-modified model.In a similar study [181], generative adversarial networks(GANs) are used for cleaning of adversarial noise.3) Adding Auxiliary Model(s): In these methods, additionalauxiliary ML/DL models are integrated to robustify the main-stream model, commonly used methods that fall into this classare described in the following paragraphs:• Adversarial Detection: In this method, an additionalbinary classifier is trained to distinguish between theadversarial and original samples that can be regardedas the detector model [182], [183]. In [184], a simpleDNN based detector model is used for the detection ofadversarial examples. Similarly, an outlier class has beenintroduced during the training of a deep model that helpsthe model to detect the adversarial examples belongingto the outlier class.• Ensembling Defenses: The literature suggests that ad-versarial examples can be constructed in multi-facetedfashion. Therefore, to develop an efficient defense methodagainst such adversarial examples, multiple defensestrategies can be integrated sequentially or in parallel[185]. The PixelDefend method is an excellent exampleof an ensemble defense method in which authors used anensemble of two methods, i.e., adversarial detection andinput reconstruction [180].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 39
    },
    {
        "text": "However, it has been shownthat the ensemble of weak defenses does not necessarilyincrease the robustness of DL models to adversarialattacks [177].• Using Generative ML Models: The idea of defendingagainst adversarial attacks by utilizing generative modelswas firstly presented by Goodfellow et al. In [186], adversarialexamples are cleaned using GAN that was trained onthe same dataset. In a similar study [187], a frameworknamed Defense-GAN is presented that is trained on thedistribution of legitimate samples. Defense-GAN findssimilar output during the testing phase without adversarialperturbations that are given as input to the original DLmodel. A summary of the state of the art defense methodsfor making DL models resilient to adversarial attacks ispresented in Table IV.C. Causal Models for HealthcareAsking causal questions in healthcare is a very challengingyet important approach and ideally, causal inferences requireexperiments. But it in healthcare this not always possible, e.g.,if we want to figure out what will happen if a person takes drugA instead of B, we can not experiment it directly on the patientwhich is unethical and can have unintended consequences.Alternatively, retrospective observational data is leveraged totrain models for making counterfactual predictions of whatwe would have observed if we had run an experiment [189].Causality can be deemed in two foundational ways, i.e.,potential outcomes and causal graphical models that requiremanipulating reality. In predictive healthcare, potential out-comes can be treatment, action, and interventions. If the totalnumber of possible treatments is T then we can have Tpossible outcomes and the unit of observation will be a patientwho gets one of the T treatments.In the literature, different approaches have been presentedfor providing causal inferences and reasoning in healthcareThis work is licensed under a Creative Commons Attribution 4.0 License. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering17TABLE IV: Summary of state-of-the-art defense methods for mitigating adversarial attacks.Author Proposed Defense Methodology Attack Method(s) Dataset(s) Defense AccuracyGu et al. [175]Proposed the use of denoising autoen-coders (DAEs) for removing adversar-ial noise.To construct adversarial examples, added ad-ditive Gaussian noise into original images.MNIST 99.1%Xu et al. [176]Proposed feature space reductionwhich is available to an adversary.Evaluated the proposed defense against differ-ent adversarial examples crafting methods.MNIST, CIFAR-10, and ImageNet MNIST (62.7%), CIFAR-10(77.27%), and ImageNet(68.11%)Gao et al. [178]Proposed the masking of unnecessaryneurons in the model.Fast Gradient Search Method (FGSM) CIFAR-10 10% increase in accuracy un-der adversarial attack.Papernotet al. [165]Proposed defense distillation for im-proving adversarial robustness.Gradient based adversarial example generationmethod.MNIST & CIFAR10 2.56% increase in robustnesswith distiallation temperatureof 50.Garg et al. [179]Used spectral property for generatingadversarially robust features.Considered L2 minimization based adversar-ial perturbations.MNIST N/ASong et al. [180]Proposed to recover adversarial exam-ples by projecting them back to themanifold of original training data.Evaluated five different adversarial examplesgeneration methods.Fashion MNIST and CIFAR-10 Achieved the increase in accu-racy under adversarial attack:21% for Fashion MNIST and38% for CIFAR-10.Goodfellowet al. [98]Trained the model by adding usingboth original images and adversarialexamples.Fast Gradient Sign (FGSM) MNIST 17.9% fall in model error.Metzend etal. [184]Trained a deep neural network (DNN)for detection of adversarial examples,i.e., binary classification into normaland adversarial examples.FGSM, BIM, and DeepFool. CIFAR-10 80% adversarial detectabilityfor all attacks.Schott etal. [188]Variational autoencoder (VAE) forgenerating clean images.Used four different adversarial example gen-eration methods that uses L2( = 1.5).MNIST 80%Ross et al. [168]Proposed input gradient regularizationfor training a model that is resilient toadversarial attacks.FGSM, TGSM, and JSMA. The use of probabilisticgraphical models to analyze causality in health conditionsfor identification sleep apnea, Alzheimers disease, and heartdiseases is presented in [190]. Solutions to Address Distribution ShiftsTo cater with data distribution shift problem various tech-niques have been proposed in the literature (e.g., transferlearning and domain adaptation), which are described next.1) Transfer Learning: The requirement of the availabilityof a large-scale dataset for training DL models capable ofproviding high performances can be partially mitigated usingtransfer learning. Transfer learning is a technique in which amodel trained on a larger dataset is re-trained (fine-tuned) onthe application-specific dataset (relatively smaller in size tothe first one). However, transfer learning can be problematic forhealthcare applications due to the requirement of sufficientlylarge data for first training and good quality data annotatedby expert clinicians such as radiologists for domain-specifictraining.2) Domain Adaptation: Domain adaptation is the methodof learning a DL model by considering a shift between thetraining (often called as source domain) and test (often calledas target domain) data distributions, i.e., source domain andtarget domain distributions are different. Domain adaptation isa special case of transfer learning that can be particularly use-ful for medical image analysis tasks such as MRI segmentation[136], [193], chest X-ray classification [194], and multi-classAlzheimer disease classification [195], etc. Different facets ofdomain adaptation have been proposed in the literature andcan be broadly categorized as supervised, unsupervised, semi-supervised, and self-supervised domain adaptation methodswhich are described below. Please note that the definition ofdomain adaptation is ambiguous since it may refer to labeleddata being available in the source or target domains and thedefinitions provided below for each method are mostly usedin the literature [196].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 40
    },
    {
        "text": "(a) Supervised Domain Adaptation: This method is similarto a supervised learning strategy with the only differenceof different distributions for source domain and targetdomain data. Supervised domain adaptation is particularlyuseful when a labeled data is available for the targetdomain and generally, the source domain also has labeleddata. (b) Unsupervised Domain Adaptation: In unsupervised do-main adaptation, source domain data is labeled and targetdomain data is unlabeled. An unsupervised domain adap-tation method using reverse flow and adversarial trainingfor generating synthetic medical images is presented in[197]. In addition, the authors used self-regularization forpreserving clinically-relevant features. (c) Semi-supervised Domain Adaptation: In semi-superviseddomain adaptation, labeled source data and partial labeledtarget domain. (d) Self-supervised Domain Adaptation: Self-supervised do-main adaptation methods aims at learning visual modelswithout manual labeling by training generic models usingauxiliary relatively simple tasks (known as pretext tasks).The supervision is provided by modifying the originalThis work is licensed under a Creative Commons Attribution 4.0 License. Towards Responsible MLIn this section, we provide different methods for ensuringresponsible ML and we start by enlisting general responsibleAI practices.1) General Responsible AI Practices: The following aresome recommended AI practices to ensure effective and reli-able AI systems.2• Consider human-centered design approach: To have alarge impact on the system being developed, it is impor-tant to consider the characteristics of the users for truerecommendations.• Evaluate training and monitoring using suitable metrics:Instead of using multiple metrics for evaluation of modeltraining, ensure that the metric is appropriate for thecontext and goals of the systems and consider users’feedback in terms of surveys.• Examine your raw data: The biases and abnormalities inthe datasets (e.g., missing values, class imbalance, andincorrect labels) are directly reflected by the learned MLmodels. To ensure the efficacy of the learning process,careful examination of the raw dataset is necessary whilerespecting the privacy concerns.• Understand limitations of the model and dataset: It iscrucial to understand the capability and limitations of theML model and dataset, e.g., a model trained for detectingcorrelations cannot be used for inferences.• Repetitive Testing: Once developed, ML systems shouldbe tested again and again to ensure that they are workingas intended. Rigorous tests should be performed to under-stand how the individual components of the ML systeminteract with each other. Other similar tests include testingfor input drifts, using gold standard datasets, incorpo-rating a larger sample base, and using quality checkingmechanisms.• Continuous Monitoring and Updating: To ensure theefficient performance of the ML systems deployed inreal-time settings, continued monitoring and updating arerequired to identify and fix various issues encountered inrealistic settings.2) Responsible ML for Healthcare: ML/DL techniqueshave a great potential for clinical applications (e.g.,radiologist-level pneumonia detection [11] and dermatologist-level classification of skin cancer [13], etc.) have provided a roadmaptowards safe, meaningful, and responsible ML for healthcareand argued that ML deployment in any field should be carriedout by an interdisciplinary team that may include differentstakeholders from multi disciplines, i.e., knowledge experts,2https://ai.google/responsibilities/responsible-ai-practices/decision-makers, and users. Examples for an interdisciplinaryteam having different stakeholders in the healthcare ecosystemare presented in Table V. In addition, the authors also identi-fied critical steps to be followed/considered when designing,testing, and deploying ML solutions for healthcare applicationsthat include: (1) choosing the right problems; (2) developinga useful solution; (3) considering ethical implications; (4)rigorously evaluating the model; (5) thoughtfully reportingresults; (6) deploying responsibly; and (7) making it to market.TABLE V: Examples for interdisciplinary teams having differ-ent stakeholders from multiple domains. Tools and Libraries for Secure and Private MLThe main strength of ensuring secure ML relies on thedevelopment of security tools and algorithms. To ensure thesecurity and privacy of ML models and data, various toolsand libraries have been released so far. For example, Ten-sorFlow Federated,3 which is an open-source framework fordistributed ML/DL that enables training of a global sharedmodel in a federated environment without sharing clients’local data. CrypTen4 is a framework for secure and privacy-preserving ML built on PyTorch that provides secure comput-ing techniques for ML/DL model training and inference usingencrypted data and PyTorch-DP5–a framework of PyTorchfor training DL models with differential privacy. Similarly,OpenMined6–an open-source community offers various toolsand libraries for building privacy-preserving ML models whichare briefly described below.• PySyft7 is python library for encrypted and privacypreserving ML. It extends PyTorch, TensorFlow, andKeras and supports differential privacy, federated learn-ing, multi-party computation, and homomorphic encryp-tion.• PyGrid8 is a platform built on PySyft that provides apeer-to-peer network to collectively train ML models.• SyferText9 is a privacy preserving framework for NLPtasks.3https://www.tensorflow.org/federated4https://github.com/facebookresearch/CrypTen5https://github.com/facebookresearch/pytorch-dp6https://www.openmined.org/7https://github.com/OpenMined/PySyft8https://github.com/OpenMined/PyGrid9https://github.com/OpenMined/SyferTextThis work is licensed under a Creative Commons Attribution 4.0 License. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering19V. OPEN RESEARCH ISSUESIn this section, various open research issues related to thedomain of secure, robust, and private ML for healthcare thatrequire further research attention are presented.A. Interpretable MLAlthough the advancement in ML/DL research has providedsignificant performance improvements over the previous stateof the art methods in terms of performance metrics such asaccuracy, precision, recall, and f1-measure, these advance-ments have made the learning process of modern models verycomplex and are usually deployed as a black-box.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 41
    },
    {
        "text": "The aforementioned problem istermed as the interpretability problem of ML in the literature,which is defined as the ability to describe the internal processesof an ML system in a human-understandable manner.Moreover, interpretability of ML/DL techniques is requiredto ensure algorithmic fairness, robustness, and generalizationbased on potentially dispersed data collected from a hetero-geneous population. For a critical application like healthcare, the ML/DLmodel is expected to be highly accurate and understandableat the same time. Moreover, it has been argued that clinicalintegration of AI models will require interpretability [201]. Toperform an interpretation of ML models, questions about thefairness of model’s predictions, transparency, and accountabil-ity are considered and interpretation is performed using expla-nation methods for justifying predictions of the model usingvisual, textual, or features information. presented a pixel-wise explanation method that uses layer-wise relevance propagation for interpreting the predictionsof non-linear classifiers [202]. presented a frameworknamed LIME and proposed two methods for interpretability,i.e., learning a local model around the predictions and repre-senting predictions and their explanations in a non-redundantway using a submodular optimization approach. In [203],the use of reinforcement learning (RL) is proposed to buildinterpretable decision support systems for heart patients and itlearns what is interpretable to each user by their interactions.One yet common method for interpreting/explaining deepmodels, in particular, CNN is the use of saliency maps [204],[205]. These methods are particularly focused on general ap-plications, however, more research that is specifically focusedon the interpretation of ML/DL systems used in healthcareapplications is required.B. Machine Learning on the EdgeThe advancements in ML research have revolutionized tradi-tional healthcare (as discussed in earlier sections). Healthcareservices will increasingly adopt the utilization of IoT devicesand wearable sensors in the future, particularly with the evolu-tion of smart cities and portable medical devices, e.g., portableMRI scanner. Handling Dataset AnnotationTo increase the performance of ML/DL models, one naturalstrategy is to acquire more labeled training data. This requiresthat radiologists and medical experts spend their valuabletime manually annotating medical data, e.g., medical images,signals, and reports. Automaticapproaches should be developed to address this issue and onesuch technique is active learning which can be used to annotateunlabelled data samples.Data from multiple sources should be considered whenperforming annotation for specific clinical applications be-cause single-source data might lack precise structured labels[115]. The integration of multiple source data is an importantapplication of ML in healthcare [206], which is known asphenotyping [207]. NLP techniques and recurrent deep modelscan be used for extracting and integrating rich informationfrom unstructured clinical notes to augment the capacity ofdata annotators.D. Distributed Data Management and MLIn healthcare settings, the data is generated in a distributedfashion, i.e., across different departments within a hospital andeven across different hospitals. This necessitates the efficientmanagement and sharing of distributed data for clinical anal-ysis purposes, particularly using ML/DL models. Fair and Accountable MLThe literature on analyzing the security and robustness ofML/DL approaches reveals that the outcomes of these mod-els lack fairness and accountability [163]. Whereas ensuringthe fairness and accountability of predictions in life-criticalapplications like healthcare are of paramount importance,the fairness property ensures that the ML model should notfavor certain cases over others. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering20arises due to biases in the training data. Fairness and accountability will assist indeveloping models robust to biases and imperfections such aspast clinical practicesF. Model-Driven MLAlthough ML, AI, and big data are immensely useful toolsfor healthcare, these tools are not panacea and it is important tobe aware of the associated caveats and pitfalls [200]. Failing torealize this, one can easily fall prey to the dangerous dogmathat data once available in abundance must and will speakfor itself and can handle hypothesis generation as well—which in clinical terms would mean that data mining is suf-ficient and independent of the need of clinical interpretation,external validation, and understanding of data’s provenance[208]. To avoid the various problems that can arise fromimproper use of ML in healthcare, it is important to combinedata-driven methods with hypothesis-driven or model-basedmethods (based on subject matter knowledge) and to bringscientific rigor in these studies. Avenuesfor developing secure and robust ML solutions for healthcarethat are scientifically robust and rigorous requires furtherattention from the community.VI. CONCLUSIONSThe use of machine learning (ML)/deep learning (DL)models for clinical applications has great potential to transformtraditional healthcare service delivery. However, to ensure a se-cure and robust application of these models in clinical settings,different privacy and security challenges should be addressed.In this paper, we provided an overview of such challenges byformulating the ML pipeline in healthcare and by identifyingdifferent sources of vulnerabilities in it. We also discussedpotential solutions to provide secure and privacy-preservingML for security-critical applications like healthcare. [2] Z. Yan, Y. Zhan, Z. Peng, S. Liao, Y. Shinagawa, S. Zhang, D. N.Metaxas, and X. S. Zhou, “Multi-instance deep learning: Discoverdiscriminative local anatomies for bodypart recognition,” IEEE trans-actions on medical imaging, vol. Mougiakakou, “Lung pattern classification for interstitial lung dis-eases using a deep convolutional neural network,” IEEE transactionson medical imaging, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 42
    },
    {
        "text": "[4] W. Shen, M. Zhou, F. Yang, C. Yang, and J. Tian, “Multi-scale convolu-tional neural networks for lung nodule classification,” in InternationalConference on Information Processing in Medical Imaging. Price, and D. Rueckert,“A deep cascade of convolutional neural networks for mr imagereconstruction,” in International Conference on Information Processingin Medical Imaging. [6] J. Mehta and A. Majumdar, “Rodeo: robust de-aliasing autoencoder forreal-time medical image reconstruction,” Pattern Recognition, vol. [7] M. Havaei, A. Davy, D. Warde-Farley, A. Biard, A. Courville, Y. Ben-gio, C. Pal, P.-M. Jodoin, and H. Larochelle, “Brain tumor segmentationwith deep neural networks,” Medical image analysis, vol. [9] L. Xing, E. A. Krupinski, and J. Cai, “Artificial intelligence willsoon change the landscape of medical physics research and practice,”Medical physics, vol. Balkenhol et al., “Diagnostic assessment of deep learning algo-rithms for detection of lymph node metastases in women with breastcancer,” Jama, vol. Bagul, C. Langlotz, K. Shpanskaya et al., “Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning,” arXivpreprint arXiv:1711.05225, 2017. [14] S. Latif, M. Asim, M. Usman, J. Qadir, and R. Rana, “Automatingmotion correction in multishot mri using generative adversarial net-works,” Published as Workshop Paper at 32nd Conference on NeuralInformation Processing Systems (NIPS 2018), 2018. [15] X.-W. Chen and X. Lin, “Big data deep learning: challenges andperspectives,” IEEE access, vol. [16] R. Miotto, F. Wang, S. Wang, X. Jiang, and J. T. Dudley, “Deeplearning for healthcare: review, opportunities and challenges,” Briefingsin bioinformatics, vol. [17] K. Papangelou, K. Sechidis, J. Weatherall, and G. Brown, “Towardan understanding of adversarial examples in clinical trials,” in JointEuropean Conference on Machine Learning and Knowledge Discoveryin Databases. [18] H. Kim, D. C. Jung, and B. W. Choi, “Exploiting the vulnerability ofdeep learning-based artificial intelligence models in medical imaging:Adversarial attacks,” Journal of the Korean Society of Radiology,vol. [19] X. Yuan, P. He, Q. Zhu, and X. Li, “Adversarial examples: Attacks anddefenses for deep learning,” IEEE transactions on neural networks andlearning systems, 2019. [20] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfel-low, and R. Fergus, “Intriguing properties of neural networks,” arXivpreprint arXiv:1312.6199, 2013. targeted clean-label poisoning attackson neural networks,” in Advances in Neural Information ProcessingSystems, 2018, pp. [22] S. G. Finlayson, J. D. Bowers, J. Ito, J. L. Zittrain, A. L. Beam, and I. S.Kohane, “Adversarial attacks on medical machine learning,” Science,vol. [24] A. K. Pandey, P. Pandey, K. Jaiswal, and A. K. Sen, “Dataminingclustering techniques in the prediction of heart disease using attributeselection method,” heart disease, vol. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering21[26] M. Alloghani, D. Al-Jumeily, J. Mustafina, A. Hussain, and A. J.Aljaaf, “A systematic review on supervised and unsupervised machinelearning algorithms for data science,” in Supervised and UnsupervisedLearning for Data Science. [28] A. Zahin, R. Q. Hu et al., “Sensor-based human activity recognitionfor smart healthcare: A semi-supervised machine learning,” in Inter-national Conference on Artificial Intelligence for Communications andNetworks. [29] D. Mahapatra, “Semi-supervised learning and graph cuts for consensusbased medical image segmentation,” Pattern recognition, vol. King, P. M. Matthews, and D. Rueckert, “Semi-supervised learning for network-based cardiac mr image segmenta-tion,” in International Conference on Medical Image Computing andComputer-Assisted Intervention. [34] A. Collins and Y. Yao, “Machine learning approaches: Data integra-tion for disease prediction and prognosis,” in Applied ComputationalGenomics. [36] W. Zhu, C. Liu, W. Fan, and X. Xie, “Deeplung: Deep 3d dual path netsfor automated pulmonary nodule detection and classification,” in 2018IEEE Winter Conference on Applications of Computer Vision (WACV).IEEE, 2018, pp. [37] P. B. Jensen, L. J. Jensen, and S. Brunak, “Mining electronic healthrecords: towards better research applications and clinical care,” NatureReviews Genetics, vol. [38] Z. Wang, A. D. Shah, A. R. Tate, S. Denaxas, J. Shawe-Taylor,and H. Hemingway, “Extracting diagnoses and investigation resultsfrom unstructured text in electronic health records by semi-supervisedmachine learning,” PLoS One, vol. Chen, “A machine learning-based framework to identify type 2diabetes through electronic health records,” International journal ofmedical informatics, vol. [40] B. Nestor, M. McDermott, W. Boag, G. Berner, T. Naumann, M. C.Hughes, A. Goldenberg, and M. Ghassemi, “Feature robustness innon-stationary health records: caveats to deployable model perfor-mance in common clinical machine learning tasks,” arXiv preprintarXiv:1908.00690, 2019. K. Khan, “Medical image analysis using convolutional neuralnetworks: a review,” Journal of medical systems, vol. [43] L. Gondara, “Medical image denoising using convolutional denoisingautoencoders,” in 2016 IEEE 16th International Conference on DataMining Workshops (ICDMW). A. Cree, and N. M. Rajpoot, “Locality sensitive deep learning fordetection and classification of nuclei in routine colon cancer histologyimages.” IEEE Trans. Feldman, J. Tomaszewski, F. Gonzalez, and A. Madabhushi,“Mitosis detection in breast cancer pathology images by combininghandcrafted and convolutional neural network features,” Journal ofMedical Imaging, vol. [47] Y. Yu, H. Lin, J. Meng, X. Wei, H. Guo, and Z. Zhao, “Deep transferlearning for modality classification of medical images,” Information,vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 43
    },
    {
        "text": "[50] M. F. Stollenga, W. Byeon, M. Liwicki, and J. Schmidhuber, “Parallelmulti-dimensional lstm, with application to fast biomedical volumetricimage segmentation,” in Advances in neural information processingsystems, 2015, pp. [51] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional net-works for biomedical image segmentation,” in International Confer-ence on Medical image computing and computer-assisted intervention.Springer, 2015, pp. Ahmadi, “V-net: Fully convolutionalneural networks for volumetric medical image segmentation,” in 2016Fourth International Conference on 3D Vision (3DV). He, and P. Kennedy, “Deep learning tech-niques for medical image segmentation: Achievements and challenges,”Journal of digital imaging, pp. [55] M. Usman, S. Latif, M. Asim, and J. Qadir, “Motion correctedmultishot mri reconstruction using generative networks with sensitivityencoding,” arXiv preprint arXiv:1902.07430, 2019. A. El-Gamal, M. Elmogy, and A. Atwan, “Current trends inmedical image registration and fusion,” Egyptian Informatics Journal,vol. [57] J. Ker, L. Wang, J. Rao, and T. Lim, “Deep learning applications inmedical image analysis,” Ieee Access, vol. [58] X. Yang, R. Kwitt, M. Styner, and M. Niethammer, “Quicksilver: Fastpredictive image registration–a deep learning approach,” NeuroImage,vol. [59] S. Miao, Z. J. Wang, and R. Liao, “A cnn regression approach forreal-time 2d/3d registration,” IEEE transactions on medical imaging,vol. Suk, “Deep learning in medical imageanalysis,” Annual review of biomedical engineering, vol. [61] A. Qayyum, S. M. Anwar, M. Awais, and M. Majid, “Medical imageretrieval using deep convolutional neural network,” Neurocomputing,vol. Bederson, J. Lehar, and E. K. Oermann, “Natural language–basedmachine learning models for the annotation of clinical radiologyreports,” Radiology, vol. [63] B. Jing, P. Xie, and E. Xing, “On the automatic generation ofmedical imaging reports,” 56th Annual Meeting of the Association forComputational Linguistics (ACL), 2018. [64] X. Wang, Y. Peng, L. Lu, Z. Lu, and R. M. Summers, “Tienet: Text-image embedding network for common thorax disease classificationand reporting in chest x-rays,” in Proceedings of the IEEE conferenceon computer vision and pattern recognition, 2018, pp. Huang, “Multimodal recurrent model with attention for automatedradiology report generation,” in International Conference on MedicalImage Computing and Computer-Assisted Intervention. [67] F. Attal, S. Mohammed, M. Dedabrishvili, F. Chamroukhi, L. Oukhel-lou, and Y. Amirat, “Physical human activity recognition using wear-able sensors,” Sensors, vol. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering22[68] S. F. Weng, J. Reps, J. Kai, J. M. Garibaldi, and N. Qureshi, “Canmachine-learning improve cardiovascular risk prediction using routineclinical data?” PloS one, vol. [69] M. Fatima and M. Pasha, “Survey of machine learning algorithmsfor disease diagnostic,” Journal of Intelligent Learning Systems andApplications, vol. A. Cruz and D. S. Wishart, “Applications of machine learningin cancer prediction and prognosis,” Cancer informatics, vol. [73] A. Raghu, “Reinforcement learning for sepsis treatment: Baselines andanalysis,” 2019. [74] H. Suresh, “Clinical event prediction and understanding with deepneural networks,” Ph.D. dissertation, Massachusetts Institute of Tech-nology, 2017. Tang, Z. Shahn, D. Sow, R. Mark, and L.-w. Lehman, “Predictingand understanding unexpected respiratory decompensation in criticalcare using sparse and heterogeneous clinical data,” in 2018 IEEEInternational Conference on Healthcare Informatics (ICHI). [79] A. Ne´ve´ol, H. Dalianis, S. Velupillai, G. Savova, and P. Zweigenbaum,“Clinical natural language processing in languages other than english:opportunities and challenges,” Journal of biomedical semantics, vol. [80] E. Soysal, J. Wang, M. Jiang, Y. Wu, S. Pakhomov, H. Liu, and H. Xu,“Clamp–a toolkit for efficiently building customized clinical naturallanguage processing pipelines,” Journal of the American MedicalInformatics Association, vol. [81] D. S. Wallace, “The role of speech recognition in clinicaldocumentation,” Nuance Communications, 2018, access on: 14-Dec-2019. [87] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, and N. Elhadad,“Intelligible models for healthcare: Predicting pneumonia risk and hos-pital 30-day readmission,” in Proceedings of the 21th ACM SIGKDDInternational Conference on Knowledge Discovery and Data Mining.ACM, 2015, pp. [89] F. Xia and M. Yetisgen-Yildiz, “Clinical corpus annotation: challengesand strategies,” in Proceedings of the Third Workshop on Building andEvaluating Resources for Biomedical Text Mining (BioTxtM’2012) inconjunction with the International Conference on Language Resourcesand Evaluation (LREC), Istanbul, Turkey, 2012. [92] N. Carlini and D. Wagner, “Magnet and” efficient defenses againstadversarial attacks” are not robust to adversarial examples,” arXivpreprint arXiv:1711.08478, 2017. [93] B. Biggio, B. Nelson, and P. Laskov, “Poisoning attacks againstsupport vector machines,” in 29th International Conference on MachineLearning, 2012, pp. [94] S. Alfeld, X. Zhu, and P. Barford, “Data poisoning attacks againstautoregressive models,” in Thirtieth AAAI Conference on ArtificialIntelligence, 2016. [95] N. Papernot, P. McDaniel, A. Sinha, and M. Wellman, “Towards thescience of security and privacy in machine learning,” arXiv preprintarXiv:1611.03814, 2016. [97] M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacksthat exploit confidence information and basic countermeasures,” inProceedings of the 22nd ACM SIGSAC Conference on Computer andCommunications Security. [98] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessingadversarial examples,” arXiv preprint arXiv:1412.6572, 2014. Swami, “The limitations of deep learning in adversarial settings,” in2016 IEEE European Symposium on Security and Privacy (EuroS&P).IEEE, 2016, pp. Swami, “Practical black-box attacks against machine learning,” inProceedings of the 2017 ACM on Asia Conference on Computer andCommunications Security.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 44
    },
    {
        "text": "[101] M. Usama, J. Qadir, A. Al-Fuqaha, and M. Hamdi, “The ad-versarial machine learning conundrum: Can the insecurity of mlbecome the achilles’ heel of cognitive networks?” arXiv preprintarXiv:1906.00679, 2019. Giacinto, and F. Roli, “Evasion attacks against machine learningat test time,” in Joint European conference on machine learning andknowledge discovery in databases. [103] M. Mozaffari-Kermani, S. Sur-Kolay, A. Raghunathan, and N. K. Jha,“Systematic poisoning attacks on and defenses for machine learning inhealthcare,” IEEE journal of biomedical and health informatics, vol. [104] S. G. Finlayson, H. W. Chung, I. S. Kohane, and A. L. Beam,“Adversarial attacks against medical deep learning systems,” arXivpreprint arXiv:1804.05296, 2018. [105] N. Karimian, M. Tehranipoor, D. Woodard, and D. Forte, “Unlock yourheart: Next generation biometric in resource-constrained healthcaresystems and iot,” IEEE Access, vol. [106] U. Kumar, E. Tripathi, S. P. Tripathi, and K. K. Gupta, “Deep learningfor healthcare biometrics,” in Design and Implementation of HealthcareBiometric Systems. Lo, “A machine learningframework for biometric authentication using electrocardiogram,” IEEEAccess, vol. [108] L. Wieclaw, Y. Khoma, P. Fałat, D. Sabodashko, and V. Herasymenko,“Biometrie identification from raw ecg signal using deep learningtechniques,” in 2017 9th IEEE International Conference on IntelligentData Acquisition and Advanced Computing Systems: Technology andApplications (IDAACS), vol. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering23[109] M. Al-Rubaie and J. M. Chang, “Privacy-preserving machine learning:Threats and solutions,” IEEE Security & Privacy, vol. [110] J. Chaudhry, “Securing healthcare data using biometric authentication,”Security and Privacy in Communication Networks, p. 123, 2018. Albahri, M. Alsalem, K. Mohammed, and M. Hashim, “Real-time medical systems based on human biometric steganography: Asystematic review,” Journal of medical systems, vol. Lo, “Security and privacy for the internetof medical things enabled healthcare systems: A survey,” IEEE Access,vol. [113] J. Zhang and E. Bareinboim, “Fairness in decision-making—the causalexplanation formula,” in Thirty-Second AAAI Conference on ArtificialIntelligence, 2018. [115] M. Ghassemi, T. Naumann, P. Schulam, A. L. Beam, and R. Ranganath,“Opportunities in machine learning for healthcare,” arXiv preprintarXiv:1806.00388, 2018. [116] E. Begoli, T. Bhattacharya, and D. Kusnezov, “The need for uncertaintyquantification in machine-assisted medical decision making,” NatureMachine Intelligence, vol. [119] B. David, R. Dowsley, R. Katti, and A. C. Nascimento, “Efficientunconditionally secure comparison and privacy preserving machinelearning classification protocols,” in International Conference on Prov-able Security. [120] M. Jagielski, A. Oprea, B. Biggio, C. Liu, C. Nita-Rotaru, and B. Li,“Manipulating machine learning: Poisoning attacks and countermea-sures for regression learning,” in 2018 IEEE Symposium on Securityand Privacy (SP). [121] M. Liu, H. Jiang, J. Chen, A. Badokhon, X. Wei, and M.-C. Huang,“A collaborative privacy-preserving deep learning system in distributedmobile environment,” in 2016 International Conference on Computa-tional Science and Computational Intelligence (CSCI). K. Sangaiah, “Hybrid reasoning-based privacy-aware disease pre-diction support system,” Computers & Electrical Engineering, vol. [123] H. Takabi, E. Hesamifard, and M. Ghasemi, “Privacy preserving multi-party machine learning with homomorphic encryption,” in 29th AnnualConference on Neural Information Processing Systems (NIPS), 2016. Song, S. Wang, Y. Xia, and X. Jiang, “Secure logisticregression based on homomorphic encryption: Design and evaluation,”JMIR medical informatics, vol. [125] D. Bogdanov, L. Kamm, S. Laur, and V. Sokk, “Implementationand evaluation of an algorithm for cryptographically private principalcomponent analysis on genomic data,” IEEE/ACM transactions oncomputational biology and bioinformatics, vol. [126] M. Min, X. Wan, L. Xiao, Y. Chen, M. Xia, D. Wu, and H. Dai,“Learning-based privacy-aware offloading for healthcare iot with en-ergy harvesting,” IEEE Internet of Things Journal, vol. [127] B. K. Beaulieu-Jones, W. Yuan, S. G. Finlayson, and Z. S. Wu,“Privacy-preserving distributed deep learning for clinical data,” Ma-chine Learning for Health (ML4H) Workshop at NeurIPS, 2018. [128] H. Zhu, X. Liu, R. Lu, and H. Li, “Efficient and privacy-preservingonline medical prediagnosis framework using nonlinear svm,” IEEEjournal of biomedical and health informatics, vol. Hsu, and A. Das, “Differential privacy-enabled federated learningfor sensitive health data,” arXiv preprint arXiv:1910.02578, 2019. [130] D. Liu, T. Miller, R. Sayeed, and K. Mandl, “Fadl: Federated-autonomous deep learning for distributed electronic health record,”Machine Learning for Health (ML4H) Workshop at NeurIPS, 2018. Chopra, N. Pontikos, C. Kern et al., “Automated deep learningdesign for medical image classification by health-care professionalswith no coding experience: a feasibility study,” The Lancet DigitalHealth, vol. h. O’Reilly, “Challenges to AI in healthcare accessed online:16 oct 2019.”[133] I. Chen, F. D. Johansson, and D. Sontag, “Why is my classifier dis-criminatory?” in Advances in Neural Information Processing Systems,2018, pp. Ranganath, “Practical guidance on artificial intelligence for health-care data,” The Lancet Digital Health, vol. [135] T. Panch, H. Mattie, and L. A. Celi, “The “inconvenient truth” aboutai in healthcare,” Npj Digital Medicine, vol. [136] C. S. Perone, P. Ballester, R. C. Barros, and J. Cohen-Adad, “Un-supervised domain adaptation for medical imaging segmentation withself-ensembling,” NeuroImage, vol. [137] A. Narayanan and V. Shmatikov, “Robust de-anonymization of largedatasets (how to break anonymity of the netflix prize dataset),” Uni-versity of Texas at Austin, 2008.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 45
    },
    {
        "text": "[138] P. Mohassel and Y. Zhang, “Secureml: A system for scalable privacy-preserving machine learning,” in 2017 IEEE Symposium on Securityand Privacy (SP). [139] Y. Aono, T. Hayashi, L. Wang, S. Moriai et al., “Privacy-preservingdeep learning via additively homomorphic encryption,” IEEE Transac-tions on Information Forensics and Security, vol. [140] S. Carpov, T. H. Nguyen, R. Sirdey, G. Constantino, and F. Martinelli,“Practical privacy-preserving medical diagnosis using homomorphicencryption,” in 2016 IEEE 9th International Conference on CloudComputing (CLOUD). Wood, and K. Najarian, “Homomorphic encryptionfor machine learning in medicine and bioinformatics,” ACM Comput.Surv., 2020. Patel, D. Ramage, A. Segal, and K. Seth, “Practical secure aggre-gation for privacy-preserving machine learning,” in Proceedings of the2017 ACM SIGSAC Conference on Computer and CommunicationsSecurity. [144] R. Bost, R. A. Popa, S. Tu, and S. Goldwasser, “Machine learningclassification over encrypted data.” in NDSS, vol. [145] A. Gribov, K. Horan, J. Gryak, K. Najarian, V. Shpilrain, R. Soroush-mehr, and D. Kahrobaei, “Medical diagnostics based on encryptedmedical data,” in International Conference on Bio-inspired Informationand Communication. Vaswani, and M. Costa, “Oblivious multi-party machine learningon trusted processors,” in 25th USENIX Security Symposium (USENIXSecurity 16), 2016, pp. [147] F. Shaon, M. Kantarcioglu, Z. Lin, and L. Khan, “Sgx-bigmatrix: Apractical encrypted data analytic framework with trusted processors,”in Proceedings of the 2017 ACM SIGSAC Conference on Computerand Communications Security, 2017, pp. Fetzer, “Tensorscone: A secure tensorflow framework using intelsgx,” arXiv preprint arXiv:1902.04413, 2019. Sun, Y. Wang, M. Shu, R. Liu, and H. Zhao, “Differential privacyfor data and model publishing of medical data,” IEEE Access, vol. [151] T. S. Brisimi, R. Chen, T. Mela, A. Olshevsky, I. C. Paschalidis,and W. Shi, “Federated learning of predictive models from federatedelectronic health records,” International journal of medical informatics,vol. [152] P. Vepakomma, O. Gupta, T. Swedish, and R. Raskar, “Split learningfor health: Distributed deep learning without sharing raw patientdata,” Published as Workshop Paper at 32nd Conference on NeuralInformation Processing Systems (NIPS 2018), 2018. [153] C. Dwork, “Differential privacy,” Encyclopedia of Cryptography andSecurity, pp. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering24[154] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov,K. Talwar, and L. Zhang, “Deep learning with differential privacy,”in Proceedings of the 2016 ACM SIGSAC Conference on Computerand Communications Security. [155] M. McDermott, S. Wang, N. Marinsek, R. Ranganath, M. Ghassemi,and L. Foschini, “Reproducibility in machine learning for health,”Presented at the Internation Conference on Learning Representative(ICLR) 2019 Reproducibility in Machine Learning Workshop, 2019. Erlingsson, “Scalable private learning with pate,” InternationalConference on Learning Representations (ICLR), 2018. Wang, B. Balle, and S. Kasiviswanathan, “Subsampled r\\’enyidifferential privacy and analytical moments accountant,” arXiv preprintarXiv:1808.00087, 2018. [159] N. Phan, X. Wu, H. Hu, and D. Dou, “Adaptive laplace mechanism:Differential privacy preservation in deep learning,” in 2017 IEEEInternational Conference on Data Mining (ICDM). [161] C. Dwork and F. D. McSherry, “Exponential noise distribution tooptimize database privacy and output utility,” Jul. [162] H. B. McMahan, E. Moore, D. Ramage, S. Hampson et al.,“Communication-efficient learning of deep networks from decentral-ized data,” Proceedings of the 20 th International Conference onArtificial Intelligence and Statistics (AISTATS) JMLR: WCP volume54, 2017. [163] A. Qayyum, M. Usama, J. Qadir, and A. Al-Fuqaha, “Securing con-nected & autonomous vehicles: Challenges posed by adversarial ma-chine learning and the way forward,” arXiv preprint arXiv:1905.12762,2019. [165] N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, “Distillationas a defense to adversarial perturbations against deep neural networks,”in 2016 IEEE Symposium on Security and Privacy (SP). [166] N. Carlini and D. Wagner, “Adversarial examples are not easilydetected: Bypassing ten detection methods,” in Proceedings of the 10thACM Workshop on Artificial Intelligence and Security. [168] A. S. Ross and F. Doshi-Velez, “Improving the adversarial robustnessand interpretability of deep neural networks by regularizing their inputgradients,” in Thirty-second AAAI conference on artificial intelligence,2018. [169] J. Bradshaw, A. G. d. G. Matthews, and Z. Ghahramani, “Adversarialexamples, uncertainty, and transfer testing robustness in gaussianprocess hybrid deep networks,” arXiv preprint arXiv:1707.02476, 2017. [170] G. Tao, S. Ma, Y. Liu, and X. Zhang, “Attacks meet interpretability:Attribute-steered detection of adversarial samples,” in Advances inNeural Information Processing Systems (NeurIPS), 2018, pp. [171] N. Carlini, “Is ami (attacks meet interpretability) robust to adversarialexamples?” arXiv preprint arXiv:1902.02322, 2019. [172] L. Nguyen, S. Wang, and A. Sinha, “A learning and masking approachto secure learning,” in International Conference on Decision and GameTheory for Security. [173] R. Huang, B. Xu, D. Schuurmans, and C. Szepesva´ri, “Learning witha strong adversary,” arXiv preprint arXiv:1511.03034, 2015. [174] A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial examplesin the physical world,” in Artificial Intelligence Safety and Security.Chapman and Hall/CRC, 2018, pp. [175] S. Gu and L. Rigazio, “Towards deep neural network architecturesrobust to adversarial examples,” Published as a Workshop Paper atInternational Conference on Learning Representative (ICLR), 2015.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 46
    },
    {
        "text": "[176] W. Xu, D. Evans, and Y. Qi, “Feature squeezing: Detectingadversarial examples in deep neural networks,” in 25th AnnualNetwork and Distributed System Security Symposium, NDSS 2018,San Diego, California, USA, February 18-21, 2018, 2018. [Online].Available: http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2018/02/ndss2018\\ 03A-4\\ Xu\\ paper.pdf[177] W. He, J. Wei, X. Chen, N. Carlini, and D. Song, “Adversarial exampledefense: Ensembles of weak defenses are not strong,” in 11th USENIXWorkshop on Offensive Technologies (WOOT)’17), 2017. [178] J. Gao, B. Wang, Z. Lin, W. Xu, and Y. Qi, “Deepcloak: Masking deepneural network models for robustness against adversarial samples,”arXiv preprint arXiv:1702.06763, 2017. [179] S. Garg, V. Sharan, B. Zhang, and G. Valiant, “A spectral viewof adversarially robust features,” in Advances in Neural InformationProcessing Systems (NeurlIPS), 2018, pp. Song, T. Kim, S. Nowozin, S. Ermon, and N. Kushman,“Pixeldefend: Leveraging generative models to understand anddefend against adversarial examples,” in International Conferenceon Learning Representations (ICLR), 2018. [182] J. Lu, T. Issaranon, and D. Forsyth, “Safetynet: Detecting and rejectingadversarial examples robustly,” in Proceedings of the IEEE Interna-tional Conference on Computer Vision, 2017, pp. [183] D. Gopinath, G. Katz, C. S. Pasareanu, and C. Barrett, “Deepsafe:A data-driven approach for checking adversarial robustness in neuralnetworks,” arXiv preprint arXiv:1710.00486, 2017. [184] J. H. Metzen, T. Genewein, V. Fischer, and B. Bischoff, “On detect-ing adversarial perturbations,” International Conference on LearningRepresentations (ICLR), 2017. McDaniel, “Ensemble adversarial training: Attacks and defenses,” inInternational Conference on Learning Representations (ICLR), 2018. [186] G. K. Santhanam and P. Grnarova, “Defending against adversarial at-tacks by leveraging an entire GAN,” arXiv preprint arXiv:1805.10652,2018. [187] P. Samangouei, M. Kabkab, and R. Chellappa, “Defense-GAN: Protect-ing classifiers against adversarial attacks using generative models,” inInternational Conference on Learning Representations (ICLR), 2018. [188] L. Schott, J. Rauber, M. Bethge, and W. Brendel, “Towards thefirst adversarially robust neural network model on mnist,” In SeventhInternational Conference on Learning Representations (ICLR 2019),pp. [192] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable arefeatures in deep neural networks?” in Advances in neural informationprocessing systems, 2014, pp. Pesteie, C. R. Guttmann, F.-E. de Leeuw, C. M. Tempany, B. vanGinneken et al., “Transfer learning for domain adaptation in mri:Application in brain lesion segmentation,” in International Conferenceon Medical Image Computing and Computer-Assisted Intervention.Springer, 2017, pp. [194] A. Madani, M. Moradi, A. Karargyris, and T. Syeda-Mahmood, “Semi-supervised learning with generative adversarial networks for chest X-ray classification with ability of data domain adaptation,” in 2018 IEEE15th International Symposium on Biomedical Imaging (ISBI 2018).IEEE, 2018, pp. [197] F. Mahmood, R. Chen, and N. J. Durr, “Unsupervised reverse domainadaptation for synthetic medical images via adversarial training,” IEEEtransactions on medical imaging, vol. [198] J. Xu, L. Xiao, and A. M. Lo´pez, “Self-supervised domain adaptationfor computer vision tasks,” IEEE Access, vol. Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering25[199] J. Wiens, S. Saria, M. Sendak, M. Ghassemi, V. X. Liu, F. Doshi-Velez,K. Jung, K. Heller, D. Kale, M. Saeed et al., “Do no harm: a roadmapfor responsible machine learning for health care,” Nature medicine,vol. [201] X. Jia, L. Ren, and J. Cai, “Clinical implementation of ai technologieswill require interpretable ai models,” Medical physics, 2019. Samek, “On pixel-wise explanations for non-linear classifier deci-sions by layer-wise relevance propagation,” PloS one, vol. using machine learning to design interpretable decision-support systems,” Machine Learning for Health (ML4H) Workshop atNeurIPS, 2018. [204] A. Alqaraawi, M. Schuessler, P. Weiß, E. Costanza, and N. Berthouze,“Evaluating saliency map explanations for convolutional neural net-works: a user study,” in Proceedings of the 25th International Confer-ence on Intelligent User Interfaces, 2020, pp. [205] H. Li, Y. Tian, K. Mueller, and X. Chen, “Beyond saliency: understand-ing convolutional neural networks from saliency prediction on layer-wise relevance propagation,” Image and Vision Computing, vol. [206] Y. Halpern, S. Horng, Y. Choi, and D. Sontag, “Electronic medicalrecord phenotyping using the anchor and learn framework,” Journalof the American Medical Informatics Association, vol. Dickerson et al., “Electronic health records based phenotyping innext-generation clinical trials: a perspective from the nih health caresystems collaboratory,” Journal of the American Medical InformaticsAssociation, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 47
    },
    {
        "text": "[168]. [70] J. [71] H.-Y. [85] J. [88] X. [112] Y. [149] Z. [180] Y.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 48
    },
    {
        "text": "e198–e199, 2019. e232–e242, 2019. e157–e159,2019. e226–e231, 2013.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 49
    },
    {
        "text": "[3] M. Anthimopoulos, S. Christodoulidis, L. Ebner, A. Christe, andS. [5] J. Schlemper, J. Caballero, J. V. Hajnal, A. Van Ginneken, N. Karsse-meijer, G. Litjens, J. [11] P. Rajpurkar, J. Irvin, K. Zhu, B. Yang, H. Mehta, T. Duan, D. Ding,A. [12] V. Gulshan, L. Peng, M. Coram, M. C. Stumpe, D. Wu,A. Narayanaswamy, S. Venugopalan, K. Widner, T. Madams,J. [30] W. Bai, O. Oktay, M. Sinclair, H. Suzuki, M. Rajchl, G. Tarroni,B. [33] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. VanDen Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam,M. [39] T. Zheng, W. Xie, L. Xu, X. He, Y. Zhang, M. You, G. Yang, andY. [41] S. M. Anwar, M. Majid, A. Qayyum, M. Awais, M. Alnowami, andM. [45] K. Sirinukunwattana, S. e Ahmed Raza, Y.-W. Tsang, D. R. Snead,I. [46] H. Wang, A. C. Roa, A. N. Basavanhally, H. L. Gilmore, N. Shih,M. [52] F. Milletari, N. Navab, and S.-A. [53] M. H. Hesamian, W. Jia, X. [54] H. Chen, Y. Zhang, M. K. Kalra, F. Lin, Y. Chen, P. Liao, J. Zhou, andG. [60] D. Shen, G. Wu, and H.-I. [62] J. Zech, M. Pain, J. Titano, M. Badgeley, J. Schefflein, A. Su, A. Costa,J. [65] Y. Xue, T. Xu, L. R. Long, Z. Xue, S. Antani, G. R. Thoma, andX. Huang, H.-Y. [77] O. Ren, A. E. Johnson, E. P. Lehman, M. Komorowski, J. Aboab,F. A. Li, A. Tai, D. W. Arthur, T. A. Buchholz, S. Macdonald,L. [96] T. J. Pollard, I. Chen, J. Wiens, S. Horng, D. Wong, M. Ghassemi,H. [99] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. [100] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. [102] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Sˇrndic´, P. Laskov,G. [107] S.-K. Kim, C. Y. Yeun, E. Damiani, and N.-W. [111] A. Mohsin, A. Zaidan, B. Zaidan, S. A. bin Ariffin, O. Albahri,A. [122] D. Malathi, R. Logesh, V. Subramaniyaswamy, V. Vijayakumar, andA. [129] O. Choudhury, A. Gkoulalas-Divanis, T. Salonidis, I. Sylla, Y. Park,G. [131] L. Faes, S. K. Wagner, D. J. Fu, X. Liu, E. Korot, J. R. Ledsam, T. Back,R. [134] M. Ghassemi, T. Naumann, P. Schulam, A. L. Beam, I. Y. Chen, andR. [142] K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan,S. [146] O. Ohrimenko, F. Schuster, C. Fournet, A. Mehta, S. Nowozin,K. [148] R. Kunkel, D. L. Quoc, F. Gregor, S. Arnautov, P. Bhatotia, andC. [156] N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, andU´. [158] H. B. McMahan, G. Andrew, U. Erlingsson, S. Chien, I. Mironov,N. [164] G. Hinton, O. Vinyals, and J. [185] F. Tramer, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, andP. [193] M. Ghafoorian, A. Mehrtash, T. Kapur, N. Karssemeijer, E. Marchiori,M. [202] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. Mu¨ller, andW. [207] R. L. Richesson, W. E. Hammond, M. Nahm, D. Wixted, G. E.Simon, J. G. Robinson, A. E. Bauck, D. Cifelli, M. M. Smerek,J.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 50
    },
    {
        "text": "10 620–10 626, 2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 51
    },
    {
        "text": "59–67, 2018.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 52
    },
    {
        "text": "308–318.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 53
    },
    {
        "text": "[157] Y.-X.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 54
    },
    {
        "text": "The fundamentalproblem in medical image reconstruction is to acceleratethe inherently slow data acquisition process, which isan interesting ill-posed inverse problem in which wewant to determine the system’s input given its output.Many important medical imaging modalities require alot of time for reconstructing an image from the rawdata samples, e.g., MRI and CT.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 55
    },
    {
        "text": "Papernot, and P. Kairouz, “A general approach to adding differentialprivacy to iterative training procedures,” NeurIPS 2018 workshop onPrivacy Preserving Machine Learning, 2018.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 56
    },
    {
        "text": "IEEE, 2017, pp.385–394.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 57
    },
    {
        "text": "[160] F. McSherry and K. Talwar, “Mechanism design via differential pri-vacy.” in FOCS, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 58
    },
    {
        "text": "7, 2007, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 59
    },
    {
        "text": "14 2009, uS Patent7,562,071.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 60
    },
    {
        "text": "Dean, “Distilling the knowledge in aneural network,” Deep Learning Workshop, NIPS, 2014.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 61
    },
    {
        "text": "3–14.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 62
    },
    {
        "text": "[167] G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer, “Re-luplex: An efficient SMT solver for verifying deep neural networks,” inInternational Conference on Computer Aided Verification.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 63
    },
    {
        "text": "7717–7728.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 64
    },
    {
        "text": "10 159–10 169.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 65
    },
    {
        "text": "[56], however,their use in actual clinical applications is very limited[57].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 66
    },
    {
        "text": "[Online].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 67
    },
    {
        "text": "Available:https://openreview.net/forum?id=rJUYGxbCW[181] G. Jin, S. Shen, D. Zhang, F. Dai, and Y. Zhang, “APE-GAN:adversarial perturbation elimination with GAN,” in ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and SignalProcessing (ICASSP).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 68
    },
    {
        "text": "3842–3846.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 69
    },
    {
        "text": "To facilitate the surgical spinal screw implant ortumor removal, image registration is usually applied inspinal surgery or neurosurgery for the localization ofspinal bony landmark or a tumor, respectively.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 70
    },
    {
        "text": "[189] P. Schulam and S. Saria, “What-if reasoning with counterfactualgaussian processes,” History, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 71
    },
    {
        "text": "[190] R. C. Sato and G. T. K. Sato, “Probabilistic graphic models appliedto identification of diseases,” Einstein (Sa˜o Paulo), vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 72
    },
    {
        "text": "[191] C. Glymour, K. Zhang, and P. Spirtes, “Review of causal discoverymethods based on graphical models,” Frontiers in Genetics, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 73
    },
    {
        "text": "Varioussimilarity metrics and reference points are calculated toalign the sensed image with the reference image.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 74
    },
    {
        "text": "3320–3328.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 75
    },
    {
        "text": "1038–1042.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 76
    },
    {
        "text": "[195] C. Wachinger, M. Reuter, A. D. N. Initiative et al., “Domain adaptationfor alzheimer’s disease diagnostics,” Neuroimage, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 77
    },
    {
        "text": "470–479, 2016.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 78
    },
    {
        "text": "[196] G. Wilson and D. J. Cook, “A survey of unsupervised deep domainadaptation,” arXiv preprint arXiv:1812.02849, 2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 79
    },
    {
        "text": "9, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 80
    },
    {
        "text": "[200] S. Latif, A. Qayyum, M. Usama, J. Qadir, A. Zwitter, and M. Shahzad,“Caveat emptor: The risks of using big data for human development,”IEEE Technology and Society Magazine, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 81
    },
    {
        "text": "7,p.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 82
    },
    {
        "text": "e0130140, 2015.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 83
    },
    {
        "text": "[203] O. Lahav, N. Mastronarde, and M. van der Schaar, “What is in-terpretable?",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 84
    },
    {
        "text": "275–285.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 85
    },
    {
        "text": "Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering6tion diffeomorphic metric mapping (LDDMM) model forpatch-wise prediction strategy.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 86
    },
    {
        "text": "e2, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 87
    },
    {
        "text": "[208] D. Belgrave, J. Henderson, A. Simpson, I. Buchan, C. Bishop, andA.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 88
    },
    {
        "text": "Custovic, “Disaggregating asthma: big investigation versus bigdata,” Journal of Allergy and Clinical Immunology, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 89
    },
    {
        "text": "He haspublished more than 100 peer-reviewed articles atvarious high-quality research venues including morethan 50 impact-factor journal publications at top international research journalsincluding IEEE Communication Magazine, IEEE Journal on Selected Areas inCommunication (JSAC), IEEE Communications Surveys and Tutorials (CST),and IEEE Transactions on Mobile Computing (TMC).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 90
    },
    {
        "text": "In [59], a CNN based regression approachfor 2D/3D image registration is presented that addressestwo fundamental limitations of existing intensity-basedimage registration methods, i.e., small capture range andslow computation.• Retrieval: The recent era has witnessed the revolutionof digital interventions from the large-scale image andvideo collections to big data.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 91
    },
    {
        "text": "He was awarded thehighest national teaching award in Pakistan—the higher education commis-sion’s (HEC) best university teacher award—for the year 2012-2013.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 92
    },
    {
        "text": "He hasbeen appointed as ACM Distinguished Speaker for a three-year term startingfrom 2020.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 93
    },
    {
        "text": "He is a senior member of IEEE and ACM.Muhammad Bilal Dr Muhammad Bilal is AssociateProfessor of Big Data and Artificial Intelligence(AI) at Big Data Laboratory, University of the Westof England (UWE), Bristol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 94
    },
    {
        "text": "Tabular, Vision andSequence) were operationalised in conjunction withBig Data, Scientific Visualisation, and GIS for au-tomating non-trivial planning and execution tasksin Megaprojects.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 95
    },
    {
        "text": "His inclinationin these areas technologies is for solving critical real-life problems relatedto workers’ productivity and efficiency through disruptive innovations anddigital transformations.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 96
    },
    {
        "text": "He has also led the development of several large-scalesoftware solutions pertaining to financials and healthcare (PACS radiology).Dr Bilal has vast expertise in designing and executing collaborative researchdevelopment projects.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 97
    },
    {
        "text": "So far, he has completed RD projects of £3.7 Million atBig Data Lab in collaboration with leading UK businesses.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 98
    },
    {
        "text": "Currently, Dr Bilalis leading Real-Time Emissions Sensing (REVIS) project (£1.79 Million) thatinvolves IoT, GIS, Big Data, Stream Analytics and Advanced Visualisations.He has also authored more than 50 research articles at high-impact journalsand international conferences.Ala Al-Fuqaha [S’00-M’04-SM’09] received Ph.D.degree in Computer Engineering and Networkingfrom the University of Missouri-Kansas City, KansasCity, MO, USA.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 99
    },
    {
        "text": "His research interestsinclude the use of machine learning in general anddeep learning in particular in support of the data-driven and self-driven management of large-scaledeployments of IoT and smart city infrastructure andservices, Wireless Vehicular Networks (VANETs), cooperation and spectrumaccess etiquette in cognitive radio networks, and management and planningof software defined networks (SDN).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 100
    },
    {
        "text": "He also served as chair, co-chair, and technical program committeemember of multiple international conferences including IEEE VTC, IEEEGlobecom, IEEE ICC, and IWCMC.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 101
    },
    {
        "text": "However, writing such reports is very chal-lenging in some scenarios, e.g., less experienced radiologistsand healthcare service providers in rural areas where thequality of healthcare services is not up to the mark.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 102
    },
    {
        "text": "On theother side, for experienced radiologists and pathologists, theprocess of preparing high-quality reports can be tedious andtime-consuming which can be exacerbated by a large numberof patients visiting daily.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 103
    },
    {
        "text": "Therefore, various researchers haveattempted to address this problem using natural languageprocessing (NLP) and ML techniques.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 104
    },
    {
        "text": "In [65], a novel multi-modal model utilizing CNN andlong short term memory (LSTM) network is developed forautomatic report generation.b) ML in Real-time Health Monitoring: Real-time mon-itoring of critical patients is crucial and is a key componentof the treatment process.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 105
    },
    {
        "text": "Then the outcomes are transmittedback to the device for appropriate action(s).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 106
    },
    {
        "text": "For instance, aframework having a similar system architecture is presentedin [66].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 107
    },
    {
        "text": "The system is developed by integrating mobile andcloud for monitoring of heart rate using PPG signals.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 108
    },
    {
        "text": "Various studies havehighlighted the potential of using predictive healthcare forthe timely treatment of diseases.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 109
    },
    {
        "text": "The system works byutilizing different functionalities including ML/DL, traditionalcomputer vision and image processing techniques and reliesheavily on the performance of these techniques.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 110
    },
    {
        "text": "IBM’s Wat-son is a classical example of CADx system developed byintegrating various techniques including ML.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 111
    },
    {
        "text": "In clinical medicine, RL can beused for providing optimal diagnosis and treatment for patientswith distinct characteristics [72].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 112
    },
    {
        "text": "Sepsis is a severe infection involvingorgan dysfunction and is a leading cause of mortality dueto expensive and suboptimal treatment.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 113
    },
    {
        "text": "The study concluded that simpleThis work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 114
    },
    {
        "text": "In a recent study, attention models areused for the management of ICUs forecasting tasks (such asdiagnosis, estimation, and prediction, etc.)",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 115
    },
    {
        "text": "by integrating clin-ical notes with multivariate and time-series measurements data[76].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 116
    },
    {
        "text": "According to Dr. Simon Wallace, clinicians spend50% of their time on clinical documentation and are highlydemotivated due to clinical workload, administrative tasks, andlack of leisure time [81].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 117
    },
    {
        "text": "Typically, they spend more time inpreparing clinical documentation as compared to interactingdirectly with patients.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 118
    },
    {
        "text": "In the literature, speech processing has beenused for the identification of disorders related to speech,e.g., vocal hyperfunction [82] and as well as disorders thatmanifest through speech, e.g., dementia [83].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 119
    },
    {
        "text": "Alzheimer’sdisease identification using linguistic features is presented in[84].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 120
    },
    {
        "text": "), which is in general often time-consuming and requires significant human efforts.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 121
    },
    {
        "text": "Let’s consider the example of oneof the widely used imagining modalities used to acquire high-resolution medical images, i.e., multishot MRI.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 122
    },
    {
        "text": "Theprocess of assigning labels to each data sample (e.g., medicalimage) is known as data annotation.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 123
    },
    {
        "text": "However, clinicians like expert radiologistsare rare professionals and hard to engage in secondary taskslike data annotation.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 124
    },
    {
        "text": "As a result, trainee staff (with littledomain expertise) or ML/DL automated algorithms are usuallyemployed during data labelling, which often leads to manyproblems such as coarse-grained labels, class imbalance, labelleakage, and misspecification.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 125
    },
    {
        "text": "A few major problemsimpacting the quality of data are described next.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 126
    },
    {
        "text": "(a) Limited and Imbalanced Datasets: The size of datasetsused for training ML/DL models is not up to the requiredscale.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 127
    },
    {
        "text": "Notably, most life-threating health conditions arenaturally rare and diagnosed once in many (thousandsto millions) patients.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 128
    },
    {
        "text": "are used for diversifying the trainingdata and increasing its size.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 129
    },
    {
        "text": "In addition, different trans-formation techniques are used for augmenting trainingdatasets, e.g., use of Gaussian for data augmentation [90],[91].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 130
    },
    {
        "text": "(c) Class Imbalance and Bias: Class imbalance is yet anotherproblem that arises in the supervised ML/DL which refersto the fact that the distribution of samples among classesis not uniform.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 131
    },
    {
        "text": "Various approaches have been proposed inthe literature to address class imbalance problems.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 132
    },
    {
        "text": "Theseapproaches are discussed in the next section.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 133
    },
    {
        "text": "(d) Sparsity: Data sparsity, i.e., missing values are commonin real-world data that arise due to various reasons (e.g.,unmeasured and unreported samples, etc.).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 134
    },
    {
        "text": "Improperor incomplete training refers to the situations when the ML/DLmodel is trained with improper parameters, e.g., learning rate,epochs, batch size.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 135
    },
    {
        "text": "and as well as life-This work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 136
    },
    {
        "text": "Therefore, ensuring the security and integrity of theML/DL systems is of paramount importance for such criticalapplications.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 137
    },
    {
        "text": "Therefore, ensuring the ro-bustness of the system while considering fairness and account-ability is necessary for the deployment phase.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 138
    },
    {
        "text": "The followingare the major vulnerabilities that can be encountered in the de-ployment phase of ML/DL systems.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 139
    },
    {
        "text": "Whereas, security issues(e.g., adversarial attacks) are discussed in the next section.Distribution Shifts: Distributions shifts are very much ex-pected in realistic healthcare settings, for example, let’s con-sider different imaging centers and DL models trained onimages of one domain (imaging center) are subsequentlydeployed on different domain images.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 140
    },
    {
        "text": "The simplest way to avoid missingvalues is to ignore them completely while doing analysisbut it cannot be done without knowing their relationshipswith already observed or unobserved data.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 141
    },
    {
        "text": "Using the missingobservations for training ML/DL models, on the other hand,leads to two well-known problems, i.e., false positives (ahealthy person is diagnosed with a disease) and false negatives(a patient is identified as healthy).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 142
    },
    {
        "text": "If the attacker does not have access tothe training data, the attacker can realize an exploratory attack,e.g., consider a disease classification problem, the adversarycan exploit query-response pairs to get intended behavior(i.e., misclassification in this case).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 143
    },
    {
        "text": "The third dimension describes the specificobjectives of the adversary.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 144
    },
    {
        "text": "Alternatively,the addition of new samples might be relatively easy, how-ever, any such consequences hinder the applicability of theML/DL systems.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 145
    },
    {
        "text": "They identified a subgroup ofadversarial patients and empirically validated that patients withidentical predictive features can have significantly differentindividual treatment effects.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 146
    },
    {
        "text": "For example, anadversary can easily evade a face recognition system that isdeployed in a restricted area to restrain unintended access forsecurity purposes.C.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 147
    },
    {
        "text": "It is their role of diagnosing rare, subtle, and hid-den health conditions which occur once in millions.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 148
    },
    {
        "text": "Worst-case testingis a powerful tool that can provide enough evidence aboutThis work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 149
    },
    {
        "text": "Explicit measures should be taken to understand thetargeted user population and their sociological aspects beforecollecting data for building ML models.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 150
    },
    {
        "text": "If ethicalconcerns are not taken into account then the application of MLin realistic settings will have adverse results.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 151
    },
    {
        "text": "Forexample, asking a question about what will happen if a doctorprescribed treatment A instead of treatment B.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 152
    },
    {
        "text": "Such questionscannot be exploited through classical learning algorithms andto answer them we need to analyze the data from the lens ofcausality [115].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 153
    },
    {
        "text": "In general, this cannot be deemed as a limitation sinceprediction does not require any causal relation.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 154
    },
    {
        "text": "For exam-ple, most people with no health insurance are denied health-care services and if AI learns from that data, it will do thesame.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 155
    },
    {
        "text": "For example,radiology is not all about clinical imaging.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 156
    },
    {
        "text": "Other patient EMRdata is crucial for radiologists to derive the precise conclusionfor an imaging study.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 157
    },
    {
        "text": "Hyperplane decisionand Naive Bayes classifiers.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 158
    },
    {
        "text": "N/AZhu et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 159
    },
    {
        "text": "[62] Polynomial aggregation and multi-party random masking.SVM with nonlinear kernel.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 160
    },
    {
        "text": "N/AJagielski et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 161
    },
    {
        "text": "[120] Proposed an algorithm names asTRIM to defend poisoning attacks.Linear Regression Anticoagulant drug War-farinLiu et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 162
    },
    {
        "text": "[121] XMPP server and several mobiledevices.Proposed a DL framework, Human Activity Recogni-tionMalathi et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 163
    },
    {
        "text": "DNN 15 datasets from UCIrepository.Kim et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 164
    },
    {
        "text": "[125] Multi-party computation Principal component analysis(PCA)Genomics dataMin et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 165
    },
    {
        "text": "[126] Reinforcement learning (RL) basedprivacy aware offloading method.Reinforcement learning (RL) Data from medical IoTsensors.Beaulieu et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 166
    },
    {
        "text": "[127] Distributed ML using differentialprivacy.N/A The eICU and The CancerGenome Atlas databases.Zhu et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 167
    },
    {
        "text": "Three layer neural network.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 168
    },
    {
        "text": "Distribution shifts are frequent inthe medical domain, in particular, medical imagining wheredifferent protocols and parameter choices can result in imagesof significantly different distributions.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 169
    },
    {
        "text": "ML models are typicallytrained under the principle of empirical risk minimization(ERM) which provides good learning bounds and guaranteesif its assumptions are satisfied.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 170
    },
    {
        "text": "For instance, one of theforemost and strong assumptions is that both the trainingand test datasets are derived from a similar domain (i.e.,data distributions).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 171
    },
    {
        "text": "It has been reported in the literature thatin 2013, the majority of hospitals were using the ninth versionof the international classification of disease (ICD) system—even though a revised version (i.e., ICD-10) was releasedas early as 1990 [22].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 172
    },
    {
        "text": "Typically, the data is encrypted usingciphertext and public keys of the original data owners.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 173
    },
    {
        "text": "Alicewill send the function in the form of the garbled circuitalong with her input.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 174
    },
    {
        "text": "After obtaining the garbled versionof his input from Alice in oblivious fashion, Bob willuse his garbled input with the garbled circuit to get theresult of the required function and can share it with Alice,if required.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 175
    },
    {
        "text": "(c) Secret Sharing: The strategy of distributing secret amongmultiple parties while holding a “share” of the secretis known as secret sharing.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 176
    },
    {
        "text": "The secret can only bereconstructed when all individual shares are combined;otherwise, they are unuseful.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 177
    },
    {
        "text": "In some settings, the secretis reconstructed using t shares (where t is a thresholdvalue) that will not require all shares to be combined.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 178
    },
    {
        "text": "Authors used a multi-secret sharingscheme for transmitting audio-visual data collected fromusers using edge devices to the cloud where a CNN andsparse autoencoder were applied for feature extractionand support vector machine (SVM) was used for emotionrecognition.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 179
    },
    {
        "text": "(d) Secure Processors: Secure processors were originallydeveloped by rogue software to ensure the confidentialityand integrity of sensitive code from unauthorized accessat higher privilege levels.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 180
    },
    {
        "text": "For instance, Ohrimenko et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 181
    },
    {
        "text": "devel-oped an SGX-processor-based data oblivious system fork-mean clustering, decision trees, SVM, and matrix fac-torization [146].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 182
    },
    {
        "text": "The key idea was to enable collaborationbetween multiple data owners running the ML task on anThis work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 183
    },
    {
        "text": "Whereas, compos-ability enables modularity of the algorithmic design, i.e., whenindividual components are differentially private.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 184
    },
    {
        "text": "Robustnessto auxiliary information means that the privacy of the systemwill not be affected by the use of any side’s information thatis known to the adversary.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 185
    },
    {
        "text": "In FL, ashared ML model is built using distributed data from multipledevices where each device trains the model using its local dataand then shares the model parameters with the central modelwithout sharing its actual data.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 186
    },
    {
        "text": "An FL-based decentralizedscheme using iterative cluster primal-dual splitting (cPDS)algorithm to predict hospitalization requiring patients usinglarge-scale EHR of heart-related diseases is presented in [151].In [152], simple vanilla, U-shaped, and vertically partitioneddata-based configurations for split learning DL models are pre-sented.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 187
    },
    {
        "text": "as a method fortransferring the knowledge from a larger model to asmaller one [164].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 188
    },
    {
        "text": "The notion of network distillationwas then adopted by Papernot et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 189
    },
    {
        "text": "The authors used the predicted labels of the firstmodel as the labels of the input sample to the originalDL model.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 190
    },
    {
        "text": "This strategy increases the robustness of theDL model to considerably small perturbations.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 191
    },
    {
        "text": "In [167],such a method is proposed that uses ReLU activation andThis work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 192
    },
    {
        "text": "The keyaspect of this method is that it identifies critical neuronsfor the individual task by initiating a bi-directional cor-respondence reasoning between the model’s parametersand its attributes.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 193
    },
    {
        "text": "The activation values of the identifiedneurons are then increased to augment the reasoning partand activation values of other neurons are decreased tomask the uninterpretable part.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 194
    },
    {
        "text": "In addition, unsupervised learning can beThis work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 195
    },
    {
        "text": "Thetransformed samples have no harmful effect on the infer-ence of deep models.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 196
    },
    {
        "text": "Toreduce the available feature space to an adversary, authorscombined heterogeneous feature vectors in the originalfeature space into a single space.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 197
    },
    {
        "text": "The feature squeezingwas performed at two levels: (1) smoothing the spatialdomain using local and non-local operations and (2)minimizing color bit depth.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 198
    },
    {
        "text": "However, in a later study, theaforementioned defense method was found to be lesseffective [177].• Features Masking: The method of feature masking wasproposed by Gao et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 199
    },
    {
        "text": "Song et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 200
    },
    {
        "text": "[98], however,in the same study the authors presented an alternativehypothesis of ensemble training and articulated that gen-erative training is not sufficient.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 201
    },
    {
        "text": "Used three datasets, i.e., MNIST,SVHN, and notMNISTMNIST (100%), SVHN(∼90%), and notMNIST(100%).using classical models.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 202
    },
    {
        "text": "For instance, the Gaussian processesbased counterfactual causal model has been presented in [189]and in a similar study, authors introduced the counterfactualGaussian process (CGP) for predicting counterfactual futureprogression and argued that counterfactual model can pro-vide reliable decision support [114].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 203
    },
    {
        "text": "A comprehensive review ofgraphical causal models can be found in this recent study[191].D.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 204
    },
    {
        "text": "The aim is to transfer knowledge learned by themodel from one domain (data distribution) to the other domain[192].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 205
    },
    {
        "text": "Citation information: DOI 10.1109/RBME.2020.3013489, IEEE Reviewsin Biomedical Engineering18visual content (e.g., a set of images) according to knowntransformations (e.g., rotation) and then the model istrained to predict such transformations that serve as labelsfor the pretext tasks [198].E.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 206
    },
    {
        "text": "but their limitedadoption in actual clinical settings indicates that these methodsare not yet optimal and not ready for clinical deployment.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 207
    },
    {
        "text": "Ina recent study [199], Wiens et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 208
    },
    {
        "text": "Sometimes, ML methods can beneither supervised nor unsupervised, i.e., where the trainingdata contains both labeled and unlabelled samples.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 209
    },
    {
        "text": "(Adopted from [199])Stakeholder Category ExamplesKnowledge expertsClinical experts, e.g., radiologist and derma-tologists.Health information and technology expertsML researchers, e.g., ML engineers and datascientists.Implementation expertsDecision-makersInstitutional leadershipHospital administratorsState and federal governmentRegulatory agenciesUsersPhysiciansNursesLaboratory techniciansPatientsCaretakers, e.g., friends and family.F.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 210
    },
    {
        "text": "Methodsutilizing such data are known as semi-supervised learningmethods.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 211
    },
    {
        "text": "These black-box methods fail at providing rational or insights as wellas at explaining their learning behavior and thought processfor making predictions [200].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 212
    },
    {
        "text": "This can eventually help in the smoothdeployment and functionality of ML/DL systems in realisticsettings.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 213
    },
    {
        "text": "For instance, Bach etal.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 214
    },
    {
        "text": "Similarly, for interpretation ofclassifiers’ predictions, Ribeiro et al.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 215
    },
    {
        "text": "With such proliferation, there is a pressingneed for pushing ML models training and inference on edgedevices.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 216
    },
    {
        "text": "This introduces unique challenges such as limitedhardware and processing capabilities, etc.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 217
    },
    {
        "text": "Moreover, this iscrucial for portal medical devices that are utilized for patientsin critical care as they cannot be moved to fixed medicalequipment in the hospital.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 218
    },
    {
        "text": "The research on enabling ML onedge devices (a.k.a fog) is in the early stages of developmentand requires further attention from the research community.The development of this field will enable to monitor patients ina critical situation and eventually enable continuous behavioralmonitoring for improving individuals’ life-style and timelydetection of diseases.C.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 219
    },
    {
        "text": "Another important aspect is devisingtrue validation sets that will evaluate the performance of theML/DL models and expose the limitations of these models.Therefore, manual annotation of samples into respective cate-gories is time consuming, costly, and a tidy process.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 220
    },
    {
        "text": "In general,for developing ML/DL models, it is assumed that completetraining and validation datasets are centrally available andeasily accessible.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 221
    },
    {
        "text": "Therefore, there is an increasing demand todevelop methods for distributed data management and ML.E.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 222
    },
    {
        "text": "Such discrimination mainlyThis work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 223
    },
    {
        "text": "On the other hand,accountability property is concerned with the interpretationof the predictions.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 224
    },
    {
        "text": "Properly designed experimentsare also necessary for deriving causal explanations.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 225
    },
    {
        "text": "Finally,we presented different open research problems that requirefurther investigation.ACKNOWLEDGEMENTThe publication of this article was funded by the QatarNational Library (QNL).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 226
    },
    {
        "text": "The statements made herein aresolely the responsibility of the authors.REFERENCES[1] S. Latif, J. Qadir, S. Farooq, and M. Imran, “How 5G wireless(and concomitant technologies) will revolutionize healthcare?” FutureInternet, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 227
    },
    {
        "text": "63,pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 228
    },
    {
        "text": "35, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 229
    },
    {
        "text": "[8] K. Bourzac, “The computer will see you now,” Nature, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 230
    },
    {
        "text": "502, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 231
    },
    {
        "text": "S92–S94, 2013.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 232
    },
    {
        "text": "45, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 233
    },
    {
        "text": "ML/DLmethods help to effectively analyze this data for actionableinsights.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 234
    },
    {
        "text": "1791–1793, 2018.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 235
    },
    {
        "text": "[10] B. E. Bejnordi, M. Veta, P. J.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 236
    },
    {
        "text": "Van Diest, B.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 237
    },
    {
        "text": "A.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 238
    },
    {
        "text": "Van Der Laak, M. Hermsen, Q. F. Manson,M.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 239
    },
    {
        "text": "22, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 240
    },
    {
        "text": "2199–2210, 2017.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 241
    },
    {
        "text": "Cuadros et al., “Development and validation of a deep learningalgorithm for detection of diabetic retinopathy in retinal fundus pho-tographs,” Jama, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 242
    },
    {
        "text": "22, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 243
    },
    {
        "text": "[13] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau,and S. Thrun, “Dermatologist-level classification of skin cancer withdeep neural networks,” Nature, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 244
    },
    {
        "text": "Adepiction of these sources of data is shown in Figure 2.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 245
    },
    {
        "text": "514–525, 2014.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 246
    },
    {
        "text": "80, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 247
    },
    {
        "text": "[21] A. Shafahi, W. R. Huang, M. Najibi, O. Suciu, C. Studer, T. Dumitras,and T. Goldstein, “Poison frogs!",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 248
    },
    {
        "text": "6103–6113.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 249
    },
    {
        "text": "6433, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 250
    },
    {
        "text": "[23] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: Asurvey,” ACM computing surveys (CSUR), vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 251
    },
    {
        "text": "16–17, 2013.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 252
    },
    {
        "text": "[25] K. Polat and S. Gu¨nes¸, “Prediction of hepatitis disease based on prin-cipal component analysis and artificial immune recognition system,”Applied Mathematics and computation, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 253
    },
    {
        "text": "3–21.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 254
    },
    {
        "text": "For instance, ML models have been largelydeveloped for the identification and classification of differentThis work is licensed under a Creative Commons Attribution 4.0 License.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 255
    },
    {
        "text": "[27] M. N. Sohail, J. Ren, and M. Uba Muhammad, “A euclidean groupassessment on semi-supervised clustering for healthcare clinical impli-cations based on real-life data,” International journal of environmentalresearch and public health, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 256
    },
    {
        "text": "16, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 257
    },
    {
        "text": "Glocker, A.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 258
    },
    {
        "text": "253–260.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 259
    },
    {
        "text": "[31] R. S. Sutton, A. G. Barto et al., Introduction to reinforcement learning.MIT press Cambridge, 1998, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 260
    },
    {
        "text": "4.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 261
    },
    {
        "text": "[32] H.-C. Kao, K.-F. Tang, and E. Y. Chang, “Context-aware symptomchecking for disease diagnosis using hierarchical reinforcement learn-ing,” in Thirty-Second AAAI Conference on Artificial Intelligence, 2018.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 262
    },
    {
        "text": "Lanctot et al., “Mastering the game of go with deep neural networksand tree search,” nature, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 263
    },
    {
        "text": "529, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 264
    },
    {
        "text": "[35] P. Afshar, A. Mohammadi, and K. N. Plataniotis, “Brain tumor typeclassification via capsule networks,” in 2018 25th IEEE InternationalConference on Image Processing (ICIP).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 265
    },
    {
        "text": "3129–3133.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 266
    },
    {
        "text": "97, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 267
    },
    {
        "text": "120–127, 2017.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 268
    },
    {
        "text": "[42] M. Lustig, D. L. Donoho, J. M. Santos, and J. M. Pauly, “Compressedsensing mri,” IEEE signal processing magazine, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 269
    },
    {
        "text": "241–246.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 270
    },
    {
        "text": "[44] Y. Chen, Y. Xie, Z. Zhou, F. Shi, A. G. Christodoulou, and D. Li,“Brain mri super resolution using 3d deep densely connected neuralnetworks,” in 2018 IEEE 15th International Symposium on BiomedicalImaging (ISBI 2018).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 271
    },
    {
        "text": "739–742.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 272
    },
    {
        "text": "Med.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 273
    },
    {
        "text": "Imaging, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 274
    },
    {
        "text": "[48] J. Antony, K. McGuinness, N. E. O’Connor, and K. Moran, “Quantify-ing radiographic knee osteoarthritis severity using deep convolutionalneural networks,” in 2016 23rd International Conference on PatternRecognition (ICPR).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 275
    },
    {
        "text": "[49] E. Kim, M. Corte-Real, and Z. Baloch, “A deep semantic mobileapplication for thyroid cytopathology,” in Medical Imaging 2016: PACSand Imaging Informatics: Next Generation and Innovations, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 276
    },
    {
        "text": "9789.International Society for Optics and Photonics, 2016, p.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 277
    },
    {
        "text": "97890A.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 278
    },
    {
        "text": "2998–3006.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 279
    },
    {
        "text": "234–241.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 280
    },
    {
        "text": "Finally, we provide insight into the current researchchallenges and promising directions for future research.I.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 281
    },
    {
        "text": "Wang, “Low-dose ct with a residual encoder-decoder convolutionalneural network,” IEEE transactions on medical imaging, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 282
    },
    {
        "text": "These modalitiesprovide important functional and anatomical information aboutdifferent body organs and play a crucial role in the detec-tion/localization and diagnosis of abnormalities.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 283
    },
    {
        "text": "[56] F. E.-Z.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 284
    },
    {
        "text": "1, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 285
    },
    {
        "text": "9375–9389, 2017.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 286
    },
    {
        "text": "19, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 287
    },
    {
        "text": "266, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 288
    },
    {
        "text": "570–580, 2018.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 289
    },
    {
        "text": "9049–9058.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 290
    },
    {
        "text": "[66] V. Jindal, “Integrating mobile and cloud for ppg signal selection tomonitor heart rate during intensive physical exercise,” in Proceedingsof the International Conference on Mobile Software Engineering andSystems.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 291
    },
    {
        "text": "36–37.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 292
    },
    {
        "text": "For instance, generating MRIimages is a quite lengthy process that typically requiresseveral minutes to produce a good quality image andto acquire detailed soft-tissue contrast, patients have toremain still and straight as much as possible.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 293
    },
    {
        "text": "Ma, Z. Zhou, S. Wu, Y.-L. Wan, and P.-H. Tsui, “A computer-aided diagnosis scheme for detection of fatty liver in vivo based onultrasound kurtosis imaging,” Journal of medical systems, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 294
    },
    {
        "text": "1,p.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 295
    },
    {
        "text": "33, 2016.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 296
    },
    {
        "text": "[72] Z. Zhang et al., “Reinforcement learning in clinical medicine: amethod to optimize dynamic treatment regime over time,” Annals oftranslational medicine, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 297
    },
    {
        "text": "14, 2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 298
    },
    {
        "text": "[75] C.-S. Rau, P.-J.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 299
    },
    {
        "text": "Kuo, P.-C. Chien, C.-Y.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 300
    },
    {
        "text": "Hsieh, and C.-H. Hsieh, “Mortality prediction in patients with isolated moderate andsevere traumatic brain injury using machine learning models,” PloSone, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 301
    },
    {
        "text": "[76] H. Song, D. Rajan, J. J. Thiagarajan, and A. Spanias, “Attend anddiagnose: Clinical time series analysis using attention models,” inThirty-Second AAAI Conference on Artificial Intelligence, 2018.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 302
    },
    {
        "text": "Therefore,any movement of the subject can introduce artifacts inthe acquired image.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 303
    },
    {
        "text": "[78] A. K. Jha, “The promise of electronic records: around the corner ordown the road?” Jama, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 304
    },
    {
        "text": "8, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 305
    },
    {
        "text": "880–881, 2011.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 306
    },
    {
        "text": "Moreover, some sort of mechanicalnoise is also sometimes introduced in the output image.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 307
    },
    {
        "text": "331–336, 2017.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 308
    },
    {
        "text": "[Online].",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 309
    },
    {
        "text": "Available: https://www.hisa.org.au/slides/hic18/wed/SimonWallace.pdf[82] M. Ghassemi, J. H. Van Stan, D. D. Mehta, M. Zan˜artu, H. A.Cheyne II, R. E. Hillman, and J. V. Guttag, “Learning to detect vocalhyperfunction from ambulatory neck-surface acceleration features: Ini-tial results for vocal fold nodules,” IEEE Transactions on BiomedicalEngineering, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 310
    },
    {
        "text": "61, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 311
    },
    {
        "text": "[83] C. Pou-Prom and F. Rudzicz, “Learning multiview embeddings for as-sessing dementia,” in Proceedings of the 2018 Conference on EmpiricalMethods in Natural Language Processing, 2018, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 312
    },
    {
        "text": "2812–2817.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 313
    },
    {
        "text": "[84] K. C. Fraser, J.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 314
    },
    {
        "text": "A. Meltzer, and F. Rudzicz, “Linguistic featuresidentify alzheimer’s disease in narrative speech,” Journal of Alzheimer’sDisease, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 315
    },
    {
        "text": "49, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 316
    },
    {
        "text": "407–422, 2016.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 317
    },
    {
        "text": "B. Andre, B. W. Bresnahan, M. Mossa-Basha, M. N. Hoff, C. P.Smith, Y. Anzai, and W. A. Cohen, “Toward quantifying the prevalence,severity, and cost associated with patient motion during clinical mrexaminations,” Journal of the American College of Radiology, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 318
    },
    {
        "text": "689–695, 2015.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 319
    },
    {
        "text": "[86] A. K. Manrai, G. Bhatia, J. Strymish, I. S. Kohane, and S. H. Jain,“Medicine’s uncomfortable relationship with math: calculating positivepredictive value,” JAMA internal medicine, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 320
    },
    {
        "text": "991–993, 2014.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 321
    },
    {
        "text": "1721–1730.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 322
    },
    {
        "text": "Super-resolution is yetanother powerful and impactful enhancement techniquefor medical images, e.g., MRI denoising [44].• Detection: The process of identifying specific diseasepatterns or abnormalities (e.g., tumor, cancer) in medicalimages is known as detection.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 323
    },
    {
        "text": "B.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 324
    },
    {
        "text": "Marks, J. M. Moran, L. J.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 325
    },
    {
        "text": "Pierce, R. Rabinovitch, A. Taghianet al., “Variability of target and normal structure delineation forbreast cancer radiotherapy: an rtog multi-institutional and multiobserverstudy,” International Journal of Radiation Oncology* Biology* Physics,vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 326
    },
    {
        "text": "73, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 327
    },
    {
        "text": "944–951, 2009.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 328
    },
    {
        "text": "[90] S. T. M. Ataky, J. de Matos, A. d. S. Britto Jr, L. E. Oliveira, andA.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 329
    },
    {
        "text": "L. Koerich, “Data augmentation for histopathological images basedon gaussian-laplacian pyramid blending,” IEEE International JointConference on Neural Networks (IJCNN 2020), Glasgow, UK, 2020.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 330
    },
    {
        "text": "In traditional clinicalpractice, such abnormalities are identified by expert ra-diologists or physicians that often require a lot of timeand effort.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 331
    },
    {
        "text": "[91] J. F. R. Rochac, L. Liang, N. Zhang, and T. Oladunni, “A gaussian dataaugmentation technique on highly dimensional, limited labeled data formulticlass classification using deep learning,” in 2019 Tenth Interna-tional Conference on Intelligent Control and Information Processing(ICICIP).",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 332
    },
    {
        "text": "145–151.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 333
    },
    {
        "text": "1807–1814.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 334
    },
    {
        "text": "Mattie, E. Lindmeer, and T. Panch, “Turning the crank for machinelearning: ease, at what expense?” The Lancet Digital Health, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 335
    },
    {
        "text": "B. Celik, andA.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 336
    },
    {
        "text": "B. Celik, andA.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 337
    },
    {
        "text": "1893–1905, 2014.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 338
    },
    {
        "text": "IGI Global, 2019, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 339
    },
    {
        "text": "73–108.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 340
    },
    {
        "text": "94 858–94 868, 2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 341
    },
    {
        "text": "Sun, F. P.-W.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 342
    },
    {
        "text": "Lo, and B.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 343
    },
    {
        "text": "183 339–183 355, 2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 344
    },
    {
        "text": "[114] P. Schulam and S. Saria, “Reliable decision support using counterfac-tual models,” in Advances in Neural Information Processing Systems,2017, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 345
    },
    {
        "text": "1697–1708.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 346
    },
    {
        "text": "Over the past few years, DL has provided stateof the art performance in different domains—e.g., computervision, text analytics, and speech processing, etc.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 347
    },
    {
        "text": "[117] A. Khademi, S. Lee, D. Foley, and V. Honavar, “Fairness in algorithmicdecision making: An excursion through the lens of causality,” in TheWorld Wide Web Conference.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 348
    },
    {
        "text": "2907–2914.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 349
    },
    {
        "text": "[118] N. Kilbertus, M. R. Carulla, G. Parascandolo, M. Hardt, D. Janzing,and B. Scho¨lkopf, “Avoiding discrimination through causal reasoning,”in Advances in Neural Information Processing Systems, 2017, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 350
    },
    {
        "text": "656–666.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 351
    },
    {
        "text": "73,pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 352
    },
    {
        "text": "[124] M. Kim, Y.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 353
    },
    {
        "text": "15, no.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 354
    },
    {
        "text": "838–850, 2016.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 355
    },
    {
        "text": "The results obtained by this approach, asreported in the literature, are promising; however, a fewstudies have reported contradictory results.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 356
    },
    {
        "text": "[132] N. u. .",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 357
    },
    {
        "text": "3539–3550.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 358
    },
    {
        "text": "4, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 359
    },
    {
        "text": "1, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 360
    },
    {
        "text": "The process of segmentationdeals with the partitioning of an image into multiplenon-overlapping parts using a pre-defined criterion suchas intrinsic color, texture, and contrast, etc.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 361
    },
    {
        "text": "[141] D. Kahrobaei, A.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 362
    },
    {
        "text": "[143] M. S. Hossain and G. Muhammad, “Emotion recognition using secureedge and cloud computing,” Information Sciences, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 363
    },
    {
        "text": "504, pp.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 364
    },
    {
        "text": "589–601, 2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 365
    },
    {
        "text": "4324, 2015, p.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 366
    },
    {
        "text": "4325.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 367
    },
    {
        "text": "Various DL architectures are being proposed for thesegmentation of multi-modal images such as the brain,skin cancer, CT images, etc.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 368
    },
    {
        "text": "152 103–152 114, 2019.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 369
    },
    {
        "text": "[150] W. Huang, S. Zhou, Y. Liao, and H. Chen, “An efficient differentialprivacy logistic classification mechanism,” IEEE Internet of ThingsJournal, vol.",
        "paperTitle": "Secure and robust machine learning for healthcare: A survey",
        "doi": "10.1109/rbme.2020.3013489",
        "chunk_index_in_doc": 370
    },
    {
        "text": "Why? Why? Why? Why?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 0
    },
    {
        "text": "By default, Flask uses the Jinja2 templating engine, which facilitates dynamic HTML pages. To collect responses from participants, the Flask extension for the WTForms Python library was used. The Flask extension for the SQLAlchemy package was used to access the SQLite database to retrieve data, record responses, and track interface interactions. Flask: The Python micro framework for building web applications. https://github.com/pallets/flask. SQLAlchemy. SQLAlchemy: The Python SQL Toolkit and Object Relational Mapper. https://github.com/sqlalchemy/sqlalchemy.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1
    },
    {
        "text": "2. 3. 4. 2. 3. 5. 6. 3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 2
    },
    {
        "text": "............................................ 5 Figure 2. ................................................................................... 12 Figure 3. ...................................................................................................................................... 21 Figure 4. 25 Figure 5. 32 Figure 8. ........................... 35 Figure 9. ...................................................... 53 Figure 10. .............................................................. 65 Figure 11. .............................................................. 66 Figure 12. .............................................................. 66 Figure 13. .............................................................. 67 Figure 14. .............................................................. 67 Figure 15. ............................................. 68 xiii Figure 16. ................................................................. 86 Figure 20. ......................................................................................................... 104 Figure A1. ............ 124 Figure A2. ...................... 129 Figure A3. Figure 1. 12 Figure 2. 21 Figure 3. 25 Figure 4. Figure 5. Figure 6. Figure 7. Figure 8. Figure 9. 66 Figure 11. Figure 12. 67 Figure 13. Figure 14. 68 Figure 15. 2 Figure 16. Figure 17. 86 Figure 19. Figure 20. Figure 21. Figure 22. Figure 24. 124 Figure A1. 129 Figure A2. Figure A3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 3
    },
    {
        "text": "137 Table A2. Table 3. Table 4. 52 Table 5. Table 6. Table 7. Table 8. Table 9. 76 Table 10. Table 11. 81 Table 12. 94 Table 13. Table 15. 99 Table 17. Table 19. Table A1.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 4
    },
    {
        "text": "94. 95. 100. 101. 102. 103. 104. 105. 106. 107. 110. 115. 121. 124. 125. 127. 128. 129. 130. 131. 132. 133. 134. 136. 142.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 5
    },
    {
        "text": "23. 31. 34. 42. 43. 44. 45. 48. 49. 50. 51. 53. 55. 57. 58. 59. 63. 64. 65. 66. 67. 71. 72. 78. 79.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 6
    },
    {
        "text": "For categorical data, missing values were retained by simply 49 adding a “missing” category. Missing values were then retained by including a “missing” category along with the discretized bins. It is important to note that all numeric features were discretized using the minimum-description-length criterion discretization method101 and missing data were treated as separate categories. It should be noted that missing values were imputed by simple random sampling from known data and continuous variables were discretized using the entropy minimization heuristic method.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 7
    },
    {
        "text": "Los Angeles, CA, USA; 2019. Los Angeles, CA, USA; 2019. Melbourne, Australia; 2017. Trondheim, Norway; 2011.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 8
    },
    {
        "text": "Using the system would enable me to accomplish tasks more quickly. Using the system would make it easier to do my job. Using the system would increase my productivity. I would find the system useful in my job. My interaction with the system would be clear and understandable. I would find the system easy to use. It would be easy for me to become skillful at using the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 9
    },
    {
        "text": " What would you change about any of these displays?  What changes would make a display easier to understand?  What would you change about any of these displays?  What changes would make a display easier to understand? Applicable to participant suggestions for new or alternative displays.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 10
    },
    {
        "text": "Verification includes examining how decisions/suggestions are made by the system to ensure it is operating as expected. Improvement can be closely tied to verification and covers activities related to improving the system performance and efficiency. Verification includes examining how decisions/suggestions are made by the system to ensure it is operating as expected, which may include activities such as detecting biases, finding and debugging errors, and ensuring that system reasoning aligns with domain knowledge (justifiability). Improvement covers activities related to improving the system performance and efficiency, which may include things such as incorporating domain knowledge to reduce biases in or improve generalization of the system, comparing and selecting between models, and improving system response times.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 11
    },
    {
        "text": "Model descriptions and performances ....................................................................... 52 Table 6. In: 2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO). IEEE; 2018:0210-0215. doi:10.23919/MIPRO.2018.8400040 29. IEEE; 2018:1-8. doi:10.1109/CIG.2018.8490433 33. IEEE; 2011:1-10. doi:10.1109/HICSS.2011.1 40. IEEE; 2018:152-162. doi:10.1109/ICHI.2018.00025 165 84. IEEE; 2017:3869-3876. doi:10.1109/BigData.2017.8258391 87.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 12
    },
    {
        "text": "Mock-up 1-1 prediction and explanation. Mock-up 1-2 prediction and explanation. Mock-up 1-3 prediction and explanation. Mock-up 2-1 prediction and explanation. Mock-up 2-2 prediction and explanation. Mock-up 1-1 prediction and explanation. Mock-up 1-2 prediction and explanation. Mock-up 1-3 prediction and explanation. Mock-up 2-1 prediction and explanation. Mock-up 2-2 prediction and explanation. Mock-up Review Individual Mock-up Question Guide  How would you summarize why the model made this prediction?  What information is missing that might help you interpret this prediction more effectively or efficiently?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 13
    },
    {
        "text": "Calculation of the Shapley value, ϕ, for the presence of fatigue. (𝑀−|𝑆|−1)!𝑀!𝑆⊆𝑆𝑎𝑙𝑙\\{𝑖}[𝑓𝑥(𝑆 ∪ {𝑖}) − 𝑓𝑥(𝑆)] (4) where 𝜙𝑖 corresponds to the Shapley value of the 𝑖-th feature, 𝑓 is the original prediction model, 𝑥 is the prediction instance to be explained, 𝑆 is a subset of the set of all features except the 𝑖-th feature, |𝑆| is the number of features in the subset, 𝑀 is the number of simplified input features, and 𝑓𝑥(𝑆) = 𝑓(𝑥𝑆) where 𝑥𝑆 is equal to the values in 𝑥 for features in the set 𝑆 but are considered missing otherwise.75 As many prediction models do not support arbitrary patterns of missing input data, in practice 𝑓𝑥(𝑆) is estimated by computing its expected value on repeated evaluations of 𝑓𝑥(𝑆𝑎𝑙𝑙) where missing values are filled in using randomly selected samples from a training dataset.75 The 𝜙𝑖 of a feature can be interpreted as the change in the expected model prediction that occurs when a feature is observed versus unknown, averaged across all possible subsets and orderings of features. A walk-through of each part of the calculation of 𝜙 for the presence of fatigue is described below and shown in Figure A2. 128 To calculate 𝜙 for the presence of fatigue, it is first necessary to estimate the marginal contribution of “fatigue = present” for each possible feature subset that can include that feature. To estimate the marginal contribution of “fatigue = present” for this subset, model predictions are obtained when this feature value is observed and not observed (i.e., missing). When “fatigue = present” is observed, the model predicts a probability of 0.75. To get an estimate of what the model would predict if the value for fatigue was missing, a value for fatigue is randomly sampled from the training dataset. Assume a randomly sampled value of “fatigue = absent” and a model prediction of 0.60. Several repetitions of this sampling procedure can be performed, and the values can be averaged to obtain a better estimate of the model prediction when fatigue is missing. Then, an estimated marginal contribution of “fatigue = present” for this subset would be 0.75 – 0.60 = 0.15. By taking a weighted average of the marginal contributions for each subset, an estimate of 𝜙 for “fatigue = present” is obtained (Figure A2). Thus, the 𝜙 value of a feature provides an estimate of how much the feature changes the model prediction relative to the average prediction. Calculation of the Shapley value, ϕ, for the presence of fatigue. These estimates are obtained by filling in any missing feature values with randomly sampled values from a training dataset and obtaining the model prediction, then averaging the predictions from repeated runs of this procedure. Subtracting estimates of 𝑓𝑥(𝑆 ∪ {𝑓𝑎𝑡𝑖𝑔𝑢𝑒 = 𝑝𝑟𝑒𝑠𝑒𝑛𝑡}) and 𝑓𝑥(𝑆) for a subset gives us an estimate of the marginal contribution of the presence of fatigue for that subset.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 14
    },
    {
        "text": "Often applicable when \"seeking information on model development process\" code is used. Often applied with “explanation design” codes. Often applicable with \"learning\" & \"improvement\" codes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 15
    },
    {
        "text": "Wynants L, Collins GS, Van Calster B. Hoffman R, Miller T, Mueller ST, Klein G, Clancey WJ. Awad A, Bader-El-Den M, McNicholas J, Briggs J. Hall M, Frank E, Holmes G, Pfahringer B, Reutemann P, Witten IH. Jeffery AD, Novak LL, Kennedy B, Dietrich MS, Mion LC.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 16
    },
    {
        "text": "Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Zhu J, Liapis A, Risi S, Bidarra R, Youngblood GM. Wang D, Yang Q, Abdul A, Lim BY. Choi E, Bahadori MT, Kulas JA, Schuetz A, Stewart WF, Sun J. Valdes G, Luna JM, Eaton E, Simone CB, Ungar LH, Solberg TD. Johnson AEW, Ghassemi MM, Nemati S, Niehaus KE, Clifton DA, Clifford GD. Kannampallil TG, Jones LK, Patel VL, Buchman TG, Franklin A.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 17
    },
    {
        "text": "The training dataset was used to perform feature selection techniques and train models, while the test dataset was used to evaluate the models. 51 Predictive performance of the models was evaluated using the test dataset. A total of eight models were learned, comprising each combination of feature selection technique and model type (Table 5). Model performance measured by AUROC and AUPRC was comparable for all models, with the exception of the Naïve Bayes model using the IG feature selection approach, which had a very low AUPRC. were trained using WEKA.103 The best performing model was trained using all data sources, included 32 features, and achieved an AUROC of 0.806 on an independent test dataset. The learned model achieved performance comparable to the original best performing model, with an AUROC of 0.806 for the test dataset. The learned model exhibited comparable performance to the original best performing model, achieving an average AUROC of 0.925 with 10-fold cross-validation on the entire dataset. The WEKA Data Mining Software: An Update.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 18
    },
    {
        "text": "In: 24th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. In: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ’15. In: 13th International Joint Conference on Artificial Intelligence. Online Appendix for “Data Mining: Practical Machine Learning Tools and Techniques.” Fourth Edi. In: Proceedings of the 23rd International Conference on Machine Learning - ICML ’06. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 19
    },
    {
        "text": "Long Beach, CA, USA; 2017. http://arxiv.org/abs/1711.08037. Melbourne, Australia; 2017. http://arxiv.org/abs/1712.00547. New York, NY, USA; 2016. http://arxiv.org/abs/1606.03490. New York, NY, USA; 2016. http://arxiv.org/abs/1606.05685. Long Beach, CA, USA; 2017. http://arxiv.org/abs/1711.07414. New York, NY, USA; 2016. http://arxiv.org/abs/1606.05386. Barcelona, Spain; 2016. http://arxiv.org/abs/1611.05817. Barcelona, Spain; 2016. http://arxiv.org/abs/1608.05745. San Francisco, CA, USA: ACM; 2016:1135-1144. http://arxiv.org/abs/1602.04938. Barcelona, Spain; 2016. http://arxiv.org/abs/1611.07478. Long Beach, CA, USA; 2017:4765-4774. http://arxiv.org/abs/1705.07874.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 20
    },
    {
        "text": "November 2018. https://arxiv.org/pdf/1711.05791.pdf. October 2016. http://arxiv.org/abs/1610.09045. February 2017. http://arxiv.org/abs/1702.08608. November 2018. http://arxiv.org/abs/1811.11839. October 2017. http://arxiv.org/abs/1710.00794. July 2018. http://arxiv.org/abs/1807.06722. February 2018. http://arxiv.org/abs/1802.07810. May 2018. http://arxiv.org/abs/1806.00069. March 2018. http://arxiv.org/abs/1803.04263. August 2017. http://arxiv.org/abs/1708.08296. 2019. http://arxiv.org/abs/1905.05134. September 2018. http://arxiv.org/abs/1809.07424.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 21
    },
    {
        "text": "Garg AX, Adhikari NKJ, McDonald H, et al. Olah C, Satyanarayan A, Johnson I, et al. Lundberg SM, Nair B, Vavilala MS, et al. Van Belle VMCA, Van Calster B, Timmerman D, et al. Soininen H, Mattila J, Koikkalainen J, et al. Kunapuli G, Varghese BA, Ganapathy P, et al. Robin X, Turck N, Hainard A, et al. Wadhwa R, Fridsma DB, Saul MI, et al. Li AC, Kannry JL, Kushniruk A, et al.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 22
    },
    {
        "text": "Freitas AA. Ribera M, Lapedriza A. Cabitza F, Zeitoun J-D.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 23
    },
    {
        "text": "J Biomed Inform. J Biomed Inform. J Biomed Inform.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 24
    },
    {
        "text": "Int J Med Inform. Int J Med Inform. Int J Med Inform. Int J Med Inform.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 25
    },
    {
        "text": "New York, New York, USA: ACM Press; 2018:1-18. doi:10.1145/3173574.3174156 32. New York, New York, USA: ACM Press; 2019:1-15. doi:10.1145/3290605.3300831 41. New York, New York, USA: ACM Press; 2016:5686-5697. doi:10.1145/2858036.2858529 75. New York, NY, USA: ACM Press; 2015:1721-1730. doi:10.1145/2783258.2788613 77. New York, New York, USA: ACM Press; 2017:233-240. doi:10.1145/3107411.3107445 85. New York, New York, USA: ACM Press; 2006:233-240. doi:10.1145/1143844.1143874 109.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 26
    },
    {
        "text": "2012;7(3):e34312. 2015;10(5):e0127428. 2015;10(7):e0132614. 2014;21(e2):e249-e256.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 27
    },
    {
        "text": "2017;32(3):68-73. doi:10.1109/MIS.2017.54 163 54. 2018;33(2):83-88. doi:10.1109/MIS.2018.022441353 61. 2018;33(3):87-95. doi:10.1109/MIS.2018.033001421 62. 2017;32(4):78-86. doi:10.1109/MIS.2017.3121544 70.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 28
    },
    {
        "text": "2017;318(6):517-518. doi:10.1001/jama.2017.7797 2. 2015;57:377-385. doi:10.1016/j.jbi.2015.07.017 4. 2018;319(13):1317-1318. doi:10.1001/jama.2017.18391 5. 2018;320(1):27-28. doi:10.1001/jama.2018.5602 6. 2019;5(1):11-17. doi:10.1159/000492428 7. 2018;19(6):1236-1246. doi:10.1093/bib/bbx044 9. 1997;9(2):107-138. doi:10.1016/s0933-3657(96)00367-3 160 14. 2015;9(3):1350-1371. doi:10.1214/15-AOAS848 18. 2017;38(3):50-57. doi:10.1609/aimag.v38i3.2741 19. 2011;51(4):782-793. doi:10.1016/j.dss.2011.01.013 22. 2015;3(1):1181. doi:10.13063/2327-9214.1181 24. 2010;14(4):1114-1120. doi:10.1109/TITB.2009.2039485 161 26. 2018;51(5):1-42. doi:10.1145/3236009 27. 2014;15(1):1-10. doi:10.1145/2594473.2594475 30. 2014;2(1):3. doi:10.1186/2047-2501-2-3 35. 2011;169:150-154. doi:10.3233/978-1-60750-806-9-150 37. 2005;293(10):1223-1238. doi:10.1001/jama.293.10.1223 38. 2017;124(3):423-432. doi:10.1111/1471-0528.14170 47. 2018;6:52138-52160. doi:10.1109/ACCESS.2018.2870052 52. 2019;32(4):661-683. doi:10.1007/s13347-018-0330-6 56. 2011;13(1):53-64. doi:10.1007/s10676-010-9253-3 60. 2012;22(4-5):399-439. doi:10.1007/s11257-011-9117-5 68. 2010;25(3):289-310. doi:10.1214/10-STS330 74. 2018;2(10):749-760. doi:10.1101/206540 76. 2012;10(1-4):149-152. doi:10.1159/000332600 82. 2018;31(6):929-939. doi:10.1007/s10278-018-0100-0 83. 2017;24(1):198-208. doi:10.1093/jamia/ocw042 88. 2016;104(2):444-466. doi:10.1109/JPROC.2015.2501978 89. 2012;2(4):138-148. doi:10.3390/jpm2040138 92. 2015;18(6):2266-2277. doi:10.1111/hex.12196 96. 2019;7(8):161-161. doi:10.21037/atm.2019.04.07 98. 2011;12(1):77. doi:10.1186/1471-2105-12-77 111. 2002;324(7341):827-830. doi:10.1136/bmj.324.7341.827 114. 2012;45(6):1202-1216. doi:10.1016/j.jbi.2012.09.002 116. 2017;32(1):38-47. doi:10.1177/0885066615585951 118. 2013;41(6):1502-1510. doi:10.1097/CCM.0b013e318287f0c0 119. 2004;21(2):102-108. doi:10.1111/j.1471-1842.2004.00506.x 120. 2016;29(6):717-726. doi:10.1097/ACO.0000000000000386 122. 2007;9(3):90-95. doi:10.1109/MCSE.2007.55 135. 2017;24(6):1102-1110. doi:10.1093/jamia/ocx060 137. 2017;32(5):752-755. doi:10.1093/ndt/gfx073 138. 2016;19(5):993-1001. doi:10.1111/hex.12380 139. 2019;100(August):103327. doi:10.1016/j.jbi.2019.103327 141.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 29
    },
    {
        "text": "2017;98:56-64. doi:10.1016/j.ijmedinf.2016.12.001 36. 2017;108(July):185-195. doi:10.1016/j.ijmedinf.2017.10.002 93. 2019;123(November 2017):1-10. doi:10.1016/j.ijmedinf.2018.12.003 113. 2012;81(11):761-772. doi:10.1016/j.ijmedinf.2012.02.009 140.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 30
    },
    {
        "text": "Explanation design options used for each mock-up .................................................. 64 Table 7. Supporting information provided in each mock-up. Mock-ups varied in explanation design options and were organized into two sets based on the different design options. The mock-up sets are summarized in Table 6 and the explanations for each mock-up are shown in Figures 10-14. An example of the supporting information included in each mock-up is shown in Figure 15. Supporting information provided in each mock-up. For each set, mock-ups were discussed individually and then presented side-by-side to facilitate discussions of preferences for the different design options. Includes comments about aspects of the system that facilitate or impede use (e.g., design elements that make information processing easier/harder) and preferences between mock-ups (e.g., saying one mock-up was easier to use/understand than another). Examples: -about mock-ups that are easier/harder to use than others -design elements that exacerbate/alleviate confusion, cognitive effort, time requirements -design elements that facilitate information synthesis or interpretation 6.3 Perceptions of system utility The utility, or usefulness, of the system (i.e., is the intended use of the system useful to pursue? Includes suggestions for possible users of the system and comments on the value of system information (e.g., information provided is perceived as informative).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 31
    },
    {
        "text": "Graphic depiction of how explanation design may impact key constructs in the unified theory of acceptance and use of technology (UTAUT). The unified theory of acceptance and use of technology (UTAUT)38 provides one possible approach to understanding such factors. The UTAUT is a validated theory of technology adoption and use that has been shown to explain some of the variance in the use of health information systems.39 The theory, shown graphically in Figure 1, identifies performance expectancy, effort expectancy, social influence, and facilitating conditions as the four key constructs that determine user acceptance and usage behavior either 5 directly or as determinants of the behavioral intention to use a technology. Graphic depiction of how explanation design may impact key constructs in the unified theory of acceptance and use of technology (UTAUT). It should be noted that the original scale items for the key UTAUT constructs in the subjective assessment task (performance expectancy, effort expectancy) were experimentally selected from the scale items of constructs from other models of technology acceptance and use (called root constructs). User Acceptance of Information Technology: Toward a Unified View.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 32
    },
    {
        "text": "Participant rankings of design options by perceived importance ........................ 79 Figure 19. Participant preferences for each design option and the perceived importance rankings of each option are summarized in Figures 17 and 18, respectively. Participant rankings of design options by perceived importance The supporting information provided in the mock-ups was vital to participant interpretation of the prediction and explanation, and in general helped participants assess the credibility and utility of the model information (Table 10, Verification; Table 10, Learning). In general, strong preferences on design options correlated with increased perceived importance of the design element (Figure 18).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 33
    },
    {
        "text": "IEEE Intell Syst their Appl. IEEE Access. IEEE Intell Syst. IEEE Intell Syst. IEEE Intell Syst. IEEE Intell Syst. Knowledge-Based Syst.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 34
    },
    {
        "text": "The framework describes three general user types based on their background and relationship to the AI system: 1) AI experts—researchers who develop an AI system, 2) domain experts—specialists in the area in which the system is being used (e.g., physicians, lawyers, etc. The authors identify three user types similar to the three types proposed by Ribera and Lapedriza42: 1) AI novices, or end-users of AI products that have limited knowledge of ML, 2) data experts, or data scientists and domain experts who use ML approaches but generally lack in-depth expertise, and 3) ML experts, who design and have a strong theoretical understanding of ML algorithms. Ras et al.20 offer a categorization of users of ML systems that further expands upon the general user types proposed by Ribera and Lapedriza42 and Mohseni et al.44 The authors define two broad categories of users based on expertise: 1) expert users who are responsible for implementing an ML system and who typically have some knowledge about the inner workings of an ML system, and 2) lay users who are the people for which an ML system is built and who are not expected to have knowledge about the inner workings of an ML system. Ribera and Lapedriza’s42 classifications of AI experts, domain experts, and lay persons capture the main categories of user cognition that appear in the literature. Ras et al.’s20 sub-categorizations of users (engineer, developer, owner, end-user, data subject, stakeholder) capture the various relationships a user may have with an AI system. Three main categories of user cognition to consider include AI experts, domain experts, and lay persons.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 35
    },
    {
        "text": "Summary of the analyses of display effect on decision accuracy and decision confidence .............................................................................................................................. 100 Table 19. Mean and variance of case review efficiency measures for each display ............ 101 Table 20. Summary of the analysis of display effect on case review time ............................ 102 Table 21. Provider self-reported confidence in urgency decisions for each display ......... 100 Figure 25. Displays were randomly assigned to patient cases such that each participant reviewed two cases (one urgent, one non-urgent) with each one of the three displays. To evaluate urgency decision accuracy, the proportion of correct decisions with 95% CIs for each of the three displays were calculated and a logistic mixed effects analysis of the relationship between urgency decision accuracy and display was performed. Analysis of decision confidence To assess the relationship between the display shown and participant-reported confidence in their urgency decision, confidence ratings for each of the displays were visualized in a stacked bar chart and an ordinal logistic mixed effects analysis was performed. To assess the relationship between the display shown and case review time, a log-linear mixed effects analysis was performed after it was determined that case review time followed a log-normal distribution. 97 To assess the relationship between the display shown and the number of unique items viewed, a Poisson mixed effects analysis was performed. To assess the relationship between the display shown and the total number of items viewed, a negative binomial mixed effects analysis was performed after it was determined that the distribution of the total number of items was over-dispersed (mean=33.0; variance=206.3). Participant responses by case urgency and display Case Urgency Display Non-urgent Urgent Total No model 14 15 29 Prediction only 15 15 30 Explanation 15 15 30 Total 44 45 89 6.2.1 Decision Accuracy and Confidence As shown in Table 17, the proportion of correct decision responses was highest with the “explanation” display; however, all proportions had substantially overlapping 95% CIs, which makes it challenging to comment on the significance of this effect. As seen in Figure 24, participants seemed confident in their urgency decisions regardless of display, with all providers rating their confidence as a 3 or higher for all decisions. Provider self-reported confidence in urgency decisions for each display Table 18. Summary of the analyses of display effect on decision accuracy and decision confidence Logistic mixed effects analysis of display effect on decision accuracy Ordinal logistic mixed effects analysis of display effect on decision confidence Random effect Variance Variance Participant (intercept) 4.71e-34 1.50 Fixed Effects Odds Ratio Std. Error p-value 95% CI Display No model Reference Reference Prediction only 1.23 0.71 0.71 [0.40, 3.83] 1.56 0.84 0.41 [0.54, 4.46] Explanation 2.93 1.97 0.11 [0.79, 10.93] 1.26 0.67 0.66 [0.45, 3.54] Urgency Not urgent Reference Reference Urgent 1.18 0.60 0.74 [0.44, 3.20] 1.81 0.78 0.17 [0.77, 4.22] Experience Attending/fellow Reference Reference Resident 1.18 0.60 0.75 [0.43, 3.21] 0.50 0.39 0.38 [0.11, 2.29] 101 6.2.2 Case Review Efficiency As seen in Table 19, the “explanation” display had the longest average case review time and lowest average number of items viewed (both unique and total), but the analyses demonstrated that there was no significant effect of the display shown on case review time, the number of unique items viewed, or the total number of items viewed (Table 20 and Table 21). Summary of the analysis of display effect on case review time Log-linear mixed effects analysis of display effect on case review time Random effect Variance Participant (intercept) 0.15 Fixed Effects Coefficient Std. Summary of the analyses of display effect on unique and total number of items viewed Poisson mixed effects analysis of display effect on unique number of items viewed Negative binomial mixed effects analysis on total number of items viewed Random effect Variance Variance Participant (intercept) 0.003 0.02 Fixed Effects Rate Ratio Std.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 36
    },
    {
        "text": "The analyses did reveal a significant effect of case urgency on case review time and the unique number of items viewed (Table 20 and Table 21). More specifically, when controlling for other factors, participants spent a longer time reviewing a case and viewed more unique items for urgent cases when compared to non-urgent cases. Specifically, providers spent significantly more time reviewing a case and viewed significantly more unique items for urgent cases than for non-urgent cases.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 37
    },
    {
        "text": "Summary of participant background knowledge of predictive modeling concepts74 Table 10. Summary of participant background knowledge of predictive modeling concepts Familiarity with risk prediction models (1 participant left question blank) # of participants (n=20) “I know what a risk prediction model is.” 17 “I have used a risk prediction model in practice.” 8 “I have been involved in the development of a risk prediction model.” 6 Familiarity with machine learning (1 participant left question blank) # of participants (n=20) None—I have never heard of this term before. Includes remarks/questions that suggest knowledge (or lack thereof) of predictive models (e.g., objective reference to known model, mentions of ML algorithms, model limitations/validity) or the model development process (e.g., cohort definition, data cleaning, feature engineering, training, evaluation, bias/overfitting, best practices). Includes comments/questions directly/indirectly expressing an interest in knowing model internals (e.g., weights, mathematical relationships, handling correlated predictors), general trends learned (e.g., how/why the model makes predictions for patient population; general risk factors), and how/why the model makes predictions for individual patients (e.g., patient-specific risk factors).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 38
    },
    {
        "text": "Graphic overview of the LIME approach to generating explanations. Figure A1 provides a graphic depiction of the LIME approach to generating an explanation for a single instance. The exact approach to generating explanations varies by input data type, but an overview of the LIME implementation approach based on tabular data input is provided. Graphic overview of the LIME approach to generating explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 39
    },
    {
        "text": "Appendix A.1 Local Interpretable Model-agnostic Explanations (LIME) The goal of the LIME algorithm123 is to “identify an interpretable model over the interpretable representation that is locally faithful to the classifier”.64 In simple terms, to generate an explanation for a single instance, LIME uses a human-readable representation of classifier inputs (e.g., words instead of word vectors) to learn an interpretable model (e.g., sparse linear regression, short decision tree) that fits the local decision boundary near the instance of interest. To generate an explanation for an instance of interest (indicated by the bolded red cross), LIME performs the following: 1) generates perturbed samples (all non-bolded points on the plot), 2) obtains their prediction from the classifier (circle or cross), 3) weights them according to distance from the instance of interest (represented here by point size), and 4) uses weighted samples to fit an interpretable model (indicated by the dashed line) that is locally faithful to the original predictive model decision boundary (indicated by the red/blue background). By default, LIME generates explanations using 10 features, selects features that have the highest product of absolute weight and original data point when learning a linear ridge regression with all features, and uses linear ridge regression with a regularization strength of =1 to learn feature weights for the explanation. This indicates that use of the LIME algorithm to generate explanations would require careful selection of algorithm parameters for each dataset to reduce errors in fidelity.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 40
    },
    {
        "text": "After reviewing all six patient cases, participants were asked to complete subjective assessments of the “prediction only” and “explanation” displays, which included completing a subset of the UTAUT construct scale38 item questionnaire to assess the performance expectancy and effort expectancy of each of the displays (see section 1.2 for a discussion on the relevance of these constructs). Data collected for each study task Study Task Data Collected Background Questionnaire  Current clinical position (e.g., resident)  Length of time in current position (e.g., <1 year) Patient Case Review Data collected for each patient case:  Time-stamped interactions with application interface (e.g., tab selections, lab tests viewed)  List of information selected to discuss during rounds  Urgency decision accuracy (see Figure 20)  Urgency decision confidence, rated from 1—not confident at all to 5—extremely confident  Free-text rationale for urgency decision  Time (in seconds) to review patient case (excludes verbal case presentation, see Figure 20)  Audio-recording of verbal patient case presentation  Moderator notes on interesting comments or behavior during case review Subjective Assessments Data collected for “prediction only” and “explanation” displays:  Selected UTAUT Root Construct Scale Items for Performance Expectancy38 (Likert scale agreement): 1. When mentioned, participants were either questioning the 100 validity of a model prediction with the “prediction only” display (e.g., “mortality risk is lower, but it looks like a lot of things are kind of trending in the ‘not right’ direction”) or using the mortality risk prediction from either the “prediction only” or “explanation” display as part of their justification for the urgency decision (“a child who is under-supported with a high risk of mortality”). In general, participants had positive perceptions of the performance expectancy of a system utilizing either the “prediction only” or “explanation” display (Figure 25, statements 1-4), but the “explanation” display improved participant perceptions of performance expectancy relative to the “prediction only” display. Participant comments indicated that the positive perceptions of the performance expectancy of the “prediction only” display were related to the benefit of having a mortality risk score to help in patient prioritization. There were features that I was much more concerned about than the model, and vice versa, that builds inherent distrust.” —2nd year fellow Overall, the “explanation” display greatly improved participant perceptions of effort expectancy relative to the “prediction only” display (Figure 25, statements 5-7). While some participants reported positive perceptions of the effort expectancy of the “prediction only” display, a large number of participants commented that the explanations greatly improved their ability to make sense of the risk prediction. One participant specifically noted his frustration with the “prediction only” display when he disagreed with a high risk prediction, commenting that the provided information did not help him understand why the model was showing an increased risk. This view can explain the positive perceptions of the performance expectancy observed for the “prediction only” display as the system was still providing new information to the participants, even though the system was less favorably perceived than the “explanation” display. Despite some participants’ favorable perception of the performance expectancy of the “prediction only” display system, provider feedback on the system demonstrated that the “explanation” display system had higher performance expectancy and a much lower effort expectancy.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 41
    },
    {
        "text": "First, it suggests that the study possibly targeted the wrong outcome metrics to assess the impact of the predictive model with explanations on provider decision-making. If this is the case, the study missed an opportunity to examine the impact of the predictive model with explanations on an important decision-making process. Alternatively, it is possible that the study examined the right decision-making process, but the predictive model with explanations did not provide information that would directly influence provider decisions. Additionally, as discussed above, it is possible that the evaluation study targeted the wrong decision-making process, or at least did not consider the full complexity of how providers might use the predictive model information to aid in decision-making.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 42
    },
    {
        "text": "Kernel SHAP computes the average model prediction as the expected value of the model prediction on the background dataset. To efficiently estimate Shapley values, Kernel SHAP first begins by determining which feature values in the instance to be explained vary (i.e., have a different value) from the values in the provided background dataset. To estimate the Shapley values of the remaining features, Kernel SHAP first generates a weighted dataset of samples from all possible feature subsets, where features in the subset are equal to the value of the instance to be explained and features not in the subset are equal to the 131 background dataset values. Finally, Kernel SHAP uses the weighted dataset of samples and their respective estimated changes in the model prediction to solve a least squares regression to obtain the Shapley values for the remaining features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 43
    },
    {
        "text": "Mean time to compute a single explanation for LIME and SHAP algorithms . Total time to compute 500 explanations for LIME and SHAP algorithms ....... 137 xii List of Figures Figure 1. 122 Appendix A Descriptions and Comparisons of SHAP and LIME Algorithms This appendix provides a description of the LIME and SHAP algorithms and presents the experiments conducted to select between the two algorithms. Section A.3 presents the experiments conducted to justify the selection of the SHAP algorithm for use in this work. The SHAP algorithm offers both model-agnostic and model-specific methods for efficiently approximating the Shapley values defined by Equation 4 to obtain explanations for any input data type. Several preliminary experiments comparing the LIME and SHAP algorithms on their fidelity and computational efficiency were conducted. 137 The mean and total computation times for the LIME and SHAP algorithms under varying parameter settings are shown in Table A1 and Table A2, respectively. Total time to compute 500 explanations for LIME and SHAP algorithms Number of samples used to generate explanation 500 1000 3000 5000 7000 Readmission Dataset SHAP total time (min) 0.31 0.46 0.75 0.92 1.16 LIME total time (min) 3.26 4.50 10.53 15.8 21.0 Infant Mortality Dataset SHAP total time (min) 0.45 0.44 0.33 0.07 0.06 LIME total time (min) 9.12 12.76 32.54 15.25 19.8 Appendix A.3.4 Discussion and Algorithm Selection The fidelity error of the SHAP algorithm under varying parameters was always 0 for both datasets, which indicates that the algorithm implementation adheres to its theoretical guarantee of local fidelity. Table A1 and Table A2 show that the SHAP algorithm appears to be faster than the LIME algorithm and its computation time is less affected by the number of samples used to generate the 138 explanation. However, unlike the LIME algorithm where each explanation must be computed individually, the SHAP algorithm also includes functions to efficiently compute explanations in large batches. Based on these preliminary timing experiments, the SHAP algorithm appears to offer better computational efficiency than the LIME algorithm. As the SHAP algorithm guarantees explanation fidelity and requires less computation time than the LIME algorithm, the SHAP algorithm was selected for use in the proposed work. It is important to note that only preliminary experiments were conducted; however, the conducted experiments provided sufficient evidence to support my selection of the SHAP algorithm. More rigorous experiments comparing the LIME and SHAP algorithms are left for future work.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 44
    },
    {
        "text": "It has been a privilege to be his student, and I want to express my sincere appreciation for his guidance, patience, and encouragement throughout the completion of this dissertation. I am grateful not only for his time and advice, but for his genuine interest in my research and in my future career path. I would like to specifically thank Vickie Johnson for reserving conference rooms for study sessions. A very special thanks also goes to Toni Porterfield, who has always gone above and beyond for me. xv I am indebted to all those who provided me with opportunities to enrich my graduate school experience. Finally, my deepest gratitude is reserved for the endless patience, support, and encouragement of my friends and family. Another special thanks to my friend, Rissa Diehl, for always being willing to lend an ear and a place to stay. Thanks to my mother-in-law, Marisa Barda, for her endless positive energy and belief in me. A very special thanks to my husband, Christopher Barda, for his endless love, encouragement, and belief in me at all times. Finally, the greatest thanks goes to my parents, Robert and Kristi Draper, for instilling in me a life-long love of learning and supporting me throughout this journey in more ways than I can count. My sincerest thanks to all, including anyone I may have inadvertently omitted, for whatever your role has been in supporting my personal and professional endeavors.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 45
    },
    {
        "text": "Title Page Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare by Amie Janeth Barda Bachelor of Science, The Ohio State University, 2013 Master of Science, University of Pittsburgh, 2015 Submitted to the Graduate Faculty of the School of Medicine in partial fulfillment of the requirements for the degree of Doctor of Philosophy University of Pittsburgh 2019 ii Committee Page UNIVERSITY OF PITTSBURGH SCHOOL OF MEDICINE This dissertation was presented by Amie Janeth Barda It was defended on December 12, 2019 and approved by Dr. Michael Becich, Professor and Chair, Department of Biomedical Informatics Dr. Christopher Horvat, Assistant Professor, Department of Pediatric Critical Care Medicine Dr. Douglas Landsittel, Professor, Department of Biomedical Informatics Dr. Shyam Visweswaran, Associate Professor, Department of Biomedical Informatics Dissertation Director: Dr. Harry Hochheiser, Associate Professor, Department of Biomedical Informatics iii Copyright © by Amie Janeth Barda 2019 iv Abstract Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare Amie Janeth Barda, PhD University of Pittsburgh, 2019 Challenges in interpreting some high-performing models present complications in applying machine learning (ML) techniques to healthcare problems. Recently, there has been rapid growth in research on model interpretability; however, approaches to explaining complex ML models are rarely informed by end-user needs and user evaluations of model interpretability are lacking, especially in healthcare. Therefore, I aimed to utilize clinician perspectives to inform the design of explanations for ML-based prediction tools and improve the adoption of these systems in practice. In this dissertation, I proposed a new theoretical framework for designing user-centered explanations for ML-based systems. I then utilized the framework to propose explanation designs for predictions from a pediatric in-hospital mortality risk model. The user-centered explanation was evaluated in a laboratory study to assess its effect on healthcare provider perceptions of the model and decision-making processes. The results demonstrated that the user-centered explanation design improved provider perceptions of utilizing the predictive model in practice, but exhibited no significant effect on provider accuracy, confidence, or efficiency in making decisions. Nonetheless, the predictive model with the user-centered explanation was positively received by healthcare providers, and demonstrated a viable approach to explaining ML model predictions in healthcare. Future work is required to address the limitations of this study and further explore the potential benefits of user-centered explanation designs for predictive models in healthcare. This work contributes a new theoretical framework for user-centered explanation design for ML-based systems that is generalizable outside the domain of healthcare. Moreover, the work provides meaningful insights into the role of model interpretability and explanation in healthcare while advancing the discussion on how to effectively communicate ML model information to healthcare providers. High-level summary of insights on explanation design .......................................... 77 Table 12. Insights on explanation design target questions ...................................................... 81 Table 13. Landscape of interpretability. General approaches to interpretability evaluation (adapted from Doshi-Velez and Kim43). Conceptual framework for reasoned explanations that describes how human reasoning processes (left) inform explainable AI techniques (right) from Wang et al.40 . Three-level nested model to designing and evaluating an explainable AI system from Mohseni et al.44............................................................................................................... 27 Figure 7. SCOPUS publications on model interpretability in healthcare from 2008-2018. . Proposed framework for designing user-centered explanations. Summary of an initial context of use and a possible space of explanation designs for the pediatric ICU in-hospital mortality risk model. Final user-centered explanation design.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 46
    },
    {
        "text": "xvi List of abbreviations: AI: artificial intelligence AUPRC: area under the precision-recall curve AUROC: area under the receiver operating characteristic curve CDSS: clinical decision support system CFS: correlation-based feature subset CHP: Children’s Hospital of Pittsburgh CI: confidence interval CPR: cardiopulmonary resuscitation EHR: electronic health record GCS: Glasgow coma scale HCI: human computer interaction ICD: International Classification of Diseases ICU: intensive care unit IG: information gain IRB: Institutional Review Board LIME: local interpretable model-agnostic explanations ML: machine learning SHAP: Shapley additive explanations SVM: support vector machine UTAUT: unified theory of acceptance and use of technology WEKA: Waikato Environment for Knowledge Acquisition 1 1.0 Introduction The healthcare industry is expected to follow the patterns of other information-rich industries and experience rapid growth in the use of statistical and machine learning (ML) techniques to leverage the predictive power of large data.1–6 There are numerous publications demonstrating the high performance of ML models on complex problems in medicine, yet there is a distinct absence of these models in practical applications in medicine.4,5,7–9 While it is possible that this absence could be due to a lack of generalizability or reproducibility of highly accurate ML models, many publications attribute the absence to a lack of interpretability, or a model’s ability to explain its behavior.3,5,6,8,10–12 Model interpretability is highly valued in medicine, as is evidenced by the long-standing use of less accurate, but comprehensible models such as logistic regression.13–17 Moreover, with increasing societal concerns and regulations on intelligent algorithms,6,18–20 recognition of the importance of incorporating providers and domain knowledge in modeling processes,4,6,8,9,21–24 and provider demand for model explanations,5,6,10,12,25 interpretability will be vital to the future success of ML models in healthcare. In response to the demand for model interpretability in healthcare as well as other domains, research within the ML community has produced several approaches to explaining models and predictions. Recently, there has been increased attention to the apparent lack of end-user involvement in the design and evaluation of explanation approaches, despite the acknowledgement that user goals, expertise, and time constraints are central in defining explanation needs.11,12,26–32 The definition of what constitutes a “good” or “useful” explanation is often left to the judgment of novice and expert model developers, whose knowledge and backgrounds are generally not representative of end-user expertise.27,29,33 More specifically, most developers are mainly concerned with the statistical and modeling challenges of generating an explanation; the display of the explanation often receives less attention and is rarely informed by end-user needs or insights from the literature.20,27,31,33 Moreover, it is unclear from current evaluation studies how end-users interpret and utilize explanations designed by modeling experts,12 which often require some level of understanding of ML models to accurately interpret. In healthcare, most ML models are proposed as tools to help healthcare providers analyze patient data and derive insights that can assist in clinical decision-making.4,12,29,34 More specifically, ML-based clinical decision support systems (CDSS) usually aim to help healthcare providers make more accurate decisions, be more confident in their decisions, and/or be more efficient in making decisions. Explanations for ML models can assist in this process by providing additional information about the model that allows the provider to integrate model information with their knowledge in order to make informed decisions. Unfortunately, there is a sparsity of interpretability evaluation focused on medical applications and most claims regarding model 3 interpretability lack rigorous evaluations utilizing real end-users.28,29,31,32 This makes it difficult to determine when explanations for ML models may be required and how to design these explanations to fit the information needs and environment of healthcare providers. In this dissertation, I aimed to utilize clinician perspectives to inform the design of explanations for ML-based prediction tools. More specifically, I aimed to utilize literature insights to develop a theoretical framework of explanation design that would account for healthcare provider explanation needs when utilizing a predictive model in clinical practice. I then aimed to utilize the framework to suggest possible explanation designs that could be augmented with feedback from healthcare providers to inform the design of a user-centered explanation. 1.1 Hypotheses and Specific Aims I hypothesized that a user-centered explanation design for an ML-based prediction tool would: 1) Improve provider perceptions of utilizing an ML-based prediction tool in clinical practice relative to the same tool without explanations 2) Improve provider accuracy, confidence, and speed in making decisions relative to the same tool without explanations and having no available tool To evaluate this hypothesis, the following specific aims were addressed: Aim 1. Develop a theoretical framework of explanation design and use the framework to suggest explanation designs. Using insights from the literature, develop a theoretical framework of clinical explanation design that accounts for healthcare provider explanation 4 needs when using a model in clinical practice. Refine explanation design with healthcare provider feedback.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 47
    },
    {
        "text": "Conduct user studies with healthcare providers to refine explanation needs, identify successful design elements, and inform the final design of a user-centered explanation. Evaluate the impact of the user-centered explanation. Conduct a laboratory study with healthcare providers to assess the impact of the user-centered explanation design on decision-making and perceptions of an ML-based prediction tool. To ground the work in a specific context, I focused on designing and evaluating a user-centered explanation for an in-hospital mortality risk model for pediatric intensive care unit (ICU) patients. 1.2 Motivation An ML-based CDSS can only be successful if healthcare providers accept and use the system.35–37 System acceptance and use will likely be determined by some combination of contextual factors and design factors. To understand how a user-centered explanation may influence successful implementation of an ML-based CDSS, it is necessary to understand the specific factors that might influence system acceptance and use. By examining how explanation design may affect key UTAUT constructs, one can obtain a better understanding of the potential role user-centered explanations may play in healthcare provider acceptance and use of an ML-based CDSS in practice. For example, how well an explanation design fits a healthcare provider’s information needs likely affects the degree to which a healthcare provider can understand the information being provided by the ML-based CDSS. Additionally, the degree to which explanation design fits the environment in which an ML-based CDSS is being used likely affects the time and cognitive resources required to understand the information being provided by the system. Thus, the degree to which explanation designs for ML-based CDSS fit healthcare providers’ information needs and environment may influence perceptions of the performance expectancy and effort expectancy of the system, both of which influence the behavioral intention to use the system. Based on the UTAUT constructs and the proposed extensions, it appears that user-centered explanations for ML-based CDSS could play an important role in healthcare provider acceptance and use of the system in practice. This suggests that employing user-centered approaches to 7 explanation design would be beneficial. Researchers in the human computer interaction (HCI) and ML communities have proposed frameworks for and provided guidance on user-centered explanation design for systems based on ML models and other artificial intelligence (AI) approaches.20,40–44 When discussing the design of explanations, this body of literature focuses mainly on who an explanation is provided to, or the user of the system, and why the user requires an explanation, or the specific goals the user is trying to accomplish.40,42,44 These are important elements in understanding the context of use of an explanation, yet little attention seems to be paid to where or when users require explanations. These additional questions relate to the environment in which a user is expected to use an explanation, which has been demonstrated to be an important consideration when designing explanations for ML-based CDSS. Thus, it appears that current frameworks for user-centered explanation design do not properly account for healthcare provider explanation needs when utilizing a predictive model in clinical practice. 1.3 Approach Combining insights from and expanding upon prior theory-informed frameworks for user-centered explanation design, I proposed a new framework for designing user-centered explanations for ML-based systems for healthcare in which explanation design is informed by the entire context of use. Specifically, I proposed that user-centered explanation design in healthcare should not only consider who an explanation is being provided to and why they desire that explanation, but also when and where that explanation will be used (i.e., the environment of use). The proposed framework supports explanation design by linking the components of the context of use (who, why, when, where) to explanation design choices such as what information the explanation needs to 8 contain (i.e., the content) and how that information needs to be provided (i.e., the presentation). I subsequently demonstrated an application of the framework by designing and evaluating explanations for a pediatric ICU in-hospital mortality risk model. Feedback from healthcare providers was then used to refine the defined context of use and inform the final design of a user-centered explanation. The impact of the user-centered explanation on healthcare provider decision-making and perceptions of the prediction tool was then evaluated in a laboratory study. 1.4 Significance and Innovation To the best of my knowledge, this is the first proposed framework for user-centered explanation design for ML-based systems that provides specific guidance on design choices based on the entire context of use of the explanation. This work also provides meaningful contributions to the discussion on the importance of model interpretability in healthcare. As mentioned previously, several papers have pointed out lack of model interpretability as a barrier to the adoption of ML models in practical clinical applications.3,5,6,8,10–12 However, a lack of model interpretability is not the only possible barrier to adoption.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 48
    },
    {
        "text": "Healthcare provider assessments are needed to identify which specific factors related to interpretability and utility might prevent an ML model from being used in practice. This study is among the few that have evaluated predictive model explanations using healthcare providers, and sheds light on how user-centered explanation designs enable healthcare providers to understand an ML model in a meaningful way. Finally, this work contributes to knowledge on how to communicate model predictions, specifically those based on complex ML models, to healthcare providers in a manner that facilitates their involvement in conversations about the development, deployment, and continuous improvement of predictive models for use in clinical practice. These conversations help ensure the development of ML-based systems that deliver information when and where it is needed in a way that is useful to providers and which may promote positive changes in clinical practice. 1.5 Dissertation Overview In Chapter 2, I present an overview of the literature on interpretability, review current frameworks and guidance on user-centered explanation design for AI systems, and discuss prior work on interpretability in healthcare. Chapter 3 presents the new proposed framework for user-centered explanation design for ML-based systems in healthcare, while Chapters 4, 5, and 6 10 demonstrate an application of the framework. Chapter 5 describes the user studies conducted with healthcare providers to refine the context of use and explanation designs to develop a final, user-centered explanation design for the ML-based prediction tool. Chapter 6 presents an evaluation of the impact of the user-centered explanation design on healthcare provider decision-making and perceptions of the ML-based prediction tool. Section 2.1 provides an overview of the literature on interpretability, including how the concept is defined and its relationship to explanation, approaches to achieving interpretability, and approaches to evaluating interpretability. Section 2.2 summarizes available frameworks and guidance for user-centered explanation design and evaluation. Section 2.3 concludes the chapter with an overview of the role of interpretability in healthcare and summarizes prior work in the area. 2.1 Landscape of Interpretability Interpretability is a multi-dimensional concept that is closely related to the concept of explanation. Figure 2 provides an overview of the concept of interpretability as viewed in this dissertation and serves as a visual guide for the concepts discussed in sections 2.1.1-2.1.2. Landscape of interpretability. A roadmap for understanding the multi-dimensional nature of the concept of interpretability. 2.1.1 Defining Interpretability and Explanation Current literature lacks a concrete definition for the term “interpretability”11,30,43,47–50; however, the demand for interpretability appears to arise when the goals of real world deployment require a system to satisfy evaluation criteria that are hard to formulize or quantify as part of the problem formulation of a system.28,43,47 Examples of such criteria are defined in Table 1. Thus, when users demand interpretability, they are often seeking some sort of explanation about a model or a system to assist them in evaluating whether certain criteria are satisfied. This close relationship between the concepts of interpretability and explanation often results in the term “explainability” being used interchangeably with “interpretability”.11,28,47,51 Interpretability generally takes the form of an explanation, but what defines an explanation and 13 what constitutes a quality explanation are topics still widely debated within both the ML and social science literature.27,43,52,53 Table 1. Gilpin et al.52 notes that this formulation of the concept of explanation is particularly interesting in ML because “when you can phrase what you want to know from an algorithm as why questions, there is a natural qualitative representation of when you have answered said question—when you can no longer keep asking why”. Under this view, it can be said that the demand for interpretability is met when the ML system has provided satisfactory explanations for all questions put forth by the users of the ML system. The differing goals, expertise (e.g., background knowledge, experiences), and time constraints of users play a central role in determining the appropriate explanation that answers a question.12,26,43,51,52,56 Researchers have noted the challenge of producing appropriate explanations to various users while also providing an accurate explanation of the underlying ML system 14 processes.11,12,26,52,56,57 Gilpin et al.52 describe this issue by proposing to view explanations as having properties of comprehensibility1 and completeness. Thus, the challenge in producing explanations for ML systems lies in appropriately balancing the tradeoff between comprehensibility and completeness. When an explanation of an ML system must provide a higher level of comprehensibility, terms like “intelligibility”, “comprehensibility”, and “understandability” are often used synonymously with “interpretability”.11,47,58 When an explanation of an ML system must provide a higher level of completeness, the term “transparency” is often used interchangeably with “interpretability”.47,58 2.1.1.1 Levels and Types of Explanation In recognition of the challenge of providing explanations for ML systems that appropriately balance comprehensibility and completeness, the literature has defined several “levels” or “types” of explanation for ML models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 49
    },
    {
        "text": "Some researchers refer to these as levels or types of interpretability, 1Gilpin et al.52 originally used the term “interpretability”, but I have chosen to use “comprehensibility” to avoid ambiguity with my previous discussion of the concept of interpretability 15 but as interpretability generally takes the form of an explanation, I will consistently use the term explanation to describe approaches to interpretability throughout this work. Although the terminology differs, many researchers have chosen to distinguish types of explanations based on whether they describe model processes or behavior.12,20,32,47,48,52,54,57,59 Explanations of processes focus on elucidating aspects of the model training algorithm, parameter settings, and/or internal representation/structure (i.e., the mathematical relationships between inputs and outputs).47,48 These are referred to as “transparent”, “white-box”, or “descriptive” explanations, as they typically provide detailed descriptions of the internal operations of a model.47,48,54,57,59 These explanations can provide insights into why an ML system may dysfunction, or fail to operate as intended, and are most useful in the context of debugging, monitoring, and improving systems.20 Thus, these explanations tend to prioritize completeness, at the possible risk of lower comprehensibility. Explanations of behavior generally focus on clarifying how a model relates inputs to outputs,32,54,59 and may involve showing the influence of each input, revealing characteristics of similarly classified instances, and/or changes in inputs that would result in a change in output.55 These may be referred to as “black box explanations”, ”observations”, “justifications”, or “persuasive explanations” as they offer reasons for a model’s outputs, but generally do not contain information regarding the internal operations of the model.32,48,54,57,59 These explanations can provide insights into why a system may misfunction, or produce unintended or undesired effects, and are typically most useful in ensuring that a system meets various evaluation criteria such as unbiasedness, justifiability, etc.20 Thus, these explanations tend to have higher comprehensibility, but lower completeness; however, it should be noted that in some cases, an explanation of model processes may be requested if an explanation of model behavior does not satisfy a user’s information needs.59 16 Researchers have also distinguished between explanations provided at the global and local/instance levels of models, with these terms being used consistently throughout the literature.12,15,26,43,51,56,60–62 According to Adadi and Berrada,51 an explanation for a model at the global level “facilitates the understanding of the whole logic of a model and follows the entire reasoning leading to all the different possible outcomes”. An explanation for a model at the local level provides the reasoning behind a specific model output or group of outputs.51,62 This is also sometimes referred to as the instance level, which is the term adopted in this work. While instance-level explanations are also aimed at helping users gain mental models of the system, they focus on helping a user understand and interpret specific model outputs.61 These explanations can achieve high levels of comprehensibility, but generally lack completeness. Both global- and instance-level explanations can be aimed at explaining either model processes or behavior, although typically global-level explanations describe model processes and instance-level explanations describe model behavior. 17 2.1.2 Interpretability Approaches As mentioned previously, I view approaches to interpretability as forms of explanation and thus consistently use the term explanation in reviewing the literature. The model itself can serve as an explanation and may be referred to as an “intrinsically interpretable model”, “inherently interpretable model”, “intelligible model”, “comprehensible model”, “transparent model”, “transparent-box model”, “white-box model”, or “glass-box model”.26,29,51,56,66 Pure transparent approaches will generate explanations that have high completeness, but the level of comprehensibility will depend on the complexity of the model. 2.1.2.2 Post-hoc Explanation Approaches Post-hoc explanation approaches involve separating the tasks of model learning and explanation, i.e., applying explanation methods after the model learning/training process.51,62 These approaches are sometimes referred to as “reverse engineering” approaches to explanation 19 as they involve a level of model reconstruction.26,51 These explanations may be in the form of visualizations, natural language or text, rules, examples, and various other formats.20,47,51 Post-hoc explanation approaches can be sub-divided into model-specific and model-agnostic approaches.15,28,51,62,65 Model-specific explanation approaches are only applicable to specific models as they rely on idiosyncrasies of the model’s internal mechanisms.28,51,62 These explanations can aim to describe model processes and/or behavior and can be provided for both the instance- and global- levels, although global-level explanations tend to be more common. Model-agnostic explanation approaches are not tied to any specific model or algorithm, i.e., they treat the original model as a “black-box”.28,51,62,64 They generally operate by analyzing only the inputs and outputs of the original model and thus describe model behavior.28,62,64 The model-agnostic approaches can be provided at both the global- and instance-levels, although instance-level explanations are more commonly seen.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 50
    },
    {
        "text": "More specifically, model-agnostic post-hoc explanation approaches provide general explanation formats that allow for customization to fit user information needs, enable comparisons of different models, and facilitate the process of switching out a model in a deployed ML system.64 Model- 20 agnostic post-hoc explanation approaches can be loosely grouped by the technique used to generate the explanation: 1) visualizations (e.g., partial dependence plots, individual conditional expectation), 2) knowledge extraction (e.g., rule-extraction, model distillation), 3) feature influence methods (e.g., sensitivity analysis, feature importance/attribution), and 4) example-based (e.g., prototypes and criticisms, counterfactual explanations).51 2.1.3 Evaluating Interpretability Approaches As what constitutes a good explanation for an ML model is both user- and context-dependent, it is unsurprising that the literature provides no standard approach to evaluating model explanations that claim to facilitate interpretability. They proposed a simple 3-level taxonomy for approaches to interpretability evaluation: 1) application-grounded, 2) human-grounded, and 3) functionally-grounded. These general categorizations provide a useful framework for discussing general approaches to evaluating interpretability. In this section I discuss only general approaches to evaluating interpretability and I discuss specific studies evaluating interpretability within the healthcare domain in section 2.3.2. General approaches to interpretability evaluation (adapted from Doshi-Velez and Kim43). A summary of the three general approaches to interpretability evaluation with example experiments for each approach. These approaches are centered on the idea that if a system that employs an explanation approach has practical utility, then the explanations must satisfy the demand for interpretability. Much of the literature on interpretability appears to take this approach to justify claims for interpretability, but it is debatable whether the current suggested proxies are appropriate. For example, many methods claim interpretability by adopting pure transparent or hybrid approaches to explanation and then using model size as a measure for explanation complexity.26,43 These approaches suggest that the size and transparency of a model can serve as proxies of explanation quality. The general challenge in functionally-grounded approaches lies in identifying appropriate proxies for explanation quality, particularly because there are limited studies on user-based measures of interpretability and relevant concepts such as comprehensibility are difficult to quantify.11,28,43,68 2.2 User-centered Explanation Design and Evaluation for AI Systems This section provides an overview of the relevant literature on user-centered explanation design and evaluation for AI systems. A summary of guidance on user-centered explanation design and evaluation that is relevant to the proposed framework is also provided. A framework proposed by Wang et al.40 relies on theories of human reasoning and explanation, and highlights specific elements of AI explanation that support these processes and mitigate errors. The framework promotes explanation design by linking specific AI explanation techniques and elements to the human cognitive processes and patterns they can support (e.g., “what if” type explanations support counterfactual reasoning; information about the prior probability can help mitigate confirmation bias). Moreover, the framework links reasoning processes to a non-comprehensive list of AI explanation elements and techniques that currently exist, which provides limited guidance on how user reasoning can inform the design of new displays for existing explanation algorithms as well as for new explanation algorithms. Although the proposed framework helps elucidate general explanation design ideas to support the goals for each user type, it includes only a select set of the available concepts on explanation design available in the model interpretability literature and it does not consider the environment in which the explanation is being provided to a user. Evaluation methods are tailored to each explanation.” (Image and caption taken directly from Ribera and Lapedriza42) 27 Mohseni et al.44 reviewed existing literature on explainable AI from a variety of domains to develop a general framework for the design and evaluation of explainable AI systems that considers the type of users and their primary goals and needs. The authors suggest designing explanations by identifying the intended user of an explainable AI application, choosing an AI application that meets the targeted user’s primary goals and needs, choosing the explanation type and format that supports the user type and intended application, and finally performing user-evaluations of the explanations. Mohseni et al.44 expand upon this suggested approach by proposing a three-level nested model to design and evaluate an explainable AI system, where each level builds upon the work of previous levels. Three-level nested model to designing and evaluating an explainable AI system from Mohseni et al.44 ”The innermost layer (Red) presents design and evaluation of interpretable ML algorithms. The outer layer (Green) demonstrates evaluation of explainable AI system outcomes with end-users.” (Image and caption taken directly from Mohseni et al.44) 28 The goal at the lowest level (Interpretable Models Level) is to design understandable models, which usually involves ML experts who want to evaluate the trustworthiness and reliability of an explanation method, usually utilizing computational measures such as comparison to an interpretable model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 51
    },
    {
        "text": "These three levels and proposed evaluation metrics closely align with the functionally-grounded, human-grounded, and application-grounded approaches to evaluating interpretability proposed by Doshi-Velez and Kim,43 respectively. While this proposed framework is useful when discussing the big picture of user-centered design and evaluation of explainable AI systems, it provides limited guidance on explanation designs that could support user needs at each of the three levels. In addition to the previously mentioned frameworks, a few other authors have provided useful insights that can guide user-centered explanation design and evaluation. These goals and concerns fall under Samek et al.’s71 four broad categories of reasons why users seek explanations of AI systems: 1) verification, 2) improvement, 3) learning, and 4) compliance. Other insights that can guide user-centered explanation design and evaluation come from the previously discussed work on interpretability evaluation by Doshi-Velez and Kim.43 The authors hypothesize several factors that may influence user explanation needs, highlighting the importance of considering user expertise and environmental factors (e.g., time constraints) when completing a task. Categories of users and explanation goals (adapted from Ras et al.20 and Samek et al.71) Main Category Sub-category Description and Concerns Explanation Goals Expert user Engineer  Have detailed knowledge about mathematical theories and principles behind a system  Concerned with developing and improving ML algorithms/models  Verification E.g., debugging models  Improvement E.g., identifying ways to improve existing models Developer  Focus on building ML systems for lay people  Often utilize off-the-shelf ML algorithms  Concerned with satisfying various use cases of the ML system  Verification E.g., model behavior alignment with use case criteria  Improvement E.g., hyperparameter tuning Lay user Owners  Acquire ML system for use  Individuals and organizations  Concerned with evaluating capabilities of system  Verification E.g., justification of predictions, malfunction rate  Compliance E.g., liability/safety concerns End-users  Individuals expected to use the ML system as part of personal and/or professional activities  Concerned with understanding capabilities of system  Verification E.g., justification of prediction, reliability concerns  Learning E.g., actionable outcomes, assistance in completing task Data subjects  Individuals or entities whose information is being processed or who are otherwise directly affected by the ML system  Concerned with system impact on self  Compliance E.g., adherence to ethical principles, privacy concerns Stakeholders  Other individuals or organizations who claim an interest in the ML system, but are not directly connected to its development, use, or outcome  Concerned with system impact in general  Compliance E.g., adherence to ethical principles, liability concerns 2.3 Interpretability in Healthcare 2.3.1 Motivations for Interpretability The high stakes and complex nature of healthcare motivates ML-based applications which assist healthcare providers in achieving various goals.12 Thus, much of the literature motivates the need for model interpretability in healthcare by claiming that it is integral to the usability, 31 acceptability, and trustworthiness of an ML model.6–8,10–12,29 Although these motivations are somewhat vague, most are linked to real-world goals in which criteria such as informativeness, accountability, liability, justifiability, etc. The most common goal for a provider utilizing an ML model is to provide better and more effective care for a patient.12 In most cases, ML models are proposed as a tools to help providers analyze patient data and derive insights that can guide clinical decision-making.4,12,29,34 Effective use of an ML model in practice requires a healthcare provider to assimilate knowledge from the model and reconcile it with prior knowledge and missing contextual information to make informed care decisions. As clinical decisions made with the assistance of an ML model may affect the lives of patients, it is essential that providers be able to validate the information provided by the model.4,8,34,51 Moreover, healthcare practitioners are legally and ethically responsible for any care decisions made based on ML model information, and will therefore be unlikely to adopt or deploy ML models that cannot justify their outputs or be vetted for potentially critical errors or data bias.6,8,11,12,21,29,34 Thus, when ML models are used to assist in providing patient care, interpretability may be demanded to allow providers to derive actionable insights from the model, verify model outputs before acting on them, and defend care decisions based on the ML model. The demand for model interpretability may also present itself even when ML models are not used directly in clinical practice. For example, it is generally accepted that ML models can be improved by integrating knowledge and feedback from domain experts into the learning/development process.6,7,72 Model interpretability approaches can serve as tools that facilitate conversations between healthcare providers and model developers.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 52
    },
    {
        "text": "Alternatively, ML models may be used in healthcare as data-driven approaches to generating new knowledge that could help advance the 32 field.7,12,34 By uncovering correlations between patient characteristics and outcomes of interest, ML approaches to predictive modeling can assist domain experts in causal reasoning and hypothesis generation.34,69,73 In this case, the explanation of a model should assist domain experts in identifying new predictively accurate explanatory variables to study,7,73 potentially leading to new therapies and interventions that lead to improved outcomes and lower costs.34 2.3.2 Explanation Approaches and Evaluations There has been a recent surge in publications of high-performing models for healthcare applications that also make a claim of interpretability (Figure 7). Table 3 uses the terms introduced in section 2.1 to summarize some of the interpretability approaches seen in this recent set of work. This table only captures a subset of the relevant literature, but it does offer insight as to model interpretability research from the ML community that has been used in healthcare applications. SCOPUS publications on model interpretability in healthcare from 2008-2018. It is vital that ML models and explanations be delivered in a manner that does not exacerbate this problem.6,12 Additionally, the intended user should be satisfied with the information provided.6,12 Based on the literature survey, no human-evaluation studies of model explanations in healthcare have fully addressed these issues. Model explanation approaches and evaluations in the recent healthcare literature Katuwal & Chen10 Yang et al.16 Lundberg et al.75 Caruana et al.76 Choi et al.77 Che et al.78 Barakat et al.25 Luo et al.79 Jovanovic et al.14 VanBelle et al.80 Soininen et al.81 Krause et al.74 Letham et al.17 Kunapuli et al. 85 Liu et al.86 Explanation Approaches Used Level Global X X X X X X X X X Instance X X X X X X X X X X X X Integrated Pure transparent X X X X X X Hybrid X Explanation-producing X X Post-hoc Model-specific X X X Model-agnostic X X X X X X X Evaluations Functionally-grounded X X X X X X X X X X X X X X X X Human-grounded Application-grounded X X 34 3.0 Proposed Framework for Designing User-Centered Explanations In this chapter, I present my proposed framework for user-centered explanation design for ML-based systems in healthcare, which is depicted in Figure 8. The framework was inspired by the frameworks of Wang et al.40 and Ribera and Laprediza42 and incorporates other guidance on user-centered explanation design for AI systems. The purpose of this framework is to propose a general approach to user-centered explanation design that can be applied to the adoption of existing explanation approaches and to the development of new approaches. Proposed framework for designing user-centered explanations. The framework was inspired by the frameworks of Wang et al.40 and Ribera and Laprediza42 and incorporates insights from work on explanations by Ras et al.20, Samek et al.,71 Lim et al.,41 and Doshi-Velez and Kim.43 36 3.1 Description of Framework The framework suggests that user-centered explanation design should be informed by the entire context of use of an explanation—that is, explanation design should consider not only who an explanation is being provided to and why they want that explanation, but also when and where that explanation will be used. Prior work has tried to create categories of users to define 37 explanation design needs, but as Ras et al.20 noted, users often don’t fall into a single category. Although several prior works have identified various user needs and goals that drive the need for explanations, most of these can be captured in Samek et al.’s71 four broad categories of reasons why explanations of intelligent systems are required: 1) verification, 2) improvement, 3) learning, and 4) compliance. The target and level of the explanation design can generally be determined by the type of explanation the user is seeking. Lim et al.41 provide a useful taxonomy of explanation types based on the intelligibility query they aim to answer: 1) “input” explanations, which provide information on the input values being used by a system; 2) “output” explanations, which provide information on specific outcomes/inferences/predictions; 3) “certainty” explanations, which provide information on the uncertainty of a certain output; 4) “why” explanations, which provide information on how a system obtained an output value based on certain input values (i.e., model traces or complete causal chains); 5) “why not”/”how to” explanations, which provide information on why an expected output was not produced based on certain input values (i.e., contrastive explanations, counterfactuals); 6) “what if” explanations, which provide information on expected changes in outputs based on certain changes in the input (i.e., explanations that permit outcome simulations); and 7) “when” explanations, which provide information on which circumstances produce a certain output (i.e., prototype or case-based explanations).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 53
    },
    {
        "text": "Summarizing and expanding upon the work of Doshi-Velez and Kim,43 the presentation of an explanation can generally be summarized using 4 main categories: 1) the unit of the explanation, or the form of the cognitive chunk being processed (e.g., raw features, feature summaries, images, or instances); 2) the organization of the explanation units, or the compositionality and relationship between the units, which may include groupings, hierarchical or relational organizations, or summary abstractions (e.g., free text summary of a combination of units); 3) the dimensionality, or processing size/levels of explanation information, which may include the overall size of an explanation and/or interactive exploration options; and 4) the manner in which information is represented, which includes the vocabulary, data structures, and visualizations used to express information. 3.2 Guidance on Application It is useful to consider the application of the framework in the context of Mohseni et al.’s44 three-level nested model to designing and evaluating an explainable AI system (see Figure 6 in section 2.2) and the taxonomy of evaluation approaches proposed by Doshi-Velez and Kim43 (see Figure 3 in section 2.1.3). At the lowest level in Mohseni et al.’s44 model (Figure 6, Interpretable Models Level, red layer), where experts develop new approaches to model interpretability and explanations are typically evaluated using functionally-grounded approaches (i.e., no human involvement), the framework can help developers consider the users and environments for which their approach might be best suited. The framework has direct applicability at the middle level in Mohseni et al.’s44 model (Figure 6, Explanation Interpretability Level, blue layer), where the goal is to design explanations that satisfy target user usability needs and where human-grounded evaluation approaches are typically utilized. Preliminary explanation designs can then be proposed and refined in a series of human-grounded evaluations utilizing target users. At the highest level in Mohseni et al.’s44 model (Figure 6, Explainable AI Systems Outcome level, green layer), the explanation design has been finalized, and human-grounded and/or application-grounded evaluation approaches are employed to evaluate whether the system satisfies target-user needs. In chapters 4-6, I demonstrate an application of the defined framework to design explanations for a model that predicts in-hospital mortality for pediatric ICU patients. 44 4.0 Application of Framework to Suggest Explanation Designs for a Pediatric ICU In-hospital Mortality Risk Model In this chapter I apply the proposed framework to the problem of predicting mortality risk for patients admitted to the pediatric ICU. Mortality risk prediction is a common application of ML in medicine.87,88 In critical care, mortality prediction models have been used to establish performance benchmarks for outcome comparison and quality improvement initiatives, to define endpoints or illness severity adjustments in research studies, and to assist in clinical decision-making by providing early warnings of clinical deterioration.89 With regard to using these models for clinical decision-making in the critical care environment, there has been growing interest in utilizing data mining techniques and ML approaches to build customized prediction models using data from local electronic health record (EHR) data repositories.90–92 These models can be integrated into EHRs to provide real-time, individualized patient mortality risk predictions, which can assist critical care providers in surveilling patients for changes in acuity,93 determining clinical priorities,94 and providing support for making decisions about prognosis and treatment.95,96 As predictive models are often based on incomplete information about a patient, use of a predictive model in decision-making challenges providers to integrate information from the model with their own clinical knowledge.45,97 However, this process may require significant cognitive demands when providers do not understand the clinical basis for a prediction.45 Thus, healthcare providers are unlikely to use a prediction model in decision-making without explanations.45,93,97 Therefore, I applied the proposed framework to gain a better understanding of the potential benefit of providing user-centered explanations for mortality risk prediction models, specifically in the context of using the model to aid in decision-making processes. In section 4.1, I describe the development and evaluation of an in-hospital mortality risk prediction model for pediatric ICU patients. In section 4.3, I present preliminary explanation designs for the model that will be refined in human-grounded evaluations with target users. All insights are derived from my prior experiences in developing predictive models as well as from an informal review of the literature on interpretable ML, social science work on human explanation and medical decision-making, HCI, information visualization, CDSS (specifically barriers, facilitators, and provider perceptions), and predictive models evaluated by providers or implemented in practice. It has been shown that adoption of predictive models can be influenced by provider perceptions of the model utility, credibility, and usability.112 Thus, it is useful to consider how the framework might inform explanation designs that positively influence these perceptions of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 54
    },
    {
        "text": "In section 4.2.3 I provide a brief commentary on how the answers to these target questions can inform explanation designs that positively influence provider perceptions of the utility, credibility, and usability of the pediatric ICU in-hospital mortality risk model. Summary of an initial context of use and a possible space of explanation designs for the pediatric ICU in-hospital mortality risk model. 54 4.2.1 Context of Use In this section, I define an initial context of use for explanations for the pediatric ICU in-hospital mortality risk model by summarizing the current understanding of who might need an explanation, when and where they might require that explanation, and why they want the explanation. 4.2.2 Explanation Design Requirements In this section, I utilize the defined context of use and insights from prior experiences and the literature to suggest promising design requirements for what information the explanation needs to contain and how to provide that information to target users. What Possible explanation design requirements: The target user goals are verification and learning, which the literature suggests can be supported by showing the influence of risk factors 58 on a specific prediction, as this facilitates comparison with clinical knowledge and can assist in deriving actionable insights.45,93,96,97,121 This finding suggests that target users are likely seeking contrastive explanations (“why not” type explanations) for specific predictions, or explanations that demonstrate which inputs are pushing the prediction toward one outcome over another. As the target users are expected to have limited ML knowledge, explanations targeted at explaining model behavior, or relationships between inputs and outputs, are likely appropriate. Prior work has supported the use of instance-level explanations for predictive models in healthcare as they provide insights on individual patients and thus support precision medicine initiatives.10,16 The aforementioned design requirements can be met by existing post-hoc explanation approaches that provide instance-level explanations based on feature influence values. A model-agnostic explanation approach would allow the explanation design to be tailored to reduce cognitive load and processing time without having any impact on the underlying predictive model or its accuracy. Gaps in knowledge: Although the context of use and literature insights support the use of model-agnostic, instance-level, explanation approaches based on feature influence methods, the utility of these explanations has not been verified in studies with healthcare providers. How Identified design requirements: As model-agnostic, instance-level, explanation approaches based on feature influence methods were identified as a promising explanation approach, design options discussed in this section relate to the presentation of these types of explanations. As the target users are expected to have limited understanding of ML and will be using explanations in a cognitively demanding and time-constrained environment, explanation content should be presented in a manner that facilitates information processing with minimal demands on cognition and time. 62 4.2.3 Potential impact on perceptions As discussed in section 4.2.1, explanations for the pediatric ICU in-hospital mortality risk model would likely be used by critical care providers who: 1) have limited knowledge of statistical and ML concepts (who), 2) work in a cognitively demanding and time-constrained environment (when/where), and 3) would be seeking explanations to assist them in verifying predictions from the model and learning information that can assist in decision-making (why). 4.3 Preliminary Explanation Designs As noted in section 4.2.2, there are several aspects of the explanation design that require further investigation in discussions with target users. To facilitate these discussions, I proposed preliminary explanation designs for the pediatric ICU in-hospital mortality risk model. As per the insights from section 4.2, I focused on suggesting explanation designs for model-agnostic, instance-level explanations based on feature influence methods to better understand the potential utility of these types of explanations within the healthcare domain. 63 Two popular and publicly-available model-agnostic, instance-level explanation algorithms have been previously applied to predictive modeling problems in the healthcare domain—the local interpretable model-agnostic explanations (LIME) algorithm64,123 and the Shapley additive explanations (SHAP) algorithm.124,125 The LIME algorithm generates an explanation for a prediction by learning an interpretable model (e.g., sparse linear regression) that fits the local decision boundary near the instance of interest. 69 5.0 User Studies to Refine Explanation Design I conducted focus groups with critical care providers to refine the defined context of use and solicit feedback on the mock-ups of the explanation designs for the pediatric ICU in-hospital mortality risk model proposed in section 4.3. Explore critical care provider preferences on the design options proposed in the mock-ups to identify those that facilitate understanding of and positively influence perceptions of the model Insights from the focus group were used to inform a final user-centered explanation design to be used in a laboratory study to evaluate the impact of a user-centered explanation design on critical care provider decision-making and perceptions of the pediatric ICU in-hospital mortality risk model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 55
    },
    {
        "text": "3) Mock-up review discussion (~50 mins): Participants received brief training on interpreting explanation information and then participated in a guided group review and critique of the five mock-ups of explanation designs for predictions from the 71 pediatric ICU in-hospital mortality risk model. Insights from the coding process were analyzed in conjunction with questionnaire responses to summarize findings about the context of use and explanation design and identify elements that influence critical care provider perceptions of the pediatric ICU in-hospital mortality risk model. The following sections summarize insights on the context of use and explanation design for the pediatric ICU in-hospital mortality risk model, specifically highlighting factors that influenced perceptions of the model. Like ‘this patient was at high risk for mortality and I didn’t otherwise recognize that.’” “Just telling you what you should know, and what you would appreciate if you clicked into the chart and dove into the information, but at least this is synthesizing that for you.” Providers sought actionable information from the model “Can I do anything to mitigate that risk of mortality based on what I know?” “I don’t think there’s a lot I can do about most of that stuff…” 77 5.2.2 Insights on Explanation Design Table 11 provides a high-level summary of the insights on explanation design discussed in this section, specifically the content to include in the explanation design as well as the preferred design options that would positively influence perceptions of usability. High-level summary of insights on explanation design Desired content (what) Benefits Preferred design options (how) Explanations:  instance-level, model behavior (SHAP explanations)  global-level, model processes  Assess model credibility and utility  Risk expressed as percent probability  Feature groups with details on demand  Interactive options to support different displays/organizations for various users  Familiar icons  Readable from left/right or top/bottom Table of raw feature values  Interpret discretized features  Examine trend-based features  Directionality for trend-based features  Simpler terminology Time-series data plots  Investigate suspicious values  Assess trends and baselines  Multiple plots  Highlight points related to features  Auto-population of data Contextual information  Clinically meaningful interpretation N/A Risk baselines and trends  Context for risk prediction  Prominent display of baseline risk By providing the plots of the SHAP explanation, the list of predictors that went into the model, and the predicted risk from the model, each mock-up provided “why not”2, “input”, and 2SHAP explanations show which inputs are responsible for pushing a prediction toward one outcome over another, which means they are contrastive explanations. Insights on explanation design target questions Topic Insight What Type, target, and level of explanation Providers sought “input”, “output”, “certainty”, “why not”, and “what if” explanations “Do I get a confidence interval somewhere?” “The first question I get when I talk to the doctor is ‘well, why did that happen?’” Some desire for explanations of model processes and at the global-level “What’s the weight of the data that is available from the moment they did transfer them to the ICU and how does that carry into this predictive model?” “Is it possible to see what the machine learned about the relationship between age and raw numbers of vital signs?” Supporting information Raw feature values, raw time-series data, and contextual information aid interpretation “Can I see the data for the blood pressure?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 56
    },
    {
        "text": "Like a 57-point deviation in mean arterial pressure is quite substantial.” “Everything bad that’s happening with this patient seems to be contributed by the Coma Score…Now I see a diagnosis code of a brain tumor I’d give it much more weight.” Providers wanted to see baseline risk and trends of risk prediction over time “This doesn’t show like ‘okay, the in-hospital mortality odds, 3 hrs ago was 1.6 and now it's actually coming down?” “I also think that an odds of death of 12% is still concerning—this child is 10 times more likely to die than the average child in our ICU.” Providers stressed importance of proper training on explanation interpretation “One risk, I think, with this type of data presentation, is I are going to over-interpret the results…this is just showing you how the model worked, it doesn’t necessarily mean the model is saying you should act on these specific [factors]” How Unit of explanation and organization Providers preferred feature groupings for the initial explanation display “I really appreciate the groupings on this graph…I said well there’s only an 8% risk of death but it’s being driven largely by this neuro bucket, so what’s going on there?” Providers had mixed preferences on organization of predictors “I like 2-2…I mean because that’s how my brain thinks—I mean I break things down by that a lot of times in my head—physical assessments, labs, that sort of thing…” “Being able to see these are the top 5 increase mortality, these are the top 5 lower mortality...as opposed to the 2-2, where I can just see sort of graph fatigue” Dimensionality Providers wanted interactive linkage of data across plots and tables “I also like that clicking on the graph directs you to the associated lab/physical assessment in the data table.” “Is it possible that when you click on lactate results it could both bring up the raw data graph as well as the little components of the lactate table? 5.3 Final User-centered Explanation Design Based on the insights in section 5.2, I proposed a final user-centered explanation design to be used in an evaluation study with target users. Final user-centered explanation design. 87 6.0 Evaluation This chapter describes the evaluation of the user-centered explanation design for the pediatric ICU in-hospital mortality risk model that was described in Section 5.3. I conducted a laboratory study with healthcare providers to assess the impact of the user-centered explanation design on provider decision-making and perceptions of the model. More specifically, when compared with the prediction model without explanations and having no prediction model, I hypothesized that the prediction model with the user-centered explanation design would improve healthcare provider: 1) accuracy in identifying patients who need to be seen urgently and in selecting relevant information to discuss with the rounding team 2) self-reported confidence in identifying patients who need to be seen urgently 3) efficiency in reviewing patient cases Additionally, I hypothesized that relative to the prediction model without explanations, the prediction model with the user-centered explanation design would improve healthcare provider perceptions of the performance expectancy and effort expectancy of using the model in clinical practice. Primary outcomes of interest included the impact of the user-centered explanation display on decision accuracy, decision confidence, case review efficiency, and provider perceptions of the pediatric ICU in-hospital mortality risk model. Many participants expressed preference for the “explanation” display, stating that the explanation facilitated model interpretation and comparison with their own clinical judgment. One participant effectively summarized these ideas: “[The ‘prediction only’ display made it] nearly impossible to tell what the key factors were—I’m simply drowning in the computer’s output without a framework to make sense of it…[It’s] very helpful to graphically demonstrate key drivers that the machine found important—it allowed me to integrate the machine’s understanding with my own clinical intuition and knowledge of the patient’s overall context, which I fear may be missed by a machine-learning model at times.” —2nd year resident 106 In addition to clarifying perceptions about the model and displays, participant comments and feedback identified a few possible design improvements for the “explanation” display. 107 7.0 Discussion In this dissertation, I aimed to utilize clinician perspectives to inform the design of explanations for ML-based prediction tools to improve the adoption of these tools in clinical practice. Toward that goal, I developed a new theoretical framework of explanation design for ML models and used the framework in conjunction with healthcare provider feedback to inform the design of a user-centered explanation for predictions from a pediatric ICU in-hospital mortality risk model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 57
    },
    {
        "text": "The user-centered explanation design was a model-agnostic, instance-level explanation of feature influence generated using the publicly available SHAP algorithm.124,125 I hypothesized that the predictive model with the user-centered explanation design would improve provider perceptions of utilizing the predictive model in practice, which would result in the predictive model improving provider accuracy, confidence, and efficiency in making decisions during preparations for patient rounds relative to having no model and having a model that does not provide explanations. While the results of the studies demonstrated that the user-centered explanation design improved provider perceptions of utilizing the predictive model in practice, no significant effect of the user-centered explanation design on decision-making accuracy, confidence, or efficiency was observed. Overall, the results of the studies revealed that critical care providers had positive perceptions of the pediatric ICU in-hospital mortality risk model and the user-centered explanation design. In the evaluation study, the user-centered design of the SHAP explanations 108 greatly improved provider perceptions of the performance expectancy and effort expectancy of using the pediatric ICU in-hospital mortality risk model in practice. These findings suggest that model-agnostic, instance-level, explanation approaches based on feature influence methods are a viable approach to explaining model predictions in a way that is both comprehensible and useful to healthcare providers. Although other studies have utilized these approaches to explain predictive models in healthcare,10,16,75 to the best of my knowledge this is the first study to verify that these explanations would be positively received by healthcare providers. Provider acceptance of these explanations could help overcome the model interpretability barrier to utilizing ML models in practical applications in medicine. Although providers indicated that they would accept and use the pediatric ICU in-hospital mortality risk model, the evaluation study revealed no significant effects of the model with the user-centered explanation display on decision-making accuracy, confidence, or efficiency, which was unexpected. Specifically, providers found that the explanations simplified interpretation of the risk prediction from the model and integration of the model information with their clinical knowledge. Although the benefit of providing explanations could not be demonstrated quantitatively, the subjective assessments and provider feedback suggest that it is still valuable to provide the explanations for the predictive risk model. Allowing users to ask for more information from the system improved participant perceptions of the system, which provides some support for claims that effective explanations for AI systems would mimic human explanation and occur as part of a social interaction or conversation.27 Providing interactive explanations would also facilitate inclusion of multiple explanation types into a single explanation display, such as incorporating the “what if” type explanations that some participants requested during the qualitative inquiry study. The proposed theoretical framework in this work could support further exploration of how to design combinations of explanations that effectively support healthcare provider explanation needs in various tasks. 115 While this work advocates the need for user-centered explanation designs for predictive models in healthcare, one could argue that there may be scenarios in which explanations are not required at all. Even if global explanations of a model are considered unnecessary, instance-level explanations could still provide valuable information to a user that enables them to act on a specific prediction. Although it is likely that some form of explanation will be required for most predictive models in healthcare, the need for explanations will be context-dependent and should be discussed in the early stages of model development. These positive perceptions warrant further exploration of the pediatric ICU in-hospital mortality risk model with explanations to address some of the limitations and unanswered questions. Some other interesting directions for future work are suggested by the two provider viewpoints regarding the benefit of the predictive model with explanations. Second, it was interesting to note that some providers viewed the predictive model with explanations as a tool that could improve provider efficiency in prioritizing patients and reviewing patient information. This suggests that instance-level explanations could be useful communication tools for model developers to incorporate provider feedback and knowledge into models based on ML approaches. This could possibly involve interactive ML approaches in which healthcare providers use instance-level explanations to provide feedback on individual predictions to improve a model. Additionally, components could be included to provide more specific design suggestions based on the category of explanation approach (e.g., design options for model-agnostic, instance-level explanations of feature influence). 7.2 Conclusions There is an increasing interest in high-performing predictive models capable of explaining the reasoning behind a prediction in a way that is both comprehensible and useful to healthcare providers. This dissertation aimed to address this need by proposing a new theoretical framework for user-centered explanation design of ML models in healthcare. The proposed framework was utilized in conjunction with healthcare provider feedback to inform the design of a user-centered explanation for predictions from a pediatric ICU in-hospital mortality risk model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 58
    },
    {
        "text": "While the user-centered explanation design improved provider perceptions of utilizing the predictive model in practice, the predictive model with the user-centered explanation did not demonstrate a significant improvement in provider accuracy, confidence, or efficiency in making decisions. Nonetheless, the work demonstrated that model-agnostic, instance-level, explanation approaches based on feature influence methods are a viable approach to explaining model predictions to healthcare providers. These explanations can be utilized for any model and can help overcome the model interpretability barrier to utilizing high performance ML models in practical applications in medicine. This work also identified several possible areas in which the proposed theoretical framework could be useful in designing explanations. 121 Overall, the work in this dissertation provides meaningful insights into the role of model interpretability and explanation in healthcare and contributes to knowledge on how to effectively communicate ML model information to healthcare providers. It is my hope that insights from this work can facilitate conversations with healthcare providers about the development, deployment, and continuous improvement of ML-based tools that can promote positive changes in clinical practice. This class of explanation model is used by several instance-level explanation methods, and therefore unifies these methods under a single approach. Appendix A.3 Algorithm Comparison Experiments To select between the SHAP and LIME algorithms, I performed experiments comparing the algorithms on two properties of explainers previously identified as desirable in the literature: 1) fidelity (i.e., the explanation model should accurately reflect the underlying predictive model’s behavior) and 2) computational efficiency.12,20,21,65 I believe that these two properties will be essential for any explanation approach used in healthcare. Environment will dictate the available user time and cognitive capacity, the available technical resources, and the user’s perception of the system, which all may influence explanation design. Context of use--why User needs and goals that drive the need for an explanation. Four general reasons why explanations of intelligent systems are required include verification, improvement, learning, and compliance. The presentation of an explanation can generally be summarized using 3 main categories: dimensionality, explanation unit granularity and organization, and information representation. 4.1 Dimensionality A main category to consider when designing an explanation. 4.3 Information representation A main category to consider when designing an explanation. Katuwal GJ, Chen R. Machine Learning Model Interpretability for Precision Medicine. Bibal A, Frénay B. Interpretability of Machine Learning Models and Representations: an Introduction. Ahmad MA, Eckert C, Teredesai A. Interpretable Machine Learning in Healthcare. Hall P, Gill N. An Introduction to Machine Learning Interpretability: An Applied Perspective on Fairness, Accountability, Transparency, and Explainable AI. Dosilovic FK, Brcic M, Hlupic N. Explainable artificial intelligence: A survey. In: Proceedings of NIPS 2017 Symposium on Interpretable Machine Learning. In: IJCAI 2017 Workshop on Explainable Artificial Intelligence. Designing Theory-Driven User-Centric Explainable AI. A proposal of User-Centered Explainable AI. Towards A Rigorous Science of Interpretable Machine Learning. A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems. The Mythos of Model Interpretability. In: 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016). Machine Learning Interpretability: A Science rather than a tool. Poursabzi-Sangdeh F, Goldstein DG, Hofman JM, Vaughan JW, Wallach H. Manipulating and Measuring Model Interpretability. Adadi A, Berrada M. Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI). Gilpin LH, Bau D, Yuan BZ, Bajwa A, Specter M, Kagal L. Explaining Explanations: An Overview of Interpretability of Machine Learning. In: 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016). The Promise and Peril of Human Evaluation for Model Interpretability. In: NIPS 2017 Symposium on Interpretable Machine Learning. In: XAI Workshop on Explainable Artificial Intelligence. Molnar C. Interpretable Machine Learning: A Guide for Making Black Box Models Explainable. In: IJCAI-17 Workshop on Explainable Artificial Intelligence (XAI). Ribeiro MT, Singh S, Guestrin C. Model-Agnostic Interpretability of Machine Learning. In: 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016). In: NIPS 2016 Workshop on Interpretable Machine Learning in Complex Systems. Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models. The Building Blocks of Interpretability. What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use. In: NIPS 2016 Workshop on Interpretable Machine Learning in Complex Systems.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 59
    },
    {
        "text": "This aligns with concepts from social science literature that explanation should occur as part of a conversation, where users may ask for additional information or explanations after receiving the initial explanation.27,56 For the model with instance-level explanations of feature influence, interactive options for controlling dimensionality could include control over the granularity of the units of explanation (e.g., whether to view individual features or feature groups), control over how units of 61 explanation are organized or grouped (e.g., by increasing/decreasing risk), and/or control over the size of the explanation (number of units of explanation shown). This mock-up depicts the following design options:1) unit of explanation—indiviudal features, 2) organization of explanation units—no grouping, 3) dimensionality—modifiable explanation size and static granularity of explanation unit, 4) risk representation—odds, and 5) explanation display format—tornado plot. This mock-up depicts the following design options:1) unit of explanation—feature groups, 2) organization of explanation units—influence groups, 3) dimensionality—modifiable explanation size and modifiable granularity of explanation unit, 4) risk representation—probability, and 5) explanation display format—tornado plot. This mock-up depicts the following design options:1) unit of explanation—feature groups, 2) organization of explanation units—influence groups, 3) dimensionality—static explanation size and static granularity of explanation unit, 4) risk representation—probability, and 5) explanation display format—force plot. This mock-up depicts the following design options:1) unit of explanation—individual features, 2) organization of explanation units—influence groups, 3) dimensionality—modifiable explanation size and static granularity of explanation unit, 4) risk repsentation—probability, and 5) explanation display format—tornado plot. This mock-up depicts the following design options:1) unit of explanation—feature groups, 2) organization of explanation units—influence groups and assessment groups, 3) dimensionality—modifiable explanation size and modifiable granularity of explanation unit, 4) risk repsentation—probability, and 5) explanation display format—tornado plot.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 60
    },
    {
        "text": "This main category code is meant for organizational purposes only and should not be applied. This main category code is meant for organizational purposes only and should not be applied. This main category code is meant for organizational purposes only and should not be applied. This main category code is meant for organizational purposes only and should not be applied. This main category code is meant for organizational purposes only and should not be applied.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 61
    },
    {
        "text": "JAMA. JAMA. JAMA. JAMA. BMJ.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 62
    },
    {
        "text": "Heal Inf Sci Syst. Heal Inf Sci Syst. Heal Expect.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 63
    },
    {
        "text": "This parent code should only be applied when a participant comment falls within this parent category, but none of its children codes can be applied appropriately. This parent code should only be applied when a participant comment falls within this parent category but none of its children codes can be applied appropriately. This parent code should only be applied when a participant comment falls within this parent category but none of its children codes can be applied appropriately. This parent code should only be applied when a participant comment falls within this parent category but none of its children codes can be applied appropriately. Should only be applied when a participant comment falls within this parent category but none of its children codes can be applied appropriately. This parent code should only be applied when a participant comment falls within this parent category but none of its children codes can be applied appropriately. This parent code should only be applied when a participant comment falls within this parent category but none of its children codes can be applied appropriately. This parent code should only be applied when a participant comment falls within this parent category but none of its children codes can be applied appropriately. This parent category code should only be applied when a participant comment falls within this parent category but none of its children codes can be applied appropriately.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 64
    },
    {
        "text": "Thanks to Dr. David Boone and the Computer Science, Biology, and Biomedical Informatics Summer Academy for providing me with the opportunity to hone my teaching and mentorship skills.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 65
    },
    {
        "text": "7.1 Limitations and Future Work The main limitation of this work was in the evaluation study design, specifically the small sample size and the insufficient study session length, which likely negatively impacted the ability 116 to detect any significant effect of the explanation design on decision-making outcomes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 66
    },
    {
        "text": "Additionally, it appears that the overall system design did not adequately represent the context in which the predictive model might be used in clinical practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 67
    },
    {
        "text": "More specifically, the predictive model system was not presented as a tool integrated into the existing EHR, which is how the model would likely be presented to providers when deployed into practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 68
    },
    {
        "text": "As noted by participant comments and feedback on the system, this presented issues due to lack of access to certain patient data (e.g., interventions) and unfamiliar data presentations (e.g., laboratory and vital sign plots).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 69
    },
    {
        "text": "The lack of contextual information and unfamiliar data displays likely negatively impacted measures of the decision-making metrics, specifically decision efficiency.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 70
    },
    {
        "text": "It may have also negatively impacted provider perceptions of the tool’s ability to help them accomplish tasks quickly.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 71
    },
    {
        "text": "As the main focus was to examine the value of explanations, model information was only presented for single predictions and providers made decisions about individual patient cases.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 72
    },
    {
        "text": "However, as noted by nurses in the qualitative inquiry study, risk trend information was considered useful in assessing changes in risk and was perceived as having higher clinical utility than single risk predictions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 73
    },
    {
        "text": "Thanks to the Jewish Healthcare Foundation for the knowledge and experience I gained in the Patient Safety Fellowship program.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 74
    },
    {
        "text": "Moreover, physicians mentioned that the system would be useful in prioritizing patients, which suggests that an overview of risk predictions for a group of patients may be helpful in making prioritization decisions about patient groups.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 75
    },
    {
        "text": "Because the system did not include risk trends or overviews of risk predictions for groups of patients, a vital piece of how the predictive model system might be used to make decisions in the clinical setting may have been missed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 76
    },
    {
        "text": "Finally, it’s possible that the 117 evaluation metrics used in the evaluation study did not capture how explanations of predictive models might impact decision-making.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 77
    },
    {
        "text": "While accuracy, confidence, and efficiency are obvious metrics to assess improved decision-making, it’s possible that explanations of predictive models improve decision-making in subtler ways.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 78
    },
    {
        "text": "Examples of alternative metrics of improved decision-making could include: 1) provider shared decision-making performance (e.g., explanations could facilitate conversations with patients that lead to better shared decision-making); 2) amount of information incorporated into a decision (e.g., explanations could prompt providers to view more patient information prior to making a decision, which could be viewed as beneficial as they would rely less on heuristic decision-making); and 3) effort required to make decisions (e.g., explanations may reduce cognitive effort required by providers to make decisions).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 79
    },
    {
        "text": "Some of these metrics may be challenging to measure (e.g., shared-decision making performance138), but are worth considering for inclusion in future studies evaluating the potential impact of predictive model systems.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 80
    },
    {
        "text": "Despite the aforementioned limitations, provider perceptions of the predictive model with explanations were generally positive, indicating that they would accept and use the system in practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 81
    },
    {
        "text": "Specifically, I would propose designing a system that presents the predictive model with the user-centered explanation as a tool integrated into the existing EHR.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 82
    },
    {
        "text": "The system would incorporate user feedback on the displays of the supporting information, specifically mimicking the familiar EHR displays for laboratory test and vital sign data and incorporating the other suggestions for improvement provided by users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 83
    },
    {
        "text": "And a special thanks to Fourth River Solutions (4RS) for providing me with invaluable professional development and leadership opportunities.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 84
    },
    {
        "text": "It would also include risk trend information for patients and provide overviews of risk predictions for groups or lists of patients.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 85
    },
    {
        "text": "Studies assessing 118 the usability of the system could then be performed to gain a better understanding of how the system information fits into provider workflow and decision-making processes, specifically focusing on the utility of the user-centered explanation design.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 86
    },
    {
        "text": "The combination of a “think-aloud” protocol analysis with “near-live” clinical simulations proposed by Li et al.139 would likely be a good approach for these studies.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 87
    },
    {
        "text": "The “think-aloud” protocol analysis would allow improvement of the usability of the system and give insight into how it might be used in clinical decision-making processes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 88
    },
    {
        "text": "The “near-live” clinical simulations would provide further information as to how the system could best accommodate clinician workflow and be used in the clinical setting, further elucidating the potential impact of the system on provider decision-making processes and patient outcomes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 89
    },
    {
        "text": "The results of this study could then be used to inform the design of evaluation studies of system impact.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 90
    },
    {
        "text": "First, providers who viewed the predictive model as a confirmatory tool exhibited a level of distrust in the system, particularly when the model information contradicted their own knowledge.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 91
    },
    {
        "text": "It is unclear from the study whether this distrust is why some providers view predictive models as confirmatory tools rather than as tools that could guide decision-making.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 92
    },
    {
        "text": "This raises an interesting question as to how provider trust in a predictive modeling system may impact use of the system, and thus affect whether the system has an impact on outcomes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 93
    },
    {
        "text": "Future studies on how provider perceptions of trust in predictive modeling systems affects use of the system would be of interest.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 94
    },
    {
        "text": "Recent work has demonstrated improvements in patient information review efficiency when using 119 past provider viewing patterns to predict and highlight relevant information in the EHR.140 In light of this work and viewpoint, an interesting future study might be to explore how instance-level explanations of models predicting clinical deterioration in patients could be used to effectively guide clinician review of patient information in the EHR by highlighting information of concern.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 95
    },
    {
        "text": "Another direction for future work arises from the finding that the SHAP explanations enabled providers to suggest ways to improve the clinical credibility and utility of the pediatric ICU in-hospital mortality risk model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 96
    },
    {
        "text": "Incorporating healthcare provider feedback and knowledge into models has been shown to improve acceptance of models in practice.23,24 Feedback could be provided in a laboratory setting during model development or in the clinical setting as part of ongoing improvement of a deployed model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 97
    },
    {
        "text": "These settings would likely require different explanation needs and designs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 98
    },
    {
        "text": "While it was beyond the scope of this study, future studies could involve applying the theoretical framework to inform the design of explanations that facilitate provider involvement in the development and ongoing improvement of predictive models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 99
    },
    {
        "text": "A final direction for future work would involve expanding the scope of the proposed theoretical framework.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 100
    },
    {
        "text": "Thank you to all my Pittsburgh friends who provided years of support and companionship.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 101
    },
    {
        "text": "This could include adding components that extend the framework to account for how the use of specific data types or models might influence explanation design and interpretation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 102
    },
    {
        "text": "For example, to account for the influence of a specific model (assuming a model-agnostic explanation approach is not taken), a component could be added that demonstrates how knowledge of the specific model type (e.g., logistic regression, random forest) would influence 120 why the user might want an explanation as well as the space of possible explanation approaches and design options.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 103
    },
    {
        "text": "Special thanks to my friend Jose Posada for helping me work through research problems and for providing support during challenging times.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 104
    },
    {
        "text": "Both algorithms generate explanations for a classifier or regressor in the form of feature-importance rankings and were developed to handle a variety of input data types, including image, text, and tabular data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 105
    },
    {
        "text": "Sections A.1 and A.2 provide an overview of how each algorithm works for a binary classification problem.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 106
    },
    {
        "text": "I focused specifically on tabular data input as this is the most common data format used for risk prediction models in healthcare.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 107
    },
    {
        "text": "Formally, for an instance 𝑥, family of interpretable models 𝐺, original predictive model 𝑓, and proximity measure Π𝑥, an explanation 𝜉(𝑥) can be produced by solving: 𝜉(𝑥) = argmin𝑔∈𝐺ℒ(𝑓, 𝑔, Π𝑥) + Ω(𝑔) (1) 123 where ℒ(𝑓, 𝑔, Π𝑥) provides a measure of how unfaithful the interpretable model 𝑔 is in approximating the original prediction model 𝑓 in the locality defined by Π𝑥, and Ω(𝑔) is a measure of the complexity of interpretable model 𝑔 (e.g., tree depth for decision trees).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 108
    },
    {
        "text": "To approximate ℒ(𝑓, 𝑔, Π𝑥) in a model-agnostic manner, LIME gains an understanding of the local behavior of the original predictive model 𝑓 by generating perturbed samples, obtaining their predictions from 𝑓, and weighting them by their distance from the instance of interest (Π𝑥).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 109
    },
    {
        "text": "Equation 1 can then be optimized to get an explanation by using the new weighted samples to fit an interpretable model that is constrained by the complexity parameter Ω(𝑔).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 110
    },
    {
        "text": "In practice, Ω(𝑔) is a user-specified parameter indicating how many features to include in an explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 111
    },
    {
        "text": "Currently, the implementation of LIME only supports explanations in the form of regressions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 112
    },
    {
        "text": "Specific details on the implementation approaches for text and image data can be found in the LIME code and documentation.141 The following implementation description is based on the code and documentation for LIME version 0.1.1.31.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 113
    },
    {
        "text": "(Image taken directly from Ribeiro et al.123) As indicated in Figure A1, the first step in the LIME explanation process is to generate perturbed data samples.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 114
    },
    {
        "text": "LIME requires training data to perform this step, which is usually the same dataset used to train the predictive model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 115
    },
    {
        "text": "Numerical features are perturbed by randomly sampling from the standard normal distribution and performing inverse mean centering and scaling using the feature means and standard deviations computed from the training data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 116
    },
    {
        "text": "Categorical features are perturbed by randomly sampling feature values according to their frequency in the training data, and then creating a binary feature to indicate whether the perturbed value matches the value for the instance being explained (i.e., 1 when the value matches, 0 otherwise).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 117
    },
    {
        "text": "Users can specify the number of perturbed samples to generate for each explanation, but the default for tabular data is 5,000 samples.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 118
    },
    {
        "text": "LIME then uses the original predictive model to obtain the class prediction 125 probabilities for each of the perturbed samples.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 119
    },
    {
        "text": "Each perturbed sample 𝑧 is weighted according to Π𝑥, which is defined as an exponential kernel: Π𝑥(𝑧) = exp (−𝐷(𝑥, 𝑧)2/𝜎2) (2) where 𝐷 and 𝜎 are a user-defined distance metric and kernel width, respectively.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 120
    },
    {
        "text": "If not specified by the user, LIME will use Euclidean distance and a kernel width equal to 75% of the square root of the number of training data features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 121
    },
    {
        "text": "The weighted perturbed samples are then used to provide an approximation to Equation 1 by first selecting a specified number of features and then learning feature weights via regression.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 122
    },
    {
        "text": "The user has control over the number of features selected, the approach to feature selection, and the type of regression.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 123
    },
    {
        "text": "Thanks to my sister, Katie Otte, for taking care of daily tasks to which I had no time to attend.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 124
    },
    {
        "text": "Users also have the option of discretizing numeric features in the explanation and are provided several discretization options.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 125
    },
    {
        "text": "By default, LIME discretizes numeric features into quartiles for explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 126
    },
    {
        "text": "As noted above, the implementation of LIME provides control over a variety of algorithm parameters.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 127
    },
    {
        "text": "While this flexibility can be beneficial, the explanations produced can be heavily affected by the choice of these parameters.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 128
    },
    {
        "text": "Defaults are provided for all parameters, but the LIME authors provide little guidance for parameter selection and do not provide justifications for the default settings.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 129
    },
    {
        "text": "126 Appendix A.2 SHapley Additive exPlanations (SHAP) The SHAP algorithm124,125 aims to unify several local explanation methods into a single approach for interpreting model predictions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 130
    },
    {
        "text": "It introduces the perspective of “viewing any explanation of a model’s prediction as a model itself”, and calls this model the explanation model.125 Additive feature attribution methods are introduced as a class of explanation models that attribute an effect, 𝜙, to each feature in a model and the sum of these effects approximates the original model prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 131
    },
    {
        "text": "The explanation model is thus defined as a linear function of binary variables: 𝑔(𝑧′) = 𝜙0 + ∑ 𝜙𝑖𝑧𝑖′𝑀𝑖=1 (3) where 𝑧′ is a binary vector of simplified features (e.g., binary vector indicating whether a specific feature was observed or not) of length 𝑀, and 𝑀 represents the number of simplified features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 132
    },
    {
        "text": "For specific details on each method and how it fits this class of explanation model, see Lundberg 2017.125 There exists a unique set of values of 𝜙 that ensures this class of explanation models meets three desirable properties: 1) local accuracy/fidelity (i.e., the sum of the attributed feature effects exactly equals the model prediction); 2) missingness (i.e., an absent input feature should have no attributed effect); and 3) consistency (i.e., if input feature always has greater impact in one model over another, then it should be attributed a higher effect for that model).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 133
    },
    {
        "text": "Thanks to my wonderful dog, Rudy, for always putting a smile on my face at the end of a rough day.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 134
    },
    {
        "text": "This unique set of values are the Shapley values, a method from cooperative game theory that fairly distributes gains among all players of a collaborative game according to their marginal contributions towards the total gain.142 For an explanation model, the “players” are the features, the “gains” are the effect 127 attributed to each feature, and the explanation model for a prediction, 𝑓(𝑥), can be formally defined as follows: 𝜙𝑖(𝑓, 𝑥) = ∑|𝑆|!",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 135
    },
    {
        "text": "To better clarify the theory and interpretation of the Shapley values produced by the SHAP algorithm, a simple example is provided.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 136
    },
    {
        "text": "Imagine a model that predicts a person’s risk of having the flu based on four features: 1) temperature, 2) presence/absence of a cough, 3) presence/absence of a runny nose, and 4) presence/absence of fatigue.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 137
    },
    {
        "text": "Assume that the model predicts 0.10 probability of having influenza for the average person and the goal is to explain the prediction for a person who has a 0.75 probability in terms of how each of the four features impacts the model’s prediction relative to the average person.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 138
    },
    {
        "text": "Assume that this person has a temperature of 102.3F, presence of a cough, no runny nose, and presence of fatigue.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 139
    },
    {
        "text": "To find the impact of each feature on the prediction, their 𝜙 values must be computed as defined in Equation 4.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 140
    },
    {
        "text": "For example, consider the last subset depicted in Figure A2 that includes the features “cough = present”, “runny nose = absent”, and “temperature=102.3F”.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 141
    },
    {
        "text": "Assume the estimate after several repetitions was 0.60.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 142
    },
    {
        "text": "Repeating the calculation shown in Figure A2 for each feature will yield the set of 𝜙s that comprise an explanation for the person of interest.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 143
    },
    {
        "text": "A full explanation might read as follows: relative to the average risk prediction of 0.10, a temperature of 102.3F increased this person’s risk by 0.35, presence of a cough increased this person’s risk by 0.20, absence of a runny nose decreased this person’s risk by 0.05, and presence of fatigue increased this person’s risk by 0.15.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 144
    },
    {
        "text": "By summing all 𝜙 values with the average prediction, the person’s prediction of 0.75 (i.e., 0.10 + 0.35 + 0.20 + -0.05 + 0.15 = 0.75) is obtained.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 145
    },
    {
        "text": "All possible subset combinations are enumerated and weighted by the proportion of all possible feature permutations they represent.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 146
    },
    {
        "text": "For each subset, the model prediction is estimated with and without the feature of interest, which are 𝑓𝑥(𝑆 ∪ {𝑓𝑎𝑡𝑖𝑔𝑢𝑒 = 𝑝𝑟𝑒𝑠𝑒𝑛𝑡}) and 𝑓𝑥(𝑆), respectively.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 147
    },
    {
        "text": "The final Shapley value is obtained by taking a weighted sum of the marginal contribution estimates of each subset.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 148
    },
    {
        "text": "As can be clearly seen in the above example, the computation of the Shapley values for a set of features is non-trivial.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 149
    },
    {
        "text": "This would have never been possible without you.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 150
    },
    {
        "text": "Although the authors point to previously defined model-agnostic methods for estimating Shapley values, they also include a new, more computationally efficient method called Kernel SHAP.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 151
    },
    {
        "text": "The authors also provide computationally efficient, model-specific methods for estimating the Shapley values of linear models, deep learning models, and tree-based models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 152
    },
    {
        "text": "An overview of the Kernel SHAP explainer is provided below.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 153
    },
    {
        "text": "Specific details 130 on the theory and implementation of the model-specific explainers can be found in the SHAP paper and code.124,126 The following description for the Kernel SHAP explainer is based on the SHAP papers124,125 as well as the code and documentation for SHAP version 0.24.0.126 Kernel SHAP proposes Shapley values as the solution to the linear model formulation of the LIME algorithm (see previous section), thus allowing for Shapley values to be approximated using a weighted linear regression.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 154
    },
    {
        "text": "This permits a joint estimation of all Shapley values, which reduces the samples needed to provide accurate estimates of the Shapley values.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 155
    },
    {
        "text": "To estimate the average model prediction and simulate missing features as in the example, Kernel SHAP requires a user-provided background dataset.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 156
    },
    {
        "text": "This can be the entire training dataset used to learn the original predictive model; however, for larger datasets the algorithm becomes very computationally expensive.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 157
    },
    {
        "text": "Therefore, it is recommended that for larger training datasets, users provide a dataset of reference values that adequately summarize the training data, such as point estimates for each feature (e.g., median or mean) or weighted samples produced by k-means or k-medians clustering.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 158
    },
    {
        "text": "If a feature does not vary compared to the background dataset, it is assumed to have no effect on the model prediction and is assigned a Shapley value of 0.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 159
    },
    {
        "text": "This helps reduce the number of computations required by the algorithm.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 160
    },
    {
        "text": "Depending on whether the background dataset contains a single reference value or a set of reference values, a “sample” in the weighted dataset may consist of a single row or a set of rows, respectively.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 161
    },
    {
        "text": "To further reduce computation time, users can specify the number of samples (i.e., model evaluations) that Kernel SHAP is permitted to use, with higher sample sizes leading to more stable estimates.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 162
    },
    {
        "text": "By default, Kernel SHAP uses 2(# of varying features) + 211 samples and caps the maximum number of samples allowed at 230.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 163
    },
    {
        "text": "If given enough samples, Kernel SHAP will fully enumerate all possible subset sizes; otherwise, the algorithm first enumerates as many high-weighted subset sizes as possible (e.g., |𝑆| = 0 and |𝑆| = 1 in Figure A2), then uses any leftover samples to randomly sample subsets from the remaining subset sizes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 164
    },
    {
        "text": "If more samples are allowed than are needed to fully enumerate each subset, unused samples are discarded to improve computational efficiency.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 165
    },
    {
        "text": "For each of the samples in the weighted dataset, the algorithm estimates the change in the model prediction from the average model prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 166
    },
    {
        "text": "For a background dataset using a set of reference values, this estimate is the expected value of the model prediction over all rows in the sample minus the average model prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 167
    },
    {
        "text": "By default, if less than 20% of all possible subsets have been enumerated in the weighted dataset, Kernel SHAP performs feature selection using a Lasso model with least angle regression using the Akaike information criterion for model selection.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 168
    },
    {
        "text": "The user has optional control over whether to run feature selection as well as the L1 regularization parameter used in the Lasso model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 169
    },
    {
        "text": "132 As with the LIME algorithm, the implementation of the SHAP algorithm allows users control over parameters that could impact the explanations generated.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 170
    },
    {
        "text": "Thus, parameters require careful selection by the user.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 171
    },
    {
        "text": "For an model-agnostic, instance-level explanation approach based on feature influence, I proposed the following metrics for quantitatively measuring these properties: Fidelity: There should exist some function of the set of generated feature influence values, 𝑔(𝜙), that approximates the original model prediction, 𝑓(𝑥).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 172
    },
    {
        "text": "A high-fidelity explanation approach is one that generates explanations such that 𝑔(𝜙) ≅ 𝑓(𝑥).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 173
    },
    {
        "text": "Computational Efficiency: The time required to generate a single explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 174
    },
    {
        "text": "To conduct experiments, two datasets curated in previous research projects were used: 1) a dataset to predict 30-day all-cause pediatric hospital readmission risk and 2) a dataset to predict 1-year postpartum infant mortality risk.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 175
    },
    {
        "text": "To enable compatibility with the explanation algorithms, comparable Python versions of the models previously learned on each of these datasets were generated.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 176
    },
    {
        "text": "A short Python module was developed 133 to facilitate the use of both explanation algorithms and conduct experiments.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 177
    },
    {
        "text": "Datasets and models are described in subsection A.3.1, the experiments are described in A.3.2, the results are presented in subsection A.3.3, and subsection A.3.4 presents a discussion of all results and uses them to justify the selection of an explanation algorithm to be used in the work.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 178
    },
    {
        "text": "Appendix A.3.1 Datasets and Models 30-day all-cause pediatric hospital readmission risk: This dataset constituted all clinical and administrative data for all inpatient visits to CHP from January 1, 2007 to December 31, 2013.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 179
    },
    {
        "text": "Patients that died during admission, were over 21 years of age, or did not have a recorded age were excluded from the dataset.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 180
    },
    {
        "text": "A readmission was defined as any inpatient visit followed by a second inpatient admission within 30 days of discharge from the initial visit.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 181
    },
    {
        "text": "Multiple readmissions within 30 days for a single patient were treated as separate cases.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 182
    },
    {
        "text": "The final dataset was comprised of 91,045 visits (13,548 readmission cases; 77,497 non-readmission controls).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 183
    },
    {
        "text": "While these approaches are discussed in detail in section 2.1.2, the general purpose of an explanation is to answer a particular question a user may have about the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 184
    },
    {
        "text": "For brevity, I have left out the specific details of the data cleaning, standardization, and feature engineering processes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 185
    },
    {
        "text": "In the original model learning process, features were selected using a two-stage predictor-selection process which included an IG filtration step followed by a wrapper-based search.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 186
    },
    {
        "text": "A series of different Naïve Bayes models using various combinations of medical data sources (e.g., medications+labs, demographics only, etc.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 187
    },
    {
        "text": "To generate a comparable Python version of this model, a 70/30 stratified split of the 91,045 visits in the dataset was used to generate training and 134 testing data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 188
    },
    {
        "text": "Using the 32 features from the best performing model and one-hot encoding procedures, a Naïve Bayes classifier was learned on the training data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 189
    },
    {
        "text": "1-year postpartum infant mortality risk: This dataset was obtained from the Magee Obstetric Medical and Infant (MOMI) Database and comprised demographic and medical information for all deliveries at Magee-Women’s Hospital from January 1, 2002 to December 31, 2014.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 190
    },
    {
        "text": "Infant death cases were identified by linking the MOMI dataset with data from the Department of Health Services (DHS).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 191
    },
    {
        "text": "As a simple example, consider a linear regression model with 100 features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 192
    },
    {
        "text": "Stillbirths and fetal deaths were excluded.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 193
    },
    {
        "text": "The final dataset encompassed 75,842 records (494 infant death cases; 75,348 alive controls).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 194
    },
    {
        "text": "Again, for brevity, I have left out the specific details of the data cleaning, standardization, and feature engineering processes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 195
    },
    {
        "text": "The final dataset contained 102 features for analysis.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 196
    },
    {
        "text": "A variety of models were learned using R, but the highest performing model was a ridge logistic regression trained on 29 features selected using a sequential IG filter, which achieved an average AUROC of 0.933 with 10-fold cross-validation on the training dataset (i.e., all 75,842 visits).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 197
    },
    {
        "text": "To generate a comparable Python version of this model, all 75,842 visits in the dataset and one-hot encoding procedures were used to learn a ridge logistic regression using the 29 features from the best performing model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 198
    },
    {
        "text": "135 Appendix A.3.2 Experiments 500 patients (250 cases, 250 controls) were randomly sampled from each dataset to use in experiments.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 199
    },
    {
        "text": "As noted in sections A.1 and A.3, the parameter settings can affect the explanations produced by both the LIME and SHAP algorithms; therefore, for each patient, LIME and SHAP explanations were generated under varying parameter settings.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 200
    },
    {
        "text": "One user may want to know the relationships the model learned between the features and the outcome of interest.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 201
    },
    {
        "text": "For the LIME algorithm, varied parameter settings included: 1) the number of perturbed samples used to learn the linear regression model and 2) the number of features selected for the explanation (i.e., the two parameter settings most likely to influence the explanations generated).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 202
    },
    {
        "text": "For the SHAP algorithm, a background dataset consisting of the median value for each feature was used and varied parameter settings included the number of samples used to estimate the Shapley values of the features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 203
    },
    {
        "text": "Default values for all other user-controllable parameters were used.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 204
    },
    {
        "text": "Explanations were generated for the prediction of the target class of interest (i.e., \"Readmitted\" for readmission model and \"Death\" for infant mortality model).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 205
    },
    {
        "text": "The two properties identified in the introduction were as assessed as follows: Fidelity: Following the measure defined in the introduction, fidelity error was estimated for each explanation as 𝑔(𝜙) − 𝑓(𝑥), where 𝑔(𝜙) is a function of the set of generated feature influence values that approximates the original model prediction, 𝑓(𝑥).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 206
    },
    {
        "text": "For the LIME algorithm, 𝑔(𝜙) takes the form of a local linear regression.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 207
    },
    {
        "text": "For the SHAP algorithm, 𝑔(𝜙) is simply the sum of all the Shapley values learned for each feature and a base value (i.e., the average model prediction or the expected model prediction when no features are known).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 208
    },
    {
        "text": "Theoretically, the SHAP algorithm guarantees fidelity (i.e., guarantees that 𝑔(𝜙) = 𝑓(𝑥)), but as approximation methods are used to estimate the Shapely values it is beneficial to check that this guarantee holds true for 136 the implementation of the algorithm.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 209
    },
    {
        "text": "For each dataset, the median absolute error (MAE) in fidelity was calculated across all 500 patients for each algorithm and varied parameter setting.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 210
    },
    {
        "text": "Computational Efficiency: To estimate computational efficiency of the algorithms, the time to generate each explanation was measured.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 211
    },
    {
        "text": "For this user, an explanation might consist of the list of weights the model assigned to all 100 features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 212
    },
    {
        "text": "Mean and total computation times for each algorithm were calculated across the 500 patients from each dataset under varying numbers of samples used to generate the explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 213
    },
    {
        "text": "For the LIME algorithm, the number of explanation features had minimal impact on computation time for a single explanation and so all timing experiments were performed using 6 features in the explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 214
    },
    {
        "text": "This value was based on the findings from the fidelity experiments (i.e., LIME’s fidelity error on the two datasets appears to be optimal somewhere between 5 and 10 features).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 215
    },
    {
        "text": "Appendix A.3.3 Results Figure A3 shows the MAE in fidelity on each dataset for the LIME algorithm under varying parameter settings.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 216
    },
    {
        "text": "The MAE in fidelity for the SHAP algorithm was always 0 for both datasets.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 217
    },
    {
        "text": "LIME median absolute error (MAE) in fidelity.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 218
    },
    {
        "text": "The MAE in fidelity for the LIME algorithm under varying parameter settings is shown for the readmission dataset (left plot) and the infant mortality dataset (right plot).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 219
    },
    {
        "text": "On the other hand, another user may only want to know why the model made a specific prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 220
    },
    {
        "text": "Mean time to compute a single explanation for LIME and SHAP algorithms Number of samples used to generate explanation 500 1000 3000 5000 7000 Readmission Dataset SHAP mean time (s) 0.04 0.05 0.09 0.11 0.14 LIME mean time (s) 0.39 0.54 1.26 1.90 2.52 Infant Mortality Dataset SHAP mean time (s) 0.05 0.05 0.04 0.01 0.01 LIME mean time (s) 1.09 1.53 3.90 1.83 2.38 Table A2.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 221
    },
    {
        "text": "On the other hand, Figure A3 demonstrates that the LIME algorithm error in fidelity varies across parameters and datasets.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 222
    },
    {
        "text": "Additionally, as no parameter setting is likely to be ideal for all instances in a dataset, it would be necessary to show users an estimate of the error in the explanation generation process.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 223
    },
    {
        "text": "Thus, the SHAP algorithm seems to be a better choice to ensure explanation fidelity.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 224
    },
    {
        "text": "It should be noted that the SHAP algorithm computation time is highly dependent on the background dataset provided to the algorithm.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 225
    },
    {
        "text": "Although not explored in these preliminary experiments, larger background datasets may lead to significant decreases in the algorithm’s computational efficiency.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 226
    },
    {
        "text": "In this case, 2 an explanation might consist of the 10 features most responsible for the specific prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 227
    },
    {
        "text": "These functions were not explored in the preliminary experiments but are worth noting for future studies.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 228
    },
    {
        "text": "139 Appendix B Qualitative Inquiry Questionnaires and Question Guide 140 Focus Group Question Guide Model Discussion Question Guide  How would you feel about deploying these kind of predictive models into clinical practice?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 229
    },
    {
        "text": " What practical applications do you think these kinds of models could have in clinical practice?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 230
    },
    {
        "text": " Would you feel confident in the predictions provided by these kinds of models?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 231
    },
    {
        "text": " What additional information about the model would you require in order to have confidence in its predictions?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 232
    },
    {
        "text": " Do you think you would use predictions from models like this?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 233
    },
    {
        "text": "Depending on the question and the user, different explanations about the model may be required.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 234
    },
    {
        "text": " Apart from predicting other outcomes, how could these kinds of models be made more useful?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 235
    },
    {
        "text": " You may have noticed that not much information about the model or the underlying algorithm was provided.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 236
    },
    {
        "text": "How might this information influence your perceptions of a model?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 237
    },
    {
        "text": "What assumptions, if any, did you make about the model or underlying algorithm?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 238
    },
    {
        "text": " Why might you be inclined to believe or disbelieve a prediction presented in this fashion?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 239
    },
    {
        "text": " Are any predictors surprising or non-sensical?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 240
    },
    {
        "text": " What information led you to belief/disbelief of the prediction?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 241
    },
    {
        "text": " Model performance?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 242
    },
    {
        "text": "Confidence intervals for contribution values?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 243
    },
    {
        "text": " Different grouping or order of predictors?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 244
    },
    {
        "text": "Different number?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 245
    },
    {
        "text": " What information provided might you find useful in performing your job?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 246
    },
    {
        "text": "Mock-up Set 1 Comparison Question Guide  What do you think of displaying risks as probabilities versus odds?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 247
    },
    {
        "text": "Which do you prefer?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 248
    },
    {
        "text": " What do you think of displaying individual predictors versus groups of predictors?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 249
    },
    {
        "text": "Which do you prefer?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 250
    },
    {
        "text": "This may lead to a lack of usability and practical interpretability of these explanations for real end-users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 251
    },
    {
        "text": " What do you think of the tornado plot versus the force plot?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 252
    },
    {
        "text": "Which do you prefer?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 253
    },
    {
        "text": " What information or design elements do you think are missing?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 254
    },
    {
        "text": " What information or design elements are not useful?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 255
    },
    {
        "text": "Mock-up Set 2 Comparison Question Guide  How does grouping predictors into plots change your opinion of displaying individual predictors versus groups of predictors?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 256
    },
    {
        "text": " What do you think of grouping predictors into multiple explanation plots?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 257
    },
    {
        "text": " What alternative ways to group predictors can you think of?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 258
    },
    {
        "text": " What is your preferred grouping, or would you prefer no grouping?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 259
    },
    {
        "text": " What information or design elements do you think are missing?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 260
    },
    {
        "text": " What information or design elements are not useful?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 261
    },
    {
        "text": "141 142 Appendix C Qualitative Inquiry Codebook Name Description 1.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 262
    },
    {
        "text": "Context of use--when & where The environment in which the explanation will be used, which is often related to the stage of system development.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 263
    },
    {
        "text": "1.1 Environment Aspects of the environment that will affect how an explanation needs to be designed in order to support use within that environment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 264
    },
    {
        "text": "1.1.1 Cognitive and time resources Participant cognitive capacity and/or time availability to use the system in a specific environment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 265
    },
    {
        "text": "This includes comments about cognitive effort to process information in a given time frame (e.g., ease and speed of information processing, time restrictions, willingness to spend mental effort or time) and workflow or other environmental influences that imply a possible impact on cognitive capacity or time availability (e.g., task order, when/how/where to capture attention) Example: -Speed or ease with which knowledge can be obtained from system (e.g., faster synthesis of relevant information, familiarity with the way information is presented) 1.1.2 Social and organizational influences Any aspect of the social or organizational environment in which the system is being used that may impact system development, design, or application.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 266
    },
    {
        "text": "This can include things related to participant workflow, organizational infrastructure (e.g., staffing procedures/challenges, patient triage/bed assignment procedures/challenges, education/training programs, financial policies), and social pressure/expectations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 267
    },
    {
        "text": "Examples: -Workflow, such as rounding practices, patient/colleague interactions, EHR interactions, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 268
    },
    {
        "text": "-Staffing/triaging procedures, such as bed availability, staff availability, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 269
    },
    {
        "text": "1.1.3 Technical resources Technical resources available (e.g., compatibility with existing systems, processing/memory constraints) when using the system in a specific environment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 270
    },
    {
        "text": "This can include limitations of pre-existing systems, difficulties with real-time data processing, and challenges in implementation and/or maintenance of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 271
    },
    {
        "text": "1.2 System stage Design/information needs in a specific system stage (e.g., development, implementation, deployment).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 272
    },
    {
        "text": "This implies that explanations must be designed to fit healthcare provider information needs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 273
    },
    {
        "text": "This code should only be applied when a different system stage may require a change in information/design needs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 274
    },
    {
        "text": "Example: -a participant mentions specific information which would assist in validating the predictive model (this may be an indirect reference to information/design needs in the development stage, which may differ from needs in the deployment stage) 143 2.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 275
    },
    {
        "text": "Context of use--who User's cognition (e.g., knowledge, experience, capabilities, etc.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 276
    },
    {
        "text": "and the user’s relationship to the system at the time the explanation is being provided.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 277
    },
    {
        "text": "A user may have several different relationships with the system over time, and thus their explanation needs may change with varying roles.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 278
    },
    {
        "text": "2.1 Cognition & experiences The knowledge, experience, capabilities, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 279
    },
    {
        "text": "of the user of a system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 280
    },
    {
        "text": "Of particular interest is any aspect of the user’s background knowledge or prior experiences that may bias their opinion of or attitude toward a new system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 281
    },
    {
        "text": "2.1.1 Background knowledge Participant’s prior level of knowledge of ML/AI/predictive modelling concepts.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 282
    },
    {
        "text": "Not applicable to remarks/questions on presentation content (e.g., AUC, inputs) 2.1.2 Prior experiences Participant’s prior experience with using an ML/AI tool or another information system (e.g., EHR).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 283
    },
    {
        "text": "This code is restricted for use when the participant expresses either a positive or negative opinion or attitude about the design, credibility, usability, or utility of the tool/system, and should not be used to code objective comparisons of tools/systems (e.g., comparing performance or data inputs, objective discussions on design and implementation).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 284
    },
    {
        "text": "2.2 Relationship to system The user's relationship to the system at the time the explanation is being provided.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 285
    },
    {
        "text": "Main roles to consider can be engineer, developer, owner, end-user, data subject, and stakeholder.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 286
    },
    {
        "text": "It should be noted that a user may occupy more than one role simultaneously.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 287
    },
    {
        "text": "2.2.1 User perspective How system design or system application might differ based on the user's current relationship with the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 288
    },
    {
        "text": "This can include comments about design differences based on intended system application (e.g., developer vs end-user needs, different end-user information needs).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 289
    },
    {
        "text": "This code should not be applied to design/application differences that would arise from variation in user cognition & experiences (e.g., background knowledge, thought processes) 3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 290
    },
    {
        "text": "Needs/goals will vary according to the who/when/where elements of the context of use.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 291
    },
    {
        "text": "3.1 Compliance Closely related to verification (3.4), this refers to any activities aimed at ensuring the system adheres to an established legal, moral, or other societal standard.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 292
    },
    {
        "text": "This includes all comments on the system from an ethical, moral or legal/organizational policy standpoint.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 293
    },
    {
        "text": "144 3.2 Improvement Closely tied with verification (3.4), this covers activities related to improving system performance and efficiency.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 294
    },
    {
        "text": "May include incorporating domain knowledge to reduce biases in or improve generalization of model, comparing/selecting models, and improving system response times.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 295
    },
    {
        "text": "Includes suggested changes in data collection, data inclusion/exclusion, data processing, and target outcomes/definitions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 296
    },
    {
        "text": "Not applicable to comments about or suggestions to improve model utility (e.g.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 297
    },
    {
        "text": "possible applications of current model information, post-hoc analyses such as distribution of risk scores across units, or tracking risk scores and outcomes of specific patients).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 298
    },
    {
        "text": "Examples: -suggestions to explore predictions of an outcome other than 24-hr pediatric ICU mortality (e.g., time to event predictions, morbidity, ICU transfer, mortality in a specific patient population, etc.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 299
    },
    {
        "text": "-suggestions to include additional data such as tests, staffing, comorbidities, bed location, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 300
    },
    {
        "text": "-suggestions to improve data processing such as removing outliers, dropping bad values, defining normal ranges, adjusting for age/condition, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 301
    },
    {
        "text": "3.3 Learning Remarks/questions indicating participant is seeking to gain knowledge or information from the system, including identifying new data patterns, generating/testing new hypotheses, and/or providing support for decision-making (e.g., provide supporting evidence for a decision, improve decision-making speed or accuracy, identifying actionable information such as courses of action or modifiable risk factors).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 302
    },
    {
        "text": "3.4 Verification A possible reason for requiring an explanation of an intelligent system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 303
    },
    {
        "text": "Includes examining how decisions/suggestions are made by the system to ensure it is operating as expected, which may include activities such as detecting biases, finding/debugging errors, and ensuring that system reasoning aligns with domain knowledge.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 304
    },
    {
        "text": "3.4.1 Comparing against known model Comparison of model to existing model/tool to validate some aspect of the system (e.g., credibility).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 305
    },
    {
        "text": "Only applicable to remarks that compare objective metrics (e.g., performance, data collection & processing).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 306
    },
    {
        "text": "Not applicable to participant opinions of existing models or preferences for system content & design (use \"prior experiences\" and \"explanation design\" category codes instead).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 307
    },
    {
        "text": "Generally not applicable to comments related to system utility (use \"Learning\" category codes instead).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 308
    },
    {
        "text": "3.4.2 Comparing model information to domain knowledge Comparison of system information against clinical knowledge to verify some aspect of the model (e.g., credibility).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 309
    },
    {
        "text": "This can include comments or questions about possible data biases, information validity, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 310
    },
    {
        "text": "Not applicable to remarks where participants are suggesting improvements based on clinical knowledge.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 311
    },
    {
        "text": "Generally not applicable to comments related to system utility (use \"Learning\" category codes instead).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 312
    },
    {
        "text": "3.4.3 Seeking information on model development processes Remarks/questions seeking to validate any aspect of the model development and maintenance process (e.g., cohort definition, data sources, data collection/inclusion/exclusion, cleaning processes, feature engineering/selection, model learning process, evaluation, maintenance over time).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 313
    },
    {
        "text": "Applicable only when participants make assumptions about or attempt to clarify/understand/question the model development/maintenance process and is not applicable to suggestions for improvement.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 314
    },
    {
        "text": "145 4.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 315
    },
    {
        "text": "Explanation design--how Can generally be determined by the who and why questions of context of use, and refers to the way in which the content of an explanation is presented to a user.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 316
    },
    {
        "text": "Refers to the processing size/levels of explanation information, which may include the overall size of an explanation or interactive exploration options.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 317
    },
    {
        "text": "4.1.2 Size & interactivity preferences Preferences for the size and/or interactivity options in the explanation design.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 318
    },
    {
        "text": "Applicable to preferences on interactivity/size options in mock-ups (e.g., plot hover and drop-down select capabilities, link between explanation plot and predictor table, scrollable list of predictors) and any suggestions for interactivity/size options not shown in mock-ups (e.g., interactions between visualizations, amount of information content, interactive explanation exploration options).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 319
    },
    {
        "text": "4.2 Explanation unit & organization Preferences regarding the granularity and organization of the explanation units.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 320
    },
    {
        "text": "This includes preferences on the unit of explanation or predictor granularity (e.g., raw predictors, grouped/summarized predictors, increasing/decreasing or net contributions) and organization of the explanation units (e.g., order of display, location of increase/decrease contributions, grouping into different plots).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 321
    },
    {
        "text": "Applicable to both remarks on mock-up options and suggested alternatives.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 322
    },
    {
        "text": "This includes the vocabulary, data structures, and visualizations used to express information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 323
    },
    {
        "text": "4.3.1 Data visualization preferences Specific preferences for how data is displayed in the explanation design, which includes data structures (e.g., free-text, data tables, lists) and graphical representations (e.g., images, plots/charts, diagrams) used to display information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 324
    },
    {
        "text": "This includes participant preferences for mock-up options (e.g., tornado vs. force plot) and alternative suggestions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 325
    },
    {
        "text": "Generally not applicable to information content preferences or vocabulary/phrasing preferences, use \"explanation design--what\" and “vocabulary preferences” codes instead.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 326
    },
    {
        "text": "4.3.2 Vocabulary preferences Specific preferences for the vocabulary used in the explanation design.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 327
    },
    {
        "text": "Includes how test content is worded (e.g., phrasing used to describe predictors and contributions), expression of numerical information (e.g., risk in probability vs. odds, displaying probability as decimal or percentage), and domain-specific terms/abbreviations that should be used.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 328
    },
    {
        "text": "Often applicable when participants express confusion/difficulties when trying to interpret text/numerical information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 329
    },
    {
        "text": "Explanation design--what Generally determined by the answers to the who and why of the context of use, and refers to the content that needs to be included in an explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 330
    },
    {
        "text": "Content of an explanation typically refers to the type of explanation being provided and any information supporting the interpretation of that explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 331
    },
    {
        "text": "146 5.1 Supporting information Any information that is not a part of the explanation but is required to help support the user's interpretation/understanding of the explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 332
    },
    {
        "text": "This may include things such as source data used in the model or explanation algorithm, supplemental data, and training materials.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 333
    },
    {
        "text": "5.1.1 Interpretation information Needs for training information on how to interpret explanation information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 334
    },
    {
        "text": "Then, use the framework to suggest explanation designs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 335
    },
    {
        "text": "This includes remarks/questions that indicate participant confusion and/or lack of understanding based on the system design (e.g., trouble interpreting predictors).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 336
    },
    {
        "text": "Not applicable to momentary confusion (i.e., if participant voices question but quickly figures it out themselves).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 337
    },
    {
        "text": "Not applicable to suggestions for data to include in interface to support explanation interpretation (use other “source & supplemental data” code instead).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 338
    },
    {
        "text": "Not applicable to preferences/opinions on system design.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 339
    },
    {
        "text": "Examples: -confusion on how to interpret predictor descriptions (e.g., making sense of discretized ranges or feature descriptions) -confusion on how to interpret predictor contributions and their relation to the baseline and model predictions Examples where “interpretation information” and “source & supplemental data” (5.1.2) both apply: -If it was more clear how to interpret xxx information, the xxx information would help me better understand the prediction and/or explanation -XXX information seems like it might be useful in understanding the prediction and/or explanation, but I find it confusing to interpret -If the system could include xxx information expressed in yyy manner, it would really help me interpret/understand the prediction/explanation 5.1.2 Source & supplemental data Preferences/suggestions for including information about the prediction model (e.g., performance statistics, certainty measures, development processes), source data used by the model or explanation algorithm (e.g., raw data used to derive predictors, (un)discretised predictor values, contribution values), or any other supplemental data required to support interpretation of the prediction or explanation (e.g., interventions, care context).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 340
    },
    {
        "text": "Not applicable to suggestions for improvements to the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 341
    },
    {
        "text": "Examples: -direct/indirect comments on utility of information in explanation plot, predictor table, raw data plots, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 342
    },
    {
        "text": "(e.g., participant uses raw data plot or predictor table to investigate a predictor in explanation plot) -requests for information on model (e.g., confidence intervals, performance information, feature engineering/selection, etc.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 343
    },
    {
        "text": "-requests for information not used by model such as care interventions performed, staffing/triaging/bed assignment procedures that may have affected care, additional patient data needed to interpret prediction, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 344
    },
    {
        "text": "-comments on utility of diagnosis, demographic & utilization tables Examples where “interpretation information” (5.1.1) and “source & supplemental data” both apply: -If it was more clear how to interpret xxx information, the xxx information would help me better understand the prediction and/or explanation -XXX information seems like it might be useful in understanding the prediction and/or explanation, but I find it confusing to interpret -If the system could include xxx information expressed in yyy manner, it would really help me interpret/understand the prediction/explanation 147 5.2 Type of explanation One part of explanation content refers to the type of explanation that is required, such as whether the explanation is one of processes or behavior and whether it is targeted at the local or global level.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 345
    },
    {
        "text": "Aim 2.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 346
    },
    {
        "text": "Type of explanation can generally be determined by the type of questions the user is asking or the reasoning processes the user is trying to use.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 347
    },
    {
        "text": "5.2.1.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 348
    },
    {
        "text": "Intelligibility query Specific intelligibility queries (i.e., “inputs”, “outputs”, “certainty”, “why not”/”how to”, “why”, “what if”, “when”) about the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 349
    },
    {
        "text": "Includes comments indicating desire to know what data/predictors/inputs are used, what predictions/outputs can be produced, how (un)certain the model is in its predictions, why inputs produce certain outputs or how to get specific outputs, how changing inputs influences outputs, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 350
    },
    {
        "text": "Coding for intelligibility queries in the form of a question should generally not include answers to the question.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 351
    },
    {
        "text": "Generally, not applicable to remarks regarding specific design elements.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 352
    },
    {
        "text": "Examples: -questions on data/inputs being used by the model -comments/questions on predictions, including certainty of predictions, how/why predictions are produced, how changes in inputs might influence predictions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 353
    },
    {
        "text": "5.2.2 Level & target preferences Preferences for explanation level (local/global) and target (behavior/processes).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 354
    },
    {
        "text": "Perceptions of the system Perceptions of the overall system application.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 355
    },
    {
        "text": "This includes perceptions on the barriers and facilitators to system adoption.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 356
    },
    {
        "text": "For risk prediction models, adoption is closely tied to the utility, credibility, and usability of a model or system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 357
    },
    {
        "text": "6.1 Perceptions of system credibility The credibility, or \"believability\", of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 358
    },
    {
        "text": "Includes comments on any aspect of the system that may influence the participant’s confidence in prediction accuracy (e.g., high performance may increase confidence, predictors that are outliers/bad data points may decrease it).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 359
    },
    {
        "text": "Not applicable to remarks about the credibility of existing systems, use \"prior experiences\" code instead.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 360
    },
    {
        "text": "Often applicable with \"verification\" category codes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 361
    },
    {
        "text": "Examples: -willingness to use/trial system based on performance (e.g., AUC) -scepticism about model predictions based on identified data errors/biases, missing info, etc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 362
    },
    {
        "text": "-comparing model performance/content with domain knowledge or to known model 6.2 Perceptions of system usability The usability, or ease of use and learnability, of the system (i.e., can the intended goal be accomplished using the system or will users have difficulty?).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 363
    },
    {
        "text": "Not applicable to remarks about 148 the usability of existing systems, use \"prior experiences\" code instead.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 364
    },
    {
        "text": "will users use it?).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 365
    },
    {
        "text": "Not applicable to remarks about the utility of existing systems, use \"prior experiences\" code instead.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 366
    },
    {
        "text": "Aim 3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 367
    },
    {
        "text": "Examples: -suggesting possible applications of the current model/system -(dis)interest in continued development of system -(dis)interest in information provided by system (e.g., “it’s not telling me anything new”, “this information could support xxx decision or help me determine xxx faster”) 149 Appendix D Evaluation Study Introductory Slides 150 151 152 153 154 155 156 157 Appendix E Evaluation Study Questionnaires Background Questionnaire Patient Case Questionnaire 158 UTAUT Questionnaires 159 Bibliography 1.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 368
    },
    {
        "text": "Cabitza F, Rasoini R, Gensini GF.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 369
    },
    {
        "text": "Unintended Consequences of Machine Learning in Medicine.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 370
    },
    {
        "text": "Bhatt U.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 371
    },
    {
        "text": "Maintaining The Humanity of Our Models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 372
    },
    {
        "text": "Feldman K, Davis D, Chawla N V. Scaling and contextualizing personalized healthcare: A case study of disease prediction algorithm integration.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 373
    },
    {
        "text": "vi Table of Contents Preface ......................................................................................................................................... xiv 1.0 Introduction ............................................................................................................................. 1 1.1 Hypotheses and Specific Aims ....................................................................................... 3 1.2 Motivation ....................................................................................................................... 4 1.3 Approach ......................................................................................................................... 7 1.4 Significance and Innovation .......................................................................................... 8 1.5 Dissertation Overview .................................................................................................... 9 2.0 Background ........................................................................................................................... 11 2.1 Landscape of Interpretability ...................................................................................... 11 2.1.1 Defining Interpretability and Explanation ..................................................... 12 2.1.1.1 Levels and Types of Explanation ....................................................... 14 2.1.2 Interpretability Approaches ............................................................................. 17 2.1.2.1 Integrated Explanation Approaches ................................................. 17 2.1.2.2 Post-hoc Explanation Approaches ..................................................... 18 2.1.3 Evaluating Interpretability Approaches ......................................................... 20 2.2 User-centered Explanation Design and Evaluation for AI Systems ........................ 23 2.3 Interpretability in Healthcare ..................................................................................... 30 2.3.1 Motivations for Interpretability ...................................................................... 30 2.3.2 Explanation Approaches and Evaluations ...................................................... 32 3.0 Proposed Framework for Designing User-Centered Explanations .................................. 34 3.1 Description of Framework ........................................................................................... 36 vii 3.2 Guidance on Application ............................................................................................. 40 4.0 Application of Framework to Suggest Explanation Designs for a Pediatric ICU In-hospital Mortality Risk Model ............................................................................................... 44 4.1 Development and Evaluation of the Mortality Risk Prediction Model ................... 45 4.1.1 Materials and Methods ..................................................................................... 45 4.1.1.1 Dataset Description ............................................................................. 45 4.1.1.2 Data Cleaning ...................................................................................... 46 4.1.1.3 Feature Generation ............................................................................. 47 4.1.1.4 Model Learning and Evaluation ........................................................ 50 4.1.2 Results ................................................................................................................ 51 4.2 Defining Context of Use and Identifying Explanation Design Requirements ......... 52 4.2.1 Context of Use .................................................................................................... 54 4.2.2 Explanation Design Requirements .................................................................. 57 4.2.3 Potential impact on perceptions ....................................................................... 62 4.3 Preliminary Explanation Designs ............................................................................... 62 5.0 User Studies to Refine Explanation Design ........................................................................ 69 5.1 Materials and Methods ................................................................................................ 70 5.1.1 Setting and Participants ................................................................................... 70 5.1.2 Procedures and Data Collection ...................................................................... 70 5.1.3 Data Analysis ..................................................................................................... 71 5.2 Results ............................................................................................................................ 72 5.2.1 Insights on Context of Use ................................................................................ 73 5.2.2 Insights on Explanation Design ....................................................................... 77 viii 5.3 Final User-centered Explanation Design .................................................................... 84 6.0 Evaluation .............................................................................................................................. 87 6.1 Materials and Methods ................................................................................................ 88 6.1.1 Participants and Patient Cases ........................................................................ 88 6.1.2 Study Design and Tasks .................................................................................... 88 6.1.3 Study Application .............................................................................................. 91 6.1.4 Data Collection .................................................................................................. 93 6.1.5 Data Analysis ..................................................................................................... 94 6.2 Results ............................................................................................................................ 97 6.2.1 Decision Accuracy and Confidence ................................................................. 98 6.2.2 Case Review Efficiency ................................................................................... 101 6.2.3 Perceptions of Prediction Tool ....................................................................... 103 7.0 Discussion............................................................................................................................. 107 7.1 Limitations and Future Work ................................................................................... 115 7.2 Conclusions ................................................................................................................. 120 Appendix A Descriptions and Comparisons of SHAP and LIME Algorithms ................... 122 Appendix A.1 Local Interpretable Model-agnostic Explanations (LIME) ................. 122 Appendix A.2 SHapley Additive exPlanations (SHAP) ................................................ 126 Appendix A.3 Algorithm Comparison Experiments ..................................................... 132 Appendix A.3.1 Datasets and Models ..................................................................... 133 Appendix A.3.2 Experiments .................................................................................. 135 Appendix A.3.3 Results ............................................................................................ 136 Appendix A.3.4 Discussion and Algorithm Selection ............................................ 137 ix Appendix B Qualitative Inquiry Questionnaires and Question Guide ................................ 139 Appendix C Qualitative Inquiry Codebook ........................................................................... 142 Appendix D Evaluation Study Introductory Slides ............................................................... 149 Appendix E Evaluation Study Questionnaires ....................................................................... 157 Bibliography .............................................................................................................................. 159 x List of Tables Table 1.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 374
    },
    {
        "text": "Beam AL, Kohane IS.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 375
    },
    {
        "text": "Big Data and Machine Learning in Health Care.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 376
    },
    {
        "text": "Shah ND, Steyerberg EW, Kent DM.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 377
    },
    {
        "text": "Big Data and Predictive Analytics: Recalibrating Expectations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 378
    },
    {
        "text": "Vellido A.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 379
    },
    {
        "text": "Societal Issues Concerning the Application of Artificial Intelligence in Medicine.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 380
    },
    {
        "text": "Kidney Dis (Basel, Switzerland).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 381
    },
    {
        "text": "Deo RC.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 382
    },
    {
        "text": "Machine Learning in Medicine.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 383
    },
    {
        "text": "Circulation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 384
    },
    {
        "text": "2015;132(20):1920-1930. doi:10.1161/CIRCULATIONAHA.115.001593 8.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 385
    },
    {
        "text": "Deep learning for healthcare: review, opportunities and challenges.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 386
    },
    {
        "text": "Brief Bioinform.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 387
    },
    {
        "text": "Nakamura F, Nakai M. Prediction Models - Why Are They Used or Not Used?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 388
    },
    {
        "text": "Circ J.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 389
    },
    {
        "text": "2017;81(12):1766-1767. doi:10.1253/circj.CJ-17-1185 10.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 390
    },
    {
        "text": "11.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 391
    },
    {
        "text": "Bruges, Belgium; 2016:77-82. https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2016-141.pdf.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 392
    },
    {
        "text": "12.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 393
    },
    {
        "text": "In: Proceedings of the 2018 ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics - BCB ’18.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 394
    },
    {
        "text": "New York, New York, USA: ACM Press; 2018:559-560. doi:10.1145/3233547.3233667 13. Cooper GF, Aliferis CF, Ambrosino R, et al.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 395
    },
    {
        "text": "An evaluation of machine-learning methods for predicting pneumonia mortality.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 396
    },
    {
        "text": "Artif Intell Med.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 397
    },
    {
        "text": "Jovanovic M, Radovanovic S, Vukicevic M, Van Poucke S, Delibasic B.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 398
    },
    {
        "text": "Building interpretable predictive models for pediatric hospital readmission using Tree-Lasso logistic regression.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 399
    },
    {
        "text": "Artif Intell Med.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 400
    },
    {
        "text": "2016;72:12-21. doi:10.1016/j.artmed.2016.07.003 15.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 401
    },
    {
        "text": "Sebastopol, CA, USA: O’Reilly Media, Inc.; 2018. http://www.oreilly.com/data/free/an-introduction-to-machine-learning-interpretability.csp.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 402
    },
    {
        "text": "16.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 403
    },
    {
        "text": "Yang C, Delcher C, Shenkman E, Ranka S. Predicting 30-day all-cause readmissions from hospital inpatient discharge data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 404
    },
    {
        "text": "In: 2016 IEEE 18th International Conference on E-Health Networking, Applications and Services (Healthcom).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 405
    },
    {
        "text": "IEEE; 2016:1-6. doi:10.1109/HealthCom.2016.7749452 17.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 406
    },
    {
        "text": "Letham B, Rudin C, McCormick TH, Madigan D. Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 407
    },
    {
        "text": "Ann Appl Stat.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 408
    },
    {
        "text": "Goodman B, Flaxman S. European Union Regulations on Algorithmic Decision-Making and a “Right to Explanation.” AI Mag.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 409
    },
    {
        "text": "U.S. Food and Drug Administration.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 410
    },
    {
        "text": "Clinical and Patient Decision Support Software: Draft Guidance for Industry and Food and Drug Adminstration Staff.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 411
    },
    {
        "text": "Washington, D.C., USA; 2017. https://www.fda.gov/downloads/MedicalDevices/DeviceRegulationandGuidance/GuidanceDocuments/UCM587819.pdf.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 412
    },
    {
        "text": "20.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 413
    },
    {
        "text": "Ras G, van Gerven M, Haselager P. Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 414
    },
    {
        "text": "In: Escalante HJ, Escalera S, Guyon I, et al., eds.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 415
    },
    {
        "text": "Explainable and Interpretable Models in Computer Vision and Machine Learning.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 416
    },
    {
        "text": "Springer, Cham; 2018:19-36. doi:10.1007/978-3-319-98131-4_2 21.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 417
    },
    {
        "text": "Martens D, Vanthienen J, Verbeke W, Baesens B.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 418
    },
    {
        "text": "Performance of classification models from a user perspective.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 419
    },
    {
        "text": "Decis Support Syst.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 420
    },
    {
        "text": "Pazzani MJ.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 421
    },
    {
        "text": "Knowledge discovery from data?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 422
    },
    {
        "text": "2000;15(2):10-12.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 423
    },
    {
        "text": "Gender, age, experience and voluntariness of user are included as moderators of the impact of the four key constructs on usage intention and behavior.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 424
    },
    {
        "text": "Johnson TL, Brewer D, Estacio R, et al.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 425
    },
    {
        "text": "Augmenting Predictive Modeling Tools with Clinical Insights for Care Coordination Program Design and Implementation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 426
    },
    {
        "text": "EGEMS (Washington, DC).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 427
    },
    {
        "text": "Elish MC.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 428
    },
    {
        "text": "The Stakes of Uncertainty: Developing and Integrating Machine Learning in Clinical Care.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 429
    },
    {
        "text": "In: Ethnographic Praxis in Industry Conference Proceedings.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 430
    },
    {
        "text": "Vol 2018. ; 2018:364-380. doi:10.1111/1559-8918.2018.01213 25.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 431
    },
    {
        "text": "Barakat NH, Bradley AP, Barakat MNH.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 432
    },
    {
        "text": "Intelligible support vector machines for diagnosis of diabetes mellitus.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 433
    },
    {
        "text": "IEEE Trans Inf Technol Biomed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 434
    },
    {
        "text": "Guidotti R, Monreale A, Ruggieri S, Turini F, Giannotti F, Pedreschi D. A Survey of Methods for Explaining Black Box Models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 435
    },
    {
        "text": "ACM Comput Surv.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 436
    },
    {
        "text": "Miller T. Explanation in artificial intelligence: Insights from the social sciences.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 437
    },
    {
        "text": "Artif Intell.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 438
    },
    {
        "text": "2019;267:1-38. doi:10.1016/j.artint.2018.07.007 28.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 439
    },
    {
        "text": "The goal in this work was to look at design issues that may impact performance expectancy and effort expectancy, as the social influence and facilitating conditions constructs would be challenging to control.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 440
    },
    {
        "text": "Comprehensible classification models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 441
    },
    {
        "text": "ACM SIGKDD Explor Newsl.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 442
    },
    {
        "text": "Lipton ZC.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 443
    },
    {
        "text": "The Doctor Just Won’t Accept That!",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 444
    },
    {
        "text": "Examples of evaluation criteria that promote a demand for interpretability ........ 13 Table 2.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 445
    },
    {
        "text": "These constructs deal with an individual’s perceptions of how the specific social environment and organizational infrastructure promotes the use of a system, which makes it difficult to theorize how explanations might affect these constructs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 446
    },
    {
        "text": "Abdul A, Vermeulen J, Wang D, Lim BY, Kankanhalli M. Trends and Trajectories for Explainable, Accountable and Intelligible Systems.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 447
    },
    {
        "text": "In: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI ’18.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 448
    },
    {
        "text": "Explainable AI for Designers: A Human-Centered Perspective on Mixed-Initiative Co-Creation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 449
    },
    {
        "text": "In: 2018 IEEE Conference on Computational Intelligence and Games (CIG).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 450
    },
    {
        "text": "Miller T, Howe P, Sonenberg L. Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to Stop Worrying and Love the Social and Behavioural Sciences.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 451
    },
    {
        "text": "Raghupathi W, Raghupathi V. Big data analytics in healthcare: promise and potential.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 452
    },
    {
        "text": "Kilsdonk E, Peute LW, Jaspers MWM.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 453
    },
    {
        "text": "Factors influencing implementation success of guideline-based clinical decision support systems: A systematic review and gaps analysis.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 454
    },
    {
        "text": "Kilsdonk E, Peute LWP, Knijnenburg SL, Jaspers MWM.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 455
    },
    {
        "text": "Factors known to influence acceptance of clinical decision support systems.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 456
    },
    {
        "text": "Stud Health Technol Inform.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 457
    },
    {
        "text": "Effects of computerized clinical decision support systems on practitioner performance and patient outcomes: a systematic review.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 458
    },
    {
        "text": "Venkatesh V, Morris MG, Davis GB, Davis FD.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 459
    },
    {
        "text": "MIS Q.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 460
    },
    {
        "text": "2003;27(3):425-478.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 461
    },
    {
        "text": "White boxes and solid line arrows depict the main constructs and modifiers that comprise the UTAUT theory.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 462
    },
    {
        "text": "162 39.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 463
    },
    {
        "text": "Venkatesh V, Sykes TA, Xiaojun Zhang.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 464
    },
    {
        "text": "“Just What the Doctor Ordered”: A Revised UTAUT for EMR System Adoption and Use by Doctors.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 465
    },
    {
        "text": "In: 2011 44th Hawaii International Conference on System Sciences.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 466
    },
    {
        "text": "In: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI ’19.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 467
    },
    {
        "text": "Lim BY, Yang Q, Abdul A, Wang D. Why these Explanations?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 468
    },
    {
        "text": "The grey ovals indicate the proposed extensions to the UTAUT model to demonstrate the potential impact of explanation design on key constructs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 469
    },
    {
        "text": "Selecting Intelligibility Types for Explanation Goals.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 470
    },
    {
        "text": "In: Joint Proceedings of the ACM IUI 2019 Workshops.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 471
    },
    {
        "text": "Can we do better explanations?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 472
    },
    {
        "text": "In: Joint Proceedings of the ACM IUI 2019 Workshops.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 473
    },
    {
        "text": "The exentions are connected to their main constructs using dashed arrows.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 474
    },
    {
        "text": "Doshi-Velez F, Kim B.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 475
    },
    {
        "text": "Mohseni S, Zarei N, Ragan ED.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 476
    },
    {
        "text": "Kappen TH, van Loon K, Kappen MAM, et al.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 477
    },
    {
        "text": "Barriers and facilitators perceived by physicians when using prediction models in practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 478
    },
    {
        "text": "(Adapted from Venkatesh et al.38) 6 Figure 1 depicts how an explanation design may affect the remaining two constructs, performance expectancy and effort expectancy.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 479
    },
    {
        "text": "J Clin Epidemiol.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 480
    },
    {
        "text": "2016;70:136-145. doi:10.1016/j.jclinepi.2015.09.008 46.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 481
    },
    {
        "text": "Key steps and common pitfalls in developing and validating risk models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 482
    },
    {
        "text": "BJOG.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 483
    },
    {
        "text": "Lipton ZC.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 484
    },
    {
        "text": "Performance expectancy refers to an individual’s perceptions of how a system might improve or detract from his/her ability to do his/her job, while effort expectancy refers to an individual’s perceptions of the degree of effort involved in understanding and using a system.38 These perceptions can be directly influenced by the degree to which explanation designs for ML-based CDSS fit healthcare providers’ information needs and environment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 485
    },
    {
        "text": "Doran D, Schulz S, Besold TR.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 486
    },
    {
        "text": "What Does Explainable AI Really Mean?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 487
    },
    {
        "text": "A New Conceptualization of Perspectives.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 488
    },
    {
        "text": "Karim A, Mishra A, Newton MH, Sattar A.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 489
    },
    {
        "text": "Hoffman RR, Klein G. Explaining Explanation, Part 1: Theoretical Foundations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 490
    },
    {
        "text": "This directly affects whether healthcare providers can integrate the system knowledge with their own in order to make informed decisions, which can affect provider perceptions of the effort required to use the system (effort expectancy) and the utility of the system to improve their job (performance expectancy).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 491
    },
    {
        "text": "Krause J, Perer A, Bertini E. Using Visual Analytics to Interpret Predictive Machine Learning Models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 492
    },
    {
        "text": "Zerilli J, Knott A, Maclaurin J, Gavaghan C. Transparency in Algorithmic and Human Decision-Making: Is There a Double Standard?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 493
    },
    {
        "text": "Philos Technol.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 494
    },
    {
        "text": "Weld DS, Bansal G. The Challenge of Crafting Intelligible Intelligence.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 495
    },
    {
        "text": "Categories of users and explanation goals (adapted from Ras et al.20 and Samek et al.71) .......................................................................................................................................... 30 Table 3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 496
    },
    {
        "text": "Herman B.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 497
    },
    {
        "text": "Ventocilla E, Helldin T, Riveiro M, Bae J.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 498
    },
    {
        "text": "Towards a Taxonomy for Interpretable and Interactive Machine Learning.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 499
    },
    {
        "text": "Demands on time and cognitive resources will also likely affect provider perceptions of the effort required to use the system (effort expectancy) and the utility of the system to improve their job (performance expectancy).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 500
    },
    {
        "text": "; 2018:151-157. https://www.researchgate.net/publication/326979343.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 501
    },
    {
        "text": "Pieters W. Explanation and trust: what to tell the user in security and AI?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 502
    },
    {
        "text": "Ethics Inf Technol.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 503
    },
    {
        "text": "Klein G. Explaining Explanation, Part 3: The Causal Landscape.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 504
    },
    {
        "text": "Explaining Explanation, Part 4: A Deep Dive on Deep Nets.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 505
    },
    {
        "text": "; 2018. https://christophm.github.io/interpretable-ml-book/.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 506
    },
    {
        "text": "Biran O, Cotton C. Explanation and Justification in Machine Learning : A Survey.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 507
    },
    {
        "text": "Hernandez PF.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 508
    },
    {
        "text": "Lighting the black box: explaining individual predictions of machine learning algorithms.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 509
    },
    {
        "text": "2018.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 510
    },
    {
        "text": "Ribeiro MT, Singh S, Guestrin C. Nothing Else Matters: Model-Agnostic Explanations By Identifying Prediction Invariance.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 511
    },
    {
        "text": "Tintarev N, Masthoff J.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 512
    },
    {
        "text": "Evaluating the effectiveness of explanations for recommender systems.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 513
    },
    {
        "text": "User Model User-adapt Interact.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 514
    },
    {
        "text": "Allahyari H, Lavesson N. User-oriented assessment of classification model understandability.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 515
    },
    {
        "text": "In: 11th Scandinavian Conference on Artificial Intelligence.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 516
    },
    {
        "text": "164 69.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 517
    },
    {
        "text": "Hoffman RR, Mueller ST, Klein G. Explaining Explanation, Part 2: Empirical Foundations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 518
    },
    {
        "text": "Grice HP.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 519
    },
    {
        "text": "Logic and Conversation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 520
    },
    {
        "text": "In: Syntax and Semantics 3: Speech Arts.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 521
    },
    {
        "text": "New York: Academic Press; 1975:41-58.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 522
    },
    {
        "text": "Samek W, Wiegand T, Müller K-R.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 523
    },
    {
        "text": "Distill.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 524
    },
    {
        "text": "2018;3(3).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 525
    },
    {
        "text": "doi:10.23915/distill.00010 73.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 526
    },
    {
        "text": "Shmueli G. To Explain or to Predict?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 527
    },
    {
        "text": "Stat Sci.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 528
    },
    {
        "text": "Krause J, Perer A, Ng K. Interacting with Predictions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 529
    },
    {
        "text": "In: Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI ’16.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 530
    },
    {
        "text": "Explainable machine learning predictions to help anesthesiologists prevent hypoxemia during surgery.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 531
    },
    {
        "text": "Nat Biomed Eng.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 532
    },
    {
        "text": "Caruana R, Lou Y, Gehrke J, Koch P, Sturm M, Elhadad N. Intelligible Models for HealthCare.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 533
    },
    {
        "text": "RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 534
    },
    {
        "text": "In: 30th Conference on Neural Information Processing Systems (NIPS 2016).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 535
    },
    {
        "text": "Che Z, Purushotham S, Khemani R, Liu Y. Interpretable Deep Models for ICU Outcome Prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 536
    },
    {
        "text": "AMIA .",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 537
    },
    {
        "text": "Annu Symp proceedings AMIA Symp.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 538
    },
    {
        "text": "2016;2016:371-380. http://www.ncbi.nlm.nih.gov/pubmed/28269832.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 539
    },
    {
        "text": "Luo G. Automatically explaining machine learning prediction results: a demonstration on type 2 diabetes risk prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 540
    },
    {
        "text": "2016;4(2).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 541
    },
    {
        "text": "doi:10.1186/s13755-016-0015-4 80.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 542
    },
    {
        "text": "A mathematical model for interpretable clinical decision support with applications in gynecology.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 543
    },
    {
        "text": "PLoS One.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 544
    },
    {
        "text": "doi:10.1371/journal.pone.0034312 81.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 545
    },
    {
        "text": "Software tool for improved prediction of Alzheimer’s disease.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 546
    },
    {
        "text": "Model explanation approaches and evaluations in the recent healthcare literature................................................................................................................................................... 33 Table 4.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 547
    },
    {
        "text": "Neurodegener Dis.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 548
    },
    {
        "text": "A Decision-Support Tool for Renal Mass Classification.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 549
    },
    {
        "text": "J Digit Imaging.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 550
    },
    {
        "text": "Yang Y, Tresp V, Wunderle M, Fasching PA.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 551
    },
    {
        "text": "Explaining Therapy Predictions with Layer-Wise Relevance Propagation in Neural Networks.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 552
    },
    {
        "text": "In: 2018 IEEE International Conference on Healthcare Informatics (ICHI).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 553
    },
    {
        "text": "Sha Y, Wang MD.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 554
    },
    {
        "text": "Interpretable Predictions of Clinical Outcomes with An Attention-based Recurrent Neural Network.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 555
    },
    {
        "text": "In: Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics - ACM-BCB ’17.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 556
    },
    {
        "text": "MediBoost: a Patient Stratification Tool for Interpretable Decision Making in the Era of Precision Medicine.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 557
    },
    {
        "text": "Sci Rep. 2016;6(1):37854. doi:10.1038/srep37854 86.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 558
    },
    {
        "text": "Liu N, Kumara S, Reich E. Explainable data-driven modeling of patient satisfaction survey data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 559
    },
    {
        "text": "In: 2017 IEEE International Conference on Big Data (Big Data).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 560
    },
    {
        "text": "More specifically, I used literature insights to define the context of use for the prediction tool and suggest possible explanation designs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 561
    },
    {
        "text": "Goldstein BA, Navar AM, Pencina MJ, Ioannidis JPA.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 562
    },
    {
        "text": "Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 563
    },
    {
        "text": "J Am Med Informatics Assoc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 564
    },
    {
        "text": "Machine Learning and Decision Support in Critical Care.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 565
    },
    {
        "text": "Proc IEEE Inst Electr Electron Eng.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 566
    },
    {
        "text": "Desai N, Gross J.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 567
    },
    {
        "text": "Scoring systems in the critically ill: uses, cautions, and future directions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 568
    },
    {
        "text": "BJA Educ.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 569
    },
    {
        "text": "2019;19(7):212-218. doi:10.1016/j.bjae.2019.03.002 90.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 570
    },
    {
        "text": "Lee J, Maslove DM, Dubin JA.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 571
    },
    {
        "text": "Personalized Mortality Prediction Driven by Electronic Medical Data and a Patient Similarity Metric.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 572
    },
    {
        "text": "Emmert-Streib F, ed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 573
    },
    {
        "text": "PLoS One.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 574
    },
    {
        "text": "doi:10.1371/journal.pone.0127428 91.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 575
    },
    {
        "text": "Celi LA, Galvin S, Davidzon G, Lee J, Scott D, Mark R. A Database-driven Decision Support System: Customized Mortality Prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 576
    },
    {
        "text": "J Pers Med.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 577
    },
    {
        "text": "Early hospital mortality prediction of intensive care unit patients using an ensemble learning approach.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 578
    },
    {
        "text": "Tonekaboni S, Joshi S, McCradden MD, Goldenberg A.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 579
    },
    {
        "text": "Pollack AH, Tweedy CG, Blondon K, Pratt W. Knowledge crystallization and clinical priorities: evaluating how physicians collect and synthesize patient-related data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 580
    },
    {
        "text": "AMIA .",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 581
    },
    {
        "text": "Annu Symp proceedings AMIA Symp.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 582
    },
    {
        "text": "2014;2014:1874-1883. http://www.ncbi.nlm.nih.gov/pubmed/25954460.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 583
    },
    {
        "text": "Hallen SAM, Hootsmans NAM, Blaisdell L, Gutheil CM, Han PKJ.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 584
    },
    {
        "text": "Physicians’ perceptions of the value of prognostic models: the benefits and risks of prognostic confidence.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 585
    },
    {
        "text": "Health Expect.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 586
    },
    {
        "text": "Van Belle V, Van Calster B. Visualizing Risk Prediction Models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 587
    },
    {
        "text": "PLoS One.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 588
    },
    {
        "text": "While the framework was developed and applied with a focus on explaining ML-based systems in healthcare, it is generalizable to other domains as well.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 589
    },
    {
        "text": "doi:10.1371/journal.pone.0132614 166 97.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 590
    },
    {
        "text": "The proof of the pudding: in praise of a culture of real-world validation for medical artificial intelligence.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 591
    },
    {
        "text": "Ann Transl Med.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 592
    },
    {
        "text": "Teasdale G, Jennett B.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 593
    },
    {
        "text": "Assessment of coma and impaired consciousness.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 594
    },
    {
        "text": "A practical scale.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 595
    },
    {
        "text": "Lancet (London, England).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 596
    },
    {
        "text": "1974;2(7872):81-84. doi:10.1016/s0140-6736(74)91639-0 99.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 597
    },
    {
        "text": "Office of Management and Budget.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 598
    },
    {
        "text": "Revisions to the standards for the classification of federal data on race and ethnicity.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 599
    },
    {
        "text": "Fed Regist.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 600
    },
    {
        "text": "1997. https://nces.ed.gov/programs/handbook/data/pdf/Appendix_A.pdf.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 601
    },
    {
        "text": "Centers for Medicare & Medicaid Services.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 602
    },
    {
        "text": "2015 ICD-10-CM and GEMs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 603
    },
    {
        "text": "https://www.cms.gov/Medicare/Coding/ICD10/2015-ICD-10-CM-and-GEMs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 604
    },
    {
        "text": "Accessed January 5, 2019.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 605
    },
    {
        "text": "Fayyad UM, Irani KB.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 606
    },
    {
        "text": "Multi-lnterval Discretization of Continuous-Valued Attributes for Classification learning.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 607
    },
    {
        "text": "; 1993:1022-1027.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 608
    },
    {
        "text": "Hall MA.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 609
    },
    {
        "text": "Correlation-based Feature Selection for Machine Learning.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 610
    },
    {
        "text": "1999;(April).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 611
    },
    {
        "text": "https://www.cs.waikato.ac.nz/~mhall/thesis.pdf.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 612
    },
    {
        "text": "Other work has identified barriers that relate to model utility, such as a poor match between model information and clinical information needs (e.g., models that don’t predict events of clinical relevance or that do not provide actionable information).45,46 While model 9 interpretability may improve model utility (e.g., providing information that leads to actionable insights), it is unclear how the relationship between these two concepts may influence the adoption of a predictive model in practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 613
    },
    {
        "text": "Frank E, Hall MA, Witten IH.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 614
    },
    {
        "text": "The WEKA Workbench.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 615
    },
    {
        "text": "Hamilton, New Zealand: Morgan Kaufmann; 2016. https://www.cs.waikato.ac.nz/ml/weka/Witten_et_al_2016_appendix.pdf.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 616
    },
    {
        "text": "SSIGKDD Explor.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 617
    },
    {
        "text": "2009;11(1).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 618
    },
    {
        "text": "Feature names and definitions .................................................................................... 49 Table 5.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 619
    },
    {
        "text": "Moreover, it is unclear if one concept might play a more influential role in adoption.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 620
    },
    {
        "text": "Reutemann P. python-weka-wrapper3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 621
    },
    {
        "text": "https://github.com/fracpete/python-weka-wrapper3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 622
    },
    {
        "text": "Pedregosa F, Varoquaux G, Gramfort A, et al.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 623
    },
    {
        "text": "Scikit-learn: Machine Learning in Python.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 624
    },
    {
        "text": "J Mach Learn Res.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 625
    },
    {
        "text": "2011;12:2825-2830. http://dl.acm.org/citation.cfm?id=2078195%5Cnhttp://arxiv.org/abs/1201.0490.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 626
    },
    {
        "text": "Meyfroidt G, Güiza F, Ramon J, Bruynooghe M. Machine learning techniques to examine large patient databases.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 627
    },
    {
        "text": "Best Pract Res Clin Anaesthesiol.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 628
    },
    {
        "text": "2009;23(1):127-143. doi:10.1016/j.bpa.2008.09.003 108.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 629
    },
    {
        "text": "Davis J, Goadrich M. The relationship between Precision-Recall and ROC curves.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 630
    },
    {
        "text": "R Core Team.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 631
    },
    {
        "text": "R: A Language and Environment for Statistical Computing.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 632
    },
    {
        "text": "Vienna, Austria: R Foundation for Statistical Computing; 2018. https://www.r-project.org/.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 633
    },
    {
        "text": "pROC: an open-source package for R and S+ to analyze and compare ROC curves.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 634
    },
    {
        "text": "BMC Bioinformatics.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 635
    },
    {
        "text": "Grau J, Grosse I, Keilwagen J. PRROC: computing and visualizing precision-recall and receiver operating characteristic curves in R. Bioinformatics.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 636
    },
    {
        "text": "2015;31(15):2595-2597. doi:10.1093/bioinformatics/btv153 167 112.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 637
    },
    {
        "text": "Kennedy G, Gallego B.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 638
    },
    {
        "text": "Clinical prediction rules: A systematic review of healthcare provider opinions and preferences.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 639
    },
    {
        "text": "Edwards A.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 640
    },
    {
        "text": "Findings from this work help partially elucidate factors related to interpretability and utility that may impact the acceptance and use of ML-based tools in practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 641
    },
    {
        "text": "Explaining risks: turning numerical data into meaningful pictures.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 642
    },
    {
        "text": "Analysis of a failed clinical decision support system for management of congestive heart failure.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 643
    },
    {
        "text": "AMIA .",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 644
    },
    {
        "text": "Annu Symp proceedings AMIA Symp.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 645
    },
    {
        "text": "November 2008:773-777. http://www.ncbi.nlm.nih.gov/pubmed/18999183.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 646
    },
    {
        "text": "Horsky J, Schiff GD, Johnston D, Mercincavage L, Bell D, Middleton B. Interface design principles for usable decision support: a targeted review of best practices for clinical prescribing interventions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 647
    },
    {
        "text": "Comparing the information seeking strategies of residents, nurse practitioners, and physician assistants in critical care settings.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 648
    },
    {
        "text": "J Am Med Informatics Assoc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 649
    },
    {
        "text": "doi:10.1136/amiajnl-2013-002615 117.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 650
    },
    {
        "text": "Lee J, Maslove DM.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 651
    },
    {
        "text": "Customization of a Severity of Illness Score Using Local Electronic Medical Record Data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 652
    },
    {
        "text": "J Intensive Care Med.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 653
    },
    {
        "text": "Pickering BW, Gajic O, Ahmed A, Herasevich V, Keegan MT.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 654
    },
    {
        "text": "Data Utilization for Medical Decision Making at the Time of Patient Admission to ICU*.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 655
    },
    {
        "text": "Crit Care Med.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 656
    },
    {
        "text": "Hall A, Walton G. Information overload within the health care system: a literature review.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 657
    },
    {
        "text": "Health Info Libr J.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 658
    },
    {
        "text": "Nushi B, Kamar E, Horvitz E. Towards Accountable AI: Hybrid Human-Machine Analyses for Characterizing System Failure.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 659
    },
    {
        "text": "Sixth AAAI Conf Hum Comput Crowdsourcing.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 660
    },
    {
        "text": "Kappen TH, Peelen LM.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 661
    },
    {
        "text": "Prediction models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 662
    },
    {
        "text": "Curr Opin Anaesthesiol.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 663
    },
    {
        "text": "Pu P, Chen L. Trust-inspiring explanation interfaces for recommender systems.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 664
    },
    {
        "text": "2007;20(6):542-556. doi:10.1016/j.knosys.2007.04.004 123.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 665
    },
    {
        "text": "Ribeiro MT, Singh S, Guestrin C. “Why Should I Trust You?”: Explaining the Predictions of Any Classifier.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 666
    },
    {
        "text": "Lundberg S, Lee S-I.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 667
    },
    {
        "text": "An unexpected unity among methods for interpreting model predictions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 668
    },
    {
        "text": "Lundberg S, Lee S-I.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 669
    },
    {
        "text": "A Unified Approach to Interpreting Model Predictions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 670
    },
    {
        "text": "Chapter 4 demonstrates how the proposed framework was used in conjunction with literature insights to define a context of use for an ML-based prediction tool and suggest possible user-centered explanation designs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 671
    },
    {
        "text": "In: Advances in Neural Information Processing Systems.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 672
    },
    {
        "text": "168 126.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 673
    },
    {
        "text": "Lundberg SM.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 674
    },
    {
        "text": "SHAP (SHapley Additive exPlanations).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 675
    },
    {
        "text": "https://github.com/slundberg/shap.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 676
    },
    {
        "text": "Accessed October 10, 2018.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 677
    },
    {
        "text": "Bokeh Development Team.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 678
    },
    {
        "text": "Bokeh: Python library for interactive visualization.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 679
    },
    {
        "text": "http://www.bokeh.pydata.org.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 680
    },
    {
        "text": "Corbin J, Strauss A.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 681
    },
    {
        "text": "Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 682
    },
    {
        "text": "3rd ed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 683
    },
    {
        "text": "Los Angeles: SAGE Publications; 2008.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 684
    },
    {
        "text": "NVivo Qualitative Data Analysis Software.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 685
    },
    {
        "text": "Version 12.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 686
    },
    {
        "text": "QSR International Pty Ltd.; 2018.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 687
    },
    {
        "text": "The Pallets Projects.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 688
    },
    {
        "text": "WTForms.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 689
    },
    {
        "text": "https://github.com/wtforms/wtforms.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 690
    },
    {
        "text": "Finally, Chapter 7 includes a discussion of the work completed, identifies limitations, suggests directions for future work, and presents final conclusions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 691
    },
    {
        "text": "StataCorp.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 692
    },
    {
        "text": "Stata Statistical Software: Release 15.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 693
    },
    {
        "text": "College Station, TX: StataCorp LLC; 2017.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 694
    },
    {
        "text": "Hunter JD.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 695
    },
    {
        "text": "Matplotlib: A 2D Graphics Environment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 696
    },
    {
        "text": "Comput Sci Eng.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 697
    },
    {
        "text": "11 2.0 Background This chapter provides a review of the literature relevant to this dissertation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 698
    },
    {
        "text": "Matplotlib.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 699
    },
    {
        "text": "https://github.com/matplotlib/matplotlib.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 700
    },
    {
        "text": "Participatory design of probability-based decision support tools for in-hospital nurses.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 701
    },
    {
        "text": "J Am Med Informatics Assoc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 702
    },
    {
        "text": "Dekker FW, Ramspek CL, van Diepen M. Con: Most clinical risk scores are useless.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 703
    },
    {
        "text": "Nephrol Dial Transplant.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 704
    },
    {
        "text": "Barr PJ, Elwyn G. Measurement challenges in shared decision making: putting the ‘patient’ in patient-reported measures.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 705
    },
    {
        "text": "Integrating usability testing and think-aloud protocol analysis with “near-live” clinical simulations in evaluating clinical decision support.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 706
    },
    {
        "text": "King AJ, Cooper GF, Clermont G, et al.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 707
    },
    {
        "text": "Using machine learning to selectively highlight patient information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 708
    },
    {
        "text": "Ribeiro MT.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 709
    },
    {
        "text": "Local Interpretable Model-Agnostic Explanations (lime).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 710
    },
    {
        "text": "https://lime-ml.readthedocs.io/en/latest/.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 711
    },
    {
        "text": "Accessed October 10, 2018.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 712
    },
    {
        "text": "Shapley LS.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 713
    },
    {
        "text": "A value for n-person games.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 714
    },
    {
        "text": "In: Contributions to the Theory of Games.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 715
    },
    {
        "text": "Vol 28.; 1953:307-317.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 716
    },
    {
        "text": "The reviewed literature lacks consistent terminology and definitions for these terms, which can make interpretation challenging.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 717
    },
    {
        "text": "This makes it challenging to determine what explanation approaches might enable providers to understand model predictions in a comprehensible and useful way.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 718
    },
    {
        "text": "Alternative terms commonly used in the literature are bolded and in quotes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 719
    },
    {
        "text": "These evaluation criteria are often interrelated and usually require subjective assessment by humans to determine if they are met.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 720
    },
    {
        "text": "Examples of evaluation criteria that promote a demand for interpretability Criteria Definition Fairness & Bias Reduction6,31,43,47,49 Ensuring that protected groups are not discriminated against Adherence to ethical principles6,47 Ensuring that algorithm decisions or suggestions conform to ethical standards Privacy6,43 Protecting sensitive information Accountability & Liability6,31,54–56 Assigning responsibility of a suggestion or decision to an algorithm Transferability, Reliability, & Robustness26,43,47 Ensuring algorithms exhibit certain levels of performance when applied in unfamiliar situations Informativeness31,47 Providing useful information for real-world decision-making or accomplishing a task Safety28 Protecting against danger, risk, or injury caused by decisions or suggestions of a system Justifiability11,21 Ensuring a model aligns with existing domain knowledge A basic definition of an explanation adopted in the ML literature is the concept of an ‘everyday explanation’, which is defined by Miller27 as an answer to a why-question.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 721
    },
    {
        "text": "Summary of participants in each focus group ........................................................... 72 Table 8.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 722
    },
    {
        "text": "The specific questions asked and explanations expected will depend on a user’s individual relationship to the system,56 and no single explanation is likely to satisfy all users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 723
    },
    {
        "text": "The comprehensibility of an explanation refers to its ability to describe a system in a way that is understandable to humans and relies on producing system descriptions that respect the cognition, knowledge, and biases of the user.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 724
    },
    {
        "text": "In other words, the explanation must produce system descriptions that are “simple enough for a person to understand using a vocabulary that is meaningful to the user”.52 The completeness of an explanation is its ability to describe the operations of a system in an accurate way.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 725
    },
    {
        "text": "These are often conflicting goals.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 726
    },
    {
        "text": "For example, an explanation that achieves perfect completeness may use highly technical language and be complex, which would likely result in low comprehensibility.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 727
    },
    {
        "text": "This balance will be heavily influenced by the user to whom the explanation is being provided and the context in which it must be provided.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 728
    },
    {
        "text": "High-level summary of insights on context of use and influences on perceptions of the model .................................................................................................................................. 73 Table 9.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 729
    },
    {
        "text": "More generally, the goal of global-level explanations is to help users develop mental models of a model and how it works.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 730
    },
    {
        "text": "These explanations can include information regarding the training information, the architecture and algorithms, the functional-level performance descriptions (e.g., accuracy), and boundary conditions and failure modes, i.e., information on what the model cannot do or does not perform well on.61 These explanations tend to have high completeness, but it is generally challenging to improve the comprehensibility of these explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 731
    },
    {
        "text": "Hall et al.15 suggest that the best explanations for ML models will likely come from a combination of both instance- and global-level explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 732
    },
    {
        "text": "However, it should be noted that outside of this work the term interpretability is used more frequently when describing and classifying various approaches.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 733
    },
    {
        "text": "Although multiple prior attempts have used differing terminology to classify approaches to explanation,15,20,26,28,47,51,52,62,63 it is generally agreed that there are at least two main categories of explanation approaches: integrated and post-hoc.20,28,65,31,47,50,51,56,62–64 In the sub-sections below, I define each category and provide further sub-categories of approaches.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 734
    },
    {
        "text": "I provide general descriptions of the various sub-categories and only give examples as is necessary to distinguish between the categories.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 735
    },
    {
        "text": "For more examples of approaches, I recommend referring to one of the several literature reviews/surveys available.26,28,51,52,63 It should be noted that many of the approaches in these categories make claims of interpretability that are not substantiated by empirical user studies.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 736
    },
    {
        "text": "2.1.2.1 Integrated Explanation Approaches Following Došilović et al.,28 I define integrated explanation approaches as those approaches that are transparency-based—that is, they are aimed at describing model processes and are generated as part of the learning/training process.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 737
    },
    {
        "text": "These approaches generally provide global-level explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 738
    },
    {
        "text": "Combining insights from Došilović et al.28 and Gilpin et al.,52 I sub-divide these approaches into pure transparent, hybrid, and explanation-producing approaches.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 739
    },
    {
        "text": "In pure transparent approaches to explanation, the family of models that can be used is restricted to those that are considered transparent, or models whose internal mechanisms can be understood.28,47 Typical examples of such model families include decision trees, Naïve Bayes 18 models, logistic regressions, and linear regressions, among others.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 740
    },
    {
        "text": "It is generally accepted that for pure transparent approaches, accuracy comes at the cost of comprehensibility.51 For example, a linear regression model using hundreds of features or highly engineered features may exhibit high accuracy, but the complexity of the model leads to decreased comprehensibility.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 741
    },
    {
        "text": "In hybrid approaches, transparent model families are paired with models whose internal mechanisms are generally considered to be opaque, i.e., “black-box” models, to produce models that sacrifice some comprehensibility to achieve better accuracy.28 Again, the model itself typically serves as the explanation in these types of approaches.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 742
    },
    {
        "text": "Insights on context of use target questions .............................................................. 76 Table 11.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 743
    },
    {
        "text": "An example of a hybrid approach from Došilović et al.28 combined logistic regression and support vector machine (SVM) approaches to credit scoring.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 744
    },
    {
        "text": "In explanation-producing approaches, models that are considered to be “black-boxes” are specifically built to provide explanations that improve the transparency of their internal mechanisms.52 These approaches typically apply to neural networks, such as those that learn disentangled representations,52 and the balance between completeness and comprehensibility will vary by approach.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 745
    },
    {
        "text": "Thus, the level of comprehensibility and completeness of a model-specific post-hoc explanation will vary by approach.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 746
    },
    {
        "text": "It should be noted that all integrated explanation approaches mentioned in section 2.1.2.1 are also model-specific, but they are not post-hoc.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 747
    },
    {
        "text": "An example of a model-specific post-hoc explanation approach is given by Barakat et al.,25 who used model-specific techniques to extract rule-based explanations from an SVM classifier for predicting diabetes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 748
    },
    {
        "text": "These approaches tend to produce explanations with lower completeness than other explanation approaches; however, they can typically provide high comprehensibility and offer the attractive advantage of being generalizable.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 749
    },
    {
        "text": "Doshi-Velez and Kim43 have posited that the evaluation of approaches to interpretability should match the claimed contribution.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 750
    },
    {
        "text": "For example, if the aim of an explanation approach is to make a model useful in some context or application, then the explanations should be evaluated with respect to that application (e.g., explanations for a model to assist in medical diagnosis should be evaluated by having doctors use the system to make diagnoses).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 751
    },
    {
        "text": "Figure 3 provides an overview of each approach, which are discussed in detail in the next few paragraphs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 752
    },
    {
        "text": "Approaches are distinguished by the type of experimental tasks and subjects involved, and get more costly as the level of user-involvement and experimental complexity increases.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 753
    },
    {
        "text": "Application-grounded approaches involve experiments in which real humans, i.e., target end-users, use real applications to perform the intended end-task of the application.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 754
    },
    {
        "text": "This allows for the evaluation of explanation quality within the context of its intended use.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 755
    },
    {
        "text": "The suggested baseline for these types of evaluations is how well human-produced explanations assist in other humans completing the task (i.e., the gold standard is the success rate of completing the task using explanations provided by humans).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 756
    },
    {
        "text": "It should be noted that these are the most demanding evaluations to perform, requiring significant time, effort, and expense to complete.43 Thus, few evaluations of interpretability employ an application-grounded approach, but some can be seen in the literature on explanations for recommender systems.67 Human-grounded approaches involve experiments in which real humans use explanations to perform simplified tasks that maintain the essence of the target application.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 757
    },
    {
        "text": "These types of 22 experiments aim to test general notions of explanation quality and can usually be performed with lay users when experiments with target end-users prove logistically challenging (e.g., highly trained domain experts pose logistical challenges as they generally have smaller recruitment pools and higher compensation requirements).43 As these approaches are typically simpler to employ than application-grounded approaches, they are the most commonly used in the interpretability evaluation literature when humans are involved.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 758
    },
    {
        "text": "Simulatability experiments, i.e., does the explanation approach allow a human to easily predict a model’s output for a given input, are quite popular in the literature.20,32,56 The general motivation for this measure is that if an explanation approach has allowed a human to build a robust, accurate understanding of a model, then they should be able to simulate the model’s behavior.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 759
    },
    {
        "text": "Other common human-grounded approaches in the literature can be loosely categorized as model evaluation experiments (e.g., impact on ability to identify model errors and/or select best model), effectiveness experiments (e.g., impact on user ability to make decisions with the model), confidence/trust experiments (e.g., change in user prediction before and after seeing the model prediction), and preference experiments (e.g., user rates the quality of different explanation formats).20,67,68 Efficiency experiments, i.e., measuring how long it takes a user to comprehend different explanations or perform tasks using explanations, are also human-grounded approaches, but are rarely seen in the literature.26,67 Functionally-grounded approaches involve no human experiments, and instead use some formal definition of interpretability as a proxy of explanation quality.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 760
    },
    {
        "text": "An example of a possible proxy would be a family of models whose interpretability has been validated in human experiments (e.g., decision trees have been validated in some contexts).43 Researchers can optimize the performance of an approach based on that proxy and use the proxy to substantiate their claims for interpretability (e.g., optimizing the performance of decision trees on some task could claim to be 23 an interpretable approach).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 761
    },
    {
        "text": "Data collected for each study task ............................................................................ 94 Table 14.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 762
    },
    {
        "text": "However, studies have found that end-user preferences for smaller or larger models is context-dependent, and the comprehensibility of various model families depends on the end-user (e.g., an end-user with no statistical background may not find a sparse linear regression comprehensible).29,69 Thus, a small transparent model will not always be an appropriate proxy for explanation quality.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 763
    },
    {
        "text": "Another proxy for explanation quality sometimes seen in the literature is agreement with knowledge about the underlying model and/or the domain problem, i.e., if the explanation seems reasonable according to modeling and/or domain experts.52 This typically involves a few experts reviewing explanations, but is a far more informal and small-scale evaluation than a human-grounded approach and is perhaps one of the weakest approaches for evaluating interpretability.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 764
    },
    {
        "text": "This section is not meant to serve as a comprehensive review 24 of the literature, and instead focuses on summarizing some existing design and evaluation frameworks and their limitations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 765
    },
    {
        "text": "The framework is shown graphically with a brief description in Figure 4.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 766
    },
    {
        "text": "In a follow up position paper,41 the researchers used the framework to theoretically justify the use of specific explanation types to support various user goals based on how users may generally reason about the goal.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 767
    },
    {
        "text": "For example, a user trying to identify a specific cause for a particular system outcome might employ contrastive reasoning, which can be supported by “why not” type explanations that provide information about why an alternative system outcome was not produced.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 768
    },
    {
        "text": "Summary of analyses examining the impact of the user-centered explanation display on outcomes ................................................................................................................ 95 Table 15.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 769
    },
    {
        "text": "Although some examples are provided, the authors provide limited guidance on how to connect reasoning processes to specific AI elements and techniques.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 770
    },
    {
        "text": "The framework also does not consider the specific type of user when considering goals and cognitive processes and it does not account for the environment in which an explanation is being provided.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 771
    },
    {
        "text": "Conceptual framework for reasoned explanations that describes how human reasoning processes (left) inform explainable AI techniques (right) from Wang et al.40 “Points describe different theories of reasoning, explainable AI techniques, and strategies for designing explainable AI.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 772
    },
    {
        "text": "Arrows indicate pathway connections: red arrows for how theories of human reasoning inform explainable AI features, and grey for inter-relations between different reasoning processes and associations between explainable AI features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 773
    },
    {
        "text": "Only some example pathways are shown.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 774
    },
    {
        "text": "For example, hypothetico-deductive reasoning can be interfered by System 1 thinking and cause confirmation bias (grey arrow).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 775
    },
    {
        "text": "Confirmation bias can be mitigated (follow the red line) by presenting information about the prior probability or input attributions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 776
    },
    {
        "text": "Next, we can see that input attributions can be implemented as lists and visualized using tornado plots (follow the grey line).” (Image and caption taken directly from Wang et al.40) A framework proposed by Ribera and Lapedriza42 is based on theories that describe explanation as a social interaction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 777
    },
    {
        "text": "Summary of participant clincial experience ............................................................ 98 Table 16.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 778
    },
    {
        "text": "The framework is shown graphically with a brief description in Figure 5.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 779
    },
    {
        "text": "Their framework focuses on understanding the explainee (i.e., the user) needs and providing explanations that both meet those needs and follow Grice’s maxims of conversation70 (quantity, quality, relation, manner—in short, only be as informative as needed, be truthful, be 26 relevant, and be perspicuous).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 780
    },
    {
        "text": "), and 3) lay users—the recipients of the final decisions of the system (e.g., a patient that has been diagnosed).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 781
    },
    {
        "text": "They combine these user types with Grice’s maxims to identify specific explanation goals (why), the content to include in an explanation (what), the type of explanation or explanation approach (how), and suitable evaluation approaches for each user type.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 782
    },
    {
        "text": "Additionally, the framework is difficult to utilize when the user types overlap (e.g., a lay-user who is also a domain expert).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 783
    },
    {
        "text": "User-centric framework based on Grice’s conversation maxims from Ribera and Lapedriza.42 “The system targets explanations to different types of user, taking into account their different goals, and providing relevant (Grice’s 3rd maxim) and customized information to them (Grice’s 2nd and 4th maxim).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 784
    },
    {
        "text": "Participant responses by case urgency and display ................................................ 98 Table 17.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 785
    },
    {
        "text": "Figure 6 depicts and briefly describes the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 786
    },
    {
        "text": "The middle layer (Blue) shows design and evaluates human understandable explanations and explainable intelligent interfaces and agents.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 787
    },
    {
        "text": "The goal of the middle level (Explanation Interpretability Level) is to design understandable explanations that satisfy target user usability needs, which usually involves subjective evaluations of target user satisfaction with and understanding of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 788
    },
    {
        "text": "The goal at the highest level (Explainable AI System Outcomes Level) is to evaluate the ability of the explainable AI system to satisfy target-user needs, which usually involves domain-specific subjective and objective measures of the system impact on user task performance and perceptions of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 789
    },
    {
        "text": "Proportion of correct decisions for each display ..................................................... 99 xi Table 18.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 790
    },
    {
        "text": "The two categories are further sub-divided into specific types 29 of users, which loosely represent the various relationships a user may have with an AI system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 791
    },
    {
        "text": "For each categorization, Ras et al.20 identify possible goals and concerns that may prompt the user to ask for explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 792
    },
    {
        "text": "Learning refers to any activity where the user seeks to extract knowledge from the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 793
    },
    {
        "text": "Compliance is also closely tied to verification and relates to any activities aimed at ensuring the system adheres to an established legal, moral, or other societal standard.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 794
    },
    {
        "text": "Table 2 combines the insights from Ras et al.20 and Samek et al.71 to provide definitions and possible explanation goals for different user categories, which are not intended to be mutually exclusive (i.e., a user may belong to more than one category).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 795
    },
    {
        "text": "Additionally, the authors define cognitive chunks as the basic units of explanation, and suggest that the form, number, level of compositionality (i.e., how chunks are organized), and relationship (e.g., combination of chunks in linear or nonlinear way) of these chunks may differ based on user explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 796
    },
    {
        "text": "These concepts demonstrate more general design considerations than those introduced in the framework by Wang et al.,40 yet more specific than those suggested by Ribera and Lapedriza.42 30 Table 2.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 797
    },
    {
        "text": "must be satisfied.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 798
    },
    {
        "text": "These conversations could lead to improved models for use in healthcare.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 799
    },
    {
        "text": "Aggregate numbers were generated using the search query ((TITLE-ABS-KEY((\"predictive model\" OR \"artificial intelligence\" OR \"machine learning\") AND (\"healthcare\" OR \"medicine\") AND (\"transparent” OR “intelligible” OR “explainable” OR “explanation” OR “interpretable” OR “comprehensible” OR “understandable”))).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 800
    },
    {
        "text": "The query was run on November 29, 2018.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 801
    },
    {
        "text": "33 Table 3 shows that researchers have recently begun to explore alternative approaches to interpretability other than the use of logistic regression and other comprehensible models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 802
    },
    {
        "text": "However, human evaluations with end-users are rarely performed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 803
    },
    {
        "text": "Such studies are particularly important in healthcare, where providers are already overwhelmed by vast amounts of data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 804
    },
    {
        "text": "Krause et al.74 performed a human evaluation of a custom visual explanation approach, but the target end-users of their system were data scientists/analysts and not healthcare providers.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 805
    },
    {
        "text": "Lundberg et al.75 performed a small-scale study to evaluate whether explanations for predictions improved anesthesiologists’ ability to predict hypoxemia risk during surgery, but did not assess provider perceptions of satisfaction with the system and explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 806
    },
    {
        "text": "82 Yang et al.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 807
    },
    {
        "text": "83 Sha and Wang84 Valdes et al.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 808
    },
    {
        "text": "Summary of the analyses of display effect on unique and total number of items viewed ..................................................................................................................................... 102 Table A1.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 809
    },
    {
        "text": "Therefore, specific design suggestions (e.g., a specific explanation approach or presentation method) are not included and the examples provided are not meant to be comprehensive.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 810
    },
    {
        "text": "However, the examples provided in the framework encompass many of the ideas that appear in the literature on interpretability and user-centered explanation design and evaluation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 811
    },
    {
        "text": "Prior to presenting the framework, it is important to clarify its scope and limitations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 812
    },
    {
        "text": "The proposed framework was developed to design explanations for empirically-based predictive models, or data-driven models based on statistical associations that aim to minimize prediction error.73 It is not intended to be used for explanatory models, or theory-driven models that aim to test causal relationships between variables and that may be used in prediction tasks.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 813
    },
    {
        "text": "A more in depth discussion on the differences between predictive and explanatory modeling is provided by Shmueli.73 Additionally, the proposed framework does not explicitly consider how the use of specific data types or models may influence explanation design and interpretation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 814
    },
    {
        "text": "For example, models that use image data would have a very different space of possible explanation designs than models that use text data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 815
    },
    {
        "text": "Similarly, the space of possible explanation designs would change based on the specific model used, as different models will have different model-specific approaches to 35 explanation (e.g., Gini importance to show feature influences in a Random Forest model).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 816
    },
    {
        "text": "Moreover, users with knowledge of modeling approaches and their limitations may interpret predictions and explanations of specific models differently.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 817
    },
    {
        "text": "Thus, it is important to acknowledge the potential role of specific data types and models in explanation design and interpretation; however, these considerations were outside the scope of the proposed framework.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 818
    },
    {
        "text": "The framework is described in detail in Section 3.1.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 819
    },
    {
        "text": "Section 3.2 provides guidance on how the framework can be applied within the larger context of the design and evaluation of explainable AI systems.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 820
    },
    {
        "text": "Answering who, why, when, and where about the use of an explanation can be used to inform what information the explanation needs to contain (i.e., the content) and how that information needs to be provided (i.e.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 821
    },
    {
        "text": "the presentation).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 822
    },
    {
        "text": "As indicated by the relationships between the target questions indicated by grey dashed lines in Figure 8, these target questions are not orthogonal and are often co-dependent in that the answers to one question can and will be determined by the answers to other target questions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 823
    },
    {
        "text": "This introduces a partial ordering to the way in which target questions should be answered.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 824
    },
    {
        "text": "More specifically, who an explanation is provided to and when/where that explanation is being provided should be answered first, as this information can then generally be used to answer why the explanation is needed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 825
    },
    {
        "text": "Similarly, who an explanation is provided to and why the explanation is needed typically determines the answer to what needs to be in the explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 826
    },
    {
        "text": "Finally, how the information in the explanation is presented to a user can generally be answered by who the explanation is provided to and when/where the explanation is being provided.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 827
    },
    {
        "text": "As shown in Figure 8, each target question (who, why, when, where, what, and how) is associated with general factors that should be considered for each question (e.g., cognition and experience for who) along with some specific examples for each factor (e.g., AI expert).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 828
    },
    {
        "text": "These are further discussed in the paragraphs below, following the suggested ordering for answering the questions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 829
    },
    {
        "text": "The answer to the target question who plays a major role in answering several other target questions and should be answered first.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 830
    },
    {
        "text": "I assert that users can generally be defined by two aspects: 1) user cognition and experience (e.g., knowledge, capabilities, influence of prior experiences, etc.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 831
    },
    {
        "text": "and 2) the user’s relationship to the system at the time the explanation is being provided.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 832
    },
    {
        "text": "In Figure 8, these sub-categorizations are generalized into the role of designer (engineer, developer), end user, and other interested party (owner, data subject, stakeholder).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 833
    },
    {
        "text": "Defining users using these two dimensions overcomes the problem of trying to create mutually exclusive user categories to define needs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 834
    },
    {
        "text": "A user may have several different relationships with the system over time, and thus their explanation needs may change with varying roles.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 835
    },
    {
        "text": "The when and where target questions are closely tied with the who target question, and also play a role in answering several other target questions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 836
    },
    {
        "text": "Perhaps the broadest classification of when/where an explanation is being used is related to the stage of the system, which often defines a user’s relationship to the system (e.g., during development the user relationship to the system is often that of designer).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 837
    },
    {
        "text": "Explanations required during system development, implementation, and deployment will likely differ in design due to the different environmental settings associated with each stage.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 838
    },
    {
        "text": "More specifically, when/where can be answered by considering the environment in which the explanation will be used and how the explanation needs to be designed in order to support use within that environment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 839
    },
    {
        "text": "Specifically, environment will dictate the constraints on the user (e.g., available time and cognitive capacity), the available technical resources, and the user’s perception of the system, which are all factors that may influence explanation design.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 840
    },
    {
        "text": "38 The why target question can often be answered by the answers to the who and when/where target question, as the user, their relationship to the system, and the environment in which they will be operating often affects why an explanation is sought.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 841
    },
    {
        "text": "Learning refers to any activity where the user seeks to extract knowledge from the system, which may include identifying previously unknown data patterns, generating/testing new hypotheses, and improving decision-making accuracy or speed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 842
    },
    {
        "text": "Finally, compliance relates to any activities aimed at ensuring the system adheres to an established legal, moral, or other societal standard.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 843
    },
    {
        "text": "It should be noted that these are not mutually exclusive categories (e.g., explanations for verification are also often used to guide improvement activities).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 844
    },
    {
        "text": "When users request explanations in the context of decision-making, they are generally requesting explanations for verification (e.g.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 845
    },
    {
        "text": "support for a specific decision suggested by the system) and/or explanations for learning (e.g., knowledge to support a decision-making process).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 846
    },
    {
        "text": "The what target question refers to the content that needs to be included in an explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 847
    },
    {
        "text": "This can generally be determined by the answers to the who and why target questions, but 39 additional context and inquiry with the target users may be required.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 848
    },
    {
        "text": "Depending on who is receiving the explanation and why they require it, the explanation design may need to be targeted at explaining either the internal processes of a system (i.e., how it specifically relates inputs to outputs) or its general behavior (i.e.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 849
    },
    {
        "text": "input/output relationships only) and the explanation may need to be provided at the global (i.e., explains the entire model or system) or instance (i.e., explains a single prediction) level.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 850
    },
    {
        "text": "It should be noted that these categories are not mutually exclusive and can be combined in various ways (e.g., it is possible to provide an “input”/”output”/”certainty”/”why not” explanation).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 851
    },
    {
        "text": "Depending on user cognition and needs, the explanation may also need to be supported by additional information such as source data (e.g.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 852
    },
    {
        "text": "raw data the model was built from), supplemental data (e.g., data not included in the 40 modeling process but relevant to the situation or context), and training materials (e.g., information on model development or explanation interpretation).40 The how target question refers to the way in which the content of an explanation is presented to a user, which can generally be determined by the answers to the who and when/where target questions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 853
    },
    {
        "text": "The specific choices in each of these four main categories will be determined by the user for whom an explanation is being provided (i.e., the who) and the environment in which it is being provided (i.e., the when/where).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 854
    },
    {
        "text": "Specifically, the context of use portion of the framework can provide 41 valuable information for design and evaluation at all three levels.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 855
    },
    {
        "text": "The context of use can be elicited using a variety of approaches involving target users, including but not limited to, interviews, workshops, surveys, site visits, focus groups, and/or contextual inquiry.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 856
    },
    {
        "text": "Literature insights on target users and/or their environment can also help elucidate certain aspects of a context of use, but it is best to include some level of target user input when defining an entire context of use to inform design.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 857
    },
    {
        "text": "This could assist developers in marketing their approach to the right audience (e.g., model developers, lay users) or to inform design requirements for the approach if the developers intended to target specific end-users or environments.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 858
    },
    {
        "text": "For example, if developing an explanation approach that is intended to be used by lay persons who have limited knowledge of modeling processes, developers might want to ensure their approach focuses on explaining system behavior over system processes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 859
    },
    {
        "text": "The framework can also be helpful in considering which metrics to use when evaluating an approach.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 860
    },
    {
        "text": "For example, if the approach is intended to provide real-time explanations in a dynamic environment (e.g., explanations for a CDSS), evaluating the computational efficiency of the approach would be vital.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 861
    },
    {
        "text": "Specifically, using the framework to define a context of use helps elucidate the 42 explanation design requirements that need to be met.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 862
    },
    {
        "text": "With a defined context of use, design requirements can be defined and existing explanation approaches can be assessed to determine whether they meet or can be adapted to meet the specified requirements.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 863
    },
    {
        "text": "The context of use and defined design requirements can help in selecting evaluation metrics to use in these studies.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 864
    },
    {
        "text": "For example, if an explanation is intended to be used in a fast-paced environment, then an evaluation study might compare proposed explanation designs by the ease and speed with which target users can process an explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 865
    },
    {
        "text": "These evaluations usually involve domain-specific subjective and objective measures of the system impact on user task performance and perceptions of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 866
    },
    {
        "text": "By using the context of use of a system to define target user needs, the framework can assist in designing evaluation studies.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 867
    },
    {
        "text": "For example, consider a system that is intended to be used for decision-making in a high stakes environment (e.g., medical decision making).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 868
    },
    {
        "text": "Users may require that the accuracy and effectiveness of such a system be thoroughly validated before they would accept or use the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 869
    },
    {
        "text": "This would suggest that a series of human-grounded evaluations with target users evaluating the accuracy and effectiveness of the system would be useful evidence to support an application-grounded evaluation of the impact of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 870
    },
    {
        "text": "In chapters 4 and 5, I demonstrate an application of the framework at the middle level of Mohseni et 43 al.’s44 model by 1) defining a context of use for the model based on literature insights and past experiences, 2) suggesting preliminary explanation designs, and 3) refining the context of use and explanation designs utilizing human-grounded evaluation approaches.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 871
    },
    {
        "text": "In chapter 6, I demonstrate an application of the framework at the highest level of Mohseni et al.’s44 model by evaluating the predictive model with the refined explanation design to determine if the system satisfies target user needs.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 872
    },
    {
        "text": "I focused the work on in-hospital 45 mortality risk for pediatric ICU patients, as there was a pre-existing dataset that could be used for model development.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 873
    },
    {
        "text": "In section 4.2, I apply the framework by utilizing insights from the literature and my prior experiences in developing predictive models to define a context of use for the model and identify promising explanation design requirements.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 874
    },
    {
        "text": "4.1 Development and Evaluation of the Mortality Risk Prediction Model Data mining and ML approaches were utilized to develop a customized mortality risk prediction model for pediatric ICU patients at a single institution.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 875
    },
    {
        "text": "As the main purpose of this work was to explore the utility of user-centered explanations for the model, a small, readily available dataset was utilized and no attempt was made to learn a best performing model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 876
    },
    {
        "text": "Section 4.1.1 describes the dataset and model development process while section 4.1.2 provides the results and final selected model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 877
    },
    {
        "text": "4.1.1 Materials and Methods 4.1.1.1 Dataset Description This work utilized a pre-existing dataset including all discharged patients with a pediatric ICU admission at the Children’s Hospital of Pittsburgh (CHP) between January 1, 2015 and 46 December 31, 2016.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 878
    },
    {
        "text": "Each hospitalization was treated as a separate encounter.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 879
    },
    {
        "text": "The Institutional Review Board (IRB) of the University of Pittsburgh approved the use of the data for this dissertation work (PRO17030743).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 880
    },
    {
        "text": "For each encounter, the dataset included demographic information (age, sex, race), hospitalization data (time of admission and discharge), outcome data (discharge disposition and deceased date), assigned diagnoses, recorded locations, mechanical ventilation information, physical assessment measurements (vital signs, pupil reaction results, and Glasgow Coma Scale98 (GCS) measurement), and laboratory test results.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 881
    },
    {
        "text": "Encounters with a length of stay of less than 24 hours or unknown age, sex, or admitting diagnosis were excluded from the analysis.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 882
    },
    {
        "text": "Only encounters with at least one recorded physical assessment measurement or laboratory test result were included in the dataset.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 883
    },
    {
        "text": "The target outcome to predict was in-hospital mortality, which was defined as an encounter with a recorded deceased date that occurred on or prior to the recorded discharge date.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 884
    },
    {
        "text": "The aim was to predict in-hospital mortality 24 hours prior to the event, and all data collected prior to the time of the prediction was utilized.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 885
    },
    {
        "text": "For death cases, this included all data collected up to 24 hours prior to death and for control cases, this included all data collected prior to discharge.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 886
    },
    {
        "text": "4.1.1.2 Data Cleaning The data cleaning processing was divided by categorical and numerical data types.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 887
    },
    {
        "text": "Categorical data included sex, race, diagnoses, recorded locations, mechanical ventilation information, and pupil reaction results.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 888
    },
    {
        "text": "Each categorical variable was mapped to a defined set of standard values.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 889
    },
    {
        "text": "For sex, values were standardized to either “male” or “female”.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 890
    },
    {
        "text": "For race, values were standardized to the six race/ethnicity categories defined by the Office of Management and Budget—“American Indian or Alaska Native”, “Asian”, “Black or African American”, “Native 47 Hawaiian or other Pacific Islander”, “White”, “Hispanic or Latino”)99—with the addition of categories for “unknown” and “multiple” races.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 891
    },
    {
        "text": "Diagnoses were recorded in International Classification of Diseases (ICD) Versions 9 and 10, and ICD-9 codes were mapped to ICD-10 whenever possible using the General Equivalency Mapping files available on the Center for Medicare and Medicaid Services website.100 Locations were standardized to one of seven generic unit types: “Direct Admit”, “Emergency Department”, “pediatric ICU”, “Other ICU”, “Inpatient”, “Outpatient”, or “Operating Room”.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 892
    },
    {
        "text": "Left and right pupil reaction results were paired by timestamp and standardized to one of six possible values summarizing the results: “normal”, “one sluggish”, “both sluggish”, “one nonreactive” “one sluggish, one nonreactive”, “both nonreactive”.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 893
    },
    {
        "text": "Pupil reaction results that could not be paired (e.g., did not have both a left and right pupil reading with the same timestamp) were removed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 894
    },
    {
        "text": "After standardizing the possible values for each categorical variable, all duplicate results were removed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 895
    },
    {
        "text": "Numerical data included age, length of stay, vital signs, GCS measurements, and laboratory test results.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 896
    },
    {
        "text": "Laboratory test and vital sign values measured by more than one technique (e.g., invasive/non-invasive blood pressures) were grouped together and names were standardized (e.g., “heart rate” and “pulse” were both standardized to “heart rate”).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 897
    },
    {
        "text": "Numeric results containing text (e.g., a comment or result interpretation) or invalid characters (e.g., “<”, “>”) were extracted and then any remaining non-numeric values were removed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 898
    },
    {
        "text": "Results of ‘0’ were also removed as these typically indicate a bad or invalid value in the EHR system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 899
    },
    {
        "text": "Finally, duplicate results were removed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 900
    },
    {
        "text": "4.1.1.3 Feature Generation Features were defined separately for non-temporal and temporal data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 901
    },
    {
        "text": "Non-temporal data included age, sex, race, length of stay, mechanical ventilation information, recorded locations, and 48 diagnoses.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 902
    },
    {
        "text": "Mechanical ventilation information was used to define a Boolean feature indicating presence or absence of a recorded ventilator event.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 903
    },
    {
        "text": "Recorded locations were used to identify the pediatric ICU admitting unit (defined as the unit location immediately prior to the first recorded visit to the pediatric ICU).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 904
    },
    {
        "text": "From the diagnoses, three features were extracted: 1) flag indicating presence of a cancer diagnosis (based on a pre-defined set of ICD-9 and ICD-10 codes); 2) flag indicating presence of cardiopulmonary resuscitation (CPR) (based on a pre-defined set of ICD-9 and ICD-10 codes for cardiac arrest); and 3) admitting diagnosis ICD-10 code category (e.g., for ICD-10 code C40.10, “malignant neoplasm of short bones of upper limb”, code category would be C40, “malignant neoplasms of bone and articular cartilage of limbs”).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 905
    },
    {
        "text": "User-centric framework based on Grice’s conversation maxims from Ribera and Lapedriza.42 ............................................................................................................................. 26 Figure 6.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 906
    },
    {
        "text": "For the admitting diagnosis ICD-10 code category, pediatric ICU admitting unit, and race features, categories with <30 observations were mapped to an “Other” category to ensure each possible category would be represented in the training dataset.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 907
    },
    {
        "text": "Temporal data in the dataset included physical assessment measurements and laboratory test results collected at irregular time intervals.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 908
    },
    {
        "text": "A fixed set of features was defined to summarize the time-series information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 909
    },
    {
        "text": "Pupil reaction was the only categorical measurement, and was summarized using five features: 1) first value, 2) most recent value, 3) second most recent value, 4) count of results where one pupil was non-reactive, and 5) count of results where both pupils were nonreactive.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 910
    },
    {
        "text": "Each non-categorical temporal measurement was summarized using 17 features comprised of five point estimates (first, minimum, maximum, second most recent, and most recent values) and three trends (difference, percent change, and slope) between the most recent value and all other point estimates (12 features total).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 911
    },
    {
        "text": "The final feature set included 422 features and is described in Table 4.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 912
    },
    {
        "text": "Missing values were present within the feature set as not all encounters had measurements required to compute each feature.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 913
    },
    {
        "text": "For numerical data, the data were first discretized using the minimum description length criterion discretization method,101 which accounts for class information (e.g., in-hospital mortality status) when defining discretization bins.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 914
    },
    {
        "text": "All features were one-hot encoded prior to learning models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 915
    },
    {
        "text": "Feature names and definitions Non-temporal features Feature Name Definition Age Patient age in days Sex Patient sex Race Patient race Length of stay Elapsed time between arrival date and time of prediction Pediatric ICU admitting unit Unit location immediately prior to first recorded visit to pediatric ICU Admitting diagnosis category ICD-10 category of admitting diagnosis code CPR flag Presence/absence of pre-defined cardiac arrest diagnosis code Cancer flag Presence/absence of pre-defined cancer diagnosis code Mechanical ventilation flag Presence/absence of recorded ventilator event Temporal features Feature Name Definition First value Result with earliest timestamp in defined time-window (missing if <3 results) Second most recent value Result with second most recent timestamp in defined time-window (missing if <2 results) Most recent value Result with most recent timestamp in defined time-window Min value Minimum result recorded in defined time-window Max value Maximum result recorded in defined time-window Change from previous Most recent value – second most recent value Change from min Most recent value –min value Change from max Most recent value – max value Change from first Most recent value – first value % change from previous (Most recent value – second most recent value)/(second most recent value)*100 % change from min (Most recent value – min value)/(min value)*100 % change from max (Most recent value – max value)/(max value)*100 % change from first (Most recent value – first value)/(first value)*100 Rate of change from previous Slope between most recent value and second most recent value Rate of change from min Slope between most recent value and min value Rate of change from max Slope between most recent value and max value Rate of change from first Slope between most recent value and first value # results w/ both pupils nonreactive Count of pupil reaction results where both pupils were nonreactive # results w/ one pupil nonreactive Count of pupil reaction results where one pupil was nonreactive 50 4.1.1.4 Model Learning and Evaluation To learn and evaluate models, the dataset was split into a training dataset (encounters from 2015) and a test dataset (encounters from 2016).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 916
    },
    {
        "text": "This split was used to simulate model performance when deployed into practice, where the model would be trained on prior years of data and be used to make predictions on future years of data that might include substantial differences from data of prior years.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 917
    },
    {
        "text": "Two popular strategies for feature selection were examined: 1) correlation-based feature subset (CFS) selection102, which aims to find a set of features that have high-correlation with in-hospital mortality but low inter-correlation with each other—that is, a set of non-redundant, highly informative features—and 2) information gain (IG) filter with a threshold of 0, which results in selecting features that contain at least some predictive information for in-hospital mortality.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 918
    },
    {
        "text": "CFS feature selection was carried out using the WEKA (Waikato Environment for Knowledge Acquisition) version 3.9.3 implementation103,104 via the Python package python-weka-wrapper3 version 0.1.7.105 IG feature selection was carried out using the Python package scikit-learn version 0.20.2.106 Several different models were trained, including a Logistic Regression model, which is the standard model utilized in the clinical domain, as well as three frequently utilized ML models—Random Forest, Naïve Bayes, and SVM.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 919
    },
    {
        "text": "Brief overviews of these algorithms can be found in Meyfroidt et al.107 All models were learned using algorithm implementations provided in the Python package scikit-learn version 0.20.2.106 Default algorithm settings were adopted for all algorithms, with the exception of the Random Forest model, which was learned using 100 trees instead of the default of 10 trees to improve the performance of the classifier.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 920
    },
    {
        "text": "Model discrimination was assessed by calculating the area under the receiver operating characteristic curve (AUROC) and 95% confidence intervals (CIs).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 921
    },
    {
        "text": "Due to the large class imbalance in the dataset (only 2% of encounters were death cases), predictive performance was also assessed by calculating the area under the precision-recall curve (AUPRC).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 922
    },
    {
        "text": "The AUPRC is an informative predictive measure that complements the AUROC for imbalanced datasets, i.e., datasets where the outcome of interest occurs rarely.108 All analyses were performed using R version 3.5.0.109 AUROCs and 95% CIs were calculated using the pROC package 1.15.3110 and AUPRCs were calculated using the PRROC package version 1.3.1.111 4.1.2 Results The final dataset included 4,910 encounters (93 in-hospital deaths; 4,817 controls; 1.9% in-hospital mortality rate).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 923
    },
    {
        "text": "The training and test datasets comprised 2,480 (42 in-hospital deaths; 2,438 controls; 1.7% in-hospital mortality rate) and 2,430 encounters (51 in-hospital deaths; 2,379 controls; 2.0% in-hospital mortality rate), respectively.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 924
    },
    {
        "text": "The Random Forest model using the IG feature selection approach was the highest performing model when examining both AUROC and AUPRC, and thus was selected as the model for which explanations would be designed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 925
    },
    {
        "text": "Model descriptions and performances Feature Selection (# features) Model AUROC [95% CI] AUPRC IG (146) Logistic regression 0.92 [0.86-0.97] 0.77 Naïve Bayes 0.92 [0.87-0.96] 0.19 Random Forest 0.94 [0.90-0.99] 0.78 SVM 0.93 [0.87-0.98] 0.78 CFS (8) Logistic regression 0.94 [0.89-0.98] 0.76 Naïve Bayes 0.94 [0.90-0.97] 0.74 Random Forest 0.93 [0.88-0.98] 0.75 SVM 0.94 [0.89-0.98] 0.73 4.2 Defining Context of Use and Identifying Explanation Design Requirements In this section, I applied the proposed framework to define an initial context of use and identify promising explanation design requirements for the pediatric ICU in-hospital mortality risk model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 926
    },
    {
        "text": "I focused specifically on using the predictive model as a tool to support clinical decision-making in the critical care setting by serving as a proxy measure for deteriorating clinical acuity.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 927
    },
    {
        "text": "The end goal of such a system would be to impact critical care provider decision-making and improve clinical outcomes; however, when designing explanations, the more immediate goal would be to promote system adoption.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 928
    },
    {
        "text": "For the purpose of this discussion, I defined utility as the perceived 53 benefit or usefulness of the model (i.e., whether providers can extract meaningful or actionable information from the model), credibility as the “believability” or “persuasiveness” of the model (i.e., whether the model predictions and reasoning processes seem unbiased and aligned with domain knowledge), and “usability” as the feasibility of using the model as part of clinical practice (i.e., ease with which the model can be understood and integrated with existing workflows).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 929
    },
    {
        "text": "In sections 4.2.1 and 4.2.2, I discuss the target questions in the framework, building upon answers to prior questions when appropriate.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 930
    },
    {
        "text": "For each target question, I address the current understanding of the question based on the available literature and highlight gaps in knowledge that need to be addressed in studies with the target users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 931
    },
    {
        "text": "Figure 9 provides a summary of the insights for each target question and serves as a guide for the discussions sections 4.2.1 and 4.2.2.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 932
    },
    {
        "text": "All insights were derived from the literature and prior experiences in developing predictive models for healthcare.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 933
    },
    {
        "text": "I recognize that prior experiences and the literature will not provide a complete picture of the context of use, and thus highlight gaps in knowledge that need to be addressed in approaches involving the identified target users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 934
    },
    {
        "text": "Who Current understanding: The target users for the model are critical care providers.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 935
    },
    {
        "text": "Any member of a critical care team (e.g., nurses, residents, fellows, attending physicians, etc.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 936
    },
    {
        "text": "would be interested in deteriorating clinical acuity of a patient, and thus might find the predictive model of use.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 937
    },
    {
        "text": "For decision-making in the clinical setting, the relationship of all providers to the model at the time of explanation would be that of an end-user of the system (as opposed to a designer if the scenario of interest was in soliciting expert feedback for model improvement).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 938
    },
    {
        "text": "In terms of user cognition, critical care providers will fall under Ribera and Lapedriza’s “domain expert” category42 and they will typically lack the knowledge to understand and critically evaluate ML models for use in practice.1,5 Moreover, there is evidence in the literature that providers have difficulties in interpreting risk and probability-based estimates,12,96,112,113 which suggests that providers might also struggle to understand and evaluate prediction models that employ traditional statistical approaches (e.g., logistic regression models).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 939
    },
    {
        "text": "In addition to user cognition, past experiences of a user could influence their explanation needs and design requirements.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 940
    },
    {
        "text": "For example, negative experiences with past predictive models or 55 health information technology may lead users to require that an explanation include specific information or be designed in a specific manner to prevent recurrence of past experiences.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 941
    },
    {
        "text": "Examples of negative experiences with health information technology and predictive models in the literature include: 1) inappropriate or disruptive alerts,93,97,112,114,115 2) high effort to use the system,35,37,45,112 3) information that lacks clinical utility (e.g., incorrect, irrelevant, not actionable),36,45,46,112 and 4) lack of control.36,112 Gaps in knowledge: The level of statistical and ML knowledge of critical care providers is unknown, although the literature suggests that most providers will have a limited understanding of the topics.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 942
    },
    {
        "text": "It has been shown that critical care providers employ different information seeking strategies based on their clinical training and role in the patient care process,116 which suggests that users with different clinical positions and knowledge may require different explanations for the same predictive model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 943
    },
    {
        "text": "These possible differences require further exploration in reference to the target users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 944
    },
    {
        "text": "Although the literature highlights some possible negative experiences that critical care providers may have previously had with health information technology and predictive models, the influence of past experiences will vary by user and setting and again requires further exploration regarding target users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 945
    },
    {
        "text": "When and where Current understanding: For use in clinical decision-making where critical care providers are end-users of the predictive model, explanations will be provided at the deployment/implementation stage of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 946
    },
    {
        "text": "For the predictive model, this would constitute use of the explanation in the pediatric ICU, which is a complex, dynamic environment where information is abundant and decisions are time-sensitive.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 947
    },
    {
        "text": "To be useful in clinical decision-making 56 in this environment, a predictive model must be able to keep up with the influx of data to provide real-time predictions (and explanations)3,12,34 and be regularly updated to reflect changes in patient populations and care processes.89,117 Additionally, evidence suggests that a successful tool should support existing clinical workflows,35,37,45,112 such as respecting a provider’s available time and current cognitive load.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 948
    },
    {
        "text": "More specifically, the tool (and by extension its explanations) should avoid contributing to information overload118,119 or requiring large time investments to use (e.g., manual data entry).35,45,96,115 Gaps in knowledge: As workflow fit is an important factor of successful adoption, further exploration of the pediatric ICU workflow and environment is required.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 949
    },
    {
        "text": "Why Current understanding: To use the predictive model in decision-making, a healthcare provider must be able to integrate the model information with their knowledge, experience, and missing contextual information and then translate the information into a meaningful decision.3,45,93,97 This process usually occurs at the patient-level (i.e.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 950
    },
    {
        "text": "for an individual prediction), and involves the closely related goals of verification and learning.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 951
    },
    {
        "text": "In verification, providers assess a prediction to determine if it is clinically relevant (i.e., aligns with domain knowledge) before using it to inform clinical decisions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 952
    },
    {
        "text": "Verification is especially important in the context of ML, as models that perform well on average are often based on statistical associations and imperfect data,3,12 may be missing important information about a patient (e.g.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 953
    },
    {
        "text": "contextual information),45,113 and may therefore have significant individual level errors.1,120 Providers must be able to understand model limitations and identify errors to determine whether a risk prediction applies to a specific patient and defend any decisions based on the prediction.1,3,6,12,97,121 When learning from 57 a predictive model system, providers extract knowledge from the system to assist in decision-making, which may include informing or confirming clinical judgments95 and deriving actionable insights (e.g., identifying potentially modifiable risk factors).7,96,112 Verification and learning often occur simultaneously, such as when providers investigate discrepancies in the match between their knowledge and the model’s knowledge (i.e., a prediction seems too high or low).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 954
    },
    {
        "text": "They may start by looking for a source of model error (verification) but end up discovering a risk factor that was overlooked (learning).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 955
    },
    {
        "text": "Gaps in knowledge: Verification of and learning from individual predictions are assumed to be the main explanation goals for critical care providers using the model in decision-making, but it is worth verifying this assumption with the target users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 956
    },
    {
        "text": "Additionally, discussions with target users can help elucidate the information they require to verify model predictions as well as determining what information they would be interested in learning from the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 957
    },
    {
        "text": "I recognize that this approach will not clearly identify all explanation design requirements, and thus highlight gaps in knowledge that need to be addressed in approaches involving target users.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 958
    },
    {
        "text": "Moreover, as it is expected that the target users will use individual predictions to assist in decision-making, it also seems appropriate to provide explanations at the instance-level (i.e.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 959
    },
    {
        "text": "patient-level explanations).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 960
    },
    {
        "text": "Utilizing a model-agnostic approach to explanation would provide further benefit, as the environment of use requires that the explanations place limited burdens on cognitive load and processing time and that the predictive model be continually updated over time.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 961
    },
    {
        "text": "Moreover, a model-agnostic explanation approach allows the predictive model to adapt over time with minimal changes to an explanation design familiar to providers.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 962
    },
    {
        "text": "It is also unclear from the literature what supporting information critical care providers might need to 59 understand these explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 963
    },
    {
        "text": "Inquires with target users are required to validate the appropriateness of these explanations and understand what supporting information facilitates target user understanding of the explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 964
    },
    {
        "text": "Moreover, it is unclear from the literature whether “why not” type explanations will be sufficient for the target users; other types of explanations may be required (e.g., “what if” explanations that allow providers to simulate how a change in a feature affects a patient’s prediction).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 965
    },
    {
        "text": "When considering the unit of explanation, utilizing larger cognitive chunks can reduce the cognitive load and processing time required.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 966
    },
    {
        "text": "For instance-level explanations of feature influence, a larger cognitive chunk could be obtained by grouping features by laboratory test or vital sign instead of showing the individual features derived for each test or vital sign.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 967
    },
    {
        "text": "There is some evidence supporting the use of feature groupings and high-level feature abstractions for non AI/ML experts.63 Organizing explanation units into meaningful groups can also potentially reduce the cognitive load and processing time.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 968
    },
    {
        "text": "For explanations based on feature influence, the standard organization of explanation units would simply be a list of the features in decreasing magnitude of 60 influence on the prediction (i.e.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 969
    },
    {
        "text": "a ranked list).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 970
    },
    {
        "text": "However, there is some evidence that users prefer meaningful groupings of explanation units over ranked lists.122 Social science literature indicates that humans prefer explanations that include causes that are abnormal or controllable (i.e., modifiable),27 suggesting that grouping explanation units by these factors might prove more informative.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 971
    },
    {
        "text": "For instance-level explanations of feature influence, grouping by abnormality could be achieved by grouping features by whether they increase or decrease the predicted risk.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 972
    },
    {
        "text": "Grouping by controllability or modifiability could be simulated by grouping features by whether they are static (i.e., cannot be changed through intervention such as age) or dynamic (i.e., could be changed through intervention such as a laboratory test result).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 973
    },
    {
        "text": "Reducing the dimensionality of an explanation can also lead to decreased demands on processing time and cognitive load, but must be balanced with a user’s ability to understand a prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 974
    },
    {
        "text": "Dimensionality refers to the level of detail of the explanation, which can be reduced through information removal (e.g., reducing explanation size) or aggregation (e.g., reducing explanation granularity).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 975
    },
    {
        "text": "There is some evidence in the literature that the desired dimensionality of an explanation will vary by individual and prediction, i.e., some users prefer more detailed explanations and users often want more detailed explanations for high risk predictions,68,122 which suggests that controlling dimensionality via interactive options may be beneficial.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 976
    },
    {
        "text": "Finally, the vocabulary, data structures, and visualizations used to express information can impact how effectively critical care providers can process an explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 977
    },
    {
        "text": "The vocabulary of the explanation should include standard clinical terms familiar to the critical care providers and should represent risk in a format with which critical care providers are comfortable.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 978
    },
    {
        "text": "The literature suggests that visual or graphical representations of risk information can facilitate healthcare provider comprehension of risk, but this has not been validated in user studies.96 For instance-level explanations of feature influence, it should be clear to critical care providers how each feature contributes to the predicted risk.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 979
    },
    {
        "text": "For feature influence explanations, feature contributions to the predicted risk have been previously represented in terms of odds or probability (e.g., a feature increases risk 2-fold or by 10%) and visualized using tornado plots and custom visualizations called force plots (see Figure 12 in section 4.3 for an example).75,123 Gaps in knowledge: Overall, the context of use and literature provide some possible design options that might prove beneficial when presenting instance-level explanations of feature influence for predictions from the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 980
    },
    {
        "text": "However, discussions and feedback from the target users are required to further understand how critical care provider cognitive load and processing time might be affected by 1) what units of explanation are used (e.g., feature groupings or individual features), 2) how the units of explanation are organized (e.g., no grouping, grouping by increasing/decreasing risk, grouping by dynamic/static), 3) what interactive options are provided for controlling explanation dimensionality, and 4) what vocabulary, data structures, and visualizations are used to present the predicted risk, the explanation, and any supporting information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 981
    },
    {
        "text": "Therefore, as discussed in section 4.2.2, the explanation design should contain (what): 1) content that supports a provider’s current information goals (e.g., verification and learning), which would likely increase the perceived utility and credibility of the model; and 2) appropriate supporting information to help a provider interpret the explanation, which would likely increase the perceived usability of the predictive model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 982
    },
    {
        "text": "Moreover, the explanation design should present information (how) in a manner that reduces the cognitive load and processing time required by a provider, which would likely increase the perceived usability of the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 983
    },
    {
        "text": "The SHAP algorithm is based on concepts from game theory and is theoretically guaranteed to be faithful to the underlying predictive model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 984
    },
    {
        "text": "It unifies several alternative instance-level explanation algorithms into a single approach, including the LIME algorithm.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 985
    },
    {
        "text": "A detailed description of both algorithms is available in Appendix A.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 986
    },
    {
        "text": "To generate model-agnostic, instance-level explanations of feature influence for the pediatric ICU in-hospital mortality risk model, the SHAP algorithm was used after a series of experiments comparing the two algorithms revealed that the LIME algorithm did not guarantee local fidelity and required more computation time.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 987
    },
    {
        "text": "The experiments are described in Appendix A.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 988
    },
    {
        "text": "Based on insights from section 4.2, I mocked-up five explanation designs for the SHAP explanations to solicit critical care provider feedback on the following explanation design options: 1.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 989
    },
    {
        "text": "Unit of explanation—individual features (low granularity) vs. feature groupings by lab test/vital sign (high granularity) 2.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 990
    },
    {
        "text": "Organization of explanation units—no groupings, grouping by influence on risk (i.e.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 991
    },
    {
        "text": "whether the unit increases/decreases risk), grouping by assessment (e.g., laboratory test features, physical assessment test features, demographic/healthcare utilization features) which was used as an approximation of the controllability of features 3.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 992
    },
    {
        "text": "Dimensionality—static vs. modifiable explanation (i.e., interactive options to control explanation size and granularity of explanation unit) 64 4.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 993
    },
    {
        "text": "Risk representation—probability vs. odds 5.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 994
    },
    {
        "text": "Explanation display format—tornado plot vs. force plot Each mock-up included the predicted risk of mortality from the pediatric ICU in-hospital mortality risk model, an explanation for the predicted risk from the SHAP algorithm, and supporting information to assist in interpreting the risk and explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 995
    },
    {
        "text": "By default, mock-ups with feature groups for the unit of explanation included groupings by influence within the explanation plot (i.e., each feature group had factors that increased or decreased the risk).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 996
    },
    {
        "text": "Mock-ups with feature groups and tornado plots also included an interactive hover-box option to view the individual level features within each group (i.e., modifiable granularity of explanation unit).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 997
    },
    {
        "text": "For mock-ups with modifiable explanation size, an interactive option to scroll down the explanation plot to view additional features was included.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 998
    },
    {
        "text": "Explanation design options used for each mock-up Set 1 Set 2 1-1 1-2 1-3 2-1 2-2 Unit of explanation Individual features X X Feature groups X X X Organization of explanation units None X Influence groups X X X X Assessment groups X Dimensionality Size Static X Modifiable X X X X Granularity of explanation unit Static X X X Modifiable X X Risk representation Probability X X X X Odds X Explanation display format Force plot X Tornado plot X X X X 65 Supporting information for each mock-up included demographic information (e.g., age, length of stay), a list of current diagnoses, a table of the raw values of the features used in the model (i.e., undiscretized feature values), and an interactive plot where the raw values of time series data from laboratory tests and vital signs could be viewed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 999
    },
    {
        "text": "SHAP explanations were generated using the Python package shap version 0.27.0126 and mock-ups were generated as interactive HTML pages using the Python package bokeh version 1.0.4.127 Figure 10.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1000
    },
    {
        "text": "I conducted focus groups with healthcare providers to obtain feedback on the proposed designs, which was used to inform the design of a user-centered explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1001
    },
    {
        "text": "Each mock-up included included demographic information (bottom left), a list of current diagnoses (bottom right), a table of the raw values of the features used in the model (middle) and an interactive plot where the raw values of time series data from laboratory tests and vital signs could be viewed (top).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1002
    },
    {
        "text": "More specifically, I aimed to: 1.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1003
    },
    {
        "text": "Assess critical care provider attitudes about using the predictive model in practice 2.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1004
    },
    {
        "text": "Assess critical care provider perceptions of the model-agnostic, instance-level approach for explaining predictions from the model 3.)",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1005
    },
    {
        "text": "Section 5.1 describes the materials and methods of the study, section 5.2 summarizes the main results, and section 5.3 presents the final user-centered explanation design.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1006
    },
    {
        "text": "70 5.1 Materials and Methods 5.1.1 Setting and Participants All focus groups were conducted at CHP during March 2019-June 2019.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1007
    },
    {
        "text": "A convenience sample of pediatric critical care providers of differing clinical expertise (e.g., nurses, residents, fellows, attending physicians) was recruited through professional connections of one of the dissertation committee members to participate in focus group sessions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1008
    },
    {
        "text": "Participants were assigned to sessions based on availability.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1009
    },
    {
        "text": "The study was approved by the University of Pittsburgh IRB.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1010
    },
    {
        "text": "5.1.2 Procedures and Data Collection I conducted a total of three focus group sessions, each ~1.5 hr in length and comprising 5-8 participants.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1011
    },
    {
        "text": "Each participant attended only a single focus group session, during which they were asked to participate in four activities: 1) Background questionnaire (~5 mins): Participants were asked to complete a background questionnaire assessing their clinical experience, familiarity with predictive modeling, and perceptions of predictive analytics.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1012
    },
    {
        "text": "2) Model discussion (~30 mins): Participants listened to a presentation on the development of the pediatric ICU in-hospital mortality risk model and then participated in a guided group discussion about their initial perceptions of the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1013
    },
    {
        "text": "Mock-ups were reviewed by set.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1014
    },
    {
        "text": "Participants were provided with print-outs of each mock-up and encouraged to write comments and design suggestions on the sheets.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1015
    },
    {
        "text": "4) Ranking questionnaire (~5 min): Participants were asked to complete a questionnaire to indicate their preferred variation of each design option presented in the mock-ups and to rank the options in order of perceived importance in understanding the model prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1016
    },
    {
        "text": "A focus group script and question guides were developed and followed for each session.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1017
    },
    {
        "text": "Copies of the background questionnaire, question guides for the discussion activities, and the ranking questionnaire can be found in Appendix B.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1018
    },
    {
        "text": "Focus group sessions were moderated by 1-2 researchers and a separate researcher took notes during each session.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1019
    },
    {
        "text": "All sessions were audio-recorded and all materials (questionnaires, print-outs of mock-ups) were collected from participants at the end of each session.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1020
    },
    {
        "text": "5.1.3 Data Analysis Background questionnaire and ranking questionnaire responses were summarized using descriptive statistics and visualizations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1021
    },
    {
        "text": "Audio recordings of the sessions were transcribed verbatim and written participant comments on mock-up print-outs were compiled by session.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1022
    },
    {
        "text": "Transcripts and written participant comments were analyzed using descriptive coding.128 One analyst developed an initial codebook with the concepts and definitions from the proposed framework along with codes to capture participant perceptions of the utility, credibility, and 72 usability of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1023
    },
    {
        "text": "The analyst then applied the codes to the transcripts and written participant comments, refining definitions and adding codes to more finely represent the participants’ responses.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1024
    },
    {
        "text": "A second analyst used the codebook to independently code one session transcript.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1025
    },
    {
        "text": "The two analysts discussed coding differences to resolve disagreements and achieve consensus on a final codebook (Appendix C).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1026
    },
    {
        "text": "The first analyst then recoded all transcripts and written participant comments.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1027
    },
    {
        "text": "QSR International’s NVivo 12 software129 was used to assign and organize codes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1028
    },
    {
        "text": "Session notes recorded by the researchers were not coded, but were used to assist in coding and interpretation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1029
    },
    {
        "text": "This analysis was intended to identify insights related to each of the target questions in the proposed framework to address the gaps in knowledge identified in section 4.2.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1030
    },
    {
        "text": "5.2 Results A total of 21 critical care providers participated in the three focus group sessions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1031
    },
    {
        "text": "Table 7 summarizes the clinical experience of the participants in each session.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1032
    },
    {
        "text": "Summary of participants in each focus group Session # of Participants Clinical Experience Attending Fellow/resident Nurse 1 5 3 2 0 2 8 6 2 0 3 8 0 0 8 73 5.2.1 Insights on Context of Use Table 8 provides a high-level summary of the ideas discussed in this section, specifically major insights related to the context of use and elements that would influence perceptions of the model credibility, utility, and usability.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1033
    },
    {
        "text": "Table 9 and Figure 16 summarize the participants’ background knowledge and attitudes towards predictive modeling, respectively.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1034
    },
    {
        "text": "Insights identified for each of the target questions related to context of use (who, when/where, why) are summarized with supporting quotes in Table 10.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1035
    },
    {
        "text": "Although the insights are separated out by target question in Table 10, I summarize the findings about the context of use as a whole.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1036
    },
    {
        "text": "High-level summary of insights on context of use and influences on perceptions of the model User characteristic (who) Desired information Factors that would positively (+) or negatively (-) influence perceptions Explanation goal (why) Verification Predictive modeling knowledge Detailed  Predictive performance  Alignment with domain knowledge  Comparison with existing models  Modeling processes Credibility + high predictive performance + predictions that aligned with clinical knowledge - influential outliers or data errors - counterintuitive risk factors - model limitations Basic  Predictive performance  Alignment with domain knowledge Learning Clinical role Physician Obtain insights about patients  Prioritization  Assessment of status  Highlight patients/info of concern Utility - insufficient training for users - clinically irrelevant information Usability + clinically appropriate alerts - high cognitive effort or attention - large time investments Nurse Actionable information  Alerts to important changes  Information to intervene or justify request for consult Participants exhibited wide variation in predictive modeling knowledge (Table 9; Table 10, User Cognition), which affected the types of information providers wanted in order to assess the credibility of the predictive model (Table 10, Verification).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1037
    },
    {
        "text": "All providers compared the model information against domain knowledge; however, providers with more detailed knowledge of predictive modeling also wanted information about the development process (e.g., cohort 74 definition, data collection and cleaning procedures) and how the model compared to similar, existing models.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1038
    },
    {
        "text": "Perceptions of model credibility were positively influenced by the high predictive performance and model predictions that aligned with domain knowledge (i.e., the participant could clinically rationalize why the model made the prediction).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1039
    },
    {
        "text": "Perceptions of model credibility were negatively influenced by limitations in the modelling process (e.g., not accounting for feature correlations) and model information that did not align with clinical knowledge (e.g., errors in data values, predictions based on outliers or with counterintuitive risk factors).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1040
    },
    {
        "text": "5 Basic awareness—I have heard of the term, but don’t know much about it.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1041
    },
    {
        "text": "6 Know a little—I am familiar with the main concepts of machine learning.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1042
    },
    {
        "text": "4 Know a fair amount—I have a practical understanding of machine learning concepts.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1043
    },
    {
        "text": "3 Know it well—I have a theoretical understanding of machine learning concepts.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1044
    },
    {
        "text": "Participant attitudes towards predictive analytics 75 Participants generally had positive attitudes towards using predictive analytics in clinical practice (Figure 16), and saw several possible applications for information from the pediatric ICU in-hospital mortality risk model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1045
    },
    {
        "text": "The information participants sought from the model depended on their clinical role (Table 10, User cognition) and factors related to their work environment (Table 10, Social and organizational influences).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1046
    },
    {
        "text": "Physicians anticipated using the model to facilitate patient prioritization during rounds and sought to gain insights about the condition of patients (Table 10, Learning).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1047
    },
    {
        "text": "They viewed the model as a useful tool to help them synthesize patient information and alert them to high-risk patients and/or concerning information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1048
    },
    {
        "text": "Participant attitudes towards predictive analytics ................................................ 74 Figure 17.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1049
    },
    {
        "text": "Nurses anticipated using the tool to assist in communicating changes in patient conditions to physicians and generally sought actionable information from the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1050
    },
    {
        "text": "They wanted to be alerted to clinically important changes in patient condition and be given information to either intervene or justify a request for a physician consult.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1051
    },
    {
        "text": "However, prior experiences with alerting systems raised concerns from the nurses about appropriate timing and relevance of alerts (Table 10, User cognition).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1052
    },
    {
        "text": "Regardless of clinical role, information seen as clinically irrelevant (e.g., a high risk prediction driven by a low Coma score for a sedated and paralyzed patient) contributed to negative perceptions of model utility.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1053
    },
    {
        "text": "Information that would be difficult to process within the constraints of the ICU environment (Table 10, Cognitive and time resources) also contributed to negative perceptions of usability.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1054
    },
    {
        "text": "Participants did not generally seek explanations to help them improve the model, but negative perceptions of the model prompted participants to suggest improvements (Table 10, Improvement).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1055
    },
    {
        "text": "These included incorporating additional relevant predictors (e.g., medications), predicting additional outcomes (e.g., morbidity), defining normal ranges for variables (either by age or by setting patient-specific baselines), setting patient-specific alert thresholds, and incorporating domain knowledge into the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1056
    },
    {
        "text": "Insights on context of use target questions Topic Insights Who User Cognition Large variation in knowledge of predictive modeling “Are we enabling the computer take over?” “Seems like there’s a lot of collinearity there.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1057
    },
    {
        "text": "And if those are two of the main contributors, I’m wondering whether it’s overestimating” Negative experiences with prior systems due to insufficient training, irrelevant information, and inappropriate disruptions in workflow “They trigger a sepsis screen every time I do vitals or every 2 hours and you call the doctors and they have to come down and see them and they’re getting really irritated.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1058
    },
    {
        "text": "Particpant preferences for design options by clinical role .................................... 78 Figure 18.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1059
    },
    {
        "text": "They don’t want to have to do that, they don’t have time.” “Most people didn’t know how to use the Rothman index.” Clinical role affects how providers anticipate using model information “From the attending perspective, when you walk in in the morning who do you need to see first?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1060
    },
    {
        "text": "Who maybe is higher risk than people are appreciating?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1061
    },
    {
        "text": "Or is changed based on data that’s emerged in the last few hours?” When/where Cognitive and time resources Providers have limited available time to process information “I don’t know if—working on the floor—I get an alert that I have time to go and look through all of this data to try and figure out where the risk is coming from.” Providers have limited available cognitive capacity and attention to process information “If you load it with a lot of numbers that will probably be not helpful…Because it dilutes your attention.” “Trying to think about what that actually means…one, you could be wrong, or if it’s 3:00 in the morning…some of the mental gymnastics you’d have to do.” Social and organizational influences Workflow and social factors determine how providers anticipate using model information “Typically, I round on new patients and then I round on any ECMO patients…and then with some filler between, I break up and it’s somewhat random where I start” “I think it might help with the doctors…If there’s another number—something saying ‘here, look at this, this is actually showing that there’s something going on.’….Because I get push back all the time.” Why Verification Providers desired comparisons to existing models and information on model development processes to help validate model “And is it better than PRISM or is it the same?” “We’re assuming that you didn’t just select for the sickest patients in this cohort.” “Does this weed out their error of charting, things like this?” Providers validated model information by comparing to domain knowledge “I mean arterial pressure of 250 seems physiologically impossible.” “The leading variables are patient is having respiratory issues and has kidney injury…from a face validity standpoint—yes, that sounds like a patient with a higher risk of dying.” Improvement Providers were interested in improving the performance and utility of the model “It’d be nice to look at morbidity as well and other things.” “One of the critical things that you might consider finding a way to incorporate into the score is medications.” “I do think, from a model validity standpoint, changing this to include maybe abnormal blood pressure for age, does add a lot.” Learning Providers wanted to use the model to gain insights about patient conditions “Does this model offer new information that I didn’t already have?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1062
    },
    {
        "text": "Explanation design was not observed to influence perceptions of credibility or utility.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1063
    },
    {
        "text": "Insights identified for each of the target questions related to explanation design (what, how) are summarized with examples quotes in Table 12.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1064
    },
    {
        "text": "Findings about the explanation design are summarized below, referring to insights on the context of use where appropriate.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1065
    },
    {
        "text": "This makes them “why not” type explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1066
    },
    {
        "text": "78 “output” type explanations, respectively.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1067
    },
    {
        "text": "Participant questions about the model indicated that they were seeking these types of explanations, with some providers also seeking “what if” type explanations, i.e., how the output might change if an input is changed (Table 12, Type, target, and level of explanation).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1068
    },
    {
        "text": "Participants sought all types of explanations when verifying model information (Table 10, Verification), but typically sought “why not” type explanations when seeking information for use in clinical practice (Table 10, Learning).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1069
    },
    {
        "text": "The instance-level explanations of model behavior provided by the SHAP algorithm were generally perceived as helpful in assessing model credibility and utility; however, some providers also requested global-level explanations and explanations of model processes (Table 12, Type, target, and level of explanation).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1070
    },
    {
        "text": "Although useful in assessing credibility and utility, type of explanation was not observed to have a specific influence on participant perceptions of the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1071
    },
    {
        "text": "Particpant preferences for design options by clinical role 79 Figure 18.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1072
    },
    {
        "text": "Participants frequently utilized the table of the raw values of the features used in the model (i.e., undiscretized feature values), the interactive plot to view the raw values of time series data from laboratory tests and vital signs, and contextual information (e.g., diagnoses) to assist in their interpretation (Table 12, Supporting information).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1073
    },
    {
        "text": "Participants found that the raw values of features used in the model helped them when interpreting the discretized features used in the explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1074
    },
    {
        "text": "For example, if the most predictive feature in the explanation was “Cr change from min >0.35” (i.e.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1075
    },
    {
        "text": "the most recent value of creatinine has increased more than 0.35 since the minimum value), participants found that to assess the clinical importance of the feature it was helpful to also know the exact amount creatinine had increased, as well as what the current and minimum values of creatinine were.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1076
    },
    {
        "text": "Plots 80 of the raw values of time series data from laboratory tests and vital signs were often utilized to verify model information, specifically to investigate suspicious values (e.g., outliers or errors), assess trend-based features, and determine patient baselines (e.g., if the patient normally has an elevated creatinine level).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1077
    },
    {
        "text": "Contextual information not included in the model (e.g., diagnoses, interventions) was considered essential to assess the clinical validity and relevance of the prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1078
    },
    {
        "text": "For example, when examining a high-risk prediction that included a low coma score as a top predictor, participants noted that they would give less weight to that prediction if the patient was sedated and paralyzed, which would explain the low coma score.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1079
    },
    {
        "text": "Participants also wanted information about the baseline risk of mortality, the trend of mortality risk over time, and proper interpretation/use of the explanations (Table 12, Supporting information).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1080
    },
    {
        "text": "The baseline risk of mortality was considered helpful in properly interpreting the predicted risk of mortality (e.g., a predicted risk of 50% is much more concerning when the baseline risk is 2%).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1081
    },
    {
        "text": "Trends of mortality risk over time were also requested (mainly by nurses) to improve model utility, as it was noted that a change in risk was of more clinical interest than a single predicted risk (e.g., a patient that has had a high predicted risk for several days is of less concern than a patient with a lower predicted risk that has been recently increasing).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1082
    },
    {
        "text": "Finally, although not specifically requested to be included in the explanation, several participants pointed out that training on interpretation of the prediction explanation would be vital to prevent improper use of the system (i.e., predictors are not suggestive of interventions to reduce mortality risk).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1083
    },
    {
        "text": "Although useful in assessing credibility and utility, supporting information elements were not observed to have a specific influence on participant perceptions of the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1084
    },
    {
        "text": "Interactive control over unit of explanation supported different information needs “With the hover capability, if people wanted more, they could have that…I have a basic that everybody can get the basic data, but if you want to dig deeper it’s there.” Information representation Providers preferred risk to be presented as probabilities expressed as percentages “I actually took out a calculator and based on the odds, I calculated the patient’s percent probability of death.” “For me, percent risk of mortality is going to be easier to interpret than the odds.” Providers preferred less statistical terminology for describing trend-based features “It would be nice if I could just say, ‘pulse ox is decreasing, creatinine is increasing’” Visual cues play an important role in interpretation and design preferences “It’s because of the scale of the bars.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1085
    },
    {
        "text": "The tighter bars just don’t grab my attention.” “I think with mock-up 1-3, my first initial thought is to look—you read left to right.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1086
    },
    {
        "text": "So I would think the SpO monitor results would be the highest contributor.” Provider had mixed preferences on explanation display format “I think 1-3 actually gives you the most visually, because you can see every element that’s playing into that...I would suspect that there are other people who are going to look at 1-1 or 1-2 and it’s going to be very obvious to them what they’re looking at.” “In my head, I’m thinking what about a pie chart?” 82 Participants exhibited strong preferences for the unit of explanation and risk representation design options, but had mixed preferences for other design options (Figure 17).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1087
    },
    {
        "text": "More specifically, all participants felt very strongly that risk be displayed in probabilities expressed as percentages (Figure 17; Figure 18; Table 12, Information representation).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1088
    },
    {
        "text": "Expressing risk in terms of odds or as proportions seemed to increase the cognitive effort required to process the risk, thus negatively influencing the perceived usability of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1089
    },
    {
        "text": "Overview of evaluation study design and tasks ..................................................... 89 Figure 21.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1090
    },
    {
        "text": "All participants also expressed strong preferences for using feature groups (e.g., larger cognitive chunks) as the unit of explanation (Figure 17; Figure 18; Table 12, Information representation).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1091
    },
    {
        "text": "Although the interactive option to view the individual features within each feature group was generally well-received (Table 12, Dimensionality), showing individual features in the initial explanation display appeared to require more cognitive effort to process and thus negatively influenced the perceived usability of the system.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1092
    },
    {
        "text": "Some participants wanted even higher-level units of explanation than the feature groups, such as groups of related labs (e.g., electrolytes) or summary explanations akin to a human explanation (e.g., “This patient is at high risk for mortality because they are comatose, newly hypotensive, have been progressively hypoxic and have newly developed lactic acidosis”).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1093
    },
    {
        "text": "The mixed preferences observed for the organization of explanation units (Figure 17; Table 12, Unit of explanation and organization) and explanation display format (Figure 17; Table 12, Information representation), and dimensionality design options (Figure 17) can be attributed to the different information needs and work environments of different clinical roles (Table 10, User cognition; Table 10, When/where).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1094
    },
    {
        "text": "Nurses tended to prefer explanations that were static (i.e., had minimal information to process) and had explanation units organized by assessment (i.e., 83 organized by controllability) (Figure 17).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1095
    },
    {
        "text": "They found the tornado plots easier to understand than the force plots, and preferred simpler explanations (i.e., “The less you have to do the better”).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1096
    },
    {
        "text": "These preferences all align with nurses’ goal to extract actionable information (Table 10, Learning) within the cognitive and time constraints of their work environment (Table 10, Cognitive and time resources).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1097
    },
    {
        "text": "On the other hand, physicians tended to prefer explanations that were modifiable (i.e., could provide more information upon request), which aligns with their desire to gain insights about a patient condition (i.e., using the model as an investigative tool).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1098
    },
    {
        "text": "Physicians demonstrated no clear trend for explanation display format or explanation unit organization (Figure 17), which could simply be attributed to differences in how individual physicians prefer to process information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1099
    },
    {
        "text": "Explanations that fit the preferences of each clinical role contributed to positive perceptions of usability.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1100
    },
    {
        "text": "“No model” display that contains information available for every patient case 91 Figure 22.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1101
    },
    {
        "text": "In addition to the design elements already noted to influence perceptions of usability, participants suggested some improvements to the design to increase the perceived usability.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1102
    },
    {
        "text": "Specifically, participants utilized the plots of raw time-series data so frequently in interpreting explanation features that they requested multiple plots to view and compare data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1103
    },
    {
        "text": "They also requested that the points used to create features (e.g., min, max, most recent) be highlighted on the plots.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1104
    },
    {
        "text": "Due to the importance of the baseline risk of mortality in interpreting the predicted risk, participants suggested that the it be more prominently displayed (e.g., above the predicted risk of mortality).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1105
    },
    {
        "text": "To facilitate efficient data exploration, participants wanted data to be linked across interface elements (Table 12, Dimensionality) so that a selection of a data element (e.g., a laboratory test) in the explanation plot or raw feature table would auto-populate the time-series data plots with the selected data element.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1106
    },
    {
        "text": "Finally, participants noted that comments on the vocabulary and visualization used suggested some possible influences on usability (Table 12, 84 Information representation).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1107
    },
    {
        "text": "Specifically, participants noted a desire for simpler terminology for trend-based features (e.g., “Cr has increased since min value” rather than “Cr change from min >0.35”) and visualizations that obeyed standard information processing procedures.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1108
    },
    {
        "text": "For example, the force plot was considered confusing because the increasing predictors were on the right and the largest increasing predictor was to the far right, violating standard ‘left to right’ reading procedures.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1109
    },
    {
        "text": "Additionally, the scroll option on the explanation plot did not have a standard icon and some participants did not know that they could scroll to view additional predictors.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1110
    },
    {
        "text": "“Predictions only” display with additional tab containing mortality risk information .............................................................................................................................. 92 Figure 23.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1111
    },
    {
        "text": "As nurses found more utility in risk trends than individual risk predictions with explanations, the proposed explanation design is intended to be used by physicians in assessing patient condition and priority.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1112
    },
    {
        "text": "I leave exploration for the optimal presentation of model information to nurses for future work.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1113
    },
    {
        "text": "Based on the insights from 5.2, I chose the following design options to maximize physician perceptions of the credibility, utility, and usability of the system: 1) Unit of explanation—feature groups for the initial display, where contributions of individual features for each time-series variable are aggregated by influence (e.g., whether they increase/decrease risk).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1114
    },
    {
        "text": "Feature groups have an interactive hover-box option to view individual features comprising each group.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1115
    },
    {
        "text": "In the interactive hover-box, trend-based features were summarized by whether they were an increasing or decreasing trend.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1116
    },
    {
        "text": "85 2) Organization of explanation units—default view of a single plot with explanation organized by decreasing magnitude of influence and increasing/decreasing risks grouped together by feature group.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1117
    },
    {
        "text": "Interactive options were included to show groups of explanation units in the single plot by influence on risk or assessment type.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1118
    },
    {
        "text": "3) Risk representation—risks represented as probabilities expressed as percentages.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1119
    },
    {
        "text": "The baseline risk was moved to a more prominent display location.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1120
    },
    {
        "text": "4) Explanation display format—tornado plot.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1121
    },
    {
        "text": "Participant accuracy in selecting relevant information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1122
    },
    {
        "text": "While the mixed preferences of physicians for tornado and force plots would suggest that an interactive option to control explanation display format would also be beneficial, I opted not to include this option as some participants had found the force plot confusing to interpret.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1123
    },
    {
        "text": "5) Dimensionality—in addition to the interactive options to control the unit of explanation and the organization of explanation units mentioned above, the scroll option on the explanation plots was included to allow control over the number of explanation units viewed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1124
    },
    {
        "text": "Per the insights in section 5.2, the explanation design included the table of raw feature values as well as two plots to display raw values of time-series data that highlighted the points used to generate features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1125
    },
    {
        "text": "As most relevant contextual information (e.g., diagnoses, interventions) requested by participants would be readily available in the EHR in which a system like this would be embedded, it was not included in the explanation design to reduce the amount of information presented on a single screen.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1126
    },
    {
        "text": "For the evaluation study, relevant contextual information was provided in banner bar and a separate information tab (see Chapter 6).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1127
    },
    {
        "text": "The final explanation design is shown in Figure 19.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1128
    },
    {
        "text": "The predicted risk and baseline risk are displayed at the top of the figure.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1129
    },
    {
        "text": "The explanation plot (top left) uses feature groups as the explanation unit, but has hover-box capability to view individual features within each feature group.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1130
    },
    {
        "text": "....................................... 99 Figure 24.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1131
    },
    {
        "text": "The plot includes interactive controls to view additional predictors and view sets of feature groups (e.g., view laboratory test feature groups).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1132
    },
    {
        "text": "The raw feature table (bottom left) includes the description, value, and contribution to the risk for each individual feature.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1133
    },
    {
        "text": "This table also includes the trend direction for trend-based features.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1134
    },
    {
        "text": "The plots to display raw values for time-series features (right) highlight the points used to compute features and include interactive controls to zoom in on regions of data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1135
    },
    {
        "text": "These plots also have a hover funtionality that can be used to show the value and time of specific point.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1136
    },
    {
        "text": "To facilitate data exploration, interactivity is linked across plots and tables (e.g., selecting a predictor on the explanation plot will highlight it in the raw feature table and load the appropriate laboratory test/vital sign in the time-series plot).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1137
    },
    {
        "text": "Specifically, I examined the use of the model in assisting healthcare providers as they reviewed patient information in preparation for patient rounds.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1138
    },
    {
        "text": "In this scenario, it was hypothesized that the prediction model with explanations could assist a healthcare provider in assessing patient condition and preparing to discuss a patient case with the rounding team.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1139
    },
    {
        "text": "88 6.1 Materials and Methods This section describes the patient cases and participants, study design and tasks, data collection procedures, and data analyses for the laboratory study.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1140
    },
    {
        "text": "The University of Pittsburgh IRB determined that this study was not considered human subjects research (STUDY19050287).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1141
    },
    {
        "text": "6.1.1 Participants and Patient Cases A senior pediatric ICU attending selected six patient cases from the test dataset described in section 4.1.1 to be utilized in the laboratory study.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1142
    },
    {
        "text": "Three cases included patients who needed to be seen urgently and three cases included patients who did not need to be seen urgently.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1143
    },
    {
        "text": "The patient cases were selected to be clinically different such that independence of patient case could be assumed when performing data analyses.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1144
    },
    {
        "text": "A convenience sample of healthcare providers was recruited through professional connections of one of the dissertation committee members.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1145
    },
    {
        "text": "Specifically, senior residents, fellows, and junior attending physicians (<1-year experience) specializing in critical care medicine were recruited to participate in the study.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1146
    },
    {
        "text": "These groups were targeted because they were experienced in preparing for rounds on pediatric ICU patients.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1147
    },
    {
        "text": "6.1.2 Study Design and Tasks I conducted a mixed-methods, within-subject evaluation study with three experimental conditions: 1) no access to information from the prediction model (“no model”), 2) access to model inputs and predictions from the prediction model (“prediction only”), and 3) access to 89 predictions and user-centered explanations from the prediction model (“explanation”).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1148
    },
    {
        "text": "Participant responses to UTAUT questionnaire for “prediction only” and “explanation” displays.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1149
    },
    {
        "text": "To conduct the evaluation study, I developed a local web-browser application that participants used to complete study tasks.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1150
    },
    {
        "text": "The application is described in Section 6.1.3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1151
    },
    {
        "text": "Figure 20 provides an overview of the study design and tasks.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1152
    },
    {
        "text": "Sessions were conducted with individual participants and lasted approximately 90 minutes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1153
    },
    {
        "text": "All sessions took place from September 2019-November 2019 and were conducted in a conference room near the participant’s place of employment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1154
    },
    {
        "text": "Overview of evaluation study design and tasks Study sessions began with the participant watching a PowerPoint video presentation introducing them to the study objectives, the prediction model, and the study application.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1155
    },
    {
        "text": "The slide deck from the video is provided in Appendix D. After the slideshow, participants were logged into the study application and asked to complete a short background questionnaire about their clinical experience.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1156
    },
    {
        "text": "They were then provided access to a practice patient case that included mortality risk predictions accompanied by the user-centered explanation design and given time to familiarize themselves with the study application and ask any questions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1157
    },
    {
        "text": "Each participant was then asked to review each of the six patient cases, pretending as though they were preparing for patient rounds.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1158
    },
    {
        "text": "For each case, participants were provided with a case vignette, diagnosis information, and access to laboratory test and vital sign results.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1159
    },
    {
        "text": "Participants were also provided with one of three 90 different displays corresponding to the three experimental conditions: 1) “no model”, which provided no additional information on the patient (Figure 21 in section 6.1.3), 2) “prediction only”, which included a mortality risk prediction with model inputs but no explanation (Figure 22 in section 6.1.3), and 3) “explanation”, which provided a mortality risk prediction accompanied by the user-centered explanation design described in section 5.3 (Figure 19 in section 5.3).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1160
    },
    {
        "text": "Participants reviewed each patient case only once, and patient cases were shown in a random order.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1161
    },
    {
        "text": "For each patient case, participants were asked to complete a questionnaire corresponding to the following tasks: 1) select the information they feel would influence changes in the plan of care for the patient (i.e., information they would want to present/discuss with the rounding team); 2) decide if the patient needs to be seen urgently by a member of the care team; 3) rate their confidence in the decision; and 4) provide a brief free-text rationale for the decision.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1162
    },
    {
        "text": "After submitting the case response form participants were asked to verbally present their assessment of the patient as if they were presenting to the rounding team.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1163
    },
    {
        "text": "Participants were also offered the chance to provide unstructured feedback on each display during the subjective assessments.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1164
    },
    {
        "text": "Copies of the background questionnaire, patient case questionnaire, and UTAUT questionnaires are provided in Appendix E. 91 6.1.3 Study Application To conduct the evaluation study, a local web-browser application was developed that would track participant progress on tasks, allow participants to interactively explore patient case information, and automate the data collection process.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1165
    },
    {
        "text": "Each participant was assigned a unique login and password to access the study application.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1166
    },
    {
        "text": "After logging in, participants were brought to a home page (Appendix D, slide 5) where they could track their progress on each of the study tasks.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1167
    },
    {
        "text": "As shown in Figure 21, each patient case contained: 1) a banner bar providing basic demographic information about the patient; 2) a case information tab containing a case vignette, admitting diagnosis information, and access to plots to view laboratory test and vital sign data; and 3) a responses tab where they could complete the patient case questionnaire.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1168
    },
    {
        "text": "This information was all that was provided for the “no model” display option.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1169
    },
    {
        "text": "“No model” display that contains information available for every patient case 92 When participants had access to information from the pediatric ICU in-hospital mortality risk model, they were provided with an additional tab that contained information related to either the “predictions only” display, which is shown in Figure 22, or the “explanation” display, which is shown in Figure 19 in section 5.3.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1170
    },
    {
        "text": "For each participant and patient case, the application recorded time-stamped interactions with interface elements (e.g., tabs, plots, tables).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1171
    },
    {
        "text": "“Predictions only” display with additional tab containing mortality risk information The application was developed in Python 3, utilizing the Python packages Flask version 1.0.2,130 bokeh version 1.1.0,127 shap version 0.28.5,126 WTForms version 2.2.1,131 and SQLAlchemy version 1.3.3.132 Flask is a Python-based web framework that formed the backend of the application and was responsible for processing user input and producing the correct output (i.e., correctly routing user requests, processing input from forms).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1172
    },
    {
        "text": "The Flask extension for the popular Bootstrap front-end framework was used to style the HTML in a consistent manner.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1173
    },
    {
        "text": "The bokeh 93 package was used to generate the interactive data displays used in the interface, i.e., the time-series plots for labs/vitals, the explanation plot, and the predictor tables.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1174
    },
    {
        "text": "The shap package was used to pre-generate patient explanations for each of the patient cases and all patient case data was stored within a local SQLite database.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1175
    },
    {
        "text": "6.1.4 Data Collection Table 13 summarizes the data collected for each study task.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1176
    },
    {
        "text": "Only a few scale items were originally selected for each key construct and not all scale items were relevant to assess in the context of the proposed experiment (e.g., performance expectancy scale item of “If I use the system, I will increase my chances of getting a raise”).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1177
    },
    {
        "text": "Therefore, for each key construct, I selected a set of scale items from each respective root construct that were relevant to assess in the context of the proposed experiment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1178
    },
    {
        "text": " Selected UTAUT Root Construct Scale Items for Effort Expectancy38 (Likert scale agreement): 1.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1179
    },
    {
        "text": " Free-text feedback on the display (optional) 6.1.5 Data Analysis Audio recordings of all verbal case presentations were transcribed verbatim and compiled with urgency decision rationales and moderator notes for each case.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1180
    },
    {
        "text": "Answers to background questionnaires were summarized in a contingency table.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1181
    },
    {
        "text": "Based on the background questionnaire responses, two levels of clinical experience (residents and fellow/attendings) were defined for use in analyses.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1182
    },
    {
        "text": "Analyses for each outcome are summarized in Table 14 and described in the next few sections.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1183
    },
    {
        "text": "P-values of <0.05 were considered 95 significant for all statistical analyses, which were carried out using Stata version 15.133 Plots were generated using the Python packages seaborn version 0.9.0134 and matplotlib version 3.0.3.135 Table 14.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1184
    },
    {
        "text": "Summary of analyses examining the impact of the user-centered explanation display on outcomes Outcome Display Comparison Groups Metrics Analytic approach Decision accuracy “No model” “Prediction only” Urgency decision accuracy Proportion of correct decisions with 95% CI Logistic mixed effect analysis Precision and recall in selecting relevant information Visual review of violin plots Mentions of predictive model in rationales, transcripts, or notes Qualitative review to assist in interpretation of quantitative results Decision confidence “No model” “Prediction only” Urgency decision confidence Visual review of stacked bar charts Ordinal logistic mixed effects analysis Mentions of predictive model in rationales, transcripts, or notes Qualitative review to assist in interpretation of quantitative results Case review efficiency “No model” “Prediction only” Time to review patient case Descriptive statistics Log-linear mixed effects analysis Number of unique items viewed (computed from interactions data) Descriptive statistics Poisson mixed effects analysis Total number of items viewed (computed from interactions data) Descriptive statistics Negative binomial mixed effects analysis Provider perceptions “Prediction only” UTAUT questionnaire responses Visual review of stacked bar charts Free-text feedback on displays and moderator notes Qualitative review for insights about participant perceptions of predictive model Analysis of decision accuracy Decision accuracy included participant accuracy in urgency decisions (i.e., identifying patients who need to be seen urgently) as well as selecting relevant information to discuss with the rounding team.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1185
    },
    {
        "text": "LIME median absolute error (MAE) in fidelity.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1186
    },
    {
        "text": "Display, case urgency (urgent, non-urgent), and participant experience (resident, attending/fellow) were included as fixed effects in the model (no interaction terms), and an intercept for participant was included as a random effect in the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1187
    },
    {
        "text": "To assess accuracy in selecting relevant information, participant 96 precision and recall in selecting ‘relevant’ items were calculated, where information items selected by a senior pediatric ICU attending using the “explanations” display served as the gold standard.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1188
    },
    {
        "text": "Precision and recall scores for each display were visualized using violin plots.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1189
    },
    {
        "text": "Decision urgency rationales, case presentation transcripts, and moderator notes were reviewed for mentions of the predictive model tool and to assist in interpretation of the results.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1190
    },
    {
        "text": "Display, case urgency (urgent, non-urgent), and participant experience (resident, attending/fellow) were included as fixed effects in the model (no interaction terms), and an intercept for participant was included as a random effect in the model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1191
    },
    {
        "text": "Decision urgency rationales, case presentation transcripts, and moderator notes were reviewed for mentions of the predictive model tool and to assist in interpretation of the results.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1192
    },
    {
        "text": "Analysis of case review efficiency Case review efficiency consisted of the time it took participants to review each patient case and the amount of information being viewed, which was measured by the number of items (e.g., lab test, vital sign) viewed during the case.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1193
    },
    {
        "text": "Descriptive statistics were used to summarize the case review time, number of unique items viewed, and the total number of items viewed.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1194
    },
    {
        "text": "................................................ 136 xiv Preface I am deeply grateful for the unwavering support that I have received throughout this journey.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1195
    },
    {
        "text": "For all three models, display, case urgency (urgent, non-urgent), participant experience (resident, attending/fellow), and case order (i.e., the order in which the case was seen by a participant) were included as fixed effects (no interaction terms) and an intercept for participant was included as a random effect.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1196
    },
    {
        "text": "Analysis of provider perceptions Responses to the UTAUT scale items for the “explanation” and “prediction only” displays were visualized and compared using stacked bar charts.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1197
    },
    {
        "text": "Free-text feedback on displays and moderator notes were qualitatively reviewed to assist in the interpretation of the UTAUT questionnaire responses and to identify additional insights about participant perceptions of the pediatric ICU in-hospital mortality risk model and the displays.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1198
    },
    {
        "text": "6.2 Results A total of 15 participants were recruited for this study.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1199
    },
    {
        "text": "Responses to the background questionnaire on clinical experience are summarized in Table 15.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1200
    },
    {
        "text": "As per the study design, each participant reviewed and provided responses for 6 patient cases.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1201
    },
    {
        "text": "Due to a technical error, one participant failed to successfully complete one of their assigned cases.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1202
    },
    {
        "text": "First and foremost, I would like to thank my thesis advisor, Dr. Harry Hochheiser, who provided me with valuable advice and support long before becoming my advisor.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1203
    },
    {
        "text": "Thus, there were a total of 89 participant responses for the patient cases.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1204
    },
    {
        "text": "The breakdown of case responses by display and 98 case urgency is shown in Table 16.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1205
    },
    {
        "text": "In 6.2.1-6.2.3, I describe the results from the analyses on decision accuracy and confidence, case review efficiency, and provider perceptions of the model, respectively.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1206
    },
    {
        "text": "Summary of participant clincial experience Time in current position Position <1 year 1 to <2 years 2 to <3 years Total Attending 1 0 0 1 Fellow 1 5 1 7 Resident 0 2 5 7 15 Table 16.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1207
    },
    {
        "text": "The results of the logistic mixed effects analysis (Table 18) detected no significant effect of display, case urgency, or participant experience on decision accuracy.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1208
    },
    {
        "text": "As seen in Figure 23, neither the precision nor recall scores revealed discernable differences in provider accuracy in selecting relevant patient information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1209
    },
    {
        "text": "Proportion of correct decisions for each display Display Proportion of correct decisions 95% CI No model 0.69 [0.49 – 0.85] Prediction only 0.73 [0.54 – 0.88] Explanation 0.87 [0.69 – 0.96] Figure 23.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1210
    },
    {
        "text": "Participant accuracy in selecting relevant information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1211
    },
    {
        "text": "The plots show the distributions of precision (left) and recall (right) scores for each of the three displays.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1212
    },
    {
        "text": "While Figure 24 suggests that providers might be more confident in their decisions when they had access to a mortality risk prediction (“predictions only” and “explanation” displays), the ordinal logistic mixed effects analysis (Table 18) detected no significant effect of display, case urgency, or participant experience on decision confidence.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1213
    },
    {
        "text": "The lack of display impact on decision accuracy and confidence is further supported by the fact that decision rationales and case presentations contained relatively few mentions of the pediatric ICU in-hospital mortality risk model (six total mentions by four different participants).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1214
    },
    {
        "text": "Error p-value 95% CI Odds Ratio Std.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1215
    },
    {
        "text": "I would also like to give a special thanks to my committee member Dr. Christopher Horvat, without whom this work would not have been possible.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1216
    },
    {
        "text": "The analyses also revealed a significant effect of the order in which the case was seen by a participant on case review time and the total number of items viewed (Table 20 and Table 21).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1217
    },
    {
        "text": "More specifically, when controlling for other factors, participants spent less time per case and viewed less total items per case as they progressed through the set of six patient cases, i.e., participants became more efficient in their case review as they went through the study tasks.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1218
    },
    {
        "text": "Mean and variance of case review efficiency measures for each display Efficiency Measure Mean (variance) Display Case review time in minutes # of unique items viewed Total # of items viewed No model 8.0 (20.5) 22.2 (9.5) 34.5 (324.1) Prediction only 7.7 (17.8) 22.0 (7.9) 33.3 (208.5) Explanation 8.8 (27.4) 21.5 (31.8) 31.3 (99.3) 102 Table 20.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1219
    },
    {
        "text": "Error p-value 95% CI Display No model Reference Prediction only 0.08 0.08 0.36 [-0.09, 0.24] Explanation 0.04 0.08 0.36 [-0.11, 0.19] Urgency Not urgent Reference Urgent 0.20 0.06 0.002 [0.07, 0.33] Experience Attending/fellow Reference Resident -0.01 0.21 0.95 [-0.43, 0.40] Case Order 1 Reference 2 -0.28 0.09 0.002 [-0.46, -0.11] 3 -0.47 0.10 0.000 [-0.66, -0.28] 4 -0.63 0.11 0.000 [-0.86, -0.42] 5 -0.72 0.11 0.000 [-0.95, -0.50] 6 -0.81 0.12 0.000 [-1.05, -0.56] Table 21.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1220
    },
    {
        "text": "Dr. Horvat provided access to the data used in this work, recruited all study participants, and helped advise the research process.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1221
    },
    {
        "text": "Error p-value 95% CI Rate Ratio Std.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1222
    },
    {
        "text": "Error p-value 95% CI Display No model Reference Reference Prediction only 0.99 0.06 0.89 [0.89, 1.11] 1.04 0.09 0.62 [0.88, 1.23] Explanation 0.97 0.05 0.56 [0.87, 1.08] 0.92 0.08 0.34 [0.79, 1.09] Urgency Not urgent Reference Reference Urgent 1.11 0.05 0.02 [1.02, 1.22] 0.99 0.07 0.93 [0.87, 1.14] Experience Attending/fellow Reference Reference Resident 0.93 0.05 0.17 [0.83, 1.03] 0.85 0.08 0.10 [0.71, 1.03] Case Order 1 Reference Reference 2 1.03 0.08 0.66 [0.89, 1.21] 0.79 0.09 0.05 [0.63, 1.00] 3 0.94 0.08 0.46 [0.80, 1.10] 0.68 0.08 0.001 [0.54, 0.86] 4 1.01 0.08 0.92 [0.86, 1.18] 0.72 0.08 0.005 [0.57, 0.91] 5 0.99 0.08 0.92 [0.85, 1.16] 0.68 0.08 0.001 [0.54, 0.86] 6 0.98 0.08 0.84 [0.84, 1.16] 0.64 0.08 0.000 [0.50, 0.81] 103 6.2.3 Perceptions of Prediction Tool Figure 25 summarizes participant responses to the UTAUT questionnaire for the “prediction only” and “explanation” displays.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1223
    },
    {
        "text": "More specifically, a majority of participants thought that a system utilizing the “explanation” display would be useful in their job (93%), make it easier to do their job (73%), and increase their productivity (60%) (Figure 25, statements 1-3).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1224
    },
    {
        "text": "In contrast, less than half of participants reported the same thoughts about the “prediction only” display (33%, 33%, and 46%, respectively).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1225
    },
    {
        "text": "Several participants mentioned that a system without explanations would not be useful to them, specifically because they could not rationalize the prediction and identify why the patient might be at higher or lower risk.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1226
    },
    {
        "text": "One participant specifically commented on their positive ratings for the “prediction only” display: “Both systems are already markedly better than our current electronic medical record (thus I marked all as strongly agree).” —2nd year fellow 104 Figure 25.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1227
    },
    {
        "text": "Participant responses to UTAUT questionnaire for “prediction only” and “explanation” displays.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1228
    },
    {
        "text": "Statements 1-4 assess perceptions of performance expectancy and statements 5-7 assess perceptions of effort expectancy.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1229
    },
    {
        "text": "Limitations of the evaluation v study design, including a small sample size, may have affected the ability to detect an impact on decision-making.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1230
    },
    {
        "text": "Despite the generally positive views of performance expectancy, only 40% of participants reported that a system utilizing either display would enable them to accomplish tasks more quickly (Figure 25, statement 4).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1231
    },
    {
        "text": "Comments from participants revealed that this perception may have been partially influenced by having to adjust to unfamiliar data displays for laboratory test and vital sign data.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1232
    },
    {
        "text": "In particular, a few participants commented that it took them longer to find and review raw data than it would have taken them in the EHR (e.g., having to look up each individual component of a basic metabolic panel), which could have negatively impacted participant perceptions of the system’s ability to help them accomplish tasks more quickly.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1233
    },
    {
        "text": "Moreover, although some participants thought the system would help them more efficiently assess a patient’s condition, many participants seemed not to trust the system as a guide, viewing it instead as a tool to confirm 105 their own assessments.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1234
    },
    {
        "text": "This view might explain why participants felt the system would not aid them in accomplishing tasks more quickly.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1235
    },
    {
        "text": "One participant succinctly summarized this viewpoint: “The explanations certainly help me dive under the black-box nature of the model without explanations, but I don’t think it would dramatically improve my productivity.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1236
    },
    {
        "text": "At this point, I would still want to evaluate each feature using my standard process, then look at the model to see if I missed anything, rather than using the model as a hypothesis generator.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1237
    },
    {
        "text": "Several participants commented that the information in the “prediction only” display was overwhelming and not helpful in understanding the prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1238
    },
    {
        "text": "Also, I want to thank committee members Dr. Shyam Visweswaran, who helped conceive this project and provided valuable insights; Dr. Douglas Landsittel, who helped me work through several statistical challenges; and Dr. Michael Becich, who advised me through some difficult circumstances and worked to find funding to support the completion of this work.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1239
    },
    {
        "text": "First, as already mentioned above, participant comments suggested that it may be beneficial to present laboratory test and vital sign data in the same format it is presented in the EHR (e.g., a fishbone diagram for basic metabolic panel data).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1240
    },
    {
        "text": "Additionally, for the laboratory test and vital sign data views, participants requested: 1) the ability to plot multiple tests on the same plot, 2) ‘quick buttons’ to zoom in on relevant time ranges of data (e.g., last 12, 24, or 48 hours); 3) drop-down boxes that allow selection by groups of related results (e.g., electrolytes); 4) the ability to select points to be highlighted (e.g., non-selected points are “greyed out”); and 5) a table or list of current values next to the plot.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1241
    },
    {
        "text": "In addition to feedback on the laboratory and vital sign test views, a few participants suggested improvements to interface interactions (e.g., using arrow keys to navigate a dropdown list) and several participants requested additional information about the patient to assist in their interpretation of the data (e.g., laboratory tests, ventilator settings, interventions).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1242
    },
    {
        "text": "I gratefully acknowledge the institutions that have provided me with funding support: the National Institutes of Health and National Library of Medicine (under award 5 T15 LM007059-27) and the Department of Biomedical Informatics (DBMI) at the University of Pittsburgh.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1243
    },
    {
        "text": "In the qualitative inquiry study, providers found the mock-ups of the SHAP explanations useful in assessing the credibility and utility of a prediction from the model, (i.e., comparing the influential risk factors to domain knowledge to determine if the prediction seemed reasonable and clinically relevant).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1244
    },
    {
        "text": "It should be noted that concerns about model interpretability as a barrier to adoption generally come after an ML model has been demonstrated to have acceptable performance, generalizability, and/or reproducibility (i.e., once a “good” model has been developed).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1245
    },
    {
        "text": "However, model interpretability can assist model developers in ensuring these criteria are met.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1246
    },
    {
        "text": "These criteria were considered outside the scope of the conducted studies, but are important to note in discussions of the value of interpretability when utilizing predictive models in healthcare.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1247
    },
    {
        "text": "Thank you to all the staff and administrators of DBMI and Children’s Hospital of Pittsburgh who helped make this work possible.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1248
    },
    {
        "text": "However, the study was likely under-powered to detect effects in these outcomes, unless the effect size was very large.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1249
    },
    {
        "text": "For example, let’s consider the comparison of decision accuracy in only the “no model” and “explanation” display groups, where there would ideally be a total of 60 observations (30 in each group).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1250
    },
    {
        "text": "Assuming the true proportion of correct responses in the “no model” display group was 0.68 (from Table 17) and assuming a total 60 observations (30 109 per group), for a chi-square test to detect a statistically significant effect at an alpha of 0.05 and power of 80%, the proportion of correct responses in the “explanation” display group would have had to have been 0.95 or higher.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1251
    },
    {
        "text": "Similarly, treating the other outcomes as continuous and comparing only the “no model” and “explanation” display groups, a paired t-test with a total sample size of 60 (30 in each group), an alpha of 0.05, and a power of 80% would be able to detect an effect size of 0.74.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1252
    },
    {
        "text": "Assuming the lowest standard deviation for each efficiency measure in Table 19 and a standard deviation of 0.5 for decision confidence, this would be a minimal difference of ~3 minutes in case review time, ~2 items in the number of unique items viewed, ~7 items in the number of total items viewed, and 0.37 points in decision confidence.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1253
    },
    {
        "text": "In light of these analyses, it is less surprising that the study did not detect any significant effect of the user-centered explanation display on decision-making outcomes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1254
    },
    {
        "text": "The analyses did detect significant effects of case urgency and the order in which a case was viewed on the decision efficiency metrics.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1255
    },
    {
        "text": "This was not surprising to find, as the urgent cases represented more medically complex patients and would likely require more review time by providers.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1256
    },
    {
        "text": "It was surprising to find that providers spent significantly less time and reviewed significantly fewer total items for cases that were viewed later in the study session.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1257
    },
    {
        "text": "This could have been because providers were still spending time to familiarize themselves with system after the practice patient case.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1258
    },
    {
        "text": "Alternatively, the study sessions may have been too short to allow adequate time for providers to review all of the patient cases, which may have caused them to rush through the material as they neared the end of the session.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1259
    },
    {
        "text": "This suggests that there was a learning curve required to use the system that was not adequately accounted for, which may have obscured the effect the shown display had on 110 measures of decision efficiency.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1260
    },
    {
        "text": "Two possible ways in which the learning curve effect could have been better controlled include: 1) running pilot studies to estimate the time it would take participants to complete each study task and planning sessions of adequate length, and 2) developing a way to assess participants’ comfort level with the system and requiring that they reach a predefined level of comfort during the practice patient case activity.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1261
    },
    {
        "text": "In contrast to the quantitative analyses, the subjective assessments of the performance expectancy of the systems suggested that providers would find the predictive model with explanations beneficial in performing their jobs, indicating that the tool would provide some benefit to decision-making.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1262
    },
    {
        "text": "Two main viewpoints emerged about the benefit of the tool in decision-making.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1263
    },
    {
        "text": "Some providers saw the tool as a confirmatory tool, i.e., a tool to confirm thought processes and check for things that they might have missed during their initial assessment.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1264
    },
    {
        "text": "This viewpoint agrees with findings from Jeffery et al.,136 who found that nurses mainly viewed probability-based CDSSs as a tool to confirm their thoughts about a patient, and Hallen et al.,95 who found that providers perceived clinical prediction models as tools to improve their prognostic confidence.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1265
    },
    {
        "text": "This would suggest that providers view predictive models as confirmatory tools to increase decision confidence, rather than as informatory tools to guide decisions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1266
    },
    {
        "text": "If used as a confirmatory tool, the system would have minimal impact on provider decision-making processes, which would partially explain the lack of observed effect on decision-making accuracy and efficiency and likely explains participants’ generally low expectations that the tool would improve their ability to accomplish tasks quickly.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1267
    },
    {
        "text": "The second viewpoint about the benefit of the tool relates to decision efficiency.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1268
    },
    {
        "text": "In particular, some participants viewed the predictive model with explanations as a useful tool to guide their assessment of patients and to prioritize patients.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1269
    },
    {
        "text": "More specifically, by highlighting 111 patients and information of concern, providers thought the tool could help them be more efficient in prioritizing patients and reviewing patient information.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1270
    },
    {
        "text": "This viewpoint likely explains the few participants who perceived the tool as something that would improve their ability to accomplish tasks quickly.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1271
    },
    {
        "text": "Interestingly, the same number of participants reported that the “prediction only” and “explanation” display would improve their ability to accomplish tasks quickly.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1272
    },
    {
        "text": "This suggests that the perceived improvement in task efficiency may stem from having a mortality risk prediction to help them prioritize patients, regardless of whether the prediction is accompanied by an explanation.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1273
    },
    {
        "text": "This viewpoint contradicts past experiences in which high performing models have gone unused due to lack of interpretability, which suggests that user and environmental characteristics likely influence the types of predictive model systems that may be accepted and used.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1274
    },
    {
        "text": "I appreciate all she does as an administrator, friend, and confidant of the students in DBMI.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1275
    },
    {
        "text": "Several participants mentioned that they would not use the system without the explanations, particularly because they could not investigate predictions that surprised them.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1276
    },
    {
        "text": "112 The discrepancy between the results of the subjective assessments of provider perceptions of the model and the quantitative analyses of the impact on decision-making raise several thoughts about the study and how to measure the potential value of a predictive model in clinical practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1277
    },
    {
        "text": "The provider view that the system would be useful in assessing and prioritizing patients suggests that perhaps the value of the tool is in comparing urgency levels of patients rather than assessing the urgency level of an individual patient, (i.e., making decisions about groups of patients rather than individual patients).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1278
    },
    {
        "text": "Conducting a more thorough investigation of how the tool would be used in practice could have helped identify the appropriate decision-making process and outcomes to assess in the evaluation study.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1279
    },
    {
        "text": "This is supported by the provider view that the system was useful as a confirmatory tool and could increase decision confidence, but would not directly influence a decision.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1280
    },
    {
        "text": "Shah et al.5 suggest that many predictive models are not deployed into practice because they do not provide information that influence decisions.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1281
    },
    {
        "text": "This would suggest that a predictive model tool would need to demonstrate a clear benefit on decision-making performance to be accepted in practice, but the results of the evaluation study showed that providers would still use and accept a tool even if it did not directly inform decision-making.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1282
    },
    {
        "text": "Dekker et al.137 mention that access to accurate risk predictions seems to have an unpredictable effect on provider decisions and thus claim that the true value of a predictive model tool cannot be known without running impact 113 studies to assess the effect on patient outcomes.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1283
    },
    {
        "text": "This raises several interesting questions about how to evaluate predictive model tools for use in clinical practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1284
    },
    {
        "text": "Specifically, what are the appropriate metrics and assessments for demonstrating the value of a predictive model tool?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1285
    },
    {
        "text": "What evidence of the value of a predictive model tool should be required before it is deployed into clinical practice?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1286
    },
    {
        "text": "If a predictive model does not demonstrate improved performance in some measureable way, do subjective assessments of provider satisfaction with the tool provide enough evidence of its value?",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1287
    },
    {
        "text": "These questions warrant further consideration as more predictive model tools make their way into clinical practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1288
    },
    {
        "text": "More generally, this work contributes to knowledge about the effective communication of predictive model risk information to healthcare providers.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1289
    },
    {
        "text": "In both the qualitative inquiry and evaluation studies, it was found that providers liked the ability to visually assess which risk factors were contributing most to an individual’s predicted risk.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1290
    },
    {
        "text": "This finding provides evidence to support claims in the literature that visualizations of risk information for individuals can improve healthcare provider interpretation and acceptance of predictive models.96,113 Additionally, results from the study revealed that providing the appropriate contextual information was vital to provider interpretation of risk.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1291
    },
    {
        "text": "Thanks to Dr. Rich Tsui and all the members of the Tsui lab for providing a supportive and intellectually challenging research environment for the first several years of this journey.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1292
    },
    {
        "text": "In particular, access to raw patient data (e.g., laboratory values, vital signs, interventions) played a significant role in provider ability to assess the clinical credibility and utility of predictions and explanations.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1293
    },
    {
        "text": "This finding is consistent with results from studies by Wang et al.40 and Jeffery et al.,136 both of whom also found that providers utilized raw patient data when working with probability-based decision support systems to verify information from the system and integrate it with their clinical knowledge.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1294
    },
    {
        "text": "In addition to raw patient data, several nurses in the qualitative inquiry study noted the importance of having a baseline risk and risk trends to assess the clinical relevance of a risk prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1295
    },
    {
        "text": "More specifically, a change in risk from a patient- 114 specific or population baseline was deemed more clinically relevant than a single risk prediction.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1296
    },
    {
        "text": "This finding is consistent with results from Jeffrey et al.,136 who also found that nurses wanted to see risk trends when using probability-based CDSS.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1297
    },
    {
        "text": "While most research has focused on developing high-performing risk prediction models, these findings suggest the need for more research on how the manner in which risk information is communicated affects provider interpretation and use of the information in clinical practice.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1298
    },
    {
        "text": "The studies also revealed that interactive explanations of risk were beneficial to supporting different user information needs and preventing information overload by allowing users to ask for additional details when desired.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1299
    },
    {
        "text": "While this type of explanation was not incorporated in the final design, an interactive explanation could support the inclusion of the additional type (e.g., adding interactive features to the SHAP explanation that allow users to change model inputs to see the change in predicted risk).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1300
    },
    {
        "text": "The need for integrating multiple explanation types into a single explanation design has also been mentioned by Wang et al.,40 who found that providers utilized a variety of different explanations to support various reasoning processes when diagnosing patients.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1301
    },
    {
        "text": "It was a privilege to know and work with you all.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1302
    },
    {
        "text": "For example, if a model was hypothetically able to achieve perfect performance on a prediction task, explanations might be considered unnecessary.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1303
    },
    {
        "text": "Alternatively, explanations might be considered unnecessary when it is obvious whether the model correctly predicts the outcome (e.g., image classifications that can be verified by visual inspection).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1304
    },
    {
        "text": "In either of these scenarios, one could argue that explanations might still be needed to instill user trust in the model (i.e., a user may want to ensure that predictions can be justified based on domain knowledge).",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1305
    },
    {
        "text": "However, Elish24 contradict this argument by pointing out that trust in a model can also be built by involving stakeholders throughout the model development process.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1306
    },
    {
        "text": "For example, consider a model that perfectly predicts a patient’s risk of mortality.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1307
    },
    {
        "text": "There are several different ways in which a patient may die and the ability of a provider to intervene will depend on the reason a patient is predicted to die.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1308
    },
    {
        "text": "Thus, instance-level explanations may still prove valuable for the perfectly performing model.",
        "paperTitle": "Design and Evaluation of User-Centered Explanations for Machine Learning Model Predictions in Healthcare",
        "doi": "10.1186/s12911-020-01276-x",
        "chunk_index_in_doc": 1309
    }
]